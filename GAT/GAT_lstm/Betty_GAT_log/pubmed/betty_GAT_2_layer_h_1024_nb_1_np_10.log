main start at this time 1700865553.876238
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
success----------------------------------------
60
500
19157
# Nodes: 19717
# Edges: 88648
# Train: 60
# Val: 500
# Test: 19157
# Classes: 3

in feats:  500
self._in_src_feats,  500
self._in_dst_feats 500
Epoch 1, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.1015, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.12890625 GB
    Memory Allocated: 2.034402847290039  GigaBytes
Max Memory Allocated: 3.034402847290039  GigaBytes

Epoch 2, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.1028, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.380859375 GB
    Memory Allocated: 2.03444766998291  GigaBytes
Max Memory Allocated: 3.520019054412842  GigaBytes

Epoch 3, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.1067, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.380859375 GB
    Memory Allocated: 2.0344438552856445  GigaBytes
Max Memory Allocated: 3.5210866928100586  GigaBytes

Epoch 4, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.1047, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.3828125 GB
    Memory Allocated: 2.034402847290039  GigaBytes
Max Memory Allocated: 3.5210866928100586  GigaBytes

epoch time :  0.5035789012908936
Epoch 5, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.1000, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.3828125 GB
    Memory Allocated: 2.0344290733337402  GigaBytes
Max Memory Allocated: 3.5210866928100586  GigaBytes

epoch time :  0.5233941078186035
Epoch 6, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.0987, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.3828125 GB
    Memory Allocated: 2.034402847290039  GigaBytes
Max Memory Allocated: 3.5210866928100586  GigaBytes

epoch time :  0.4795820713043213
Epoch 7, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.0932, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.3828125 GB
    Memory Allocated: 2.034412384033203  GigaBytes
Max Memory Allocated: 3.5210866928100586  GigaBytes

epoch time :  0.49951744079589844
Epoch 8, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.1037, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.3828125 GB
    Memory Allocated: 2.034421443939209  GigaBytes
Max Memory Allocated: 3.5210866928100586  GigaBytes

epoch time :  0.49814701080322266
Epoch 9, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.1001, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.3828125 GB
    Memory Allocated: 2.034414291381836  GigaBytes
Max Memory Allocated: 3.5210866928100586  GigaBytes

epoch time :  0.5013937950134277
Epoch 10, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.0950, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.3828125 GB
    Memory Allocated: 2.0344700813293457  GigaBytes
Max Memory Allocated: 3.5210866928100586  GigaBytes

epoch time :  0.4973914623260498
Total (block generation + training)time/epoch 0.5004278251102993
pure train time/epoch nan

num_input_list  []
