main start at this time 1700860063.7321544
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
success----------------------------------------
140
500
2068
# Nodes: 2708
# Edges: 10556
# Train: 140
# Val: 500
# Test: 2068
# Classes: 7

in feats:  1433
self._in_src_feats,  1433
self._in_dst_feats 1433
Epoch 1, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.9525, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.408203125 GB
    Memory Allocated: 2.095867156982422  GigaBytes
Max Memory Allocated: 3.095867156982422  GigaBytes

Epoch 2, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.9518, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.66015625 GB
    Memory Allocated: 2.095914840698242  GigaBytes
Max Memory Allocated: 3.8071370124816895  GigaBytes

Epoch 3, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.9519, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.66015625 GB
    Memory Allocated: 2.0959949493408203  GigaBytes
Max Memory Allocated: 3.815103054046631  GigaBytes

Epoch 4, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.9515, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.66015625 GB
    Memory Allocated: 2.0959763526916504  GigaBytes
Max Memory Allocated: 3.8192267417907715  GigaBytes

epoch time :  0.5238978862762451
Epoch 5, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.9507, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.66015625 GB
    Memory Allocated: 2.09592866897583  GigaBytes
Max Memory Allocated: 3.8192267417907715  GigaBytes

epoch time :  0.5237374305725098
Epoch 6, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.9501, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.66015625 GB
    Memory Allocated: 2.0959577560424805  GigaBytes
Max Memory Allocated: 3.8211607933044434  GigaBytes

epoch time :  0.5231964588165283
Epoch 7, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.9512, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.66015625 GB
    Memory Allocated: 2.095925807952881  GigaBytes
Max Memory Allocated: 3.8211607933044434  GigaBytes

epoch time :  0.5253047943115234
Epoch 8, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.9512, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.66015625 GB
    Memory Allocated: 2.095968246459961  GigaBytes
Max Memory Allocated: 3.8211607933044434  GigaBytes

epoch time :  0.5231361389160156
Epoch 9, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.9488, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.66015625 GB
    Memory Allocated: 2.0958776473999023  GigaBytes
Max Memory Allocated: 3.8211607933044434  GigaBytes

epoch time :  0.5228030681610107
Epoch 10, Learning Rate: 0.001
----------------------------------------------------------loss  tensor(1.9508, device='cuda:0', grad_fn=<NllLossBackward>)
-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.66015625 GB
    Memory Allocated: 2.0958614349365234  GigaBytes
Max Memory Allocated: 3.8211607933044434  GigaBytes

epoch time :  0.5229251384735107
Total (block generation + training)time/epoch 0.5235697882516044
pure train time/epoch nan

num_input_list  []
