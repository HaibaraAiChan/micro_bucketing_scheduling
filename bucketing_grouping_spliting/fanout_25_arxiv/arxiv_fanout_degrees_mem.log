main start at this time 1688877223.8626478
-----------------------------------------before load data 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

----------------------------------------start of run function 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

self.global_to_local() spend sec:  0.047130584716796875
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

25
25
[0.14765617268338813, 0.12872081899253363, 0.10201119407088112, 0.08049174739666377, 0.06841798528716421, 0.05352921124685236, 0.04447938773490505, 0.038178599311641616, 0.03272451369569281, 0.028578968781957533, 0.02422449720148228, 0.02129952386712264, 0.01820960842744197, 0.01576846526869069, 0.014174024917254044, 0.012216711934111127, 0.011326024565377553, 0.010424341056289243, 0.009192773336558867, 0.00887388526627154, 0.007884232634345345, 0.006113854037232931, 0.005706996844107718, 0.005772973686236131, 0.10402348775579771]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014826297760009766
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.0001201629638671875
len local_batched_seeds_list  25
partition total batch output list spend :  0.9152061939239502
self.buckets_partition() spend  sec:  0.014986753463745117
layer  0
 the number of batches:  25
check_connections_block*********************************
layer  1
num of batch  25
check_connections_block*********************************
redundancy ratio #input/#seeds/degree
4.5732797140303845
3.1955407483341878
2.835830548668751
2.6975751366120218
2.5698810671809706
2.6380101342098055
2.630372594031432
2.619419642857143
2.640681003584229
2.658907272027703
2.6945074897866546
2.7856220960247806
2.837931995540691
2.9378860330743177
2.9799844840961986
3.0256525652565256
3.065562535693889
3.05983356774496
3.2087635356333415
3.0985749690210658
3.2045560204556023
3.4635382603008504
3.5387450783278878
3.427698412698413
0.5191585623678647
layer  0
{1: 13428, 2: 1514, 3: 1424, 4: 1036, 5: 890, 6: 712, 7: 552, 8: 442, 9: 392, 10: 3685}
layer  1
{1: 13428}

layer  0
{1: 1525, 2: 12162, 3: 2064, 4: 1606, 5: 1420, 6: 1110, 7: 954, 8: 766, 9: 639, 10: 5875}
layer  1
{2: 11706}

layer  0
{1: 1582, 2: 2280, 3: 9755, 4: 1987, 5: 1726, 6: 1356, 7: 1163, 8: 966, 9: 828, 10: 7423}
layer  1
{3: 9277}

layer  0
{1: 1251, 2: 1864, 3: 2112, 4: 7759, 5: 1867, 6: 1529, 7: 1277, 8: 1115, 9: 912, 10: 8511}
layer  1
{4: 7320}

layer  0
{1: 1076, 2: 1735, 3: 2034, 4: 2003, 5: 6670, 6: 1576, 7: 1397, 8: 1196, 9: 1033, 10: 9513}
layer  1
{5: 6222}

layer  0
{1: 904, 2: 1401, 3: 1546, 4: 1745, 5: 1668, 6: 5231, 7: 1341, 8: 1178, 9: 993, 10: 9999}
layer  1
{6: 4868}

layer  0
{1: 724, 2: 1210, 3: 1421, 4: 1525, 5: 1541, 6: 1424, 7: 4368, 8: 1150, 9: 1022, 10: 10305}
layer  1
{7: 4045}

layer  0
{1: 615, 2: 990, 3: 1214, 4: 1372, 5: 1431, 6: 1273, 7: 1220, 8: 3789, 9: 1041, 10: 10789}
layer  1
{8: 3472}

layer  0
{1: 519, 2: 890, 3: 1092, 4: 1243, 5: 1253, 6: 1154, 7: 1128, 8: 1065, 9: 3251, 10: 10836}
layer  1
{9: 2976}

layer  0
{1: 457, 2: 779, 3: 940, 4: 1085, 5: 1115, 6: 1112, 7: 1051, 8: 1002, 9: 910, 10: 13099}
layer  1
{10: 2599}

layer  0
{1: 373, 2: 610, 3: 837, 4: 910, 5: 994, 6: 944, 7: 952, 8: 949, 9: 857, 10: 12460}
layer  1
{11: 2203}

layer  0
{1: 345, 2: 621, 3: 789, 4: 892, 5: 968, 6: 980, 7: 898, 8: 920, 9: 813, 10: 12180}
layer  1
{12: 1937}

layer  0
{1: 357, 2: 566, 3: 685, 4: 775, 5: 803, 6: 793, 7: 797, 8: 819, 9: 733, 10: 11507}
layer  1
{13: 1656}

layer  0
{1: 279, 2: 460, 3: 602, 4: 672, 5: 713, 6: 780, 7: 730, 8: 740, 9: 657, 10: 11030}
layer  1
{14: 1434}

layer  0
{1: 280, 2: 457, 3: 563, 4: 621, 5: 651, 6: 667, 7: 663, 8: 707, 9: 659, 10: 10813}
layer  1
{15: 1289}

layer  0
{1: 195, 2: 356, 3: 454, 4: 544, 5: 576, 6: 610, 7: 579, 8: 589, 9: 572, 10: 10217}
layer  1
{16: 1111}

layer  0
{1: 205, 2: 377, 3: 470, 4: 546, 5: 572, 6: 590, 7: 564, 8: 547, 9: 612, 10: 10194}
layer  1
{17: 1030}

layer  0
{1: 204, 2: 315, 3: 373, 4: 487, 5: 485, 6: 570, 7: 536, 8: 542, 9: 542, 10: 9940}
layer  1
{18: 948}

layer  0
{1: 199, 2: 299, 3: 387, 4: 450, 5: 489, 6: 514, 7: 507, 8: 514, 9: 532, 10: 9413}
layer  1
{19: 836}

layer  0
{1: 143, 2: 272, 3: 351, 4: 424, 5: 444, 6: 496, 7: 474, 8: 532, 9: 494, 10: 9707}
layer  1
{20: 807}

layer  0
{1: 203, 2: 288, 3: 371, 4: 397, 5: 448, 6: 453, 7: 433, 8: 441, 9: 491, 10: 9029}
layer  1
{21: 717}

layer  0
{1: 105, 2: 206, 3: 255, 4: 308, 5: 307, 6: 349, 7: 377, 8: 386, 9: 342, 10: 7803}
layer  1
{22: 556}

layer  0
{1: 125, 2: 220, 3: 284, 4: 287, 5: 318, 6: 324, 7: 350, 8: 357, 9: 353, 10: 7787}
layer  1
{23: 519}

layer  0
{1: 115, 2: 197, 3: 259, 4: 313, 5: 337, 6: 338, 7: 332, 8: 333, 9: 373, 10: 7982}
layer  1
{24: 525}

layer  0
{1: 1520, 2: 2559, 3: 3183, 4: 3484, 5: 3744, 6: 3737, 7: 3707, 8: 3588, 9: 3442, 10: 51826}
layer  1
{25: 9460}

data_dict
[[{1: 13428, 2: 1514, 3: 1424, 4: 1036, 5: 890, 6: 712, 7: 552, 8: 442, 9: 392, 10: 3685}, {1: 13428}], [{1: 1525, 2: 12162, 3: 2064, 4: 1606, 5: 1420, 6: 1110, 7: 954, 8: 766, 9: 639, 10: 5875}, {2: 11706}], [{1: 1582, 2: 2280, 3: 9755, 4: 1987, 5: 1726, 6: 1356, 7: 1163, 8: 966, 9: 828, 10: 7423}, {3: 9277}], [{1: 1251, 2: 1864, 3: 2112, 4: 7759, 5: 1867, 6: 1529, 7: 1277, 8: 1115, 9: 912, 10: 8511}, {4: 7320}], [{1: 1076, 2: 1735, 3: 2034, 4: 2003, 5: 6670, 6: 1576, 7: 1397, 8: 1196, 9: 1033, 10: 9513}, {5: 6222}], [{1: 904, 2: 1401, 3: 1546, 4: 1745, 5: 1668, 6: 5231, 7: 1341, 8: 1178, 9: 993, 10: 9999}, {6: 4868}], [{1: 724, 2: 1210, 3: 1421, 4: 1525, 5: 1541, 6: 1424, 7: 4368, 8: 1150, 9: 1022, 10: 10305}, {7: 4045}], [{1: 615, 2: 990, 3: 1214, 4: 1372, 5: 1431, 6: 1273, 7: 1220, 8: 3789, 9: 1041, 10: 10789}, {8: 3472}], [{1: 519, 2: 890, 3: 1092, 4: 1243, 5: 1253, 6: 1154, 7: 1128, 8: 1065, 9: 3251, 10: 10836}, {9: 2976}], [{1: 457, 2: 779, 3: 940, 4: 1085, 5: 1115, 6: 1112, 7: 1051, 8: 1002, 9: 910, 10: 13099}, {10: 2599}], [{1: 373, 2: 610, 3: 837, 4: 910, 5: 994, 6: 944, 7: 952, 8: 949, 9: 857, 10: 12460}, {11: 2203}], [{1: 345, 2: 621, 3: 789, 4: 892, 5: 968, 6: 980, 7: 898, 8: 920, 9: 813, 10: 12180}, {12: 1937}], [{1: 357, 2: 566, 3: 685, 4: 775, 5: 803, 6: 793, 7: 797, 8: 819, 9: 733, 10: 11507}, {13: 1656}], [{1: 279, 2: 460, 3: 602, 4: 672, 5: 713, 6: 780, 7: 730, 8: 740, 9: 657, 10: 11030}, {14: 1434}], [{1: 280, 2: 457, 3: 563, 4: 621, 5: 651, 6: 667, 7: 663, 8: 707, 9: 659, 10: 10813}, {15: 1289}], [{1: 195, 2: 356, 3: 454, 4: 544, 5: 576, 6: 610, 7: 579, 8: 589, 9: 572, 10: 10217}, {16: 1111}], [{1: 205, 2: 377, 3: 470, 4: 546, 5: 572, 6: 590, 7: 564, 8: 547, 9: 612, 10: 10194}, {17: 1030}], [{1: 204, 2: 315, 3: 373, 4: 487, 5: 485, 6: 570, 7: 536, 8: 542, 9: 542, 10: 9940}, {18: 948}], [{1: 199, 2: 299, 3: 387, 4: 450, 5: 489, 6: 514, 7: 507, 8: 514, 9: 532, 10: 9413}, {19: 836}], [{1: 143, 2: 272, 3: 351, 4: 424, 5: 444, 6: 496, 7: 474, 8: 532, 9: 494, 10: 9707}, {20: 807}], [{1: 203, 2: 288, 3: 371, 4: 397, 5: 448, 6: 453, 7: 433, 8: 441, 9: 491, 10: 9029}, {21: 717}], [{1: 105, 2: 206, 3: 255, 4: 308, 5: 307, 6: 349, 7: 377, 8: 386, 9: 342, 10: 7803}, {22: 556}], [{1: 125, 2: 220, 3: 284, 4: 287, 5: 318, 6: 324, 7: 350, 8: 357, 9: 353, 10: 7787}, {23: 519}], [{1: 115, 2: 197, 3: 259, 4: 313, 5: 337, 6: 338, 7: 332, 8: 333, 9: 373, 10: 7982}, {24: 525}], [{1: 1520, 2: 2559, 3: 3183, 4: 3484, 5: 3744, 6: 3737, 7: 3707, 8: 3588, 9: 3442, 10: 51826}, {25: 9460}]]
 MM estimated memory/GB degree 0: 0.7450554370880127 * 4.5732797140303845
 MM estimated memory/GB degree 1: 1.0546706020832062 * 3.1955407483341878
 MM estimated memory/GB degree 2: 0.40809836983680725 * 2.835830548668751
 MM estimated memory/GB degree 3: 0.37566670775413513 * 2.6975751366120218
 MM estimated memory/GB degree 4: 0.37189847230911255 * 2.5698810671809706
 MM estimated memory/GB degree 5: 0.32915210723876953 * 2.6380101342098055
 MM estimated memory/GB degree 6: 0.30266234278678894 * 2.630372594031432
 MM estimated memory/GB degree 7: 0.27946874499320984 * 2.619419642857143
 MM estimated memory/GB degree 8: 0.262010782957077 * 2.640681003584229
 MM estimated memory/GB degree 9: 0.2465204894542694 * 2.658907272027703
 MM estimated memory/GB degree 10: 0.21968740224838257 * 2.6945074897866546
 MM estimated memory/GB degree 11: 0.21266189217567444 * 2.7856220960247806
 MM estimated memory/GB degree 12: 0.1978711187839508 * 2.837931995540691
 MM estimated memory/GB degree 13: 0.17765530943870544 * 2.9378860330743177
 MM estimated memory/GB degree 14: 0.17252156138420105 * 2.9799844840961986
 MM estimated memory/GB degree 15: 0.15164431929588318 * 3.0256525652565256
 MM estimated memory/GB degree 16: 0.15171298384666443 * 3.065562535693889
 MM estimated memory/GB degree 17: 0.14442408084869385 * 3.05983356774496
 MM estimated memory/GB degree 18: 0.13520774245262146 * 3.2087635356333415
 MM estimated memory/GB degree 19: 0.132772296667099 * 3.0985749690210658
 MM estimated memory/GB degree 20: 0.12907111644744873 * 3.2045560204556023
 MM estimated memory/GB degree 21: 0.10047581791877747 * 3.4635382603008504
 MM estimated memory/GB degree 22: 0.10027974843978882 * 3.5387450783278878
 MM estimated memory/GB degree 23: 0.10273584723472595 * 3.427698412698413
 MM estimated memory/GB degree 24: 1.8239461183547974 * 0.5191585623678647

modified_mem [1, fanout-1]: 
[3.4073469162626497, 3.370242885027037, 1.157297824045136, 1.0133891704904496, 0.9557348429007149, 0.8683065945923867, 0.7961147317117165, 0.7320459201998476, 0.6918868972889838, 0.6554751221137857, 0.5919493507700404, 0.5923956658269981, 0.5615447789904067, 0.5219310523014687, 0.514111576096969, 0.4588230236841686, 0.46508563945866666, 0.44191365057154547, 0.4338496737172759, 0.411404915032112, 0.41361562327859797, 0.3480018395967075, 0.35486446624726137, 0.3521475004936968]

mem size of fanout degree bucket by formula (GB):  1.8239461183547974

the modified memory estimation spend (sec) 0.1206979751586914
the time of number of fanout blocks generation (sec) 8.660377025604248
the time dict collection (sec) 0.11983680725097656
the time estimate mem (sec) 0.00042176246643066406
