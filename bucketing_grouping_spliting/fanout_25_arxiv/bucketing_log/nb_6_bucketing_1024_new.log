main start at this time 1689367558.2215526
-----------------------------------------before load data 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
dtype  torch.int64
data type  <class 'torch.Tensor'>
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

----------------------------------------start of run function 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.04658961296081543
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

fanout_dst_nids  size  9460
map_output_list size  9460
self.K  6
the grouping_fanout_arxiv called successfully
capacity  6029
 
G_BUCKET_ID_list [[0, 2, 5], [1, 3, 4], [6, 7, 8, 9, 10, 11, 12, 22], [13, 14, 16, 15, 17, 18, 19, 20, 23, 21]]
Groups_mem_list  [5967, 5798, 5968, 5327]
G_BUCKET_ID_list length 4
backpack scheduling spend  0.3641982078552246
4
6
[0, 2, 5]
current group_mem  5.9693025638712705
[1, 3, 4]
current group_mem  5.798917120112315
[6, 7, 8, 9, 10, 11, 12, 22]
current group_mem  5.9713268028243105
[13, 14, 16, 15, 17, 18, 19, 20, 23, 21]
current group_mem  5.331661808831789
batches output list generation spend  0.0008060932159423828
self.weights_list  [0.3205374913405395, 0.2949714650157795, 0.23074300920376947, 0.11908820004178533, 0.017329917199063127, 0.017329917199063127]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015298604965209961
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.36530303955078125
len local_batched_seeds_list  6
partition total batch output list spend :  0.6335577964782715
self.buckets_partition() spend  sec:  0.38065481185913086
layer  0
 the number of batches:  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
layer  1
num of batch  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.552734375 GB
    Memory Allocated: 0.10504913330078125  GigaBytes
Max Memory Allocated: 0.10504913330078125  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.9375 GB
    Memory Allocated: 11.470390796661377  GigaBytes
Max Memory Allocated: 12.104841709136963  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.9375 GB
    Memory Allocated: 11.47532320022583  GigaBytes
Max Memory Allocated: 12.104841709136963  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 14.787109375 GB
    Memory Allocated: 0.14551067352294922  GigaBytes
Max Memory Allocated: 12.104841709136963  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 17.361328125 GB
    Memory Allocated: 12.392787456512451  GigaBytes
Max Memory Allocated: 13.066065311431885  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 17.361328125 GB
    Memory Allocated: 12.396853923797607  GigaBytes
Max Memory Allocated: 13.066065311431885  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 18.3046875 GB
    Memory Allocated: 0.14901494979858398  GigaBytes
Max Memory Allocated: 13.066065311431885  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.71484375 GB
    Memory Allocated: 19.563690662384033  GigaBytes
Max Memory Allocated: 20.596139907836914  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.71484375 GB
    Memory Allocated: 19.567383766174316  GigaBytes
Max Memory Allocated: 20.596139907836914  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.404296875 GB
    Memory Allocated: 0.14897489547729492  GigaBytes
Max Memory Allocated: 20.596139907836914  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.408203125 GB
    Memory Allocated: 17.471797943115234  GigaBytes
Max Memory Allocated: 20.596139907836914  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.408203125 GB
    Memory Allocated: 17.473469257354736  GigaBytes
Max Memory Allocated: 20.596139907836914  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.185546875 GB
    Memory Allocated: 0.12190580368041992  GigaBytes
Max Memory Allocated: 20.596139907836914  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.248046875 GB
    Memory Allocated: 4.50815486907959  GigaBytes
Max Memory Allocated: 20.596139907836914  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.248046875 GB
    Memory Allocated: 4.508390426635742  GigaBytes
Max Memory Allocated: 20.596139907836914  GigaBytes

step  5
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.248046875 GB
    Memory Allocated: 0.12213516235351562  GigaBytes
Max Memory Allocated: 20.596139907836914  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.25390625 GB
    Memory Allocated: 4.54880428314209  GigaBytes
Max Memory Allocated: 20.596139907836914  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.25390625 GB
    Memory Allocated: 4.549039840698242  GigaBytes
Max Memory Allocated: 20.596139907836914  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.25390625 GB
    Memory Allocated: 0.1909499168395996  GigaBytes
Max Memory Allocated: 20.596139907836914  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.7771964073181152
pure train time :  2.926088809967041
train time :  4.75751805305481
end to end time :  10.82388687133789
connection check time:  2.268535614013672
block generation time  3.142340898513794
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.04852890968322754
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

fanout_dst_nids  size  9460
map_output_list size  9460
self.K  6
the grouping_fanout_arxiv called successfully
capacity  6029
 
G_BUCKET_ID_list [[0, 2, 5], [1, 3, 4], [6, 7, 8, 9, 10, 11, 12, 22], [13, 14, 16, 15, 17, 18, 19, 20, 23, 21]]
Groups_mem_list  [5967, 5798, 5968, 5327]
G_BUCKET_ID_list length 4
backpack scheduling spend  0.31159019470214844
4
6
[0, 2, 5]
current group_mem  5.9693025638712705
[1, 3, 4]
current group_mem  5.798917120112315
[6, 7, 8, 9, 10, 11, 12, 22]
current group_mem  5.9713268028243105
[13, 14, 16, 15, 17, 18, 19, 20, 23, 21]
current group_mem  5.331661808831789
batches output list generation spend  0.00034618377685546875
self.weights_list  [0.3205374913405395, 0.2949714650157795, 0.23074300920376947, 0.11908820004178533, 0.017329917199063127, 0.017329917199063127]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015207767486572266
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.31214451789855957
len local_batched_seeds_list  6
partition total batch output list spend :  0.4791529178619385
self.buckets_partition() spend  sec:  0.32739901542663574
layer  0
 the number of batches:  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
layer  1
num of batch  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.25390625 GB
    Memory Allocated: 0.20563936233520508  GigaBytes
Max Memory Allocated: 20.596139907836914  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.25390625 GB
    Memory Allocated: 11.578424453735352  GigaBytes
Max Memory Allocated: 20.596139907836914  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.25390625 GB
    Memory Allocated: 11.582135677337646  GigaBytes
Max Memory Allocated: 20.596139907836914  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.25390625 GB
    Memory Allocated: 0.21126985549926758  GigaBytes
Max Memory Allocated: 20.596139907836914  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.25390625 GB
    Memory Allocated: 12.442259788513184  GigaBytes
Max Memory Allocated: 20.596139907836914  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.25390625 GB
    Memory Allocated: 12.446353912353516  GigaBytes
Max Memory Allocated: 20.596139907836914  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.25390625 GB
    Memory Allocated: 0.21517372131347656  GigaBytes
Max Memory Allocated: 20.596139907836914  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.65625 GB
    Memory Allocated: 19.674156665802002  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.65625 GB
    Memory Allocated: 19.67817974090576  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.65625 GB
    Memory Allocated: 0.2153491973876953  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.65625 GB
    Memory Allocated: 17.533970832824707  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.65625 GB
    Memory Allocated: 17.53561496734619  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.65625 GB
    Memory Allocated: 0.18855714797973633  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.66015625 GB
    Memory Allocated: 4.585421085357666  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.66015625 GB
    Memory Allocated: 4.585656642913818  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  5
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.66015625 GB
    Memory Allocated: 0.18790340423583984  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.66015625 GB
    Memory Allocated: 4.576846122741699  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.66015625 GB
    Memory Allocated: 4.577081680297852  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.66015625 GB
    Memory Allocated: 0.19059038162231445  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.189779281616211
pure train time :  2.4359564781188965
train time :  3.7660305500030518
end to end time :  9.769275426864624
connection check time:  2.3358333110809326
block generation time  3.166534185409546
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.05149030685424805
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

fanout_dst_nids  size  9460
map_output_list size  9460
self.K  6
the grouping_fanout_arxiv called successfully
capacity  6029
 
G_BUCKET_ID_list [[0, 2, 5], [1, 3, 4], [6, 7, 8, 9, 10, 11, 12, 22], [13, 14, 16, 15, 17, 18, 19, 20, 23, 21]]
Groups_mem_list  [5967, 5798, 5968, 5327]
G_BUCKET_ID_list length 4
backpack scheduling spend  0.34327030181884766
4
6
[0, 2, 5]
current group_mem  5.9693025638712705
[1, 3, 4]
current group_mem  5.798917120112315
[6, 7, 8, 9, 10, 11, 12, 22]
current group_mem  5.9713268028243105
[13, 14, 16, 15, 17, 18, 19, 20, 23, 21]
current group_mem  5.331661808831789
batches output list generation spend  0.0003960132598876953
self.weights_list  [0.3205374913405395, 0.2949714650157795, 0.23074300920376947, 0.11908820004178533, 0.017329917199063127, 0.017329917199063127]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015491247177124023
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.3439946174621582
len local_batched_seeds_list  6
partition total batch output list spend :  0.5152039527893066
self.buckets_partition() spend  sec:  0.3595395088195801
layer  0
 the number of batches:  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
layer  1
num of batch  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.66015625 GB
    Memory Allocated: 0.2055368423461914  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.66015625 GB
    Memory Allocated: 11.579490184783936  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.66015625 GB
    Memory Allocated: 11.58289909362793  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.66015625 GB
    Memory Allocated: 0.2110733985900879  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.66015625 GB
    Memory Allocated: 12.430272102355957  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.66015625 GB
    Memory Allocated: 12.434302806854248  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.66015625 GB
    Memory Allocated: 0.2151036262512207  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.740234375 GB
    Memory Allocated: 19.66818380355835  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.740234375 GB
    Memory Allocated: 19.67221450805664  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.21529722213745117  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 17.534003734588623  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 17.535650730133057  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.18836450576782227  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.578645706176758  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.57888126373291  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  5
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.18759727478027344  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.56550931930542  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.565744876861572  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.19027376174926758  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.604353904724121
pure train time :  2.433281183242798
train time :  3.768815040588379
end to end time :  9.730780124664307
connection check time:  2.266941547393799
block generation time  3.1577446460723877
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.04662609100341797
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

fanout_dst_nids  size  9460
map_output_list size  9460
self.K  6
the grouping_fanout_arxiv called successfully
capacity  6029
 
G_BUCKET_ID_list [[0, 2, 5], [1, 3, 4], [6, 7, 8, 9, 10, 11, 12, 22], [13, 14, 16, 15, 17, 18, 19, 20, 23, 21]]
Groups_mem_list  [5967, 5798, 5968, 5327]
G_BUCKET_ID_list length 4
backpack scheduling spend  0.2178668975830078
4
6
[0, 2, 5]
current group_mem  5.9693025638712705
[1, 3, 4]
current group_mem  5.798917120112315
[6, 7, 8, 9, 10, 11, 12, 22]
current group_mem  5.9713268028243105
[13, 14, 16, 15, 17, 18, 19, 20, 23, 21]
current group_mem  5.331661808831789
batches output list generation spend  0.0003685951232910156
self.weights_list  [0.3205374913405395, 0.2949714650157795, 0.23074300920376947, 0.11908820004178533, 0.017329917199063127, 0.017329917199063127]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.016604185104370117
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.2184751033782959
len local_batched_seeds_list  6
partition total batch output list spend :  0.40193843841552734
self.buckets_partition() spend  sec:  0.23512887954711914
layer  0
 the number of batches:  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
layer  1
num of batch  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.20564556121826172  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 11.564110279083252  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 11.567549228668213  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.21126556396484375  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 12.458569526672363  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 12.462969779968262  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.2151942253112793  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 19.668853282928467  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 19.67269515991211  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.21516752243041992  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 17.537981033325195  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 17.539679527282715  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.18835163116455078  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.581549167633057  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.581784725189209  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  5
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.18784093856811523  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.601047992706299  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.601283550262451  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.1905374526977539  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.082160234451294
pure train time :  2.4636757373809814
train time :  3.8047618865966797
end to end time :  9.845008134841919
connection check time:  2.3533363342285156
block generation time  3.263145685195923
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.0559234619140625
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

fanout_dst_nids  size  9460
map_output_list size  9460
self.K  6
the grouping_fanout_arxiv called successfully
capacity  6029
 
G_BUCKET_ID_list [[0, 2, 5], [1, 3, 4], [6, 7, 8, 9, 10, 11, 12, 22], [13, 14, 16, 15, 17, 18, 19, 20, 23, 21]]
Groups_mem_list  [5967, 5798, 5968, 5327]
G_BUCKET_ID_list length 4
backpack scheduling spend  0.37160539627075195
4
6
[0, 2, 5]
current group_mem  5.9693025638712705
[1, 3, 4]
current group_mem  5.798917120112315
[6, 7, 8, 9, 10, 11, 12, 22]
current group_mem  5.9713268028243105
[13, 14, 16, 15, 17, 18, 19, 20, 23, 21]
current group_mem  5.331661808831789
batches output list generation spend  0.00045680999755859375
self.weights_list  [0.3205374913405395, 0.2949714650157795, 0.23074300920376947, 0.11908820004178533, 0.017329917199063127, 0.017329917199063127]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01672530174255371
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.37235236167907715
len local_batched_seeds_list  6
partition total batch output list spend :  0.5566084384918213
self.buckets_partition() spend  sec:  0.3891477584838867
layer  0
 the number of batches:  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
layer  1
num of batch  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.20553970336914062  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 11.55355453491211  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 11.556931495666504  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.21128129959106445  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 12.475037097930908  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 12.479166507720947  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.21519994735717773  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 19.671340465545654  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 19.675437450408936  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.21549606323242188  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 17.548099994659424  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 17.549757957458496  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.18812847137451172  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.575234889984131  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.575470447540283  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  5
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.18808269500732422  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.602112770080566  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.602348327636719  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.1907801628112793  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.0672285556793213
pure train time :  2.4603450298309326
train time :  3.7912638187408447
end to end time :  9.879932403564453
connection check time:  2.3269081115722656
block generation time  3.183439254760742
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.05082535743713379
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

fanout_dst_nids  size  9460
map_output_list size  9460
self.K  6
the grouping_fanout_arxiv called successfully
capacity  6029
 
G_BUCKET_ID_list [[0, 2, 5], [1, 3, 4], [6, 7, 8, 9, 10, 11, 12, 22], [13, 14, 16, 15, 17, 18, 19, 20, 23, 21]]
Groups_mem_list  [5967, 5798, 5968, 5327]
G_BUCKET_ID_list length 4
backpack scheduling spend  0.3502616882324219
4
6
[0, 2, 5]
current group_mem  5.9693025638712705
[1, 3, 4]
current group_mem  5.798917120112315
[6, 7, 8, 9, 10, 11, 12, 22]
current group_mem  5.9713268028243105
[13, 14, 16, 15, 17, 18, 19, 20, 23, 21]
current group_mem  5.331661808831789
batches output list generation spend  0.0004839897155761719
self.weights_list  [0.3205374913405395, 0.2949714650157795, 0.23074300920376947, 0.11908820004178533, 0.017329917199063127, 0.017329917199063127]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01666259765625
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.35101819038391113
len local_batched_seeds_list  6
partition total batch output list spend :  0.5471439361572266
self.buckets_partition() spend  sec:  0.3677351474761963
layer  0
 the number of batches:  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
layer  1
num of batch  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.20557212829589844  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 11.575080871582031  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 11.578501224517822  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.21115684509277344  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 12.443370819091797  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 12.447457313537598  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.21516036987304688  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 19.67037057876587  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 19.67445707321167  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.21536779403686523  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 17.532801151275635  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 17.53445529937744  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.18826532363891602  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.574794769287109  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.575030326843262  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  5
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.18788957595825195  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.6030707359313965  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.603306293487549  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.19058513641357422  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.0661842823028564
pure train time :  2.4586644172668457
train time :  3.8105742931365967
end to end time :  9.914912223815918
connection check time:  2.3392698764801025
block generation time  3.1981632709503174
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.052710771560668945
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

fanout_dst_nids  size  9460
map_output_list size  9460
self.K  6
the grouping_fanout_arxiv called successfully
capacity  6029
 
G_BUCKET_ID_list [[0, 2, 5], [1, 3, 4], [6, 7, 8, 9, 10, 11, 12, 22], [13, 14, 16, 15, 17, 18, 19, 20, 23, 21]]
Groups_mem_list  [5967, 5798, 5968, 5327]
G_BUCKET_ID_list length 4
backpack scheduling spend  0.37923765182495117
4
6
[0, 2, 5]
current group_mem  5.9693025638712705
[1, 3, 4]
current group_mem  5.798917120112315
[6, 7, 8, 9, 10, 11, 12, 22]
current group_mem  5.9713268028243105
[13, 14, 16, 15, 17, 18, 19, 20, 23, 21]
current group_mem  5.331661808831789
batches output list generation spend  0.00040912628173828125
self.weights_list  [0.3205374913405395, 0.2949714650157795, 0.23074300920376947, 0.11908820004178533, 0.017329917199063127, 0.017329917199063127]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.016016244888305664
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.37989211082458496
len local_batched_seeds_list  6
partition total batch output list spend :  0.5622568130493164
self.buckets_partition() spend  sec:  0.395965576171875
layer  0
 the number of batches:  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
layer  1
num of batch  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.2056260108947754  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 11.566678524017334  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 11.570098400115967  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.2113628387451172  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 12.452685356140137  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 12.45669937133789  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.21509027481079102  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 19.671494960784912  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 19.675508975982666  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.21536684036254883  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 17.537020683288574  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 17.538654327392578  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.18857049942016602  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.606320381164551  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.606555938720703  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  5
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.1877155303955078  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.570079803466797  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.570315361022949  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.19039297103881836  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.0303540229797363
pure train time :  2.4545485973358154
train time :  3.800748586654663
end to end time :  9.919545650482178
connection check time:  2.349719762802124
block generation time  3.186711549758911
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.052474260330200195
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

fanout_dst_nids  size  9460
map_output_list size  9460
self.K  6
the grouping_fanout_arxiv called successfully
capacity  6029
 
G_BUCKET_ID_list [[0, 2, 5], [1, 3, 4], [6, 7, 8, 9, 10, 11, 12, 22], [13, 14, 16, 15, 17, 18, 19, 20, 23, 21]]
Groups_mem_list  [5967, 5798, 5968, 5327]
G_BUCKET_ID_list length 4
backpack scheduling spend  0.3815021514892578
4
6
[0, 2, 5]
current group_mem  5.9693025638712705
[1, 3, 4]
current group_mem  5.798917120112315
[6, 7, 8, 9, 10, 11, 12, 22]
current group_mem  5.9713268028243105
[13, 14, 16, 15, 17, 18, 19, 20, 23, 21]
current group_mem  5.331661808831789
batches output list generation spend  0.0004000663757324219
self.weights_list  [0.3205374913405395, 0.2949714650157795, 0.23074300920376947, 0.11908820004178533, 0.017329917199063127, 0.017329917199063127]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.018270254135131836
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.38219428062438965
len local_batched_seeds_list  6
partition total batch output list spend :  0.5606842041015625
self.buckets_partition() spend  sec:  0.4005289077758789
layer  0
 the number of batches:  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
layer  1
num of batch  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.20558977127075195  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 11.570325374603271  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 11.573777198791504  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.21133995056152344  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 12.476006507873535  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 12.480449676513672  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.21520328521728516  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 19.657344341278076  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 19.66047191619873  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.21452093124389648  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 17.534868240356445  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 17.536534786224365  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.18812227249145508  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.597457408905029  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.597692966461182  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  5
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.18793249130249023  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.588623523712158  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.5888590812683105  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.1906261444091797  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.959909677505493
pure train time :  2.467017650604248
train time :  3.8109405040740967
end to end time :  9.896651983261108
connection check time:  2.3394978046417236
block generation time  3.165780544281006
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.04959273338317871
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

fanout_dst_nids  size  9460
map_output_list size  9460
self.K  6
the grouping_fanout_arxiv called successfully
capacity  6029
 
G_BUCKET_ID_list [[0, 2, 5], [1, 3, 4], [6, 7, 8, 9, 10, 11, 12, 22], [13, 14, 16, 15, 17, 18, 19, 20, 23, 21]]
Groups_mem_list  [5967, 5798, 5968, 5327]
G_BUCKET_ID_list length 4
backpack scheduling spend  0.3777778148651123
4
6
[0, 2, 5]
current group_mem  5.9693025638712705
[1, 3, 4]
current group_mem  5.798917120112315
[6, 7, 8, 9, 10, 11, 12, 22]
current group_mem  5.9713268028243105
[13, 14, 16, 15, 17, 18, 19, 20, 23, 21]
current group_mem  5.331661808831789
batches output list generation spend  0.00039577484130859375
self.weights_list  [0.3205374913405395, 0.2949714650157795, 0.23074300920376947, 0.11908820004178533, 0.017329917199063127, 0.017329917199063127]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015968799591064453
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.3784317970275879
len local_batched_seeds_list  6
partition total batch output list spend :  0.5506997108459473
self.buckets_partition() spend  sec:  0.3944563865661621
layer  0
 the number of batches:  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
layer  1
num of batch  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.20556640625  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 11.576300621032715  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 11.580330848693848  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.21169662475585938  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 12.436596870422363  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 12.440674781799316  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.21514320373535156  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 19.644113540649414  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 19.648191452026367  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.2143840789794922  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 17.548845291137695  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 17.550551414489746  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.18819046020507812  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.577387809753418  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.57762336730957  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  5
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.18797779083251953  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.6087751388549805  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.609010696411133  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.19068288803100586  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.8702614307403564
pure train time :  2.4468584060668945
train time :  3.798973321914673
end to end time :  9.812394380569458
connection check time:  2.2790777683258057
block generation time  3.1664459705352783
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.05077075958251953
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

fanout_dst_nids  size  9460
map_output_list size  9460
self.K  6
the grouping_fanout_arxiv called successfully
capacity  6029
 
G_BUCKET_ID_list [[0, 2, 5], [1, 3, 4], [6, 7, 8, 9, 10, 11, 12, 22], [13, 14, 16, 15, 17, 18, 19, 20, 23, 21]]
Groups_mem_list  [5967, 5798, 5968, 5327]
G_BUCKET_ID_list length 4
backpack scheduling spend  0.34574389457702637
4
6
[0, 2, 5]
current group_mem  5.9693025638712705
[1, 3, 4]
current group_mem  5.798917120112315
[6, 7, 8, 9, 10, 11, 12, 22]
current group_mem  5.9713268028243105
[13, 14, 16, 15, 17, 18, 19, 20, 23, 21]
current group_mem  5.331661808831789
batches output list generation spend  0.0004975795745849609
self.weights_list  [0.3205374913405395, 0.2949714650157795, 0.23074300920376947, 0.11908820004178533, 0.017329917199063127, 0.017329917199063127]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01559901237487793
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.346524715423584
len local_batched_seeds_list  6
partition total batch output list spend :  0.5187697410583496
self.buckets_partition() spend  sec:  0.3621835708618164
layer  0
 the number of batches:  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
layer  1
num of batch  6
check_connections_block*********************************
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
dtype  None
data type  <class 'list'>
res  length 6
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
dtype  torch.int64
data type  <class 'list'>
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.20555639266967773  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 11.565975189208984  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 11.56937551498413  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.21129608154296875  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 12.450815677642822  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 12.454834938049316  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.21508502960205078  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 19.655122756958008  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 19.659142017364502  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.2144923210144043  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 17.54750394821167  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 17.54917335510254  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  4
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.1880035400390625  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.576770782470703  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.5770063400268555  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

step  5
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.18805217742919922  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.60146951675415  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 4.601705074310303  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.615234375 GB
    Memory Allocated: 0.1907496452331543  GigaBytes
Max Memory Allocated: 20.706290245056152  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.771294116973877
pure train time :  2.4654781818389893
train time :  3.804103374481201
end to end time :  9.80868649482727
connection check time:  2.2882020473480225
block generation time  3.1752853393554688
end to end time  9.989033222198486
Total (block generation + training)time/epoch 9.989033222198486
pure train time per /epoch  [2.926088809967041, 2.4359564781188965, 2.433281183242798, 2.4636757373809814, 2.4603450298309326, 2.4586644172668457, 2.4545485973358154, 2.467017650604248, 2.4468584060668945, 2.4654781818389893]
pure train time average  2.459512574332101
input num list  [696498, 697053, 695529, 696849, 696837, 696385, 697112, 696311, 696183, 696284]
