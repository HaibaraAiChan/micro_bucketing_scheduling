main start at this time 1697669249.193223
-----------------------------------------before load data 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

----------------------------------------start of run function 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0009238719940185547
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01488947868347168
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7380204200744629
len local_batched_seeds_list  2
partition total batch output list spend :  0.8264665603637695
self.buckets_partition() spend  sec:  0.7529466152191162
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0452876091003418

in edges time spent  0.156174898147583
local to global src and eids time spent  0.27457284927368164
time gen tails  0.05169820785522461
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.098297119140625

in edges time spent  0.3878607749938965
local to global src and eids time spent  0.5839829444885254
time gen tails  0.08119010925292969
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.529296875 GB
    Memory Allocated: 0.08733367919921875  GigaBytes
Max Memory Allocated: 0.08733367919921875  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 15.361328125 GB
    Memory Allocated: 12.976958274841309  GigaBytes
Max Memory Allocated: 13.448422908782959  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 15.361328125 GB
    Memory Allocated: 12.98479175567627  GigaBytes
Max Memory Allocated: 13.448422908782959  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 16.52734375 GB
    Memory Allocated: 0.10790681838989258  GigaBytes
Max Memory Allocated: 13.448422908782959  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 18.837890625 GB
    Memory Allocated: 11.791447639465332  GigaBytes
Max Memory Allocated: 13.448422908782959  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 18.837890625 GB
    Memory Allocated: 11.797167301177979  GigaBytes
Max Memory Allocated: 13.448422908782959  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 19.490234375 GB
    Memory Allocated: 0.1240382194519043  GigaBytes
Max Memory Allocated: 13.448422908782959  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.8332743644714355
pure train time :  0.9651284217834473
train time :  1.651841640472412
end to end time :  5.448464632034302
connection check time:  1.9463140964508057
block generation time  1.0015640258789062
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.005116939544677734
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014517068862915039
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6979410648345947
len local_batched_seeds_list  2
partition total batch output list spend :  0.7842137813568115
self.buckets_partition() spend  sec:  0.7124955654144287
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04488229751586914

in edges time spent  0.14948487281799316
local to global src and eids time spent  0.27401232719421387
time gen tails  0.05341315269470215
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09360933303833008

in edges time spent  0.3728504180908203
local to global src and eids time spent  0.5462865829467773
time gen tails  0.060495853424072266
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.490234375 GB
    Memory Allocated: 0.11004114151000977  GigaBytes
Max Memory Allocated: 13.448422908782959  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.908203125 GB
    Memory Allocated: 13.03822135925293  GigaBytes
Max Memory Allocated: 13.515458583831787  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.908203125 GB
    Memory Allocated: 13.037416934967041  GigaBytes
Max Memory Allocated: 13.515458583831787  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.908203125 GB
    Memory Allocated: 0.11430883407592773  GigaBytes
Max Memory Allocated: 13.515458583831787  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.787207126617432  GigaBytes
Max Memory Allocated: 13.515458583831787  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.792926788330078  GigaBytes
Max Memory Allocated: 13.515458583831787  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.12489748001098633  GigaBytes
Max Memory Allocated: 13.515458583831787  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.5781354904174805
pure train time :  0.44863462448120117
train time :  0.6202273368835449
end to end time :  4.287725210189819
connection check time:  1.8644251823425293
block generation time  1.001114845275879
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005979537963867188
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.02378082275390625
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6704599857330322
len local_batched_seeds_list  2
partition total batch output list spend :  0.7245621681213379
self.buckets_partition() spend  sec:  0.6942734718322754
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04431867599487305

in edges time spent  0.1577012538909912
local to global src and eids time spent  0.2748572826385498
time gen tails  0.054720401763916016
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09509778022766113

in edges time spent  0.4102158546447754
local to global src and eids time spent  0.5970356464385986
time gen tails  0.08654904365539551
res  length 2
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.11121320724487305  GigaBytes
Max Memory Allocated: 13.515458583831787  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 13.00204849243164  GigaBytes
Max Memory Allocated: 13.515458583831787  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 13.000492095947266  GigaBytes
Max Memory Allocated: 13.515458583831787  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.11434602737426758  GigaBytes
Max Memory Allocated: 13.515458583831787  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.783832550048828  GigaBytes
Max Memory Allocated: 13.515458583831787  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.789552211761475  GigaBytes
Max Memory Allocated: 13.515458583831787  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.1244196891784668  GigaBytes
Max Memory Allocated: 13.515458583831787  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.364997625350952
pure train time :  0.44850826263427734
train time :  0.6215207576751709
end to end time :  4.365147352218628
connection check time:  1.9969282150268555
block generation time  1.0019803047180176
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005562305450439453
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014423131942749023
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5948085784912109
len local_batched_seeds_list  2
partition total batch output list spend :  0.6818933486938477
self.buckets_partition() spend  sec:  0.6092727184295654
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04485821723937988

in edges time spent  0.15362048149108887
local to global src and eids time spent  0.2722902297973633
time gen tails  0.0538787841796875
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09447860717773438

in edges time spent  0.3644449710845947
local to global src and eids time spent  0.5757966041564941
time gen tails  0.08392047882080078
res  length 2
block collection to dataloader spend  1.1920928955078125e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.11027860641479492  GigaBytes
Max Memory Allocated: 13.515458583831787  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 13.040655612945557  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 13.039887428283691  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.11299896240234375  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.770403861999512  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.776123523712158  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.12346506118774414  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.219095230102539
pure train time :  0.4445061683654785
train time :  0.6124203205108643
end to end time :  4.237196207046509
connection check time:  1.9135675430297852
block generation time  1.012852430343628
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005559921264648438
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014767885208129883
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7143926620483398
len local_batched_seeds_list  2
partition total batch output list spend :  0.8013849258422852
self.buckets_partition() spend  sec:  0.7291965484619141
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04512643814086914

in edges time spent  0.1508162021636963
local to global src and eids time spent  0.2725377082824707
time gen tails  0.05367422103881836
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09570503234863281

in edges time spent  0.360032320022583
local to global src and eids time spent  0.5691757202148438
time gen tails  0.08383798599243164
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.10994958877563477  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 12.999607563018799  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 12.99887752532959  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.11358261108398438  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.796390533447266  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.802110195159912  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.12543773651123047  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.172821521759033
pure train time :  0.4478788375854492
train time :  0.6160237789154053
end to end time :  4.326238393783569
connection check time:  1.8979933261871338
block generation time  0.9947023391723633
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000553131103515625
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014493227005004883
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6784164905548096
len local_batched_seeds_list  2
partition total batch output list spend :  0.7650866508483887
self.buckets_partition() spend  sec:  0.692943811416626
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.045679569244384766

in edges time spent  0.15071535110473633
local to global src and eids time spent  0.2734255790710449
time gen tails  0.05332159996032715
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0967416763305664

in edges time spent  0.36330699920654297
local to global src and eids time spent  0.572986364364624
time gen tails  0.08360147476196289
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.11013174057006836  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 12.996898651123047  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 12.995988368988037  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.1131291389465332  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.780400276184082  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.786119937896729  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.12374734878540039  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.1223104000091553
pure train time :  0.4348881244659424
train time :  0.5946128368377686
end to end time :  4.2806782722473145
connection check time:  1.9068713188171387
block generation time  0.9981648921966553
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005795955657958984
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014831066131591797
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6804885864257812
len local_batched_seeds_list  2
partition total batch output list spend :  0.7677252292633057
self.buckets_partition() spend  sec:  0.6953644752502441
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.045030832290649414

in edges time spent  0.15088725090026855
local to global src and eids time spent  0.273756742477417
time gen tails  0.05391383171081543
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09565496444702148

in edges time spent  0.3623371124267578
local to global src and eids time spent  0.5798022747039795
time gen tails  0.08380985260009766
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.11021995544433594  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 13.004798889160156  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 13.003805160522461  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.11313724517822266  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.78252649307251  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.788246154785156  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.12374258041381836  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.0587730407714844
pure train time :  0.44220781326293945
train time :  0.6020212173461914
end to end time :  4.296411752700806
connection check time:  1.9120550155639648
block generation time  0.9986984729766846
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00052642822265625
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014450788497924805
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6692214012145996
len local_batched_seeds_list  2
partition total batch output list spend :  0.7554311752319336
self.buckets_partition() spend  sec:  0.6837136745452881
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04581499099731445

in edges time spent  0.1490497589111328
local to global src and eids time spent  0.27024340629577637
time gen tails  0.05340862274169922
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09489822387695312

in edges time spent  0.37110137939453125
local to global src and eids time spent  0.5668132305145264
time gen tails  0.0881500244140625
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.11022233963012695  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 13.003462314605713  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 13.00246524810791  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.11368989944458008  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.77182388305664  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.777543544769287  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.1246185302734375  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.0059642791748047
pure train time :  0.45001816749572754
train time :  0.6143815517425537
end to end time :  4.299258470535278
connection check time:  1.9080512523651123
block generation time  1.0047638416290283
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005362033843994141
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015360593795776367
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6912407875061035
len local_batched_seeds_list  2
partition total batch output list spend :  0.7790987491607666
self.buckets_partition() spend  sec:  0.7066359519958496
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04729604721069336

in edges time spent  0.15106749534606934
local to global src and eids time spent  0.27411341667175293
time gen tails  0.05434012413024902
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09768366813659668

in edges time spent  0.3821394443511963
local to global src and eids time spent  0.5719442367553711
time gen tails  0.08583521842956543
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.1104426383972168  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 13.040173053741455  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 13.03936767578125  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.11314010620117188  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.78486442565918  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.790584087371826  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.1238408088684082  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.957465648651123
pure train time :  0.44281554222106934
train time :  0.6120271682739258
end to end time :  4.347364902496338
connection check time:  1.9305362701416016
block generation time  1.0028910636901855
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005681514739990234
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014704227447509766
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.700484037399292
len local_batched_seeds_list  2
partition total batch output list spend :  0.7873249053955078
self.buckets_partition() spend  sec:  0.7152330875396729
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04541921615600586

in edges time spent  0.15338468551635742
local to global src and eids time spent  0.2752852439880371
time gen tails  0.0537717342376709
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09558510780334473

in edges time spent  0.3670079708099365
local to global src and eids time spent  0.5672221183776855
time gen tails  0.08365297317504883
res  length 2
block collection to dataloader spend  1.33514404296875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.11029338836669922  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 13.040021419525146  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 13.039086818695068  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.11340570449829102  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.782954692840576  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.788674354553223  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.12459087371826172  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.913573741912842
pure train time :  0.44395947456359863
train time :  0.6035435199737549
end to end time :  4.312203645706177
connection check time:  1.9083349704742432
block generation time  0.997565507888794
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00045180320739746094
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015809059143066406
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6769077777862549
len local_batched_seeds_list  2
partition total batch output list spend :  0.7256848812103271
self.buckets_partition() spend  sec:  0.6927528381347656
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04262042045593262

in edges time spent  0.15126633644104004
local to global src and eids time spent  0.2728590965270996
time gen tails  0.05375790596008301
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09824562072753906

in edges time spent  0.36488842964172363
local to global src and eids time spent  0.5682680606842041
time gen tails  0.08397293090820312
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.11009502410888672  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 13.00376272201538  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 13.003027439117432  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.11313486099243164  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.782416343688965  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 11.788136005401611  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.12387514114379883  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.86594295501709
pure train time :  0.45136094093322754
train time :  0.630535364151001
end to end time :  4.2793965339660645
connection check time:  1.8980822563171387
block generation time  1.0093159675598145
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005278587341308594
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01661372184753418
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6977717876434326
len local_batched_seeds_list  2
partition total batch output list spend :  0.792064905166626
self.buckets_partition() spend  sec:  0.7144196033477783
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04708123207092285

in edges time spent  0.1555788516998291
local to global src and eids time spent  0.2773935794830322
time gen tails  0.05423569679260254
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0960237979888916

in edges time spent  0.38852405548095703
local to global src and eids time spent  0.5777878761291504
time gen tails  0.08573460578918457
res  length 2
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.9140625 GB
    Memory Allocated: 0.11035299301147461  GigaBytes
Max Memory Allocated: 13.518294334411621  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04315996170044  GigaBytes
Max Memory Allocated: 13.519887924194336  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042181968688965  GigaBytes
Max Memory Allocated: 13.519887924194336  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1131753921508789  GigaBytes
Max Memory Allocated: 13.519887924194336  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.75515079498291  GigaBytes
Max Memory Allocated: 13.519887924194336  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.760870456695557  GigaBytes
Max Memory Allocated: 13.519887924194336  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12460899353027344  GigaBytes
Max Memory Allocated: 13.519887924194336  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.8152856826782227
pure train time :  0.4491255283355713
train time :  0.6208231449127197
end to end time :  4.389948844909668
connection check time:  1.9493165016174316
block generation time  1.0042569637298584
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00047969818115234375
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015013694763183594
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5959522724151611
len local_batched_seeds_list  2
partition total batch output list spend :  0.6835575103759766
self.buckets_partition() spend  sec:  0.6110031604766846
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04528641700744629

in edges time spent  0.1514732837677002
local to global src and eids time spent  0.27445554733276367
time gen tails  0.054340362548828125
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09747719764709473

in edges time spent  0.36786603927612305
local to global src and eids time spent  0.564974308013916
time gen tails  0.08508896827697754
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11021995544433594  GigaBytes
Max Memory Allocated: 13.519887924194336  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.03999137878418  GigaBytes
Max Memory Allocated: 13.519887924194336  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.03900146484375  GigaBytes
Max Memory Allocated: 13.519887924194336  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11390256881713867  GigaBytes
Max Memory Allocated: 13.519887924194336  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786223411560059  GigaBytes
Max Memory Allocated: 13.519887924194336  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791943073272705  GigaBytes
Max Memory Allocated: 13.519887924194336  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12557077407836914  GigaBytes
Max Memory Allocated: 13.519887924194336  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.761730194091797
pure train time :  0.44811558723449707
train time :  0.6082808971405029
end to end time :  4.227175951004028
connection check time:  1.9084663391113281
block generation time  1.0104358196258545
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004935264587402344
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01525259017944336
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7133574485778809
len local_batched_seeds_list  2
partition total batch output list spend :  0.8009159564971924
self.buckets_partition() spend  sec:  0.7287216186523438
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.044677734375

in edges time spent  0.15039348602294922
local to global src and eids time spent  0.27265477180480957
time gen tails  0.054001808166503906
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09796619415283203

in edges time spent  0.3626081943511963
local to global src and eids time spent  0.5637996196746826
time gen tails  0.0841531753540039
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11058330535888672  GigaBytes
Max Memory Allocated: 13.519887924194336  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04439401626587  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043056011199951  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11513090133666992  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.759365558624268  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.765085220336914  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12573528289794922  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.7022998332977295
pure train time :  0.45092153549194336
train time :  0.612907886505127
end to end time :  4.325554370880127
connection check time:  1.897514820098877
block generation time  0.9985625743865967
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004868507385253906
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014585256576538086
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6750950813293457
len local_batched_seeds_list  2
partition total batch output list spend :  0.7623720169067383
self.buckets_partition() spend  sec:  0.689713716506958
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04584193229675293

in edges time spent  0.15097522735595703
local to global src and eids time spent  0.27348780632019043
time gen tails  0.053971052169799805
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09737014770507812

in edges time spent  0.36335062980651855
local to global src and eids time spent  0.5654072761535645
time gen tails  0.08762550354003906
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11132001876831055  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041304588317871  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039639472961426  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1140589714050293  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.778297901153564  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784017562866211  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12400197982788086  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.6535589694976807
pure train time :  0.45255279541015625
train time :  0.6734941005706787
end to end time :  4.361034393310547
connection check time:  1.9090015888214111
block generation time  1.0001740455627441
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.03921794891357422
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015802383422851562
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7504701614379883
len local_batched_seeds_list  2
partition total batch output list spend :  0.8385248184204102
self.buckets_partition() spend  sec:  0.7663133144378662
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.046494483947753906

in edges time spent  0.15343785285949707
local to global src and eids time spent  0.2739739418029785
time gen tails  0.05516624450683594
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09805727005004883

in edges time spent  0.42552781105041504
local to global src and eids time spent  0.5659396648406982
time gen tails  0.08305716514587402
res  length 2
block collection to dataloader spend  1.4781951904296875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11110877990722656  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038283348083496  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037367343902588  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11486530303955078  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.782182693481445  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787902355194092  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12470817565917969  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.6060099601745605
pure train time :  0.4506967067718506
train time :  0.6261732578277588
end to end time :  4.456353425979614
connection check time:  1.9671483039855957
block generation time  0.9978704452514648
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004837512969970703
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014308452606201172
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.702289342880249
len local_batched_seeds_list  2
partition total batch output list spend :  0.7912404537200928
self.buckets_partition() spend  sec:  0.7166311740875244
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04539799690246582

in edges time spent  0.15256166458129883
local to global src and eids time spent  0.2727792263031006
time gen tails  0.05402517318725586
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09747982025146484

in edges time spent  0.36611461639404297
local to global src and eids time spent  0.5671343803405762
time gen tails  0.08385729789733887
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10999774932861328  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001887321472168  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001391410827637  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11359310150146484  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781662464141846  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787382125854492  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12329483032226562  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.5490224361419678
pure train time :  0.44815778732299805
train time :  0.6114575862884521
end to end time :  4.336626291275024
connection check time:  1.9072816371917725
block generation time  1.0123300552368164
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000453948974609375
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014231204986572266
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6767890453338623
len local_batched_seeds_list  2
partition total batch output list spend :  0.7630808353424072
self.buckets_partition() spend  sec:  0.6910552978515625
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04503321647644043

in edges time spent  0.15140318870544434
local to global src and eids time spent  0.27092599868774414
time gen tails  0.05638551712036133
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09491467475891113

in edges time spent  0.3857841491699219
local to global src and eids time spent  0.585615873336792
time gen tails  0.08737802505493164
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11085891723632812  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.99544906616211  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.994770050048828  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11397504806518555  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780576705932617  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786296367645264  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12496328353881836  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.4962551593780518
pure train time :  0.44922900199890137
train time :  0.6166470050811768
end to end time :  4.34991979598999
connection check time:  1.954589605331421
block generation time  0.9985265731811523
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0009810924530029297
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014167547225952148
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7172551155090332
len local_batched_seeds_list  2
partition total batch output list spend :  0.7616863250732422
self.buckets_partition() spend  sec:  0.7314555644989014
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04430866241455078

in edges time spent  0.1523609161376953
local to global src and eids time spent  0.2757608890533447
time gen tails  0.05391526222229004
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0973975658416748

in edges time spent  0.3726463317871094
local to global src and eids time spent  0.5733625888824463
time gen tails  0.08382654190063477
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11037492752075195  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000669002532959  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999850273132324  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11351346969604492  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792484283447266  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.798203945159912  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12414407730102539  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.447070598602295
pure train time :  0.4485933780670166
train time :  0.6192033290863037
end to end time :  4.320074081420898
connection check time:  1.9164578914642334
block generation time  1.0026707649230957
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005753040313720703
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014608144760131836
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7138195037841797
len local_batched_seeds_list  2
partition total batch output list spend :  0.8008854389190674
self.buckets_partition() spend  sec:  0.728463888168335
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04516768455505371

in edges time spent  0.15039801597595215
local to global src and eids time spent  0.27360010147094727
time gen tails  0.05414462089538574
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09517526626586914

in edges time spent  0.36763668060302734
local to global src and eids time spent  0.5778214931488037
time gen tails  0.0837717056274414
res  length 2
block collection to dataloader spend  1.5020370483398438e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10995244979858398  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001256942749023  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000523090362549  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11275291442871094  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785455703735352  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791175365447998  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12334823608398438  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.4090123176574707
pure train time :  0.4468724727630615
train time :  0.6066310405731201
end to end time :  4.332504510879517
connection check time:  1.916541576385498
block generation time  0.9938526153564453
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00047469139099121094
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014257669448852539
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7281732559204102
len local_batched_seeds_list  2
partition total batch output list spend :  0.8151545524597168
self.buckets_partition() spend  sec:  0.7424662113189697
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04541826248168945

in edges time spent  0.15098047256469727
local to global src and eids time spent  0.2728846073150635
time gen tails  0.054116010665893555
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09537410736083984

in edges time spent  0.3625640869140625
local to global src and eids time spent  0.5668871402740479
time gen tails  0.0839836597442627
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10995149612426758  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002407550811768  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002544403076172  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11466693878173828  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78047227859497  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786191940307617  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12452507019042969  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.367100477218628
pure train time :  0.44508790969848633
train time :  0.6046724319458008
end to end time :  4.348501682281494
connection check time:  1.9002814292907715
block generation time  1.0078482627868652
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004336833953857422
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015215873718261719
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6030104160308838
len local_batched_seeds_list  2
partition total batch output list spend :  0.6899197101593018
self.buckets_partition() spend  sec:  0.6182606220245361
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04518246650695801

in edges time spent  0.150709867477417
local to global src and eids time spent  0.272676944732666
time gen tails  0.05408525466918945
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0956718921661377

in edges time spent  0.3622570037841797
local to global src and eids time spent  0.5689363479614258
time gen tails  0.0829305648803711
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11017608642578125  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043953895568848  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043296813964844  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11502313613891602  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790416717529297  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796136379241943  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12561655044555664  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.328517436981201
pure train time :  0.439422607421875
train time :  0.602790117263794
end to end time :  4.197304964065552
connection check time:  1.898421049118042
block generation time  0.9883651733398438
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004737377166748047
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014267683029174805
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6739473342895508
len local_batched_seeds_list  2
partition total batch output list spend :  0.7598481178283691
self.buckets_partition() spend  sec:  0.6882481575012207
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04440450668334961

in edges time spent  0.14824628829956055
local to global src and eids time spent  0.2697639465332031
time gen tails  0.05347466468811035
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09691882133483887

in edges time spent  0.3669471740722656
local to global src and eids time spent  0.5725317001342773
time gen tails  0.08397817611694336
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11130762100219727  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041462421417236  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040678024291992  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1145930290222168  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786917209625244  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79263687133789  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12440156936645508  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.2926180362701416
pure train time :  0.44585728645324707
train time :  0.6176877021789551
end to end time :  4.286564588546753
connection check time:  1.9022679328918457
block generation time  0.991844654083252
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005249977111816406
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014836549758911133
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6820583343505859
len local_batched_seeds_list  2
partition total batch output list spend :  0.7690093517303467
self.buckets_partition() spend  sec:  0.6969294548034668
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04692244529724121

in edges time spent  0.15677404403686523
local to global src and eids time spent  0.2744441032409668
time gen tails  0.05402827262878418
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09668660163879395

in edges time spent  0.3905637264251709
local to global src and eids time spent  0.5791192054748535
time gen tails  0.08617830276489258
res  length 2
block collection to dataloader spend  6.67572021484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1109309196472168  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042917251586914  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04304313659668  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11501312255859375  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.768856048583984  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.77457571029663  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1245431900024414  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.2610645294189453
pure train time :  0.43734312057495117
train time :  0.6130197048187256
end to end time :  4.353543758392334
connection check time:  1.9532427787780762
block generation time  0.9969637393951416
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0006406307220458984
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014485836029052734
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7344675064086914
len local_batched_seeds_list  2
partition total batch output list spend :  0.8210606575012207
self.buckets_partition() spend  sec:  0.7489848136901855
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04516863822937012

in edges time spent  0.15132856369018555
local to global src and eids time spent  0.26946187019348145
time gen tails  0.05337190628051758
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0949709415435791

in edges time spent  0.35683393478393555
local to global src and eids time spent  0.5193541049957275
time gen tails  0.05852103233337402
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10967111587524414  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.996887683868408  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.996429443359375  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11383533477783203  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785539627075195  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791259288787842  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12364530563354492  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.2138164043426514
pure train time :  0.4467349052429199
train time :  0.605750560760498
end to end time :  4.198235034942627
connection check time:  1.803217887878418
block generation time  0.9490265846252441
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005061626434326172
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015113115310668945
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.649979829788208
len local_batched_seeds_list  2
partition total batch output list spend :  0.6950712203979492
self.buckets_partition() spend  sec:  0.6651265621185303
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04068303108215332

in edges time spent  0.14277935028076172
local to global src and eids time spent  0.2619307041168213
time gen tails  0.051850318908691406
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08999252319335938

in edges time spent  0.3447725772857666
local to global src and eids time spent  0.5350711345672607
time gen tails  0.08005380630493164
res  length 2
block collection to dataloader spend  1.430511474609375e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11000728607177734  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003452777862549  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003537654876709  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11455488204956055  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780350685119629  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786070346832275  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1252436637878418  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.17897367477417
pure train time :  0.4316720962524414
train time :  0.5945498943328857
end to end time :  4.036598443984985
connection check time:  1.791269302368164
block generation time  0.9339625835418701
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00048613548278808594
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013766050338745117
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6784799098968506
len local_batched_seeds_list  2
partition total batch output list spend :  0.7630913257598877
self.buckets_partition() spend  sec:  0.692279577255249
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0426027774810791

in edges time spent  0.14308762550354004
local to global src and eids time spent  0.259901762008667
time gen tails  0.0519869327545166
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09078025817871094

in edges time spent  0.3634324073791504
local to global src and eids time spent  0.5598859786987305
time gen tails  0.08202672004699707
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11122322082519531  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.0011887550354  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000149726867676  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1148386001586914  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786792755126953  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.7925124168396  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1246023178100586  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.1406726837158203
pure train time :  0.4432508945465088
train time :  0.6065165996551514
end to end time :  4.2041015625
connection check time:  1.8493194580078125
block generation time  0.9669625759124756
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004279613494873047
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014085531234741211
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6915326118469238
len local_batched_seeds_list  2
partition total batch output list spend :  0.7772471904754639
self.buckets_partition() spend  sec:  0.7056519985198975
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04456782341003418

in edges time spent  0.14960002899169922
local to global src and eids time spent  0.2684321403503418
time gen tails  0.05317950248718262
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09103536605834961

in edges time spent  0.36402416229248047
local to global src and eids time spent  0.5678610801696777
time gen tails  0.08363676071166992
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11053609848022461  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041460990905762  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040778636932373  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11499786376953125  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786985874176025  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792705535888672  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12511253356933594  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.1004929542541504
pure train time :  0.43174266815185547
train time :  0.5906329154968262
end to end time :  4.2379443645477295
connection check time:  1.88413667678833
block generation time  0.9686794281005859
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004928112030029297
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014020204544067383
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6922099590301514
len local_batched_seeds_list  2
partition total batch output list spend :  0.7783825397491455
self.buckets_partition() spend  sec:  0.7062649726867676
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04538154602050781

in edges time spent  0.1446847915649414
local to global src and eids time spent  0.2740781307220459
time gen tails  0.053427696228027344
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09880495071411133

in edges time spent  0.34989213943481445
local to global src and eids time spent  0.5397167205810547
time gen tails  0.07953548431396484
res  length 2
block collection to dataloader spend  6.67572021484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11026573181152344  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.0028657913208  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002965927124023  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11434459686279297  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789210319519043  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79492998123169  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12461042404174805  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.0598912239074707
pure train time :  0.4401719570159912
train time :  0.6044485569000244
end to end time :  4.186043739318848
connection check time:  1.839674711227417
block generation time  0.9447646141052246
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004394054412841797
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015071868896484375
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5789179801940918
len local_batched_seeds_list  2
partition total batch output list spend :  0.665952205657959
self.buckets_partition() spend  sec:  0.594029426574707
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04250788688659668

in edges time spent  0.14345622062683105
local to global src and eids time spent  0.2603440284729004
time gen tails  0.05245518684387207
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0899355411529541

in edges time spent  0.36224365234375
local to global src and eids time spent  0.5456609725952148
time gen tails  0.08508968353271484
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11014747619628906  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002326011657715  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001401901245117  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11451578140258789  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786333084106445  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792052745819092  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12458276748657227  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.0258824825286865
pure train time :  0.4317173957824707
train time :  0.5939128398895264
end to end time :  4.063857555389404
connection check time:  1.8376350402832031
block generation time  0.9462845325469971
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005114078521728516
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015334844589233398
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6639199256896973
len local_batched_seeds_list  2
partition total batch output list spend :  0.7508058547973633
self.buckets_partition() spend  sec:  0.679288387298584
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0460963249206543

in edges time spent  0.15213537216186523
local to global src and eids time spent  0.2868812084197998
time gen tails  0.05458784103393555
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09522604942321777

in edges time spent  0.38988208770751953
local to global src and eids time spent  0.5683882236480713
time gen tails  0.08156824111938477
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1099543571472168  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042107582092285  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041382312774658  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11339759826660156  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788112163543701  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793831825256348  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12421989440917969  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.98984694480896
pure train time :  0.4358551502227783
train time :  0.6052348613739014
end to end time :  4.290547609329224
connection check time:  1.9643895626068115
block generation time  0.9518091678619385
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004642009735107422
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01455068588256836
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7201478481292725
len local_batched_seeds_list  2
partition total batch output list spend :  0.807025671005249
self.buckets_partition() spend  sec:  0.7347369194030762
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042616844177246094

in edges time spent  0.1448194980621338
local to global src and eids time spent  0.26091742515563965
time gen tails  0.05276179313659668
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0923166275024414

in edges time spent  0.36543798446655273
local to global src and eids time spent  0.551159143447876
time gen tails  0.07874441146850586
res  length 2
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11043596267700195  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043773174285889  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042859077453613  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11450767517089844  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.768006324768066  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.773725986480713  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12453937530517578  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.948782205581665
pure train time :  0.44555044174194336
train time :  0.610952615737915
end to end time :  4.216593265533447
connection check time:  1.8392043113708496
block generation time  0.9353969097137451
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005905628204345703
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014318466186523438
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6819882392883301
len local_batched_seeds_list  2
partition total batch output list spend :  0.7667102813720703
self.buckets_partition() spend  sec:  0.6963398456573486
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04325389862060547

in edges time spent  0.14320015907287598
local to global src and eids time spent  0.25864624977111816
time gen tails  0.0520014762878418
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09067058563232422

in edges time spent  0.3588738441467285
local to global src and eids time spent  0.5662176609039307
time gen tails  0.08334469795227051
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11086654663085938  GigaBytes
Max Memory Allocated: 13.52022647857666  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.047104358673096  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.046432971954346  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1146702766418457  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787232398986816  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792952060699463  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12446260452270508  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.924466848373413
pure train time :  0.4452648162841797
train time :  0.605231761932373
end to end time :  4.223681926727295
connection check time:  1.855851650238037
block generation time  0.9805047512054443
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004868507385253906
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014014959335327148
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6727035045623779
len local_batched_seeds_list  2
partition total batch output list spend :  0.7591462135314941
self.buckets_partition() spend  sec:  0.6867513656616211
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04492831230163574

in edges time spent  0.14702153205871582
local to global src and eids time spent  0.2590487003326416
time gen tails  0.051750898361206055
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08879446983337402

in edges time spent  0.34781575202941895
local to global src and eids time spent  0.5672268867492676
time gen tails  0.08018350601196289
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10992860794067383  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000162124633789  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999452114105225  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11529254913330078  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791420936584473  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79714059829712  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1258711814880371  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.897599458694458
pure train time :  0.43999719619750977
train time :  0.5969703197479248
end to end time :  4.140671968460083
connection check time:  1.8362901210784912
block generation time  0.9343676567077637
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005121231079101562
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01457977294921875
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6807763576507568
len local_batched_seeds_list  2
partition total batch output list spend :  0.7675867080688477
self.buckets_partition() spend  sec:  0.6953911781311035
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04275918006896973

in edges time spent  0.14566922187805176
local to global src and eids time spent  0.2615327835083008
time gen tails  0.051911354064941406
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09043455123901367

in edges time spent  0.3553738594055176
local to global src and eids time spent  0.5480053424835205
time gen tails  0.08040285110473633
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1112823486328125  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.007112503051758  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.005506038665771  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11405420303344727  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790246963500977  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.795966625213623  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12580156326293945  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.8790128231048584
pure train time :  0.4463183879852295
train time :  0.6049468517303467
end to end time :  4.143990516662598
connection check time:  1.825829029083252
block generation time  0.931877851486206
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00046324729919433594
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014403581619262695
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6874411106109619
len local_batched_seeds_list  2
partition total batch output list spend :  0.773859977722168
self.buckets_partition() spend  sec:  0.7019555568695068
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042430877685546875

in edges time spent  0.14377236366271973
local to global src and eids time spent  0.2609424591064453
time gen tails  0.05160403251647949
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09078788757324219

in edges time spent  0.3598294258117676
local to global src and eids time spent  0.550217866897583
time gen tails  0.07944679260253906
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11011552810668945  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00331974029541  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002431392669678  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1137547492980957  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788814544677734  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79453420639038  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12350130081176758  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.846703290939331
pure train time :  0.4391136169433594
train time :  0.5984148979187012
end to end time :  4.152560472488403
connection check time:  1.8295526504516602
block generation time  0.9326877593994141
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004830360412597656
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014175176620483398
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6915733814239502
len local_batched_seeds_list  2
partition total batch output list spend :  0.7777972221374512
self.buckets_partition() spend  sec:  0.7057840824127197
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04292011260986328

in edges time spent  0.14437317848205566
local to global src and eids time spent  0.259676456451416
time gen tails  0.05239224433898926
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09029674530029297

in edges time spent  0.34354615211486816
local to global src and eids time spent  0.5341253280639648
time gen tails  0.07993841171264648
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1099696159362793  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04532527923584  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04459524154663  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11278200149536133  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.753689289093018  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.759408950805664  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1235804557800293  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.810816764831543
pure train time :  0.4381887912750244
train time :  0.5976455211639404
end to end time :  4.123719692230225
connection check time:  1.7968401908874512
block generation time  0.9344916343688965
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.001093149185180664
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014330148696899414
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.699094295501709
len local_batched_seeds_list  2
partition total batch output list spend :  0.7867031097412109
self.buckets_partition() spend  sec:  0.7135055065155029
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04477977752685547

in edges time spent  0.15082645416259766
local to global src and eids time spent  0.2683103084564209
time gen tails  0.05309748649597168
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09298944473266602

in edges time spent  0.3465867042541504
local to global src and eids time spent  0.5320827960968018
time gen tails  0.0794222354888916
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11017370223999023  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041055679321289  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041255474090576  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11474132537841797  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784055709838867  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789775371551514  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12431478500366211  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.795314073562622
pure train time :  0.4543466567993164
train time :  0.6237263679504395
end to end time :  4.187890529632568
connection check time:  1.817753553390503
block generation time  0.9410099983215332
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004956722259521484
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014662027359008789
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5741024017333984
len local_batched_seeds_list  2
partition total batch output list spend :  0.6602005958557129
self.buckets_partition() spend  sec:  0.5888006687164307
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04270434379577637

in edges time spent  0.14874887466430664
local to global src and eids time spent  0.2611696720123291
time gen tails  0.052405357360839844
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09107136726379395

in edges time spent  0.3482978343963623
local to global src and eids time spent  0.49756503105163574
time gen tails  0.05888938903808594
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10986948013305664  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038968563079834  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.03832721710205  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11328697204589844  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796674728393555  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.802394390106201  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12462472915649414  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.761070728302002
pure train time :  0.44612836837768555
train time :  0.6106469631195068
end to end time :  3.9752414226531982
connection check time:  1.7543573379516602
block generation time  0.9354944229125977
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000522613525390625
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01746225357055664
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6529872417449951
len local_batched_seeds_list  2
partition total batch output list spend :  0.7000243663787842
self.buckets_partition() spend  sec:  0.6704821586608887
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04742860794067383

in edges time spent  0.1351001262664795
local to global src and eids time spent  0.2153785228729248
time gen tails  0.03910541534423828
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09044361114501953

in edges time spent  0.3449592590332031
local to global src and eids time spent  0.5331299304962158
time gen tails  0.0793297290802002
res  length 2
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11014604568481445  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.007009029388428  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00609302520752  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11532115936279297  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780455112457275  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786174774169922  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12518739700317383  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.7445104122161865
pure train time :  0.43624353408813477
train time :  0.608372688293457
end to end time :  3.987056016921997
connection check time:  1.729109525680542
block generation time  0.9342765808105469
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004963874816894531
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014218568801879883
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6610822677612305
len local_batched_seeds_list  2
partition total batch output list spend :  0.7447218894958496
self.buckets_partition() spend  sec:  0.6753356456756592
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04301023483276367

in edges time spent  0.1451857089996338
local to global src and eids time spent  0.2604644298553467
time gen tails  0.05246281623840332
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09179353713989258

in edges time spent  0.35915231704711914
local to global src and eids time spent  0.5564327239990234
time gen tails  0.08230757713317871
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11136913299560547  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.006077766418457  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.005236625671387  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11490488052368164  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785248756408691  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790968418121338  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12468862533569336  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.7159994840621948
pure train time :  0.4397003650665283
train time :  0.6066451072692871
end to end time :  4.188745498657227
connection check time:  1.846975326538086
block generation time  0.9737410545349121
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004999637603759766
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013763189315795898
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6737911701202393
len local_batched_seeds_list  2
partition total batch output list spend :  0.7584958076477051
self.buckets_partition() spend  sec:  0.6875872611999512
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04410839080810547

in edges time spent  0.15005207061767578
local to global src and eids time spent  0.2693798542022705
time gen tails  0.053262948989868164
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09469223022460938

in edges time spent  0.35881876945495605
local to global src and eids time spent  0.5578081607818604
time gen tails  0.0827937126159668
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10991907119750977  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00007152557373  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999369144439697  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11434602737426758  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.799629211425781  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.805348873138428  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1239466667175293  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.701904058456421
pure train time :  0.4410536289215088
train time :  0.6006295680999756
end to end time :  4.224383354187012
connection check time:  1.8719909191131592
block generation time  0.9764795303344727
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004620552062988281
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015033960342407227
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6531705856323242
len local_batched_seeds_list  2
partition total batch output list spend :  0.6978151798248291
self.buckets_partition() spend  sec:  0.6682376861572266
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04225969314575195

in edges time spent  0.14563560485839844
local to global src and eids time spent  0.26322507858276367
time gen tails  0.05223536491394043
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09086990356445312

in edges time spent  0.35733985900878906
local to global src and eids time spent  0.5558230876922607
time gen tails  0.0820474624633789
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1100153923034668  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.99825382232666  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997453212738037  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1137080192565918  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.761865139007568  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.767584800720215  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12346744537353516  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.6748055219650269
pure train time :  0.44072461128234863
train time :  0.6000747680664062
end to end time :  4.116399049758911
connection check time:  1.8443706035614014
block generation time  0.9595956802368164
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00043487548828125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015491485595703125
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6764616966247559
len local_batched_seeds_list  2
partition total batch output list spend :  0.7627415657043457
self.buckets_partition() spend  sec:  0.6919877529144287
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04673480987548828

in edges time spent  0.16538214683532715
local to global src and eids time spent  0.2737081050872803
time gen tails  0.055498361587524414
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09583759307861328

in edges time spent  0.3833348751068115
local to global src and eids time spent  0.5659542083740234
time gen tails  0.08342218399047852
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11021566390991211  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040529251098633  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039543628692627  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11336421966552734  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780909061431885  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786628723144531  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12410449981689453  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.661894679069519
pure train time :  0.4433906078338623
train time :  0.6135604381561279
end to end time :  4.285060405731201
connection check time:  1.9340298175811768
block generation time  0.9552278518676758
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004627704620361328
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01477360725402832
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7179915904998779
len local_batched_seeds_list  2
partition total batch output list spend :  0.804619312286377
self.buckets_partition() spend  sec:  0.7328057289123535
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043775081634521484

in edges time spent  0.15027093887329102
local to global src and eids time spent  0.2653615474700928
time gen tails  0.05212855339050293
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09067463874816895

in edges time spent  0.3515355587005615
local to global src and eids time spent  0.5098011493682861
time gen tails  0.058069705963134766
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11035537719726562  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039716720581055  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038589477539062  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11335611343383789  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79112720489502  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796846866607666  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12415838241577148  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.6362248659133911
pure train time :  0.43953394889831543
train time :  0.59739089012146
end to end time :  4.131795644760132
connection check time:  1.7711491584777832
block generation time  0.9449889659881592
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004527568817138672
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015350818634033203
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6780714988708496
len local_batched_seeds_list  2
partition total batch output list spend :  0.7232818603515625
self.buckets_partition() spend  sec:  0.6934547424316406
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043440818786621094

in edges time spent  0.14580392837524414
local to global src and eids time spent  0.26143622398376465
time gen tails  0.0523533821105957
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0918436050415039

in edges time spent  0.36421799659729004
local to global src and eids time spent  0.5432543754577637
time gen tails  0.07964801788330078
res  length 2
block collection to dataloader spend  6.67572021484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11040115356445312  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041368007659912  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040479183197021  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11289644241333008  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786019325256348  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791738986968994  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12371826171875  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.6204485893249512
pure train time :  0.4416470527648926
train time :  0.6012322902679443
end to end time :  4.104477643966675
connection check time:  1.8269567489624023
block generation time  0.9340939521789551
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00047206878662109375
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01386404037475586
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.642268180847168
len local_batched_seeds_list  2
partition total batch output list spend :  0.7276077270507812
self.buckets_partition() spend  sec:  0.6561670303344727
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04273104667663574

in edges time spent  0.14320874214172363
local to global src and eids time spent  0.26021361351013184
time gen tails  0.052355051040649414
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09640622138977051

in edges time spent  0.35279083251953125
local to global src and eids time spent  0.5357329845428467
time gen tails  0.08047032356262207
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10989189147949219  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002683639526367  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00201940536499  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11446189880371094  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.76699686050415  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.772716522216797  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12437820434570312  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.5989574193954468
pure train time :  0.443936824798584
train time :  0.6070632934570312
end to end time :  4.136655807495117
connection check time:  1.8141920566558838
block generation time  0.9688210487365723
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004596710205078125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015256166458129883
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5957729816436768
len local_batched_seeds_list  2
partition total batch output list spend :  0.6903092861175537
self.buckets_partition() spend  sec:  0.6110649108886719
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04462933540344238

in edges time spent  0.15161967277526855
local to global src and eids time spent  0.2636275291442871
time gen tails  0.051894426345825195
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08974742889404297

in edges time spent  0.38374996185302734
local to global src and eids time spent  0.56890869140625
time gen tails  0.08279633522033691
res  length 2
block collection to dataloader spend  1.1444091796875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11005687713623047  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004156112670898  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003323554992676  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1146702766418457  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78930139541626  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.795021057128906  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12462472915649414  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.579068660736084
pure train time :  0.43866848945617676
train time :  0.609156608581543
end to end time :  4.155987739562988
connection check time:  1.8928356170654297
block generation time  0.943378210067749
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0006971359252929688
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014491796493530273
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6904740333557129
len local_batched_seeds_list  2
partition total batch output list spend :  0.775954008102417
self.buckets_partition() spend  sec:  0.7050020694732666
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042377471923828125

in edges time spent  0.14354300498962402
local to global src and eids time spent  0.2596125602722168
time gen tails  0.0521845817565918
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09109187126159668

in edges time spent  0.35832715034484863
local to global src and eids time spent  0.5427672863006592
time gen tails  0.08015632629394531
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10982990264892578  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002073287963867  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00146198272705  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11452007293701172  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79227876663208  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.797998428344727  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12458038330078125  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.5676863193511963
pure train time :  0.43140459060668945
train time :  0.5913403034210205
end to end time :  4.158478498458862
connection check time:  1.8212437629699707
block generation time  0.9537441730499268
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00047588348388671875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013998985290527344
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6891684532165527
len local_batched_seeds_list  2
partition total batch output list spend :  0.7760756015777588
self.buckets_partition() spend  sec:  0.7032060623168945
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042310476303100586

in edges time spent  0.145888090133667
local to global src and eids time spent  0.2601954936981201
time gen tails  0.05206465721130371
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08987140655517578

in edges time spent  0.3548765182495117
local to global src and eids time spent  0.5491514205932617
time gen tails  0.08085322380065918
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11049556732177734  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00276517868042  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002639293670654  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11445999145507812  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.761005878448486  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.766725540161133  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12487220764160156  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.5460807085037231
pure train time :  0.44212818145751953
train time :  0.6165285110473633
end to end time :  4.167949199676514
connection check time:  1.825791358947754
block generation time  0.9358611106872559
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00051116943359375
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.020413875579833984
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6420583724975586
len local_batched_seeds_list  2
partition total batch output list spend :  0.7329390048980713
self.buckets_partition() spend  sec:  0.6625056266784668
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04493141174316406

in edges time spent  0.15976667404174805
local to global src and eids time spent  0.26725292205810547
time gen tails  0.05346989631652832
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09427833557128906

in edges time spent  0.3923680782318115
local to global src and eids time spent  0.5666015148162842
time gen tails  0.08275032043457031
res  length 2
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11031579971313477  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042089462280273  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041293621063232  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11445236206054688  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780490398406982  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786210060119629  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12462186813354492  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.532529592514038
pure train time :  0.4371180534362793
train time :  0.606844425201416
end to end time :  4.247370958328247
connection check time:  1.920403003692627
block generation time  0.9695773124694824
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004990100860595703
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01483154296875
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7102525234222412
len local_batched_seeds_list  2
partition total batch output list spend :  0.7972733974456787
self.buckets_partition() spend  sec:  0.7251286506652832
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04446053504943848

in edges time spent  0.1491866111755371
local to global src and eids time spent  0.26888489723205566
time gen tails  0.053392887115478516
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09370946884155273

in edges time spent  0.35077333450317383
local to global src and eids time spent  0.5352225303649902
time gen tails  0.08055734634399414
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11005020141601562  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042880535125732  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043212413787842  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11453914642333984  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785206317901611  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790925979614258  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12497234344482422  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.516553521156311
pure train time :  0.44234585762023926
train time :  0.6059894561767578
end to end time :  4.199626445770264
connection check time:  1.8305213451385498
block generation time  0.9511752128601074
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005137920379638672
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014309883117675781
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6818499565124512
len local_batched_seeds_list  2
partition total batch output list spend :  0.7679429054260254
self.buckets_partition() spend  sec:  0.6961929798126221
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042656660079956055

in edges time spent  0.1444568634033203
local to global src and eids time spent  0.2617495059967041
time gen tails  0.05221962928771973
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09082341194152832

in edges time spent  0.3580322265625
local to global src and eids time spent  0.5550470352172852
time gen tails  0.08256077766418457
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11030006408691406  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.996843814849854  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.996047496795654  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11433267593383789  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788462162017822  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.794181823730469  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12406778335571289  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.5013307332992554
pure train time :  0.4406743049621582
train time :  0.6014823913574219
end to end time :  4.208983898162842
connection check time:  1.8433516025543213
block generation time  0.9790832996368408
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005342960357666016
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014521360397338867
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7015302181243896
len local_batched_seeds_list  2
partition total batch output list spend :  0.787773847579956
self.buckets_partition() spend  sec:  0.7160913944244385
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04519200325012207

in edges time spent  0.15209317207336426
local to global src and eids time spent  0.27019500732421875
time gen tails  0.05349302291870117
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09473586082458496

in edges time spent  0.3530290126800537
local to global src and eids time spent  0.5584626197814941
time gen tails  0.08266091346740723
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11114835739135742  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002184391021729  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001222133636475  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1142721176147461  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791616439819336  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.797336101531982  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12487602233886719  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4910306930541992
pure train time :  0.455935001373291
train time :  0.61785888671875
end to end time :  4.284654140472412
connection check time:  1.8715848922729492
block generation time  0.9900777339935303
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00048732757568359375
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014692306518554688
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6755831241607666
len local_batched_seeds_list  2
partition total batch output list spend :  0.7620096206665039
self.buckets_partition() spend  sec:  0.6903116703033447
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04756784439086914

in edges time spent  0.15911579132080078
local to global src and eids time spent  0.27068638801574707
time gen tails  0.05708479881286621
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09128689765930176

in edges time spent  0.3773612976074219
local to global src and eids time spent  0.579824686050415
time gen tails  0.08105087280273438
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1111445426940918  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044220924377441  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043269634246826  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11392402648925781  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.777845859527588  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.783565521240234  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12469720840454102  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4746520519256592
pure train time :  0.43711113929748535
train time :  0.6066365242004395
end to end time :  4.261465072631836
connection check time:  1.9271965026855469
block generation time  0.9514622688293457
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004966259002685547
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.017772674560546875
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6994054317474365
len local_batched_seeds_list  2
partition total batch output list spend :  0.7901897430419922
self.buckets_partition() spend  sec:  0.717212438583374
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04676079750061035

in edges time spent  0.14948678016662598
local to global src and eids time spent  0.27187275886535645
time gen tails  0.05309295654296875
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09001374244689941

in edges time spent  0.366560697555542
local to global src and eids time spent  0.5553698539733887
time gen tails  0.08010315895080566
res  length 2
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11012887954711914  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.045942783355713  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.045052528381348  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11434030532836914  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.757955074310303  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.76367473602295  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12437009811401367  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4684710502624512
pure train time :  0.4395112991333008
train time :  0.6085186004638672
end to end time :  4.227446794509888
connection check time:  1.8671863079071045
block generation time  0.9399161338806152
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005335807800292969
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.017802953720092773
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5949389934539795
len local_batched_seeds_list  2
partition total batch output list spend :  0.6846230030059814
self.buckets_partition() spend  sec:  0.6127834320068359
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04440045356750488

in edges time spent  0.14931273460388184
local to global src and eids time spent  0.26329946517944336
time gen tails  0.05477643013000488
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.10014772415161133

in edges time spent  0.33511924743652344
local to global src and eids time spent  0.4914379119873047
time gen tails  0.05843853950500488
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10990047454833984  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043866157531738  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043192863464355  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11310195922851562  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.772063255310059  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.777782917022705  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12482118606567383  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4512217044830322
pure train time :  0.44011735916137695
train time :  0.6064600944519043
end to end time :  4.017378091812134
connection check time:  1.75380277633667
block generation time  0.9591166973114014
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004985332489013672
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015397071838378906
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6497573852539062
len local_batched_seeds_list  2
partition total batch output list spend :  0.6955816745758057
self.buckets_partition() spend  sec:  0.6652629375457764
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.040227651596069336

in edges time spent  0.13917279243469238
local to global src and eids time spent  0.2609703540802002
time gen tails  0.05206179618835449
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09038448333740234

in edges time spent  0.34068799018859863
local to global src and eids time spent  0.5356903076171875
time gen tails  0.07932090759277344
res  length 2
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11060714721679688  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043313980102539  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042222023010254  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11327171325683594  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.77209186553955  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.777811527252197  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12398147583007812  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4388725757598877
pure train time :  0.4394419193267822
train time :  0.5995676517486572
end to end time :  4.028245687484741
connection check time:  1.7840592861175537
block generation time  0.9320096969604492
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004839897155761719
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015731096267700195
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6842124462127686
len local_batched_seeds_list  2
partition total batch output list spend :  0.7714166641235352
self.buckets_partition() spend  sec:  0.6999819278717041
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04557299613952637

in edges time spent  0.15166211128234863
local to global src and eids time spent  0.2700693607330322
time gen tails  0.05227160453796387
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.089691162109375

in edges time spent  0.3688225746154785
local to global src and eids time spent  0.5579073429107666
time gen tails  0.08106112480163574
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1103515625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040257453918457  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04000186920166  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11367511749267578  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.76311206817627  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.768831729888916  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12381124496459961  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4312162399291992
pure train time :  0.44267749786376953
train time :  0.6126060485839844
end to end time :  4.2199625968933105
connection check time:  1.872279167175293
block generation time  0.943842887878418
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00048470497131347656
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013677358627319336
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6422147750854492
len local_batched_seeds_list  2
partition total batch output list spend :  0.7246663570404053
self.buckets_partition() spend  sec:  0.6559250354766846
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04488563537597656

in edges time spent  0.15642619132995605
local to global src and eids time spent  0.2686750888824463
time gen tails  0.05249643325805664
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09007453918457031

in edges time spent  0.34816408157348633
local to global src and eids time spent  0.5017986297607422
time gen tails  0.058272361755371094
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11028099060058594  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.994184494018555  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.993393898010254  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11434602737426758  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790844440460205  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796564102172852  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1249384880065918  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4176311492919922
pure train time :  0.43532252311706543
train time :  0.6077711582183838
end to end time :  4.088477373123169
connection check time:  1.806079626083374
block generation time  0.9358758926391602
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005192756652832031
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015457868576049805
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6376121044158936
len local_batched_seeds_list  2
partition total batch output list spend :  0.6828091144561768
self.buckets_partition() spend  sec:  0.6531085968017578
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04119062423706055

in edges time spent  0.14992284774780273
local to global src and eids time spent  0.2633075714111328
time gen tails  0.05228304862976074
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09107160568237305

in edges time spent  0.36340808868408203
local to global src and eids time spent  0.5470123291015625
time gen tails  0.08072757720947266
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1112065315246582  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004509925842285  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003851890563965  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1149134635925293  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789587020874023  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79530668258667  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1255664825439453  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.409639835357666
pure train time :  0.43401503562927246
train time :  0.5923891067504883
end to end time :  4.071760654449463
connection check time:  1.8350262641906738
block generation time  0.9388985633850098
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004658699035644531
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014798641204833984
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6966612339019775
len local_batched_seeds_list  2
partition total batch output list spend :  0.7826752662658691
self.buckets_partition() spend  sec:  0.7114946842193604
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042511940002441406

in edges time spent  0.14589142799377441
local to global src and eids time spent  0.2614307403564453
time gen tails  0.051827430725097656
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09048175811767578

in edges time spent  0.3493373394012451
local to global src and eids time spent  0.538062334060669
time gen tails  0.08047866821289062
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10983657836914062  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002828598022461  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003080368041992  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11478233337402344  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.800918579101562  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.806638240814209  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12490272521972656  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.398725152015686
pure train time :  0.42907094955444336
train time :  0.5897932052612305
end to end time :  4.150265216827393
connection check time:  1.8096396923065186
block generation time  0.9493327140808105
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004935264587402344
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014167308807373047
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6382882595062256
len local_batched_seeds_list  2
partition total batch output list spend :  0.7235262393951416
self.buckets_partition() spend  sec:  0.652489185333252
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04269719123840332

in edges time spent  0.14471006393432617
local to global src and eids time spent  0.26097965240478516
time gen tails  0.05232810974121094
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09075570106506348

in edges time spent  0.3458991050720215
local to global src and eids time spent  0.5397815704345703
time gen tails  0.08016824722290039
res  length 2
block collection to dataloader spend  6.67572021484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11000537872314453  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040411949157715  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039915084838867  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11457633972167969  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780662059783936  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786381721496582  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12495136260986328  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.388554573059082
pure train time :  0.43603992462158203
train time :  0.5944795608520508
end to end time :  4.086829662322998
connection check time:  1.8068757057189941
block generation time  0.9432055950164795
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005195140838623047
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014203071594238281
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6462023258209229
len local_batched_seeds_list  2
partition total batch output list spend :  0.7309658527374268
self.buckets_partition() spend  sec:  0.6604471206665039
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04352426528930664

in edges time spent  0.14409756660461426
local to global src and eids time spent  0.26126646995544434
time gen tails  0.05186009407043457
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09056925773620605

in edges time spent  0.33110952377319336
local to global src and eids time spent  0.4940989017486572
time gen tails  0.057488203048706055
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11026144027709961  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041651248931885  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040903091430664  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11433601379394531  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789604187011719  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.795323848724365  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1238412857055664  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3784418106079102
pure train time :  0.4423253536224365
train time :  0.6131212711334229
end to end time :  4.024910926818848
connection check time:  1.7246603965759277
block generation time  0.9422059059143066
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005159378051757812
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01477956771850586
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6563456058502197
len local_batched_seeds_list  2
partition total batch output list spend :  0.7399158477783203
self.buckets_partition() spend  sec:  0.671159029006958
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.045121192932128906

in edges time spent  0.15566492080688477
local to global src and eids time spent  0.27264881134033203
time gen tails  0.05216860771179199
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09016633033752441

in edges time spent  0.3702390193939209
local to global src and eids time spent  0.5493381023406982
time gen tails  0.08252978324890137
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10997200012207031  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039892196655273  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040011405944824  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11458683013916016  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.783029079437256  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788748741149902  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1244964599609375  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3678028583526611
pure train time :  0.4400637149810791
train time :  0.6086220741271973
end to end time :  4.203308582305908
connection check time:  1.9019079208374023
block generation time  0.9294509887695312
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004589557647705078
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014204263687133789
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5927503108978271
len local_batched_seeds_list  2
partition total batch output list spend :  0.6777498722076416
self.buckets_partition() spend  sec:  0.6069931983947754
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04267573356628418

in edges time spent  0.15206456184387207
local to global src and eids time spent  0.2639954090118408
time gen tails  0.05188918113708496
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08960485458374023

in edges time spent  0.3446681499481201
local to global src and eids time spent  0.5314891338348389
time gen tails  0.07975387573242188
res  length 2
block collection to dataloader spend  1.0967254638671875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1097874641418457  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040693283081055  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040135860443115  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11342048645019531  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786542892456055  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792262554168701  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12488842010498047  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3618333339691162
pure train time :  0.44133925437927246
train time :  0.6035945415496826
end to end time :  4.041919231414795
connection check time:  1.8057208061218262
block generation time  0.9374606609344482
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004773139953613281
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014002323150634766
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.690650224685669
len local_batched_seeds_list  2
partition total batch output list spend :  0.7751760482788086
self.buckets_partition() spend  sec:  0.7046859264373779
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04250597953796387

in edges time spent  0.14478087425231934
local to global src and eids time spent  0.25853466987609863
time gen tails  0.05182456970214844
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09062433242797852

in edges time spent  0.3385472297668457
local to global src and eids time spent  0.5297338962554932
time gen tails  0.07887887954711914
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11037826538085938  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002823829650879  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001946449279785  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11479902267456055  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.7877836227417  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793503284454346  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1251049041748047  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3542636632919312
pure train time :  0.4410285949707031
train time :  0.6040620803833008
end to end time :  4.106840372085571
connection check time:  1.785813808441162
block generation time  0.9257166385650635
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004642009735107422
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014048099517822266
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6614387035369873
len local_batched_seeds_list  2
partition total batch output list spend :  0.7462081909179688
self.buckets_partition() spend  sec:  0.6755180358886719
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042974233627319336

in edges time spent  0.14493083953857422
local to global src and eids time spent  0.25983500480651855
time gen tails  0.0519871711730957
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08911752700805664

in edges time spent  0.36017942428588867
local to global src and eids time spent  0.5461676120758057
time gen tails  0.07957649230957031
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11019229888916016  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.005363941192627  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004677295684814  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.113616943359375  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.77896499633789  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784684658050537  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12356758117675781  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.346236228942871
pure train time :  0.4419560432434082
train time :  0.6046493053436279
end to end time :  4.117824077606201
connection check time:  1.8252851963043213
block generation time  0.9236612319946289
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004863739013671875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013956546783447266
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6328561305999756
len local_batched_seeds_list  2
partition total batch output list spend :  0.7171616554260254
self.buckets_partition() spend  sec:  0.6468460559844971
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042465925216674805

in edges time spent  0.14461827278137207
local to global src and eids time spent  0.2586793899536133
time gen tails  0.05229759216308594
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08860540390014648

in edges time spent  0.3332087993621826
local to global src and eids time spent  0.5330145359039307
time gen tails  0.07995486259460449
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11017417907714844  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044728755950928  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043797969818115  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1143040657043457  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.757648944854736  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.763368606567383  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12405061721801758  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3373829126358032
pure train time :  0.4358515739440918
train time :  0.5921590328216553
end to end time :  4.031038761138916
connection check time:  1.7823975086212158
block generation time  0.9260151386260986
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004982948303222656
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014342546463012695
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.688286304473877
len local_batched_seeds_list  2
partition total batch output list spend :  0.7728695869445801
self.buckets_partition() spend  sec:  0.702662467956543
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042375802993774414

in edges time spent  0.14471435546875
local to global src and eids time spent  0.25901365280151367
time gen tails  0.051917314529418945
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0895545482635498

in edges time spent  0.35474205017089844
local to global src and eids time spent  0.5529122352600098
time gen tails  0.08427071571350098
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10990190505981445  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003165245056152  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00248384475708  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11454105377197266  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788279056549072  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793998718261719  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12452983856201172  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3282450437545776
pure train time :  0.43191075325012207
train time :  0.5975909233093262
end to end time :  4.156288146972656
connection check time:  1.8357820510864258
block generation time  0.9360787868499756
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004603862762451172
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014054059982299805
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6705522537231445
len local_batched_seeds_list  2
partition total batch output list spend :  0.7561404705047607
self.buckets_partition() spend  sec:  0.6846420764923096
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04262208938598633

in edges time spent  0.15337562561035156
local to global src and eids time spent  0.26513218879699707
time gen tails  0.05182957649230957
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09047532081604004

in edges time spent  0.36774682998657227
local to global src and eids time spent  0.5469920635223389
time gen tails  0.07891488075256348
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1098785400390625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004955291748047  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004305839538574  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11404609680175781  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789837837219238  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.795557498931885  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12381744384765625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3203825950622559
pure train time :  0.4424705505371094
train time :  0.6178891658782959
end to end time :  4.177039623260498
connection check time:  1.845689296722412
block generation time  0.9308581352233887
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000476837158203125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013757705688476562
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6664741039276123
len local_batched_seeds_list  2
partition total batch output list spend :  0.749807596206665
self.buckets_partition() spend  sec:  0.6802718639373779
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04184150695800781

in edges time spent  0.14559054374694824
local to global src and eids time spent  0.2592287063598633
time gen tails  0.05177593231201172
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09102606773376465

in edges time spent  0.36543703079223633
local to global src and eids time spent  0.5799307823181152
time gen tails  0.08289504051208496
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11023235321044922  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041091918945312  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040953636169434  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11436796188354492  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785957336425781  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791676998138428  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12456130981445312  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3133615255355835
pure train time :  0.44259047508239746
train time :  0.6018130779266357
end to end time :  4.213137626647949
connection check time:  1.877173662185669
block generation time  0.9662914276123047
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005023479461669922
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014243125915527344
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7057309150695801
len local_batched_seeds_list  2
partition total batch output list spend :  0.7911169528961182
self.buckets_partition() spend  sec:  0.720008373260498
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04240226745605469

in edges time spent  0.14434361457824707
local to global src and eids time spent  0.26054978370666504
time gen tails  0.05189323425292969
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08987784385681152

in edges time spent  0.3454716205596924
local to global src and eids time spent  0.5303223133087158
time gen tails  0.0799570083618164
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11007022857666016  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002472877502441  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002490043640137  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11422348022460938  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784877300262451  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790596961975098  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12407684326171875  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3060672283172607
pure train time :  0.4366481304168701
train time :  0.5946536064147949
end to end time :  4.132356882095337
connection check time:  1.793426275253296
block generation time  0.9345457553863525
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00047659873962402344
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014193534851074219
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5497181415557861
len local_batched_seeds_list  2
partition total batch output list spend :  0.6344406604766846
self.buckets_partition() spend  sec:  0.5639529228210449
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04274439811706543

in edges time spent  0.14420247077941895
local to global src and eids time spent  0.2589750289916992
time gen tails  0.05187678337097168
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08817005157470703

in edges time spent  0.34300732612609863
local to global src and eids time spent  0.5311672687530518
time gen tails  0.07959771156311035
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10973834991455078  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043515682220459  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043005466461182  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11305713653564453  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.764818668365479  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.770538330078125  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12395286560058594  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3009717464447021
pure train time :  0.4312887191772461
train time :  0.5894899368286133
end to end time :  3.951042413711548
connection check time:  1.7894952297210693
block generation time  0.9244542121887207
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0007174015045166016
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014116287231445312
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6873266696929932
len local_batched_seeds_list  2
partition total batch output list spend :  0.7737514972686768
self.buckets_partition() spend  sec:  0.7014822959899902
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.045186519622802734

in edges time spent  0.1589047908782959
local to global src and eids time spent  0.2731003761291504
time gen tails  0.05359339714050293
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0949091911315918

in edges time spent  0.36241626739501953
local to global src and eids time spent  0.556840181350708
time gen tails  0.07863306999206543
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11051225662231445  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04171085357666  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04070520401001  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11452198028564453  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781612396240234  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78733205795288  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1250009536743164  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2932350635528564
pure train time :  0.4417083263397217
train time :  0.6037402153015137
end to end time :  4.209028720855713
connection check time:  1.8801183700561523
block generation time  0.9364211559295654
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005075931549072266
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014405488967895508
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.629873514175415
len local_batched_seeds_list  2
partition total batch output list spend :  0.7155179977416992
self.buckets_partition() spend  sec:  0.6443185806274414
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04634261131286621

in edges time spent  0.15722107887268066
local to global src and eids time spent  0.26894426345825195
time gen tails  0.05463671684265137
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09069275856018066

in edges time spent  0.3750002384185791
local to global src and eids time spent  0.5595250129699707
time gen tails  0.08202838897705078
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11036109924316406  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00402021408081  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004028797149658  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11463546752929688  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786718845367432  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792438507080078  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1249551773071289  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2859747409820557
pure train time :  0.44209861755371094
train time :  0.603518009185791
end to end time :  4.162644624710083
connection check time:  1.8901021480560303
block generation time  0.9406805038452148
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004851818084716797
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014220237731933594
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6638131141662598
len local_batched_seeds_list  2
partition total batch output list spend :  0.7499406337738037
self.buckets_partition() spend  sec:  0.6780686378479004
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04222369194030762

in edges time spent  0.14948439598083496
local to global src and eids time spent  0.2644331455230713
time gen tails  0.05435061454772949
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09072375297546387

in edges time spent  0.3468348979949951
local to global src and eids time spent  0.5363373756408691
time gen tails  0.07941699028015137
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11020517349243164  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002980709075928  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00228214263916  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1140141487121582  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.782776832580566  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788496494293213  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12381267547607422  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2822513580322266
pure train time :  0.4418966770172119
train time :  0.6025059223175049
end to end time :  4.1083879470825195
connection check time:  1.8119380474090576
block generation time  0.9286558628082275
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005021095275878906
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013717412948608398
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6338028907775879
len local_batched_seeds_list  2
partition total batch output list spend :  0.7185087203979492
self.buckets_partition() spend  sec:  0.6475529670715332
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042687177658081055

in edges time spent  0.14292359352111816
local to global src and eids time spent  0.2591891288757324
time gen tails  0.05152153968811035
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09006905555725098

in edges time spent  0.35172486305236816
local to global src and eids time spent  0.5396177768707275
time gen tails  0.07965803146362305
res  length 2
block collection to dataloader spend  6.67572021484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11026859283447266  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.013505458831787  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.01246690750122  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11357975006103516  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780386924743652  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786106586456299  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12390565872192383  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2767338752746582
pure train time :  0.441331148147583
train time :  0.6138927936553955
end to end time :  4.08335542678833
connection check time:  1.8056182861328125
block generation time  0.926720142364502
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004565715789794922
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014181852340698242
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6791186332702637
len local_batched_seeds_list  2
partition total batch output list spend :  0.7647445201873779
self.buckets_partition() spend  sec:  0.6933333873748779
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042400360107421875

in edges time spent  0.14293313026428223
local to global src and eids time spent  0.25911545753479004
time gen tails  0.05194425582885742
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08888387680053711

in edges time spent  0.3649747371673584
local to global src and eids time spent  0.5344438552856445
time gen tails  0.08209776878356934
res  length 2
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11052703857421875  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000016212463379  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.99898910522461  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11509561538696289  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79508638381958  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.800806045532227  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12555551528930664  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2747466564178467
pure train time :  0.44106125831604004
train time :  0.6058120727539062
end to end time :  4.133621454238892
connection check time:  1.8173577785491943
block generation time  0.9257161617279053
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00047779083251953125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013953208923339844
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7117366790771484
len local_batched_seeds_list  2
partition total batch output list spend :  0.7975881099700928
self.buckets_partition() spend  sec:  0.7258045673370361
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04249715805053711

in edges time spent  0.14350080490112305
local to global src and eids time spent  0.25862979888916016
time gen tails  0.05166268348693848
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09070515632629395

in edges time spent  0.35930490493774414
local to global src and eids time spent  0.5306613445281982
time gen tails  0.07921338081359863
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11116600036621094  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004230976104736  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002742290496826  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11435937881469727  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.783584117889404  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78930377960205  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12498044967651367  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.270472526550293
pure train time :  0.44129037857055664
train time :  0.6026716232299805
end to end time :  4.157172918319702
connection check time:  1.8067998886108398
block generation time  0.9349884986877441
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00047397613525390625
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014032840728759766
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6523699760437012
len local_batched_seeds_list  2
partition total batch output list spend :  0.7368295192718506
self.buckets_partition() spend  sec:  0.6664373874664307
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04244518280029297

in edges time spent  0.1439521312713623
local to global src and eids time spent  0.25942134857177734
time gen tails  0.051993370056152344
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08979082107543945

in edges time spent  0.3439033031463623
local to global src and eids time spent  0.5342762470245361
time gen tails  0.07935643196105957
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11138629913330078  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04136037826538  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.03965139389038  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11441898345947266  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781915664672852  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787635326385498  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12511396408081055  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2603838443756104
pure train time :  0.44046854972839355
train time :  0.6061649322509766
end to end time :  4.083084344863892
connection check time:  1.7934510707855225
block generation time  0.9265508651733398
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004673004150390625
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015241861343383789
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6738777160644531
len local_batched_seeds_list  2
partition total batch output list spend :  0.7598752975463867
self.buckets_partition() spend  sec:  0.6891531944274902
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04318976402282715

in edges time spent  0.14368057250976562
local to global src and eids time spent  0.2568953037261963
time gen tails  0.05117535591125488
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09084892272949219

in edges time spent  0.3574361801147461
local to global src and eids time spent  0.5577619075775146
time gen tails  0.08184194564819336
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11145925521850586  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04094123840332  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039156436920166  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11537837982177734  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78819751739502  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793917179107666  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12528514862060547  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2529911994934082
pure train time :  0.44202566146850586
train time :  0.603095531463623
end to end time :  4.16695237159729
connection check time:  1.8386406898498535
block generation time  0.9515771865844727
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00045490264892578125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013788223266601562
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5901768207550049
len local_batched_seeds_list  2
partition total batch output list spend :  0.6752166748046875
self.buckets_partition() spend  sec:  0.6040048599243164
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04225945472717285

in edges time spent  0.1466064453125
local to global src and eids time spent  0.2598297595977783
time gen tails  0.051434993743896484
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09103512763977051

in edges time spent  0.3569808006286621
local to global src and eids time spent  0.5520679950714111
time gen tails  0.07950019836425781
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11152362823486328  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042579650878906  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041013717651367  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11534452438354492  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793753147125244  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79947280883789  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12510919570922852  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2466989755630493
pure train time :  0.4289357662200928
train time :  0.5864033699035645
end to end time :  4.0332841873168945
connection check time:  1.8281986713409424
block generation time  0.929675817489624
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004992485046386719
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0141143798828125
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6576168537139893
len local_batched_seeds_list  2
partition total batch output list spend :  0.7417538166046143
self.buckets_partition() spend  sec:  0.6717638969421387
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04240107536315918

in edges time spent  0.14409756660461426
local to global src and eids time spent  0.2569921016693115
time gen tails  0.0513916015625
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08905792236328125

in edges time spent  0.3396792411804199
local to global src and eids time spent  0.49160265922546387
time gen tails  0.05823659896850586
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1113743782043457  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042746543884277  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04104471206665  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11348724365234375  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.756652355194092  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.762372016906738  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12483882904052734  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2448112964630127
pure train time :  0.43998098373413086
train time :  0.6000819206237793
end to end time :  4.002295970916748
connection check time:  1.7220797538757324
block generation time  0.9227936267852783
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004868507385253906
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015358924865722656
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6381101608276367
len local_batched_seeds_list  2
partition total batch output list spend :  0.6828534603118896
self.buckets_partition() spend  sec:  0.6534998416900635
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042043447494506836

in edges time spent  0.1380162239074707
local to global src and eids time spent  0.25711941719055176
time gen tails  0.051702022552490234
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0905756950378418

in edges time spent  0.35920000076293945
local to global src and eids time spent  0.5781948566436768
time gen tails  0.09027385711669922
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.110137939453125  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004754066467285  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004705429077148  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11460161209106445  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.782685279846191  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788404941558838  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12494993209838867  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2428863048553467
pure train time :  0.4461071491241455
train time :  0.6117446422576904
end to end time :  4.162028074264526
connection check time:  1.866567611694336
block generation time  0.9862511157989502
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005035400390625
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01467132568359375
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6681911945343018
len local_batched_seeds_list  2
partition total batch output list spend :  0.7543845176696777
self.buckets_partition() spend  sec:  0.6829020977020264
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04363751411437988

in edges time spent  0.15165495872497559
local to global src and eids time spent  0.25881385803222656
time gen tails  0.05205845832824707
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0906827449798584

in edges time spent  0.3877701759338379
local to global src and eids time spent  0.5660552978515625
time gen tails  0.0800318717956543
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1102304458618164  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003251075744629  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00252628326416  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11473369598388672  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788915634155273  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79463529586792  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12498283386230469  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2365211248397827
pure train time :  0.43329930305480957
train time :  0.5917487144470215
end to end time :  4.177761793136597
connection check time:  1.8814127445220947
block generation time  0.9266047477722168
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004570484161376953
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014620780944824219
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6769504547119141
len local_batched_seeds_list  2
partition total batch output list spend :  0.7620165348052979
self.buckets_partition() spend  sec:  0.6916036605834961
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04226970672607422

in edges time spent  0.15120315551757812
local to global src and eids time spent  0.2598118782043457
time gen tails  0.05215740203857422
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08855748176574707

in edges time spent  0.3483550548553467
local to global src and eids time spent  0.4949045181274414
time gen tails  0.0570371150970459
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11015701293945312  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044454574584961  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043828010559082  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11424446105957031  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.761789798736572  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.767509460449219  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12383079528808594  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.229860544204712
pure train time :  0.4384794235229492
train time :  0.606043815612793
end to end time :  4.053556680679321
connection check time:  1.7425649166107178
block generation time  0.9278886318206787
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004711151123046875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015181303024291992
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6124839782714844
len local_batched_seeds_list  2
partition total batch output list spend :  0.657334566116333
self.buckets_partition() spend  sec:  0.6277062892913818
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.040082693099975586

in edges time spent  0.14310359954833984
local to global src and eids time spent  0.2601795196533203
time gen tails  0.052237510681152344
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08924460411071777

in edges time spent  0.36174654960632324
local to global src and eids time spent  0.5516409873962402
time gen tails  0.07918357849121094
res  length 2
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1097402572631836  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.99979305267334  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999274253845215  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11347436904907227  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788040161132812  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793759822845459  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12434577941894531  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2272896766662598
pure train time :  0.42958950996398926
train time :  0.5895464420318604
end to end time :  4.019301414489746
connection check time:  1.8213160037994385
block generation time  0.9291579723358154
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004999637603759766
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014250993728637695
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6722376346588135
len local_batched_seeds_list  2
partition total batch output list spend :  0.756950855255127
self.buckets_partition() spend  sec:  0.6865262985229492
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042694091796875

in edges time spent  0.14464926719665527
local to global src and eids time spent  0.25772547721862793
time gen tails  0.05130743980407715
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0895531177520752

in edges time spent  0.33995556831359863
local to global src and eids time spent  0.5314273834228516
time gen tails  0.07924389839172363
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11048364639282227  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.045265197753906  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04516077041626  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1144871711730957  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.74598741531372  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.751707077026367  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12443685531616211  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2224985361099243
pure train time :  0.4384040832519531
train time :  0.5976846218109131
end to end time :  4.108395099639893
connection check time:  1.786691427230835
block generation time  0.9505882263183594
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00046706199645996094
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014404535293579102
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.68910813331604
len local_batched_seeds_list  2
partition total batch output list spend :  0.7749471664428711
self.buckets_partition() spend  sec:  0.7035479545593262
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043116092681884766

in edges time spent  0.14374232292175293
local to global src and eids time spent  0.25717878341674805
time gen tails  0.05167412757873535
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09050369262695312

in edges time spent  0.3558018207550049
local to global src and eids time spent  0.5454158782958984
time gen tails  0.08039450645446777
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1098318099975586  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042790412902832  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043058395385742  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11463022232055664  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789878368377686  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.795598030090332  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12476253509521484  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.215691089630127
pure train time :  0.4330124855041504
train time :  0.590003490447998
end to end time :  4.122689723968506
connection check time:  1.817718505859375
block generation time  0.9260637760162354
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000499725341796875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014102697372436523
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6440880298614502
len local_batched_seeds_list  2
partition total batch output list spend :  0.7293379306793213
self.buckets_partition() spend  sec:  0.6582241058349609
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042649269104003906

in edges time spent  0.14405107498168945
local to global src and eids time spent  0.25951433181762695
time gen tails  0.05173802375793457
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08990979194641113

in edges time spent  0.338303804397583
local to global src and eids time spent  0.5372834205627441
time gen tails  0.07898163795471191
res  length 2
block collection to dataloader spend  6.67572021484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1100163459777832  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038240432739258  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037460803985596  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11460542678833008  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792870998382568  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.798590660095215  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12466192245483398  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.212565541267395
pure train time :  0.4399130344390869
train time :  0.5994210243225098
end to end time :  4.066327095031738
connection check time:  1.791142225265503
block generation time  0.9290988445281982
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000457763671875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014108896255493164
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5792117118835449
len local_batched_seeds_list  2
partition total batch output list spend :  0.6661596298217773
self.buckets_partition() spend  sec:  0.5933563709259033
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04264235496520996

in edges time spent  0.14319062232971191
local to global src and eids time spent  0.25896501541137695
time gen tails  0.052016258239746094
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08979034423828125

in edges time spent  0.3634035587310791
local to global src and eids time spent  0.5462667942047119
time gen tails  0.08050227165222168
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1108999252319336  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.03882646560669  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.03897762298584  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11476707458496094  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.783289432525635  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789009094238281  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12447547912597656  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2091264724731445
pure train time :  0.4433858394622803
train time :  0.6166541576385498
end to end time :  4.063107967376709
connection check time:  1.8256714344024658
block generation time  0.9390711784362793
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004551410675048828
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014533758163452148
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.667834997177124
len local_batched_seeds_list  2
partition total batch output list spend :  0.754122257232666
self.buckets_partition() spend  sec:  0.6824014186859131
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04301023483276367

in edges time spent  0.1479816436767578
local to global src and eids time spent  0.26660752296447754
time gen tails  0.051935434341430664
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09001874923706055

in edges time spent  0.38584113121032715
local to global src and eids time spent  0.5480327606201172
time gen tails  0.07872533798217773
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10986471176147461  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.009259700775146  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.008625984191895  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11524343490600586  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784204483032227  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789924144744873  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12527942657470703  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2050471305847168
pure train time :  0.4432499408721924
train time :  0.6024782657623291
end to end time :  4.177343368530273
connection check time:  1.8605108261108398
block generation time  0.9395349025726318
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005106925964355469
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014006376266479492
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6898024082183838
len local_batched_seeds_list  2
partition total batch output list spend :  0.7760169506072998
self.buckets_partition() spend  sec:  0.7038426399230957
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04568910598754883

in edges time spent  0.1553630828857422
local to global src and eids time spent  0.2708737850189209
time gen tails  0.05324149131774902
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08867025375366211

in edges time spent  0.3705456256866455
local to global src and eids time spent  0.5491130352020264
time gen tails  0.07919692993164062
res  length 2
block collection to dataloader spend  6.67572021484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11153268814086914  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003458976745605  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001871109008789  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11484336853027344  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791479110717773  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79719877243042  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12536382675170898  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2010679244995117
pure train time :  0.4335775375366211
train time :  0.5902385711669922
end to end time :  4.1804986000061035
connection check time:  1.8641605377197266
block generation time  0.932887077331543
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000457763671875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014020204544067383
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6351308822631836
len local_batched_seeds_list  2
partition total batch output list spend :  0.7192811965942383
self.buckets_partition() spend  sec:  0.6491835117340088
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04222679138183594

in edges time spent  0.14171671867370605
local to global src and eids time spent  0.25835442543029785
time gen tails  0.05203557014465332
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08953475952148438

in edges time spent  0.34609031677246094
local to global src and eids time spent  0.53011155128479
time gen tails  0.08012604713439941
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10967445373535156  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999946117401123  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999487400054932  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11445999145507812  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78998327255249  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.795702934265137  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12405729293823242  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1990410089492798
pure train time :  0.4439699649810791
train time :  0.6062757968902588
end to end time :  4.059467315673828
connection check time:  1.78879976272583
block generation time  0.9281935691833496
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005421638488769531
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014282941818237305
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6892354488372803
len local_batched_seeds_list  2
partition total batch output list spend :  0.772367000579834
self.buckets_partition() spend  sec:  0.7035620212554932
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04285120964050293

in edges time spent  0.14261960983276367
local to global src and eids time spent  0.25922489166259766
time gen tails  0.05162978172302246
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08996081352233887

in edges time spent  0.3602416515350342
local to global src and eids time spent  0.5363748073577881
time gen tails  0.07922673225402832
res  length 2
block collection to dataloader spend  1.4543533325195312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1100316047668457  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002455711364746  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00165319442749  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11452484130859375  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792325973510742  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.798045635223389  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12439823150634766  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.198197841644287
pure train time :  0.45119738578796387
train time :  0.6115543842315674
end to end time :  4.168045282363892
connection check time:  1.8106331825256348
block generation time  0.958397388458252
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.004304409027099609
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014447212219238281
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7014331817626953
len local_batched_seeds_list  2
partition total batch output list spend :  0.7878079414367676
self.buckets_partition() spend  sec:  0.7159149646759033
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0448918342590332

in edges time spent  0.1491377353668213
local to global src and eids time spent  0.27199530601501465
time gen tails  0.0534822940826416
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0935359001159668

in edges time spent  0.35969090461730957
local to global src and eids time spent  0.551851749420166
time gen tails  0.07969284057617188
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10976028442382812  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003110408782959  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00257158279419  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1145172119140625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.767455577850342  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.773175239562988  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12471961975097656  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1888365745544434
pure train time :  0.4400770664215088
train time :  0.605933666229248
end to end time :  4.22602391242981
connection check time:  1.8612830638885498
block generation time  0.9528903961181641
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005903244018554688
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014343023300170898
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6390876770019531
len local_batched_seeds_list  2
partition total batch output list spend :  0.7238612174987793
self.buckets_partition() spend  sec:  0.6534669399261475
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04286026954650879

in edges time spent  0.14452505111694336
local to global src and eids time spent  0.2589726448059082
time gen tails  0.05174517631530762
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0892951488494873

in edges time spent  0.3436100482940674
local to global src and eids time spent  0.5040774345397949
time gen tails  0.057333946228027344
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11010503768920898  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039361476898193  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038497924804688  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1143341064453125  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.783305168151855  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789024829864502  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12468338012695312  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1867291927337646
pure train time :  0.43708133697509766
train time :  0.5956301689147949
end to end time :  4.011259078979492
connection check time:  1.7425081729888916
block generation time  0.9290866851806641
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005633831024169922
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01752758026123047
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6304702758789062
len local_batched_seeds_list  2
partition total batch output list spend :  0.6782476902008057
self.buckets_partition() spend  sec:  0.6480324268341064
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.041274070739746094

in edges time spent  0.15625524520874023
local to global src and eids time spent  0.2703225612640381
time gen tails  0.05223655700683594
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08958244323730469

in edges time spent  0.3307669162750244
local to global src and eids time spent  0.4887990951538086
time gen tails  0.061711788177490234
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11022329330444336  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041723728179932  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041876792907715  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11472225189208984  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78999137878418  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.795711040496826  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12479019165039062  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1837549209594727
pure train time :  0.43587422370910645
train time :  0.5956707000732422
end to end time :  3.959567070007324
connection check time:  1.7377896308898926
block generation time  0.9280827045440674
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004801750183105469
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015365839004516602
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6299514770507812
len local_batched_seeds_list  2
partition total batch output list spend :  0.6750102043151855
self.buckets_partition() spend  sec:  0.6453506946563721
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.040572166442871094

in edges time spent  0.144927978515625
local to global src and eids time spent  0.2619621753692627
time gen tails  0.05212593078613281
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09001326560974121

in edges time spent  0.3748767375946045
local to global src and eids time spent  0.5579664707183838
time gen tails  0.07974958419799805
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10994529724121094  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.005513668060303  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.005077838897705  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11394214630126953  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.763323307037354  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.76904296875  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12370681762695312  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1816468238830566
pure train time :  0.4411172866821289
train time :  0.5993978977203369
end to end time :  4.06699013710022
connection check time:  1.8475923538208008
block generation time  0.931480884552002
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004661083221435547
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014081716537475586
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5514132976531982
len local_batched_seeds_list  2
partition total batch output list spend :  0.6363565921783447
self.buckets_partition() spend  sec:  0.5655298233032227
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04212236404418945

in edges time spent  0.14438080787658691
local to global src and eids time spent  0.25896525382995605
time gen tails  0.05179333686828613
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0889286994934082

in edges time spent  0.34794163703918457
local to global src and eids time spent  0.5313067436218262
time gen tails  0.08267736434936523
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11022424697875977  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002264976501465  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002126216888428  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11450481414794922  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.767352104187012  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.773071765899658  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12446880340576172  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1730971336364746
pure train time :  0.43657708168029785
train time :  0.5936377048492432
end to end time :  3.9673702716827393
connection check time:  1.7967913150787354
block generation time  0.9239087104797363
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004520416259765625
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015087366104125977
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6032888889312744
len local_batched_seeds_list  2
partition total batch output list spend :  0.660114049911499
self.buckets_partition() spend  sec:  0.6184852123260498
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04037737846374512

in edges time spent  0.15376806259155273
local to global src and eids time spent  0.26025390625
time gen tails  0.0521693229675293
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08924150466918945

in edges time spent  0.35625505447387695
local to global src and eids time spent  0.5284316539764404
time gen tails  0.07917976379394531
res  length 2
block collection to dataloader spend  1.1920928955078125e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10984134674072266  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.03884220123291  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038227081298828  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11432075500488281  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.771507263183594  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.77722692489624  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1241445541381836  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1734826564788818
pure train time :  0.44202184677124023
train time :  0.6188905239105225
end to end time :  4.024876594543457
connection check time:  1.805199384689331
block generation time  0.925649881362915
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005521774291992188
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014122247695922852
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6546118259429932
len local_batched_seeds_list  2
partition total batch output list spend :  0.7383489608764648
self.buckets_partition() spend  sec:  0.6687734127044678
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042319297790527344

in edges time spent  0.14192652702331543
local to global src and eids time spent  0.25835132598876953
time gen tails  0.052094459533691406
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08866167068481445

in edges time spent  0.35039496421813965
local to global src and eids time spent  0.5320076942443848
time gen tails  0.07941055297851562
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11030197143554688  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000346660614014  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999268054962158  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11464071273803711  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78410291671753  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789822578430176  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12443685531616211  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1673356294631958
pure train time :  0.4296553134918213
train time :  0.587019681930542
end to end time :  4.075218200683594
connection check time:  1.7929859161376953
block generation time  0.9374172687530518
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005624294281005859
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01442718505859375
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6942138671875
len local_batched_seeds_list  2
partition total batch output list spend :  0.7796065807342529
self.buckets_partition() spend  sec:  0.7086713314056396
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04238414764404297

in edges time spent  0.1444406509399414
local to global src and eids time spent  0.261044979095459
time gen tails  0.05128765106201172
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08860158920288086

in edges time spent  0.34000706672668457
local to global src and eids time spent  0.5299811363220215
time gen tails  0.07894301414489746
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10969734191894531  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044372081756592  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04478406906128  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11398649215698242  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.767115116119385  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.772834777832031  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12404108047485352  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.168028712272644
pure train time :  0.4334752559661865
train time :  0.5913422107696533
end to end time :  4.100621938705444
connection check time:  1.7850356101989746
block generation time  0.9259650707244873
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0006296634674072266
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014645576477050781
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6499247550964355
len local_batched_seeds_list  2
partition total batch output list spend :  0.7351582050323486
self.buckets_partition() spend  sec:  0.664602518081665
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.041600704193115234

in edges time spent  0.14346837997436523
local to global src and eids time spent  0.2622971534729004
time gen tails  0.0518953800201416
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08983349800109863

in edges time spent  0.3711516857147217
local to global src and eids time spent  0.5777404308319092
time gen tails  0.08702278137207031
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11087512969970703  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002435684204102  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001745223999023  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11473798751831055  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786751747131348  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792471408843994  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1247100830078125  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1696646213531494
pure train time :  0.4445633888244629
train time :  0.620750904083252
end to end time :  4.217328786849976
connection check time:  1.8865385055541992
block generation time  0.9612162113189697
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005762577056884766
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015006780624389648
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6891839504241943
len local_batched_seeds_list  2
partition total batch output list spend :  0.7751049995422363
self.buckets_partition() spend  sec:  0.7042262554168701
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04323911666870117

in edges time spent  0.1473102569580078
local to global src and eids time spent  0.2613251209259033
time gen tails  0.0520017147064209
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0891106128692627

in edges time spent  0.3523581027984619
local to global src and eids time spent  0.5180253982543945
time gen tails  0.05752921104431152
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11074161529541016  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042215824127197  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04160737991333  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1143798828125  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.778028011322021  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.783747673034668  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12426280975341797  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1616065502166748
pure train time :  0.4402322769165039
train time :  0.6110315322875977
end to end time :  4.1140196323394775
connection check time:  1.7693159580230713
block generation time  0.9358842372894287
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005137920379638672
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015479087829589844
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6693146228790283
len local_batched_seeds_list  2
partition total batch output list spend :  0.7153682708740234
self.buckets_partition() spend  sec:  0.6848297119140625
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04179096221923828

in edges time spent  0.1362459659576416
local to global src and eids time spent  0.21242356300354004
time gen tails  0.039063453674316406
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08822751045227051

in edges time spent  0.3408365249633789
local to global src and eids time spent  0.511033296585083
time gen tails  0.05839896202087402
res  length 2
block collection to dataloader spend  1.3113021850585938e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11014699935913086  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044652462005615  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043788433074951  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11358022689819336  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781334400177002  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787054061889648  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12323665618896484  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1633929014205933
pure train time :  0.4398026466369629
train time :  0.5988593101501465
end to end time :  3.962127685546875
connection check time:  1.6791739463806152
block generation time  0.9524006843566895
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004792213439941406
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015444040298461914
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6503472328186035
len local_batched_seeds_list  2
partition total batch output list spend :  0.6970202922821045
self.buckets_partition() spend  sec:  0.6658244132995605
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.02436995506286621

in edges time spent  0.07877063751220703
local to global src and eids time spent  0.10820889472961426
time gen tails  0.031351566314697266
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.05850553512573242

in edges time spent  0.19499874114990234
local to global src and eids time spent  0.2249159812927246
time gen tails  0.04682803153991699
res  length 2
block collection to dataloader spend  5.9604644775390625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1098484992980957  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.99790906906128  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997279167175293  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11298084259033203  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78542709350586  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791146755218506  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12355518341064453  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.161765456199646
pure train time :  0.4272477626800537
train time :  0.5901000499725342
end to end time :  2.8488059043884277
connection check time:  0.8768603801727295
block generation time  0.6715452671051025
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004248619079589844
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013332128524780273
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.28162431716918945
len local_batched_seeds_list  2
partition total batch output list spend :  0.31891465187072754
self.buckets_partition() spend  sec:  0.2949848175048828
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.02465343475341797

in edges time spent  0.08010244369506836
local to global src and eids time spent  0.10968971252441406
time gen tails  0.03187298774719238
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.05885934829711914

in edges time spent  0.20324015617370605
local to global src and eids time spent  0.22962045669555664
time gen tails  0.04819655418395996
res  length 2
block collection to dataloader spend  6.67572021484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11004066467285156  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.99864673614502  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997822761535645  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1146693229675293  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78767728805542  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793396949768066  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12446069717407227  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1587269306182861
pure train time :  0.4216182231903076
train time :  0.5848791599273682
end to end time :  2.494680643081665
connection check time:  0.8994796276092529
block generation time  0.6826729774475098
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004420280456542969
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013473987579345703
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.18642592430114746
len local_batched_seeds_list  2
partition total batch output list spend :  0.22409534454345703
self.buckets_partition() spend  sec:  0.19992709159851074
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.023926258087158203

in edges time spent  0.07836341857910156
local to global src and eids time spent  0.10869717597961426
time gen tails  0.031125783920288086
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.05678439140319824

in edges time spent  0.34541797637939453
local to global src and eids time spent  0.551459789276123
time gen tails  0.07906866073608398
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11006402969360352  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002692222595215  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001848697662354  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11375188827514648  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787861347198486  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793581008911133  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1242070198059082  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1596189737319946
pure train time :  0.4397754669189453
train time :  0.6056439876556396
end to end time :  3.1451363563537598
connection check time:  1.465679407119751
block generation time  0.8393316268920898
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005338191986083984
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015368223190307617
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6516754627227783
len local_batched_seeds_list  2
partition total batch output list spend :  0.7380542755126953
self.buckets_partition() spend  sec:  0.6670773029327393
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043091535568237305

in edges time spent  0.14560222625732422
local to global src and eids time spent  0.25914859771728516
time gen tails  0.05181241035461426
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09030437469482422

in edges time spent  0.3523428440093994
local to global src and eids time spent  0.5325195789337158
time gen tails  0.07857751846313477
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1100168228149414  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.03907060623169  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038282871246338  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1143498420715332  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787117958068848  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792837619781494  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12447786331176758  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1559295654296875
pure train time :  0.43271327018737793
train time :  0.5913820266723633
end to end time :  4.072488784790039
connection check time:  1.8023121356964111
block generation time  0.926826000213623
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005061626434326172
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01425623893737793
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6667990684509277
len local_batched_seeds_list  2
partition total batch output list spend :  0.752187967300415
self.buckets_partition() spend  sec:  0.6810901165008545
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042247772216796875

in edges time spent  0.14409780502319336
local to global src and eids time spent  0.2582051753997803
time gen tails  0.051253557205200195
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08850312232971191

in edges time spent  0.34226369857788086
local to global src and eids time spent  0.5317692756652832
time gen tails  0.08006811141967773
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11031055450439453  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044454097747803  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043691158294678  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11364459991455078  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.731115818023682  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.736835479736328  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12339591979980469  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.156064748764038
pure train time :  0.4395780563354492
train time :  0.5978546142578125
end to end time :  4.075911998748779
connection check time:  1.786771535873413
block generation time  0.925487756729126
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004699230194091797
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014207601547241211
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6637001037597656
len local_batched_seeds_list  2
partition total batch output list spend :  0.7487514019012451
self.buckets_partition() spend  sec:  0.6779415607452393
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04425358772277832

in edges time spent  0.1571793556213379
local to global src and eids time spent  0.2690548896789551
time gen tails  0.05666351318359375
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08974623680114746

in edges time spent  0.38696837425231934
local to global src and eids time spent  0.5685732364654541
time gen tails  0.08326506614685059
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10996723175048828  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003615856170654  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002875804901123  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11377096176147461  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.778017520904541  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.783737182617188  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12358903884887695  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1515041589736938
pure train time :  0.43035197257995605
train time :  0.5910942554473877
end to end time :  4.1991798877716064
connection check time:  1.911414623260498
block generation time  0.9342148303985596
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005009174346923828
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013909339904785156
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6368441581726074
len local_batched_seeds_list  2
partition total batch output list spend :  0.7212727069854736
self.buckets_partition() spend  sec:  0.6507890224456787
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042591094970703125

in edges time spent  0.15107345581054688
local to global src and eids time spent  0.26934194564819336
time gen tails  0.05225086212158203
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09052562713623047

in edges time spent  0.3692805767059326
local to global src and eids time spent  0.5362200736999512
time gen tails  0.07982492446899414
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11114645004272461  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041356563568115  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041261672973633  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11493110656738281  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787111759185791  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792831420898438  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1244659423828125  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.152825951576233
pure train time :  0.4308779239654541
train time :  0.5928184986114502
end to end time :  4.118696212768555
connection check time:  1.8394484519958496
block generation time  0.9336402416229248
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004782676696777344
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013818740844726562
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6345477104187012
len local_batched_seeds_list  2
partition total batch output list spend :  0.7182457447052002
self.buckets_partition() spend  sec:  0.6484003067016602
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04243588447570801

in edges time spent  0.14446020126342773
local to global src and eids time spent  0.25850677490234375
time gen tails  0.05167508125305176
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08872675895690918

in edges time spent  0.3535642623901367
local to global src and eids time spent  0.5323348045349121
time gen tails  0.07961916923522949
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10967159271240234  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999675273895264  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999223232269287  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11301088333129883  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78410005569458  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789819717407227  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12357234954833984  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1502432823181152
pure train time :  0.4378316402435303
train time :  0.5947260856628418
end to end time :  4.059200286865234
connection check time:  1.7995028495788574
block generation time  0.9328229427337646
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00046896934509277344
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013738632202148438
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6392312049865723
len local_batched_seeds_list  2
partition total batch output list spend :  0.7233896255493164
self.buckets_partition() spend  sec:  0.6530075073242188
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042723655700683594

in edges time spent  0.1439661979675293
local to global src and eids time spent  0.25959062576293945
time gen tails  0.05149579048156738
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09020280838012695

in edges time spent  0.3446216583251953
local to global src and eids time spent  0.5538656711578369
time gen tails  0.08115410804748535
res  length 2
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10991573333740234  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.046179294586182  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.045506000518799  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11451244354248047  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780179500579834  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78589916229248  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12435626983642578  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1494953632354736
pure train time :  0.43992018699645996
train time :  0.6056838035583496
end to end time :  4.101474046707153
connection check time:  1.827502727508545
block generation time  0.9282803535461426
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005402565002441406
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013876676559448242
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6715185642242432
len local_batched_seeds_list  2
partition total batch output list spend :  0.7557883262634277
self.buckets_partition() spend  sec:  0.685434103012085
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04285907745361328

in edges time spent  0.1433088779449463
local to global src and eids time spent  0.258908748626709
time gen tails  0.051896095275878906
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08985042572021484

in edges time spent  0.34732890129089355
local to global src and eids time spent  0.5292582511901855
time gen tails  0.07934880256652832
res  length 2
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11014509201049805  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999699592590332  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998775005340576  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11400794982910156  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780885219573975  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786604881286621  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12410163879394531  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1456612348556519
pure train time :  0.4419898986816406
train time :  0.600590705871582
end to end time :  4.094581842422485
connection check time:  1.7912752628326416
block generation time  0.9254763126373291
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00049591064453125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014043807983398438
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5502004623413086
len local_batched_seeds_list  2
partition total batch output list spend :  0.6350376605987549
self.buckets_partition() spend  sec:  0.564284086227417
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04222989082336426

in edges time spent  0.14345121383666992
local to global src and eids time spent  0.2593846321105957
time gen tails  0.0521082878112793
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08846426010131836

in edges time spent  0.33657121658325195
local to global src and eids time spent  0.5057322978973389
time gen tails  0.05743241310119629
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11043930053710938  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.99915361404419  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998218059539795  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1132359504699707  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785608291625977  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791327953338623  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1246647834777832  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1452710628509521
pure train time :  0.4389939308166504
train time :  0.6008312702178955
end to end time :  3.919645071029663
connection check time:  1.7342522144317627
block generation time  0.9365546703338623
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005059242248535156
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015369653701782227
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6406867504119873
len local_batched_seeds_list  2
partition total batch output list spend :  0.6861021518707275
self.buckets_partition() spend  sec:  0.656090259552002
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04023432731628418

in edges time spent  0.14302349090576172
local to global src and eids time spent  0.26097869873046875
time gen tails  0.05210518836975098
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08893585205078125

in edges time spent  0.33954930305480957
local to global src and eids time spent  0.5355606079101562
time gen tails  0.07898974418640137
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11020231246948242  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.005430698394775  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00445556640625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11490440368652344  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.757081508636475  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.762801170349121  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1252117156982422  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1408493518829346
pure train time :  0.435927152633667
train time :  0.5947747230529785
end to end time :  4.002898693084717
connection check time:  1.7832615375518799
block generation time  0.921088695526123
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004887580871582031
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014067649841308594
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6509006023406982
len local_batched_seeds_list  2
partition total batch output list spend :  0.7353196144104004
self.buckets_partition() spend  sec:  0.6650078296661377
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0423121452331543

in edges time spent  0.14321613311767578
local to global src and eids time spent  0.2587723731994629
time gen tails  0.052094221115112305
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08832931518554688

in edges time spent  0.34850621223449707
local to global src and eids time spent  0.5328998565673828
time gen tails  0.07979226112365723
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11082935333251953  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043810844421387  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042497634887695  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11531352996826172  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.774886131286621  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780605792999268  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12600421905517578  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1409410238265991
pure train time :  0.44091033935546875
train time :  0.5990135669708252
end to end time :  4.0763161182403564
connection check time:  1.7949745655059814
block generation time  0.9298453330993652
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004591941833496094
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014058828353881836
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6645264625549316
len local_batched_seeds_list  2
partition total batch output list spend :  0.7488369941711426
self.buckets_partition() spend  sec:  0.6786174774169922
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04221367835998535

in edges time spent  0.14388656616210938
local to global src and eids time spent  0.2594723701477051
time gen tails  0.05168604850769043
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08910417556762695

in edges time spent  0.3377492427825928
local to global src and eids time spent  0.5315608978271484
time gen tails  0.0796515941619873
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11140012741088867  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003236770629883  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002357482910156  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11486434936523438  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.778548240661621  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784267902374268  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12489509582519531  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1372942924499512
pure train time :  0.44100069999694824
train time :  0.6067540645599365
end to end time :  4.086708307266235
connection check time:  1.78546142578125
block generation time  0.9293153285980225
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005266666412353516
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014224529266357422
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6316356658935547
len local_batched_seeds_list  2
partition total batch output list spend :  0.716177225112915
self.buckets_partition() spend  sec:  0.6458940505981445
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0420689582824707

in edges time spent  0.14459800720214844
local to global src and eids time spent  0.2586071491241455
time gen tails  0.05197405815124512
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09006118774414062

in edges time spent  0.34075093269348145
local to global src and eids time spent  0.5331206321716309
time gen tails  0.07905077934265137
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11019134521484375  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041052341461182  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.0403733253479  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11402225494384766  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.747010707855225  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.752730369567871  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12412643432617188  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1378076076507568
pure train time :  0.43286657333374023
train time :  0.5918350219726562
end to end time :  4.037655830383301
connection check time:  1.788522720336914
block generation time  0.9278638362884521
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004963874816894531
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013931989669799805
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.632429838180542
len local_batched_seeds_list  2
partition total batch output list spend :  0.7170803546905518
self.buckets_partition() spend  sec:  0.6463956832885742
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04273676872253418

in edges time spent  0.14493441581726074
local to global src and eids time spent  0.2584247589111328
time gen tails  0.05197572708129883
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09187674522399902

in edges time spent  0.3497340679168701
local to global src and eids time spent  0.5656979084014893
time gen tails  0.08454132080078125
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11057567596435547  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.990331649780273  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.990102767944336  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11465787887573242  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.795682430267334  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.80140209197998  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12464761734008789  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1366674900054932
pure train time :  0.4348750114440918
train time :  0.596717357635498
end to end time :  4.1309287548065186
connection check time:  1.8482284545898438
block generation time  0.9523844718933105
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005087852478027344
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014646768569946289
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6767280101776123
len local_batched_seeds_list  2
partition total batch output list spend :  0.7625117301940918
self.buckets_partition() spend  sec:  0.6914882659912109
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04273629188537598

in edges time spent  0.15266990661621094
local to global src and eids time spent  0.2692272663116455
time gen tails  0.05263328552246094
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09215235710144043

in edges time spent  0.3833954334259033
local to global src and eids time spent  0.5600800514221191
time gen tails  0.08024311065673828
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1098637580871582  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.005017280578613  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.005242824554443  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11361074447631836  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789834022521973  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79555368423462  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12394571304321289  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1380038261413574
pure train time :  0.44129490852355957
train time :  0.6057567596435547
end to end time :  4.216504096984863
connection check time:  1.8835844993591309
block generation time  0.9389963150024414
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000518798828125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013924121856689453
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6434581279754639
len local_batched_seeds_list  2
partition total batch output list spend :  0.7276637554168701
self.buckets_partition() spend  sec:  0.6574170589447021
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04271221160888672

in edges time spent  0.1488337516784668
local to global src and eids time spent  0.2642397880554199
time gen tails  0.05257701873779297
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08884143829345703

in edges time spent  0.35511350631713867
local to global src and eids time spent  0.5085129737854004
time gen tails  0.05743098258972168
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1110849380493164  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002930641174316  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002033710479736  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11501026153564453  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.77913522720337  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784854888916016  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12499046325683594  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.134779691696167
pure train time :  0.4298417568206787
train time :  0.5872130393981934
end to end time :  4.028489828109741
connection check time:  1.766679048538208
block generation time  0.9272949695587158
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004923343658447266
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015251636505126953
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6229085922241211
len local_batched_seeds_list  2
partition total batch output list spend :  0.6679685115814209
self.buckets_partition() spend  sec:  0.6381919384002686
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.03991556167602539

in edges time spent  0.14740943908691406
local to global src and eids time spent  0.26293301582336426
time gen tails  0.05178475379943848
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08919024467468262

in edges time spent  0.3440711498260498
local to global src and eids time spent  0.5442712306976318
time gen tails  0.07942724227905273
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11018991470336914  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00451946258545  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003553867340088  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11452436447143555  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780638694763184  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78635835647583  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12420940399169922  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1315581798553467
pure train time :  0.4412848949432373
train time :  0.6103506088256836
end to end time :  4.032778978347778
connection check time:  1.8049323558807373
block generation time  0.9368462562561035
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005078315734863281
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014026641845703125
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5745909214019775
len local_batched_seeds_list  2
partition total batch output list spend :  0.6594650745391846
self.buckets_partition() spend  sec:  0.588655948638916
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042047977447509766

in edges time spent  0.1430063247680664
local to global src and eids time spent  0.2607877254486084
time gen tails  0.052297353744506836
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08942651748657227

in edges time spent  0.35060644149780273
local to global src and eids time spent  0.5493454933166504
time gen tails  0.0843958854675293
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10985851287841797  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042901039123535  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042277336120605  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11429119110107422  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789910793304443  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79563045501709  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12436246871948242  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1324241161346436
pure train time :  0.42981863021850586
train time :  0.5888173580169678
end to end time :  4.020307779312134
connection check time:  1.8251628875732422
block generation time  0.9287612438201904
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005559921264648438
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013747215270996094
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6809327602386475
len local_batched_seeds_list  2
partition total batch output list spend :  0.764716386795044
self.buckets_partition() spend  sec:  0.6947140693664551
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043833255767822266

in edges time spent  0.14763379096984863
local to global src and eids time spent  0.271512508392334
time gen tails  0.05372333526611328
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09356069564819336

in edges time spent  0.3555717468261719
local to global src and eids time spent  0.5531671047210693
time gen tails  0.08152890205383301
res  length 2
block collection to dataloader spend  1.33514404296875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11054277420043945  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038665294647217  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037633895874023  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11288309097290039  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.754265785217285  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.759985446929932  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12351465225219727  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1291362047195435
pure train time :  0.44414734840393066
train time :  0.6058363914489746
end to end time :  4.217844247817993
connection check time:  1.8621611595153809
block generation time  0.9708232879638672
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005095005035400391
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014106512069702148
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6759202480316162
len local_batched_seeds_list  2
partition total batch output list spend :  0.7623629570007324
self.buckets_partition() spend  sec:  0.6900589466094971
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.044646263122558594

in edges time spent  0.1482384204864502
local to global src and eids time spent  0.26685237884521484
time gen tails  0.053138017654418945
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09249615669250488

in edges time spent  0.3632018566131592
local to global src and eids time spent  0.5584454536437988
time gen tails  0.08236289024353027
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1099858283996582  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042555332183838  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041802406311035  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1150827407836914  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79245662689209  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.798176288604736  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12471199035644531  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1268377304077148
pure train time :  0.43311142921447754
train time :  0.5921764373779297
end to end time :  4.2208757400512695
connection check time:  1.8695344924926758
block generation time  0.9826962947845459
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004513263702392578
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01392054557800293
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6615951061248779
len local_batched_seeds_list  2
partition total batch output list spend :  0.7455277442932129
self.buckets_partition() spend  sec:  0.6755528450012207
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04388093948364258

in edges time spent  0.14868974685668945
local to global src and eids time spent  0.2678110599517822
time gen tails  0.05323934555053711
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09169411659240723

in edges time spent  0.3609585762023926
local to global src and eids time spent  0.562751054763794
time gen tails  0.0823216438293457
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11111259460449219  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042315483093262  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040867805480957  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11385250091552734  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787888526916504  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79360818862915  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12444543838500977  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1258535385131836
pure train time :  0.44278669357299805
train time :  0.6079330444335938
end to end time :  4.206838369369507
connection check time:  1.8712501525878906
block generation time  0.9681463241577148
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000522613525390625
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015448331832885742
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6574013233184814
len local_batched_seeds_list  2
partition total batch output list spend :  0.7025892734527588
self.buckets_partition() spend  sec:  0.6728808879852295
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042388200759887695

in edges time spent  0.14854097366333008
local to global src and eids time spent  0.2619471549987793
time gen tails  0.05156588554382324
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09335803985595703

in edges time spent  0.3526339530944824
local to global src and eids time spent  0.5558853149414062
time gen tails  0.08255529403686523
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11015510559082031  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999585628509521  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998646259307861  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11507606506347656  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.767093181610107  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.772812843322754  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12471628189086914  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1243538856506348
pure train time :  0.44295454025268555
train time :  0.6075246334075928
end to end time :  4.135560989379883
connection check time:  1.843691349029541
block generation time  0.9676980972290039
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00044608116149902344
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014412641525268555
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6836609840393066
len local_batched_seeds_list  2
partition total batch output list spend :  0.7703163623809814
self.buckets_partition() spend  sec:  0.6981058120727539
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04412508010864258

in edges time spent  0.14893460273742676
local to global src and eids time spent  0.26717329025268555
time gen tails  0.053073883056640625
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0923306941986084

in edges time spent  0.3554677963256836
local to global src and eids time spent  0.5138180255889893
time gen tails  0.05956864356994629
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1111440658569336  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043639659881592  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042177677154541  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11370420455932617  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793458461761475  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.799178123474121  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1253376007080078  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1221647262573242
pure train time :  0.4418172836303711
train time :  0.6011817455291748
end to end time :  4.152241945266724
connection check time:  1.7974231243133545
block generation time  0.9677650928497314
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004858970642089844
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01543569564819336
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6520848274230957
len local_batched_seeds_list  2
partition total batch output list spend :  0.6977496147155762
self.buckets_partition() spend  sec:  0.6675548553466797
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04172635078430176

in edges time spent  0.14938807487487793
local to global src and eids time spent  0.26751708984375
time gen tails  0.053211212158203125
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09709811210632324

in edges time spent  0.36475658416748047
local to global src and eids time spent  0.5578033924102783
time gen tails  0.0818331241607666
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11053133010864258  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00283432006836  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001810550689697  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11302614212036133  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.783232688903809  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788952350616455  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12355661392211914  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1231374740600586
pure train time :  0.44031286239624023
train time :  0.5988638401031494
end to end time :  4.165579795837402
connection check time:  1.8705909252166748
block generation time  0.9801309108734131
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004780292510986328
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014350175857543945
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6738710403442383
len local_batched_seeds_list  2
partition total batch output list spend :  0.7652108669281006
self.buckets_partition() spend  sec:  0.6882550716400146
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04770517349243164

in edges time spent  0.15848398208618164
local to global src and eids time spent  0.2747955322265625
time gen tails  0.05784201622009277
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09445643424987793

in edges time spent  0.3599703311920166
local to global src and eids time spent  0.5616466999053955
time gen tails  0.08325862884521484
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11013221740722656  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004369258880615  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00346326828003  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11438846588134766  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.76680040359497  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.772520065307617  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12498617172241211  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1224275827407837
pure train time :  0.44382715225219727
train time :  0.6080186367034912
end to end time :  4.282918453216553
connection check time:  1.906641960144043
block generation time  0.9859960079193115
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004825592041015625
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01399993896484375
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6727409362792969
len local_batched_seeds_list  2
partition total batch output list spend :  0.7575485706329346
self.buckets_partition() spend  sec:  0.6867749691009521
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0465550422668457

in edges time spent  0.15013504028320312
local to global src and eids time spent  0.2685706615447998
time gen tails  0.05307364463806152
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09370994567871094

in edges time spent  0.3831937313079834
local to global src and eids time spent  0.5627591609954834
time gen tails  0.08232426643371582
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11122703552246094  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04258918762207  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041033744812012  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11374330520629883  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784786224365234  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79050588607788  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12447309494018555  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1205819845199585
pure train time :  0.4427645206451416
train time :  0.6097066402435303
end to end time :  4.2536680698394775
connection check time:  1.9003016948699951
block generation time  0.9690656661987305
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00046563148498535156
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014028549194335938
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5928688049316406
len local_batched_seeds_list  2
partition total batch output list spend :  0.6791131496429443
self.buckets_partition() spend  sec:  0.6069333553314209
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04530501365661621

in edges time spent  0.1573045253753662
local to global src and eids time spent  0.28104376792907715
time gen tails  0.05407547950744629
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09299492835998535

in edges time spent  0.3481309413909912
local to global src and eids time spent  0.49595022201538086
time gen tails  0.05781269073486328
res  length 2
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11033201217651367  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043691158294678  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043460845947266  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1145172119140625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789054870605469  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.794774532318115  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12452411651611328  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1153926849365234
pure train time :  0.4347376823425293
train time :  0.6007328033447266
end to end time :  4.038825273513794
connection check time:  1.8001518249511719
block generation time  0.9417881965637207
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005025863647460938
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015464305877685547
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.628636360168457
len local_batched_seeds_list  2
partition total batch output list spend :  0.6738054752349854
self.buckets_partition() spend  sec:  0.6441395282745361
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04008984565734863

in edges time spent  0.13016200065612793
local to global src and eids time spent  0.21411752700805664
time gen tails  0.038750648498535156
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08887863159179688

in edges time spent  0.3407561779022217
local to global src and eids time spent  0.49144792556762695
time gen tails  0.05801725387573242
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10988855361938477  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040124893188477  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040338039398193  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11434125900268555  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.782167911529541  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787887573242188  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12460088729858398  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1174542903900146
pure train time :  0.43242883682250977
train time :  0.5899033546447754
end to end time :  3.865861415863037
connection check time:  1.6459531784057617
block generation time  0.9380602836608887
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004787445068359375
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015237092971801758
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6469829082489014
len local_batched_seeds_list  2
partition total batch output list spend :  0.6917376518249512
self.buckets_partition() spend  sec:  0.6622517108917236
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.040488243103027344

in edges time spent  0.1430051326751709
local to global src and eids time spent  0.2605156898498535
time gen tails  0.05211448669433594
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08938264846801758

in edges time spent  0.3490927219390869
local to global src and eids time spent  0.5324466228485107
time gen tails  0.07923269271850586
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11015176773071289  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04309368133545  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042459964752197  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11314916610717773  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78169870376587  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787418365478516  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12424945831298828  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1157432794570923
pure train time :  0.4305155277252197
train time :  0.5881996154785156
end to end time :  4.011311054229736
connection check time:  1.7899432182312012
block generation time  0.9284713268280029
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005171298980712891
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01544952392578125
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6061418056488037
len local_batched_seeds_list  2
partition total batch output list spend :  0.651111364364624
self.buckets_partition() spend  sec:  0.6216249465942383
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04033207893371582

in edges time spent  0.14421439170837402
local to global src and eids time spent  0.25908684730529785
time gen tails  0.05213642120361328
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09011316299438477

in edges time spent  0.34137439727783203
local to global src and eids time spent  0.533482551574707
time gen tails  0.07986211776733398
res  length 2
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11070823669433594  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000386714935303  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999178409576416  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11427783966064453  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.794162273406982  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.799881935119629  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12473392486572266  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.11422598361969
pure train time :  0.4410989284515381
train time :  0.6071317195892334
end to end time :  3.9894769191741943
connection check time:  1.784308910369873
block generation time  0.9286463260650635
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005002021789550781
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013816595077514648
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6575117111206055
len local_batched_seeds_list  2
partition total batch output list spend :  0.7416996955871582
self.buckets_partition() spend  sec:  0.6713676452636719
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04313540458679199

in edges time spent  0.14401626586914062
local to global src and eids time spent  0.25934338569641113
time gen tails  0.05207657814025879
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08994007110595703

in edges time spent  0.35717153549194336
local to global src and eids time spent  0.537949800491333
time gen tails  0.08145809173583984
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11106061935424805  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001227855682373  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999839305877686  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11509037017822266  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790149211883545  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.795868873596191  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12625741958618164  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.112107515335083
pure train time :  0.4414074420928955
train time :  0.6061930656433105
end to end time :  4.140553951263428
connection check time:  1.822157859802246
block generation time  0.9545161724090576
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004963874816894531
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014179468154907227
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6674604415893555
len local_batched_seeds_list  2
partition total batch output list spend :  0.7514128684997559
self.buckets_partition() spend  sec:  0.6816728115081787
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042607784271240234

in edges time spent  0.14432215690612793
local to global src and eids time spent  0.2619972229003906
time gen tails  0.05191946029663086
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09127926826477051

in edges time spent  0.36384034156799316
local to global src and eids time spent  0.5783679485321045
time gen tails  0.08092999458312988
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11034488677978516  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003225326538086  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00324821472168  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11472463607788086  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786717891693115  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792437553405762  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12480831146240234  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.111250400543213
pure train time :  0.4416799545288086
train time :  0.6090939044952393
end to end time :  4.197627305984497
connection check time:  1.8672864437103271
block generation time  0.9557955265045166
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004858970642089844
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014735937118530273
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.675529956817627
len local_batched_seeds_list  2
partition total batch output list spend :  0.7621593475341797
self.buckets_partition() spend  sec:  0.6903002262115479
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043437957763671875

in edges time spent  0.14438843727111816
local to global src and eids time spent  0.2594773769378662
time gen tails  0.05187654495239258
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09035921096801758

in edges time spent  0.3765997886657715
local to global src and eids time spent  0.547245979309082
time gen tails  0.08095526695251465
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11093330383300781  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.045158386230469  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.045281410217285  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11482000350952148  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.761682033538818  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.767401695251465  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12450075149536133  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.113976001739502
pure train time :  0.4338111877441406
train time :  0.5922133922576904
end to end time :  4.161394119262695
connection check time:  1.8396902084350586
block generation time  0.9456496238708496
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005044937133789062
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014143943786621094
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6421787738800049
len local_batched_seeds_list  2
partition total batch output list spend :  0.7259104251861572
self.buckets_partition() spend  sec:  0.6563587188720703
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04219341278076172

in edges time spent  0.14374446868896484
local to global src and eids time spent  0.2619931697845459
time gen tails  0.05199599266052246
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09017419815063477

in edges time spent  0.3578617572784424
local to global src and eids time spent  0.5385136604309082
time gen tails  0.08036613464355469
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11046695709228516  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041949272155762  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041336059570312  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11497163772583008  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.75424337387085  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.759963035583496  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12488555908203125  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1076946258544922
pure train time :  0.44470787048339844
train time :  0.5981316566467285
end to end time :  4.110150337219238
connection check time:  1.8205771446228027
block generation time  0.9441885948181152
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005407333374023438
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015886545181274414
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6535804271697998
len local_batched_seeds_list  2
partition total batch output list spend :  0.6995983123779297
self.buckets_partition() spend  sec:  0.6695010662078857
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04071664810180664

in edges time spent  0.14531993865966797
local to global src and eids time spent  0.2703702449798584
time gen tails  0.052733659744262695
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08948397636413574

in edges time spent  0.3701820373535156
local to global src and eids time spent  0.5659096240997314
time gen tails  0.08280515670776367
res  length 2
block collection to dataloader spend  1.1682510375976562e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11102867126464844  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00237512588501  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001531600952148  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11491060256958008  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.759039878845215  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.764759540557861  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12485265731811523  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1069425344467163
pure train time :  0.43928980827331543
train time :  0.6075711250305176
end to end time :  4.139475345611572
connection check time:  1.865079402923584
block generation time  0.9548358917236328
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005762577056884766
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014663934707641602
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5927238464355469
len local_batched_seeds_list  2
partition total batch output list spend :  0.678919792175293
self.buckets_partition() spend  sec:  0.607428789138794
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04247879981994629

in edges time spent  0.14538860321044922
local to global src and eids time spent  0.2601487636566162
time gen tails  0.05236983299255371
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0912928581237793

in edges time spent  0.3494992256164551
local to global src and eids time spent  0.5538945198059082
time gen tails  0.09632277488708496
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11072683334350586  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042981147766113  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04238748550415  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11420392990112305  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78737211227417  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793091773986816  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12395048141479492  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1035728454589844
pure train time :  0.44347286224365234
train time :  0.6104393005371094
end to end time :  4.128095865249634
connection check time:  1.8547918796539307
block generation time  0.9696924686431885
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005931854248046875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015174150466918945
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6779286861419678
len local_batched_seeds_list  2
partition total batch output list spend :  0.764472484588623
self.buckets_partition() spend  sec:  0.6932241916656494
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04637455940246582

in edges time spent  0.14561223983764648
local to global src and eids time spent  0.26323843002319336
time gen tails  0.052754878997802734
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0904684066772461

in edges time spent  0.3479492664337158
local to global src and eids time spent  0.5379669666290283
time gen tails  0.0797872543334961
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11089944839477539  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999317646026611  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998600006103516  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11490583419799805  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791564464569092  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.797284126281738  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12510299682617188  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1011911630630493
pure train time :  0.4474496841430664
train time :  0.6203200817108154
end to end time :  4.17625093460083
connection check time:  1.8143551349639893
block generation time  0.9521694183349609
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00045943260192871094
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014392375946044922
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6285572052001953
len local_batched_seeds_list  2
partition total batch output list spend :  0.714402437210083
self.buckets_partition() spend  sec:  0.6429831981658936
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04545879364013672

in edges time spent  0.15992140769958496
local to global src and eids time spent  0.27378368377685547
time gen tails  0.05746650695800781
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09179377555847168

in edges time spent  0.37387537956237793
local to global src and eids time spent  0.5312895774841309
time gen tails  0.06279253959655762
res  length 2
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11043071746826172  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042866706848145  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041981220245361  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11457347869873047  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780593872070312  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786313533782959  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12463951110839844  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1030325889587402
pure train time :  0.44942259788513184
train time :  0.6179225444793701
end to end time :  4.177769660949707
connection check time:  1.854123830795288
block generation time  0.972088098526001
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004978179931640625
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.016164541244506836
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7029860019683838
len local_batched_seeds_list  2
partition total batch output list spend :  0.7494685649871826
self.buckets_partition() spend  sec:  0.7191905975341797
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04388689994812012

in edges time spent  0.15520906448364258
local to global src and eids time spent  0.27506232261657715
time gen tails  0.054270029067993164
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09616351127624512

in edges time spent  0.36663222312927246
local to global src and eids time spent  0.5736885070800781
time gen tails  0.08396697044372559
res  length 2
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11022138595581055  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042781352996826  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042071342468262  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11300230026245117  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788698673248291  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.794418334960938  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12367868423461914  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.103151798248291
pure train time :  0.45104336738586426
train time :  0.6131527423858643
end to end time :  4.296664476394653
connection check time:  1.9117443561553955
block generation time  1.0015861988067627
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005381107330322266
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01499176025390625
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7151503562927246
len local_batched_seeds_list  2
partition total batch output list spend :  0.8020434379577637
self.buckets_partition() spend  sec:  0.7301771640777588
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0447087287902832

in edges time spent  0.15114808082580566
local to global src and eids time spent  0.26962947845458984
time gen tails  0.05371999740600586
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0953679084777832

in edges time spent  0.36177563667297363
local to global src and eids time spent  0.5516972541809082
time gen tails  0.07984137535095215
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11028337478637695  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043083667755127  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042313575744629  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11311531066894531  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787232875823975  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792952537536621  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12372732162475586  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0983772277832031
pure train time :  0.43579936027526855
train time :  0.5975735187530518
end to end time :  4.23798394203186
connection check time:  1.8631346225738525
block generation time  0.9579269886016846
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005857944488525391
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014808893203735352
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6401896476745605
len local_batched_seeds_list  2
partition total batch output list spend :  0.7255825996398926
self.buckets_partition() spend  sec:  0.6550333499908447
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04229474067687988

in edges time spent  0.14470648765563965
local to global src and eids time spent  0.2744629383087158
time gen tails  0.055124521255493164
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0901792049407959

in edges time spent  0.3804140090942383
local to global src and eids time spent  0.5554664134979248
time gen tails  0.08350467681884766
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1102137565612793  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.035567283630371  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.0345778465271  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11528348922729492  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784453392028809  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790173053741455  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12512826919555664  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.100856900215149
pure train time :  0.44777536392211914
train time :  0.6158199310302734
end to end time :  4.207629442214966
connection check time:  1.9020776748657227
block generation time  0.9508950710296631
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005176067352294922
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014126300811767578
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6437220573425293
len local_batched_seeds_list  2
partition total batch output list spend :  0.7293691635131836
self.buckets_partition() spend  sec:  0.6578845977783203
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04405045509338379

in edges time spent  0.15202808380126953
local to global src and eids time spent  0.27183008193969727
time gen tails  0.05219411849975586
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09031438827514648

in edges time spent  0.3597280979156494
local to global src and eids time spent  0.5364432334899902
time gen tails  0.08263134956359863
res  length 2
block collection to dataloader spend  1.2159347534179688e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11132574081420898  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000528335571289  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999150276184082  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11430931091308594  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784467697143555  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790187358856201  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12495231628417969  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0973930358886719
pure train time :  0.4438037872314453
train time :  0.6118769645690918
end to end time :  4.171827793121338
connection check time:  1.853187084197998
block generation time  0.9490270614624023
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005786418914794922
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014810562133789062
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6686015129089355
len local_batched_seeds_list  2
partition total batch output list spend :  0.7536559104919434
self.buckets_partition() spend  sec:  0.6834628582000732
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043062686920166016

in edges time spent  0.1434028148651123
local to global src and eids time spent  0.2615659236907959
time gen tails  0.05298304557800293
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09121990203857422

in edges time spent  0.36443352699279785
local to global src and eids time spent  0.5766177177429199
time gen tails  0.0839223861694336
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11139535903930664  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042103290557861  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040387630462646  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1134176254272461  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789421081542969  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.795140743255615  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1238870620727539  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0970537662506104
pure train time :  0.44931912422180176
train time :  0.611475944519043
end to end time :  4.260946989059448
connection check time:  1.8813726902008057
block generation time  1.0009269714355469
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005228519439697266
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014999151229858398
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7066726684570312
len local_batched_seeds_list  2
partition total batch output list spend :  0.7936203479766846
self.buckets_partition() spend  sec:  0.7217116355895996
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04508256912231445

in edges time spent  0.14921021461486816
local to global src and eids time spent  0.2696421146392822
time gen tails  0.05394887924194336
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0941152572631836

in edges time spent  0.3560967445373535
local to global src and eids time spent  0.5575830936431885
time gen tails  0.08267331123352051
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10980892181396484  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044841766357422  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044271469116211  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11290454864501953  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.749524116516113  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.75524377822876  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12334012985229492  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0948474407196045
pure train time :  0.44912219047546387
train time :  0.6170248985290527
end to end time :  4.284837007522583
connection check time:  1.8706600666046143
block generation time  0.9853603839874268
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005228519439697266
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014698028564453125
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5483746528625488
len local_batched_seeds_list  2
partition total batch output list spend :  0.6351349353790283
self.buckets_partition() spend  sec:  0.563107967376709
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04534482955932617

in edges time spent  0.15050220489501953
local to global src and eids time spent  0.26998448371887207
time gen tails  0.05386519432067871
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09478163719177246

in edges time spent  0.36161351203918457
local to global src and eids time spent  0.5674734115600586
time gen tails  0.08295702934265137
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10979795455932617  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044437885284424  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.0438814163208  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11463165283203125  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.768260955810547  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.773980617523193  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12472105026245117  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0924382209777832
pure train time :  0.44965052604675293
train time :  0.6159701347351074
end to end time :  4.158517599105835
connection check time:  1.8948805332183838
block generation time  0.994182825088501
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005166530609130859
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015521049499511719
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.678551197052002
len local_batched_seeds_list  2
partition total batch output list spend :  0.7660539150238037
self.buckets_partition() spend  sec:  0.6941072940826416
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0457003116607666

in edges time spent  0.1536705493927002
local to global src and eids time spent  0.27097225189208984
time gen tails  0.054175376892089844
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09421277046203613

in edges time spent  0.3668794631958008
local to global src and eids time spent  0.5644102096557617
time gen tails  0.08341598510742188
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11040687561035156  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042212963104248  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041316509246826  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11336994171142578  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788149356842041  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793869018554688  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12395381927490234  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0928452014923096
pure train time :  0.4489140510559082
train time :  0.6170363426208496
end to end time :  4.283320903778076
connection check time:  1.8991179466247559
block generation time  0.9869904518127441
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005738735198974609
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014696121215820312
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6801671981811523
len local_batched_seeds_list  2
partition total batch output list spend :  0.7666561603546143
self.buckets_partition() spend  sec:  0.694896936416626
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0464787483215332

in edges time spent  0.15157318115234375
local to global src and eids time spent  0.2685096263885498
time gen tails  0.053823232650756836
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09552931785583496

in edges time spent  0.3686075210571289
local to global src and eids time spent  0.5656940937042236
time gen tails  0.08348798751831055
res  length 2
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1101689338684082  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002941131591797  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001991748809814  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1154332160949707  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.795543670654297  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.801263332366943  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12501859664916992  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0947316884994507
pure train time :  0.4502577781677246
train time :  0.625999927520752
end to end time :  4.298820495605469
connection check time:  1.8983509540557861
block generation time  0.9869601726531982
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000598907470703125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014492273330688477
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6509873867034912
len local_batched_seeds_list  2
partition total batch output list spend :  0.7365255355834961
self.buckets_partition() spend  sec:  0.6655232906341553
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0432133674621582

in edges time spent  0.14551949501037598
local to global src and eids time spent  0.26139378547668457
time gen tails  0.0526430606842041
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09114861488342285

in edges time spent  0.35570621490478516
local to global src and eids time spent  0.5471343994140625
time gen tails  0.07990646362304688
res  length 2
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11105537414550781  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003539562225342  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002155303955078  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11526966094970703  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788058757781982  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793778419494629  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12487268447875977  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.091949224472046
pure train time :  0.4483363628387451
train time :  0.614495038986206
end to end time :  4.143219709396362
connection check time:  1.8296730518341064
block generation time  0.9456312656402588
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004913806915283203
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014150142669677734
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6574141979217529
len local_batched_seeds_list  2
partition total batch output list spend :  0.7423923015594482
self.buckets_partition() spend  sec:  0.6715993881225586
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04263496398925781

in edges time spent  0.14494848251342773
local to global src and eids time spent  0.2612898349761963
time gen tails  0.052507638931274414
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08951258659362793

in edges time spent  0.3565561771392822
local to global src and eids time spent  0.5468428134918213
time gen tails  0.08079171180725098
res  length 2
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11119985580444336  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040661811828613  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040008544921875  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11485528945922852  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790482521057129  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796202182769775  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1255497932434082  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0873615741729736
pure train time :  0.4492313861846924
train time :  0.6089730262756348
end to end time :  4.14391565322876
connection check time:  1.8264291286468506
block generation time  0.9521794319152832
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005261898040771484
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01434183120727539
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6471326351165771
len local_batched_seeds_list  2
partition total batch output list spend :  0.7319939136505127
self.buckets_partition() spend  sec:  0.6615095138549805
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043004751205444336

in edges time spent  0.14427495002746582
local to global src and eids time spent  0.2606017589569092
time gen tails  0.05266308784484863
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09292316436767578

in edges time spent  0.3708944320678711
local to global src and eids time spent  0.5744631290435791
time gen tails  0.08442544937133789
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10988521575927734  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042263984680176  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042476654052734  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11455583572387695  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787710189819336  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793429851531982  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12473297119140625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.08907949924469
pure train time :  0.44066667556762695
train time :  0.6011660099029541
end to end time :  4.215978622436523
connection check time:  1.885270357131958
block generation time  0.9843084812164307
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005068778991699219
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014455556869506836
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6763575077056885
len local_batched_seeds_list  2
partition total batch output list spend :  0.7628393173217773
self.buckets_partition() spend  sec:  0.6908478736877441
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0445408821105957

in edges time spent  0.14954900741577148
local to global src and eids time spent  0.26934313774108887
time gen tails  0.05366921424865723
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09575414657592773

in edges time spent  0.35471343994140625
local to global src and eids time spent  0.5552911758422852
time gen tails  0.08209419250488281
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11005067825317383  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002013683319092  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002052307128906  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11451148986816406  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.782564640045166  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788284301757812  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12491035461425781  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.086185336112976
pure train time :  0.44860267639160156
train time :  0.6119701862335205
end to end time :  4.236077070236206
connection check time:  1.8672232627868652
block generation time  0.977001428604126
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00048804283142089844
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014590740203857422
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6947195529937744
len local_batched_seeds_list  2
partition total batch output list spend :  0.7817268371582031
self.buckets_partition() spend  sec:  0.7093453407287598
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04331231117248535

in edges time spent  0.1462874412536621
local to global src and eids time spent  0.2620811462402344
time gen tails  0.05261945724487305
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09154152870178223

in edges time spent  0.3631601333618164
local to global src and eids time spent  0.573096752166748
time gen tails  0.08310317993164062
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11027097702026367  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997982501983643  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997207641601562  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11328840255737305  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792873859405518  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.798593521118164  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1240224838256836  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0827572345733643
pure train time :  0.4384455680847168
train time :  0.5967187881469727
end to end time :  4.2333664894104
connection check time:  1.8731279373168945
block generation time  0.9677433967590332
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005006790161132812
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014636039733886719
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5804526805877686
len local_batched_seeds_list  2
partition total batch output list spend :  0.666820764541626
self.buckets_partition() spend  sec:  0.5951306819915771
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04346013069152832

in edges time spent  0.1450362205505371
local to global src and eids time spent  0.2604384422302246
time gen tails  0.052544355392456055
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0942690372467041

in edges time spent  0.3451850414276123
local to global src and eids time spent  0.537339448928833
time gen tails  0.08117294311523438
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11031389236450195  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.006357192993164  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00527048110962  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11380290985107422  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.753328800201416  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.759048461914062  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12374734878540039  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.082715392112732
pure train time :  0.448026180267334
train time :  0.6089308261871338
end to end time :  4.044065713882446
connection check time:  1.8090109825134277
block generation time  0.945521354675293
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005309581756591797
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014163494110107422
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6290826797485352
len local_batched_seeds_list  2
partition total batch output list spend :  0.7145020961761475
self.buckets_partition() spend  sec:  0.6432812213897705
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04375052452087402

in edges time spent  0.14580607414245605
local to global src and eids time spent  0.26160311698913574
time gen tails  0.05243325233459473
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09116458892822266

in edges time spent  0.34709620475769043
local to global src and eids time spent  0.5586550235748291
time gen tails  0.08486723899841309
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11042022705078125  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002730369567871  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001532554626465  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11315202713012695  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781530857086182  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787250518798828  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12363433837890625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.082434892654419
pure train time :  0.4495716094970703
train time :  0.6120479106903076
end to end time :  4.123885154724121
connection check time:  1.8393580913543701
block generation time  0.9447901248931885
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005433559417724609
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014597654342651367
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6358871459960938
len local_batched_seeds_list  2
partition total batch output list spend :  0.732903003692627
self.buckets_partition() spend  sec:  0.6505379676818848
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04663372039794922

in edges time spent  0.15717363357543945
local to global src and eids time spent  0.269977331161499
time gen tails  0.053496599197387695
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09180784225463867

in edges time spent  0.38798999786376953
local to global src and eids time spent  0.5779151916503906
time gen tails  0.08446812629699707
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11010026931762695  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044361114501953  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043506145477295  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11394357681274414  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.753468036651611  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.759187698364258  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12373590469360352  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0780619382858276
pure train time :  0.4482238292694092
train time :  0.6160733699798584
end to end time :  4.288912534713745
connection check time:  1.931480884552002
block generation time  0.9833903312683105
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0006263256072998047
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014825820922851562
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.637336254119873
len local_batched_seeds_list  2
partition total batch output list spend :  0.7225301265716553
self.buckets_partition() spend  sec:  0.6521956920623779
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042949676513671875

in edges time spent  0.14741182327270508
local to global src and eids time spent  0.2615475654602051
time gen tails  0.05260968208312988
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09466719627380371

in edges time spent  0.3719635009765625
local to global src and eids time spent  0.5737357139587402
time gen tails  0.08437776565551758
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11028194427490234  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042523384094238  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042337417602539  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11449432373046875  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793529987335205  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.799249649047852  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12485837936401367  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.08059561252594
pure train time :  0.44590067863464355
train time :  0.6059753894805908
end to end time :  4.235936164855957
connection check time:  1.8890304565429688
block generation time  1.0012924671173096
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005624294281005859
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01467752456665039
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6715254783630371
len local_batched_seeds_list  2
partition total batch output list spend :  0.7569565773010254
self.buckets_partition() spend  sec:  0.686237096786499
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04486703872680664

in edges time spent  0.1498703956604004
local to global src and eids time spent  0.27106523513793945
time gen tails  0.05384492874145508
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09508180618286133

in edges time spent  0.3652458190917969
local to global src and eids time spent  0.5694894790649414
time gen tails  0.08452463150024414
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11025619506835938  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.005699634552002  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004950046539307  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11402320861816406  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781701564788818  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787421226501465  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12400150299072266  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0770198106765747
pure train time :  0.45026516914367676
train time :  0.6107521057128906
end to end time :  4.285253524780273
connection check time:  1.9014647006988525
block generation time  1.0020909309387207
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0006070137023925781
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014557600021362305
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7045638561248779
len local_batched_seeds_list  2
partition total batch output list spend :  0.7915909290313721
self.buckets_partition() spend  sec:  0.7191555500030518
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04560685157775879

in edges time spent  0.15103912353515625
local to global src and eids time spent  0.26967597007751465
time gen tails  0.05351734161376953
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09567523002624512

in edges time spent  0.3718113899230957
local to global src and eids time spent  0.5665669441223145
time gen tails  0.08517026901245117
res  length 2
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.110443115234375  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038692951202393  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037760257720947  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1132822036743164  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.765553951263428  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.771273612976074  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12404155731201172  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.076269268989563
pure train time :  0.44686198234558105
train time :  0.6158452033996582
end to end time :  4.316457986831665
connection check time:  1.9024500846862793
block generation time  0.9836020469665527
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0006010532379150391
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014515399932861328
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6981363296508789
len local_batched_seeds_list  2
partition total batch output list spend :  0.7833538055419922
self.buckets_partition() spend  sec:  0.7127697467803955
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0442509651184082

in edges time spent  0.1481633186340332
local to global src and eids time spent  0.2696549892425537
time gen tails  0.05381178855895996
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09349751472473145

in edges time spent  0.36387038230895996
local to global src and eids time spent  0.5672271251678467
time gen tails  0.08249902725219727
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11039972305297852  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04292917251587  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041765213012695  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11449527740478516  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.783153057098389  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788872718811035  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12442684173583984  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0740524530410767
pure train time :  0.44925856590270996
train time :  0.6120703220367432
end to end time :  4.287169456481934
connection check time:  1.8847577571868896
block generation time  0.9862885475158691
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005397796630859375
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014838457107543945
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6866042613983154
len local_batched_seeds_list  2
partition total batch output list spend :  0.7732925415039062
self.buckets_partition() spend  sec:  0.7014780044555664
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04476737976074219

in edges time spent  0.15060806274414062
local to global src and eids time spent  0.27062392234802246
time gen tails  0.05383467674255371
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09252572059631348

in edges time spent  0.35535144805908203
local to global src and eids time spent  0.5588061809539795
time gen tails  0.08317780494689941
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10981512069702148  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04237985610962  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041793823242188  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1132516860961914  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786811351776123  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79253101348877  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1248326301574707  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0731027126312256
pure train time :  0.4490687847137451
train time :  0.6154425144195557
end to end time :  4.272746562957764
connection check time:  1.8718500137329102
block generation time  0.994865894317627
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005233287811279297
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014354944229125977
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6755449771881104
len local_batched_seeds_list  2
partition total batch output list spend :  0.7617616653442383
self.buckets_partition() spend  sec:  0.6899335384368896
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04483151435852051

in edges time spent  0.1492154598236084
local to global src and eids time spent  0.2681884765625
time gen tails  0.053652286529541016
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09600663185119629

in edges time spent  0.36370062828063965
local to global src and eids time spent  0.5676617622375488
time gen tails  0.08424854278564453
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1104879379272461  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04575252532959  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.045645713806152  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11442279815673828  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.775489330291748  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781208992004395  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12441587448120117  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.072200059890747
pure train time :  0.4396247863769531
train time :  0.6002402305603027
end to end time :  4.26990532875061
connection check time:  1.8962335586547852
block generation time  0.9942562580108643
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005488395690917969
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014552593231201172
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5755336284637451
len local_batched_seeds_list  2
partition total batch output list spend :  0.6619319915771484
self.buckets_partition() spend  sec:  0.590130090713501
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0442347526550293

in edges time spent  0.14948010444641113
local to global src and eids time spent  0.2681999206542969
time gen tails  0.05425381660461426
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09507966041564941

in edges time spent  0.36442017555236816
local to global src and eids time spent  0.5641114711761475
time gen tails  0.08333897590637207
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10987710952758789  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04271650314331  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04207992553711  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11453962326049805  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792186260223389  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.797905921936035  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12470865249633789  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0724124908447266
pure train time :  0.43837952613830566
train time :  0.5983092784881592
end to end time :  4.139541387557983
connection check time:  1.8845462799072266
block generation time  0.9807512760162354
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004956722259521484
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014110326766967773
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6556611061096191
len local_batched_seeds_list  2
partition total batch output list spend :  0.7436630725860596
self.buckets_partition() spend  sec:  0.6698050498962402
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04430103302001953

in edges time spent  0.16126060485839844
local to global src and eids time spent  0.27656006813049316
time gen tails  0.05855417251586914
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09487152099609375

in edges time spent  0.36303067207336426
local to global src and eids time spent  0.5733520984649658
time gen tails  0.08466506004333496
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11029767990112305  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.993266105651855  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.992456912994385  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11319398880004883  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792953491210938  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.798673152923584  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12381458282470703  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.072106957435608
pure train time :  0.44718098640441895
train time :  0.6089458465576172
end to end time :  4.282334327697754
connection check time:  1.9254560470581055
block generation time  0.9898984432220459
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005204677581787109
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014293670654296875
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6627063751220703
len local_batched_seeds_list  2
partition total batch output list spend :  0.7485058307647705
self.buckets_partition() spend  sec:  0.6770346164703369
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.045229434967041016

in edges time spent  0.1506054401397705
local to global src and eids time spent  0.2608144283294678
time gen tails  0.05270075798034668
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09004664421081543

in edges time spent  0.374605655670166
local to global src and eids time spent  0.5531039237976074
time gen tails  0.08108210563659668
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11090850830078125  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001267433166504  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000544548034668  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11480379104614258  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.783041000366211  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788760662078857  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12438726425170898  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0686790943145752
pure train time :  0.44457459449768066
train time :  0.6118783950805664
end to end time :  4.191793441772461
connection check time:  1.8599631786346436
block generation time  0.9571561813354492
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005943775177001953
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014157295227050781
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6366078853607178
len local_batched_seeds_list  2
partition total batch output list spend :  0.7222182750701904
self.buckets_partition() spend  sec:  0.6507992744445801
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04314017295837402

in edges time spent  0.14545202255249023
local to global src and eids time spent  0.26462888717651367
time gen tails  0.05370306968688965
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09133505821228027

in edges time spent  0.35962581634521484
local to global src and eids time spent  0.5549883842468262
time gen tails  0.08053326606750488
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10974454879760742  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04609203338623  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04558801651001  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11423635482788086  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.782650470733643  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788370132446289  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12434911727905273  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0676398277282715
pure train time :  0.4476604461669922
train time :  0.6135666370391846
end to end time :  4.153841972351074
connection check time:  1.8462467193603516
block generation time  0.951669454574585
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005419254302978516
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014633893966674805
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6387197971343994
len local_batched_seeds_list  2
partition total batch output list spend :  0.7242178916931152
self.buckets_partition() spend  sec:  0.6533868312835693
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04456591606140137

in edges time spent  0.1458263397216797
local to global src and eids time spent  0.2609901428222656
time gen tails  0.0528264045715332
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09003353118896484

in edges time spent  0.35173845291137695
local to global src and eids time spent  0.5406830310821533
time gen tails  0.08081388473510742
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11027383804321289  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.0439133644104  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043157577514648  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11466789245605469  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.765125751495361  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.770845413208008  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1246042251586914  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0673317909240723
pure train time :  0.446826696395874
train time :  0.6212973594665527
end to end time :  4.122514963150024
connection check time:  1.819108247756958
block generation time  0.9452810287475586
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005159378051757812
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014341354370117188
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6367471218109131
len local_batched_seeds_list  2
partition total batch output list spend :  0.7214038372039795
self.buckets_partition() spend  sec:  0.6511228084564209
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04271650314331055

in edges time spent  0.1440904140472412
local to global src and eids time spent  0.2638707160949707
time gen tails  0.0520477294921875
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09010124206542969

in edges time spent  0.34641551971435547
local to global src and eids time spent  0.5368542671203613
time gen tails  0.08156013488769531
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10979843139648438  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998115062713623  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997535228729248  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11339473724365234  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.797711849212646  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.803431510925293  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12397289276123047  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0669691562652588
pure train time :  0.44638729095458984
train time :  0.6236822605133057
end to end time :  4.106989622116089
connection check time:  1.8073101043701172
block generation time  0.9385085105895996
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005004405975341797
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01436614990234375
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6890406608581543
len local_batched_seeds_list  2
partition total batch output list spend :  0.7783281803131104
self.buckets_partition() spend  sec:  0.7034435272216797
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04281806945800781

in edges time spent  0.1441786289215088
local to global src and eids time spent  0.2600116729736328
time gen tails  0.05249762535095215
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09116458892822266

in edges time spent  0.36136651039123535
local to global src and eids time spent  0.567594051361084
time gen tails  0.08398199081420898
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11014795303344727  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999932289123535  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999011516571045  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11318492889404297  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78049898147583  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786218643188477  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12388134002685547  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0663206577301025
pure train time :  0.4434549808502197
train time :  0.6029889583587646
end to end time :  4.248524904251099
connection check time:  1.8643128871917725
block generation time  0.9830572605133057
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0007078647613525391
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014962911605834961
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6808831691741943
len local_batched_seeds_list  2
partition total batch output list spend :  0.7665915489196777
self.buckets_partition() spend  sec:  0.6958804130554199
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042996883392333984

in edges time spent  0.1441051959991455
local to global src and eids time spent  0.26227784156799316
time gen tails  0.05279827117919922
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09134268760681152

in edges time spent  0.3409609794616699
local to global src and eids time spent  0.5378773212432861
time gen tails  0.08029747009277344
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1102895736694336  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043303489685059  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042255401611328  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1135716438293457  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780162811279297  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785882472991943  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12356185913085938  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.064725399017334
pure train time :  0.44074130058288574
train time :  0.5997183322906494
end to end time :  4.133390188217163
connection check time:  1.8050577640533447
block generation time  0.9484336376190186
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005991458892822266
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014461040496826172
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6451056003570557
len local_batched_seeds_list  2
partition total batch output list spend :  0.7292447090148926
self.buckets_partition() spend  sec:  0.6596009731292725
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042980194091796875

in edges time spent  0.1440739631652832
local to global src and eids time spent  0.2615842819213867
time gen tails  0.05326700210571289
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08971524238586426

in edges time spent  0.3491945266723633
local to global src and eids time spent  0.5370879173278809
time gen tails  0.08025455474853516
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11077165603637695  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038619041442871  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037980556488037  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11351251602172852  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788033485412598  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793753147125244  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12422513961791992  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0643986463546753
pure train time :  0.4399240016937256
train time :  0.6004650592803955
end to end time :  4.1087806224823
connection check time:  1.8087611198425293
block generation time  0.9573774337768555
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005745887756347656
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01603841781616211
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.530125617980957
len local_batched_seeds_list  2
partition total batch output list spend :  0.5767257213592529
self.buckets_partition() spend  sec:  0.5461990833282471
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04073596000671387

in edges time spent  0.1454145908355713
local to global src and eids time spent  0.26259589195251465
time gen tails  0.052872419357299805
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09036803245544434

in edges time spent  0.3412656784057617
local to global src and eids time spent  0.5381453037261963
time gen tails  0.08054852485656738
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11029958724975586  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999773979187012  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998693943023682  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11454963684082031  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78767204284668  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793391704559326  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1244807243347168  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0634064674377441
pure train time :  0.44019627571105957
train time :  0.5986835956573486
end to end time :  3.9397079944610596
connection check time:  1.798887014389038
block generation time  0.9489023685455322
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005590915679931641
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014409780502319336
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6590926647186279
len local_batched_seeds_list  2
partition total batch output list spend :  0.745267391204834
self.buckets_partition() spend  sec:  0.6735355854034424
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04431009292602539

in edges time spent  0.14791440963745117
local to global src and eids time spent  0.26508092880249023
time gen tails  0.052361249923706055
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09378743171691895

in edges time spent  0.3604624271392822
local to global src and eids time spent  0.5433657169342041
time gen tails  0.08145308494567871
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10983085632324219  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041685104370117  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041091918945312  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11326932907104492  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.776871681213379  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.782591342926025  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12407588958740234  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0625910758972168
pure train time :  0.43639111518859863
train time :  0.5946271419525146
end to end time :  4.143278360366821
connection check time:  1.8425588607788086
block generation time  0.9473719596862793
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005822181701660156
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01590561866760254
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6529788970947266
len local_batched_seeds_list  2
partition total batch output list spend :  0.6984591484069824
self.buckets_partition() spend  sec:  0.6689229011535645
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04152035713195801

in edges time spent  0.1512892246246338
local to global src and eids time spent  0.27014732360839844
time gen tails  0.05407118797302246
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09651398658752441

in edges time spent  0.3676443099975586
local to global src and eids time spent  0.5526232719421387
time gen tails  0.08266115188598633
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11044836044311523  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038604259490967  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037402153015137  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11345720291137695  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78389596939087  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789615631103516  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12318181991577148  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.059779167175293
pure train time :  0.4412519931793213
train time :  0.6078026294708252
end to end time :  4.151122093200684
connection check time:  1.8665711879730225
block generation time  0.9625554084777832
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0006465911865234375
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014965057373046875
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6345887184143066
len local_batched_seeds_list  2
partition total batch output list spend :  0.720181941986084
self.buckets_partition() spend  sec:  0.6495881080627441
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04621100425720215

in edges time spent  0.14916133880615234
local to global src and eids time spent  0.26392531394958496
time gen tails  0.05355381965637207
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09412312507629395

in edges time spent  0.3758721351623535
local to global src and eids time spent  0.5634641647338867
time gen tails  0.08367180824279785
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11088323593139648  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001532077789307  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00083065032959  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11485099792480469  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791584968566895  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.797304630279541  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12443065643310547  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0605411529541016
pure train time :  0.44959473609924316
train time :  0.6098940372467041
end to end time :  4.20521354675293
connection check time:  1.8888583183288574
block generation time  0.9725496768951416
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005335807800292969
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014262199401855469
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6504616737365723
len local_batched_seeds_list  2
partition total batch output list spend :  0.7352349758148193
self.buckets_partition() spend  sec:  0.6647646427154541
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04309248924255371

in edges time spent  0.1459519863128662
local to global src and eids time spent  0.26720643043518066
time gen tails  0.05378556251525879
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09480905532836914

in edges time spent  0.35386013984680176
local to global src and eids time spent  0.5580534934997559
time gen tails  0.08284640312194824
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10976600646972656  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997682094573975  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997133731842041  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11307525634765625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.794308185577393  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.800027847290039  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12376880645751953  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0580253601074219
pure train time :  0.43650341033935547
train time :  0.5958356857299805
end to end time :  4.190568923950195
connection check time:  1.8596446514129639
block generation time  0.9825663566589355
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004603862762451172
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01457357406616211
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6690640449523926
len local_batched_seeds_list  2
partition total batch output list spend :  0.757638692855835
self.buckets_partition() spend  sec:  0.6836700439453125
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04439735412597656

in edges time spent  0.14950084686279297
local to global src and eids time spent  0.26811695098876953
time gen tails  0.053879737854003906
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09361505508422852

in edges time spent  0.36759352684020996
local to global src and eids time spent  0.5592701435089111
time gen tails  0.0832223892211914
res  length 2
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11002922058105469  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.99929141998291  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998762130737305  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11324167251586914  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78459119796753  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790310859680176  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12465429306030273  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0574842691421509
pure train time :  0.44440627098083496
train time :  0.6153581142425537
end to end time :  4.2694737911224365
connection check time:  1.904005527496338
block generation time  0.9787912368774414
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0006406307220458984
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015938520431518555
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.679340124130249
len local_batched_seeds_list  2
partition total batch output list spend :  0.7242939472198486
self.buckets_partition() spend  sec:  0.6953279972076416
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04202103614807129

in edges time spent  0.15067291259765625
local to global src and eids time spent  0.2693347930908203
time gen tails  0.053542375564575195
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09406423568725586

in edges time spent  0.36517333984375
local to global src and eids time spent  0.5656089782714844
time gen tails  0.08250808715820312
res  length 2
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11018657684326172  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04059362411499  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039635181427002  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11418962478637695  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.778286457061768  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784006118774414  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1250600814819336  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0556361675262451
pure train time :  0.4462721347808838
train time :  0.6150131225585938
end to end time :  4.215697526931763
connection check time:  1.8817706108093262
block generation time  0.9809653759002686
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005664825439453125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014044761657714844
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6534240245819092
len local_batched_seeds_list  2
partition total batch output list spend :  0.7383759021759033
self.buckets_partition() spend  sec:  0.6675035953521729
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.045439720153808594

in edges time spent  0.14920568466186523
local to global src and eids time spent  0.2700657844543457
time gen tails  0.053830623626708984
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09549641609191895

in edges time spent  0.36208271980285645
local to global src and eids time spent  0.5590810775756836
time gen tails  0.08266091346740723
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11022186279296875  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002599239349365  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002744197845459  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11456632614135742  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780414581298828  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786134243011475  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1247248649597168  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0540510416030884
pure train time :  0.4451425075531006
train time :  0.6057612895965576
end to end time :  4.2357800006866455
connection check time:  1.882091760635376
block generation time  0.9959487915039062
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005452632904052734
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014590978622436523
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6754040718078613
len local_batched_seeds_list  2
partition total batch output list spend :  0.7610511779785156
self.buckets_partition() spend  sec:  0.6900308132171631
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04464244842529297

in edges time spent  0.14948344230651855
local to global src and eids time spent  0.2701833248138428
time gen tails  0.05363869667053223
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09494757652282715

in edges time spent  0.3542001247406006
local to global src and eids time spent  0.5616719722747803
time gen tails  0.08290290832519531
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11003494262695312  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000665187835693  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.99984884262085  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11405372619628906  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.779599666595459  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785319328308105  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12414932250976562  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.051929235458374
pure train time :  0.44898080825805664
train time :  0.6149895191192627
end to end time :  4.24760627746582
connection check time:  1.8740291595458984
block generation time  0.9842841625213623
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005514621734619141
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014233589172363281
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.575690746307373
len local_batched_seeds_list  2
partition total batch output list spend :  0.6606466770172119
self.buckets_partition() spend  sec:  0.5899591445922852
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04410958290100098

in edges time spent  0.1486344337463379
local to global src and eids time spent  0.2690422534942627
time gen tails  0.0538480281829834
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09529519081115723

in edges time spent  0.35605931282043457
local to global src and eids time spent  0.5580718517303467
time gen tails  0.08106207847595215
res  length 2
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11055326461791992  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041540145874023  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04049825668335  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11407136917114258  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790514945983887  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796234607696533  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12361764907836914  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0504157543182373
pure train time :  0.44909024238586426
train time :  0.6150913238525391
end to end time :  4.115170001983643
connection check time:  1.861726999282837
block generation time  0.964543342590332
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005159378051757812
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014690399169921875
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6578707695007324
len local_batched_seeds_list  2
partition total batch output list spend :  0.7433922290802002
self.buckets_partition() spend  sec:  0.6726717948913574
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04446148872375488

in edges time spent  0.150068998336792
local to global src and eids time spent  0.26941585540771484
time gen tails  0.053730010986328125
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09755063056945801

in edges time spent  0.3745906352996826
local to global src and eids time spent  0.5684859752655029
time gen tails  0.08424973487854004
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10998916625976562  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002532958984375  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001761436462402  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11446619033813477  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784900188446045  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790619850158691  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12446212768554688  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0528433322906494
pure train time :  0.438554048538208
train time :  0.5970301628112793
end to end time :  4.256013631820679
connection check time:  1.9065110683441162
block generation time  0.9955923557281494
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005323886871337891
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015189886093139648
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6267588138580322
len local_batched_seeds_list  2
partition total batch output list spend :  0.7115616798400879
self.buckets_partition() spend  sec:  0.6419835090637207
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.044138193130493164

in edges time spent  0.15497183799743652
local to global src and eids time spent  0.266110897064209
time gen tails  0.05592083930969238
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09153985977172852

in edges time spent  0.39282846450805664
local to global src and eids time spent  0.5714950561523438
time gen tails  0.08067846298217773
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10988187789916992  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00326919555664  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002609729766846  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11418485641479492  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789967060089111  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.795686721801758  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1238861083984375  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0495712757110596
pure train time :  0.4489762783050537
train time :  0.6132607460021973
end to end time :  4.207150459289551
connection check time:  1.9116199016571045
block generation time  0.9535634517669678
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005340576171875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014475107192993164
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6730456352233887
len local_batched_seeds_list  2
partition total batch output list spend :  0.7575831413269043
self.buckets_partition() spend  sec:  0.6875569820404053
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04447579383850098

in edges time spent  0.1518545150756836
local to global src and eids time spent  0.2686805725097656
time gen tails  0.05394101142883301
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0910637378692627

in edges time spent  0.3669888973236084
local to global src and eids time spent  0.5585691928863525
time gen tails  0.08089280128479004
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11014318466186523  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001260757446289  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000341892242432  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11310482025146484  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.76012372970581  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.765843391418457  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12387514114379883  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0514596700668335
pure train time :  0.44087958335876465
train time :  0.6004242897033691
end to end time :  4.192509174346924
connection check time:  1.8677656650543213
block generation time  0.9538438320159912
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005259513854980469
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014469623565673828
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6693551540374756
len local_batched_seeds_list  2
partition total batch output list spend :  0.7546801567077637
self.buckets_partition() spend  sec:  0.68385910987854
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04272651672363281

in edges time spent  0.14661335945129395
local to global src and eids time spent  0.2610599994659424
time gen tails  0.05292081832885742
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09103941917419434

in edges time spent  0.35654425621032715
local to global src and eids time spent  0.5191659927368164
time gen tails  0.06027078628540039
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1113276481628418  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00546646118164  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004323482513428  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11457347869873047  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791976928710938  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.797696590423584  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1252121925354004  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0484979152679443
pure train time :  0.43987202644348145
train time :  0.59657883644104
end to end time :  4.125995635986328
connection check time:  1.7863116264343262
block generation time  0.9692833423614502
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005245208740234375
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.016127347946166992
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6437695026397705
len local_batched_seeds_list  2
partition total batch output list spend :  0.6889400482177734
self.buckets_partition() spend  sec:  0.6599307060241699
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04275846481323242

in edges time spent  0.14830684661865234
local to global src and eids time spent  0.2694540023803711
time gen tails  0.05385851860046387
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09389066696166992

in edges time spent  0.3592183589935303
local to global src and eids time spent  0.5567598342895508
time gen tails  0.08337879180908203
res  length 2
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11148595809936523  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.993800163269043  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.992494106292725  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11386585235595703  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.762319087982178  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.768038749694824  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12458276748657227  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0471729040145874
pure train time :  0.43814587593078613
train time :  0.5974230766296387
end to end time :  4.145242214202881
connection check time:  1.8632385730743408
block generation time  0.9799582958221436
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005221366882324219
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014543771743774414
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6681876182556152
len local_batched_seeds_list  2
partition total batch output list spend :  0.7537543773651123
self.buckets_partition() spend  sec:  0.6827666759490967
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04439377784729004

in edges time spent  0.14899539947509766
local to global src and eids time spent  0.277036190032959
time gen tails  0.05360221862792969
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09302926063537598

in edges time spent  0.36969614028930664
local to global src and eids time spent  0.5792372226715088
time gen tails  0.08324742317199707
res  length 2
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11010551452636719  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042791366577148  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041972160339355  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11368608474731445  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785886287689209  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791605949401855  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12345027923583984  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0452053546905518
pure train time :  0.44532155990600586
train time :  0.6147675514221191
end to end time :  4.286264657974243
connection check time:  1.9245269298553467
block generation time  0.9794285297393799
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005371570587158203
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014483213424682617
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6735625267028809
len local_batched_seeds_list  2
partition total batch output list spend :  0.7598681449890137
self.buckets_partition() spend  sec:  0.6880934238433838
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04471302032470703

in edges time spent  0.15099811553955078
local to global src and eids time spent  0.27001428604125977
time gen tails  0.05388045310974121
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09527945518493652

in edges time spent  0.3606088161468506
local to global src and eids time spent  0.5644021034240723
time gen tails  0.0838325023651123
res  length 2
block collection to dataloader spend  1.2874603271484375e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11002445220947266  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000130653381348  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999386310577393  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11346864700317383  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792043209075928  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.797762870788574  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12422847747802734  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0465381145477295
pure train time :  0.4529228210449219
train time :  0.613257646560669
end to end time :  4.300826072692871
connection check time:  1.8915305137634277
block generation time  1.0119407176971436
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005800724029541016
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014400243759155273
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7021496295928955
len local_batched_seeds_list  2
partition total batch output list spend :  0.7868573665618896
self.buckets_partition() spend  sec:  0.7165899276733398
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.046770572662353516

in edges time spent  0.1491680145263672
local to global src and eids time spent  0.2687854766845703
time gen tails  0.05363893508911133
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0955507755279541

in edges time spent  0.3609616756439209
local to global src and eids time spent  0.5593769550323486
time gen tails  0.08281421661376953
res  length 2
block collection to dataloader spend  1.2636184692382812e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11033201217651367  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038023948669434  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037205219268799  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11375761032104492  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.797186374664307  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.802906036376953  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12357664108276367  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.043940782546997
pure train time :  0.4480001926422119
train time :  0.6103489398956299
end to end time :  4.293771743774414
connection check time:  1.8799967765808105
block generation time  0.9971714019775391
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005116462707519531
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014461755752563477
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5485303401947021
len local_batched_seeds_list  2
partition total batch output list spend :  0.6330745220184326
self.buckets_partition() spend  sec:  0.5630264282226562
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04415702819824219

in edges time spent  0.15015292167663574
local to global src and eids time spent  0.2701599597930908
time gen tails  0.05358576774597168
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09486794471740723

in edges time spent  0.3539886474609375
local to global src and eids time spent  0.5571703910827637
time gen tails  0.0821235179901123
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10996007919311523  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041631698608398  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04118013381958  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1135406494140625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.756851196289062  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.762570858001709  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12355995178222656  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0467267036437988
pure train time :  0.44827985763549805
train time :  0.6124129295349121
end to end time :  4.110540151596069
connection check time:  1.8685111999511719
block generation time  0.9832432270050049
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005347728729248047
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01443338394165039
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6686103343963623
len local_batched_seeds_list  2
partition total batch output list spend :  0.7554836273193359
self.buckets_partition() spend  sec:  0.6830761432647705
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04509377479553223

in edges time spent  0.1504671573638916
local to global src and eids time spent  0.2689778804779053
time gen tails  0.05390572547912598
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09374737739562988

in edges time spent  0.35954904556274414
local to global src and eids time spent  0.5607397556304932
time gen tails  0.08332562446594238
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11028718948364258  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042503833770752  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042647361755371  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11475610733032227  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786128044128418  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791847705841064  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12426042556762695  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.04254150390625
pure train time :  0.4368109703063965
train time :  0.5972738265991211
end to end time :  4.236397743225098
connection check time:  1.87868070602417
block generation time  0.9881207942962646
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005195140838623047
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014620780944824219
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6767926216125488
len local_batched_seeds_list  2
partition total batch output list spend :  0.763923168182373
self.buckets_partition() spend  sec:  0.6914522647857666
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04600954055786133

in edges time spent  0.15079331398010254
local to global src and eids time spent  0.2701706886291504
time gen tails  0.053998708724975586
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0951542854309082

in edges time spent  0.34613895416259766
local to global src and eids time spent  0.5494661331176758
time gen tails  0.0838313102722168
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10965204238891602  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004633903503418  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.005069255828857  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11450910568237305  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785181999206543  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79090166091919  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12457418441772461  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0401501655578613
pure train time :  0.44988083839416504
train time :  0.6171035766601562
end to end time :  4.2190282344818115
connection check time:  1.8541789054870605
block generation time  0.9661738872528076
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005693435668945312
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015290260314941406
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6602249145507812
len local_batched_seeds_list  2
partition total batch output list spend :  0.7464570999145508
self.buckets_partition() spend  sec:  0.6755483150482178
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043149471282958984

in edges time spent  0.15244579315185547
local to global src and eids time spent  0.27314329147338867
time gen tails  0.0529780387878418
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0962362289428711

in edges time spent  0.3884873390197754
local to global src and eids time spent  0.5341544151306152
time gen tails  0.06118297576904297
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10996389389038086  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.045829772949219  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.045386791229248  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11437463760375977  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790732860565186  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796452522277832  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12478780746459961  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0406371355056763
pure train time :  0.4401564598083496
train time :  0.6025218963623047
end to end time :  4.20968770980835
connection check time:  1.8611180782318115
block generation time  0.9801931381225586
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00054168701171875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015818357467651367
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6429073810577393
len local_batched_seeds_list  2
partition total batch output list spend :  0.6879439353942871
self.buckets_partition() spend  sec:  0.6587598323822021
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.044266462326049805

in edges time spent  0.150618314743042
local to global src and eids time spent  0.2714264392852783
time gen tails  0.053881168365478516
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09434342384338379

in edges time spent  0.37213826179504395
local to global src and eids time spent  0.5665862560272217
time gen tails  0.08315420150756836
res  length 2
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11028718948364258  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041589260101318  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040815353393555  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11453580856323242  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.76651382446289  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.772233486175537  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12481546401977539  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0379656553268433
pure train time :  0.4483351707458496
train time :  0.6128325462341309
end to end time :  4.202456951141357
connection check time:  1.8961424827575684
block generation time  0.9869515895843506
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005316734313964844
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014622688293457031
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6813697814941406
len local_batched_seeds_list  2
partition total batch output list spend :  0.7672646045684814
self.buckets_partition() spend  sec:  0.6960282325744629
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.044438838958740234

in edges time spent  0.14848041534423828
local to global src and eids time spent  0.27024102210998535
time gen tails  0.053812503814697266
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09344720840454102

in edges time spent  0.36504554748535156
local to global src and eids time spent  0.5549628734588623
time gen tails  0.08351945877075195
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11013460159301758  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.990560054779053  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.989912033081055  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11379051208496094  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791520118713379  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.797239780426025  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12347126007080078  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0386799573898315
pure train time :  0.4353299140930176
train time :  0.605548620223999
end to end time :  4.244450569152832
connection check time:  1.8764102458953857
block generation time  0.9818134307861328
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005860328674316406
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015829801559448242
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6485373973846436
len local_batched_seeds_list  2
partition total batch output list spend :  0.6938691139221191
self.buckets_partition() spend  sec:  0.6644041538238525
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.044774532318115234

in edges time spent  0.14919757843017578
local to global src and eids time spent  0.27060484886169434
time gen tails  0.05368661880493164
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09401464462280273

in edges time spent  0.3611867427825928
local to global src and eids time spent  0.5662040710449219
time gen tails  0.08345580101013184
res  length 2
block collection to dataloader spend  1.5497207641601562e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11011743545532227  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037886619567871  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.03699541091919  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11348438262939453  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781236171722412  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786955833435059  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12409305572509766  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0412232875823975
pure train time :  0.450162410736084
train time :  0.6166799068450928
end to end time :  4.209190845489502
connection check time:  1.8893518447875977
block generation time  0.9875264167785645
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004987716674804688
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014574050903320312
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7129058837890625
len local_batched_seeds_list  2
partition total batch output list spend :  0.7989883422851562
self.buckets_partition() spend  sec:  0.7275180816650391
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04415464401245117

in edges time spent  0.14979195594787598
local to global src and eids time spent  0.2661583423614502
time gen tails  0.052886009216308594
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09305739402770996

in edges time spent  0.3419687747955322
local to global src and eids time spent  0.5412497520446777
time gen tails  0.08105731010437012
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1102151870727539  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.005123138427734  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004138946533203  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11324310302734375  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787064552307129  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792784214019775  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12386322021484375  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.038529396057129
pure train time :  0.4439103603363037
train time :  0.6044824123382568
end to end time :  4.207520008087158
connection check time:  1.8228113651275635
block generation time  0.9677984714508057
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0006306171417236328
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014455556869506836
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5523471832275391
len local_batched_seeds_list  2
partition total batch output list spend :  0.637897253036499
self.buckets_partition() spend  sec:  0.5668439865112305
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043067216873168945

in edges time spent  0.1457679271697998
local to global src and eids time spent  0.26309633255004883
time gen tails  0.05301308631896973
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0904233455657959

in edges time spent  0.35211682319641113
local to global src and eids time spent  0.5377049446105957
time gen tails  0.08055663108825684
res  length 2
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11023998260498047  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044408321380615  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043405055999756  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1153573989868164  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.760904788970947  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.766624450683594  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12637042999267578  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0370750427246094
pure train time :  0.44895195960998535
train time :  0.6141171455383301
end to end time :  4.0437071323394775
connection check time:  1.8199338912963867
block generation time  0.9551331996917725
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005564689636230469
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01528167724609375
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6271746158599854
len local_batched_seeds_list  2
partition total batch output list spend :  0.7134666442871094
self.buckets_partition() spend  sec:  0.642491340637207
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04323244094848633

in edges time spent  0.14633846282958984
local to global src and eids time spent  0.26160168647766113
time gen tails  0.05300307273864746
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.090972900390625

in edges time spent  0.353198766708374
local to global src and eids time spent  0.5095336437225342
time gen tails  0.06039786338806152
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11176347732543945  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038524627685547  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037562370300293  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11452913284301758  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.7954683303833  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.801187992095947  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12447357177734375  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0386483669281006
pure train time :  0.44841814041137695
train time :  0.6154336929321289
end to end time :  4.100322484970093
connection check time:  1.7769477367401123
block generation time  0.975679874420166
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005283355712890625
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01539754867553711
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6371386051177979
len local_batched_seeds_list  2
partition total batch output list spend :  0.6816990375518799
self.buckets_partition() spend  sec:  0.6525766849517822
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042093753814697266

in edges time spent  0.14844179153442383
local to global src and eids time spent  0.2684903144836426
time gen tails  0.05526471138000488
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09340405464172363

in edges time spent  0.3618600368499756
local to global src and eids time spent  0.555584192276001
time gen tails  0.08301973342895508
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11007976531982422  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004249572753906  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003392219543457  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11469507217407227  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791068077087402  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796787738800049  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12479543685913086  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0354204177856445
pure train time :  0.45110201835632324
train time :  0.6152706146240234
end to end time :  4.160297393798828
connection check time:  1.864973783493042
block generation time  0.9846158027648926
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0006847381591796875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014690876007080078
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.701470136642456
len local_batched_seeds_list  2
partition total batch output list spend :  0.7876150608062744
self.buckets_partition() spend  sec:  0.716193437576294
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04536700248718262

in edges time spent  0.15819168090820312
local to global src and eids time spent  0.27787017822265625
time gen tails  0.05441594123840332
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09531569480895996

in edges time spent  0.37455296516418457
local to global src and eids time spent  0.567375898361206
time gen tails  0.08802342414855957
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1099853515625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004222869873047  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003463745117188  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11394786834716797  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.782116413116455  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787836074829102  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12397289276123047  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0355935096740723
pure train time :  0.4611222743988037
train time :  0.62872314453125
end to end time :  4.354117393493652
connection check time:  1.9304251670837402
block generation time  0.9931013584136963
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005371570587158203
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014765024185180664
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6692092418670654
len local_batched_seeds_list  2
partition total batch output list spend :  0.7548820972442627
self.buckets_partition() spend  sec:  0.6840078830718994
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04633641242980957

in edges time spent  0.1549539566040039
local to global src and eids time spent  0.27418994903564453
time gen tails  0.054285287857055664
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09969067573547363

in edges time spent  0.3689913749694824
local to global src and eids time spent  0.5660505294799805
time gen tails  0.08349609375
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11049890518188477  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04308271408081  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042099952697754  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1143798828125  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.755268096923828  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.760987758636475  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12463665008544922  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.036552906036377
pure train time :  0.4496028423309326
train time :  0.6132762432098389
end to end time :  4.287917375564575
connection check time:  1.9092941284179688
block generation time  0.9920980930328369
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005512237548828125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014896869659423828
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6786093711853027
len local_batched_seeds_list  2
partition total batch output list spend :  0.7649900913238525
self.buckets_partition() spend  sec:  0.6935398578643799
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0468597412109375

in edges time spent  0.15028905868530273
local to global src and eids time spent  0.27374744415283203
time gen tails  0.05435013771057129
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09320187568664551

in edges time spent  0.3727426528930664
local to global src and eids time spent  0.5881924629211426
time gen tails  0.08721184730529785
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1101384162902832  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037560939788818  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.03664779663086  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1136789321899414  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793896198272705  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.799615859985352  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12437152862548828  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0360257625579834
pure train time :  0.4512491226196289
train time :  0.6184413433074951
end to end time :  4.329852819442749
connection check time:  1.9375905990600586
block generation time  0.9956634044647217
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0006232261657714844
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014137506484985352
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.700537919998169
len local_batched_seeds_list  2
partition total batch output list spend :  0.786508321762085
self.buckets_partition() spend  sec:  0.7147905826568604
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04464268684387207

in edges time spent  0.14921975135803223
local to global src and eids time spent  0.2694234848022461
time gen tails  0.05386829376220703
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09386205673217773

in edges time spent  0.36104512214660645
local to global src and eids time spent  0.5570671558380127
time gen tails  0.0827939510345459
res  length 2
block collection to dataloader spend  1.1920928955078125e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11072301864624023  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.005350112915039  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004814147949219  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11474037170410156  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78086805343628  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786587715148926  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1246805191040039  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0360325574874878
pure train time :  0.4503052234649658
train time :  0.6221568584442139
end to end time :  4.283141374588013
connection check time:  1.873915433883667
block generation time  0.9831318855285645
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000553131103515625
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014252424240112305
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6867592334747314
len local_batched_seeds_list  2
partition total batch output list spend :  0.7723574638366699
self.buckets_partition() spend  sec:  0.7010464668273926
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04441475868225098

in edges time spent  0.14845561981201172
local to global src and eids time spent  0.2616424560546875
time gen tails  0.05244565010070801
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09039831161499023

in edges time spent  0.3417503833770752
local to global src and eids time spent  0.5372264385223389
time gen tails  0.08330297470092773
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11014461517333984  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043486595153809  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042571067810059  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11314773559570312  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.782179355621338  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787899017333984  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12435531616210938  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0375142097473145
pure train time :  0.45239901542663574
train time :  0.613408088684082
end to end time :  4.189777135848999
connection check time:  1.8164010047912598
block generation time  0.966191291809082
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005407333374023438
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014736413955688477
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7008917331695557
len local_batched_seeds_list  2
partition total batch output list spend :  0.7877638339996338
self.buckets_partition() spend  sec:  0.7156636714935303
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04540586471557617

in edges time spent  0.14990735054016113
local to global src and eids time spent  0.268444299697876
time gen tails  0.0527803897857666
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09757375717163086

in edges time spent  0.34917402267456055
local to global src and eids time spent  0.5436770915985107
time gen tails  0.08128213882446289
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11107492446899414  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999569416046143  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998678207397461  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11412239074707031  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788589000701904  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79430866241455  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12492942810058594  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0309468507766724
pure train time :  0.45171403884887695
train time :  0.6203241348266602
end to end time :  4.24419093132019
connection check time:  1.842033863067627
block generation time  0.9776873588562012
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005295276641845703
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014687299728393555
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5583553314208984
len local_batched_seeds_list  2
partition total batch output list spend :  0.6446528434753418
self.buckets_partition() spend  sec:  0.5730776786804199
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04433894157409668

in edges time spent  0.14738011360168457
local to global src and eids time spent  0.265195369720459
time gen tails  0.05343461036682129
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09404206275939941

in edges time spent  0.35694241523742676
local to global src and eids time spent  0.5614542961120605
time gen tails  0.0834348201751709
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11076068878173828  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041229724884033  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040595531463623  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11436653137207031  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786447048187256  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792166709899902  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12433528900146484  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0355724096298218
pure train time :  0.4506189823150635
train time :  0.6228721141815186
end to end time :  4.126505136489868
connection check time:  1.8661396503448486
block generation time  0.9794440269470215
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005357265472412109
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014717817306518555
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6376731395721436
len local_batched_seeds_list  2
partition total batch output list spend :  0.7233643531799316
self.buckets_partition() spend  sec:  0.6524233818054199
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0455927848815918

in edges time spent  0.15900945663452148
local to global src and eids time spent  0.27870678901672363
time gen tails  0.05539894104003906
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09122085571289062

in edges time spent  0.38320398330688477
local to global src and eids time spent  0.5687534809112549
time gen tails  0.08499836921691895
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11017131805419922  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.045001029968262  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044347763061523  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11458444595336914  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.755917072296143  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.761636734008789  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12432575225830078  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.032302737236023
pure train time :  0.4452090263366699
train time :  0.6079919338226318
end to end time :  4.227009534835815
connection check time:  1.9200735092163086
block generation time  0.956017255783081
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005910396575927734
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014771461486816406
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.639735221862793
len local_batched_seeds_list  2
partition total batch output list spend :  0.7250008583068848
self.buckets_partition() spend  sec:  0.6545400619506836
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.044022321701049805

in edges time spent  0.15102863311767578
local to global src and eids time spent  0.27093935012817383
time gen tails  0.053708553314208984
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09139704704284668

in edges time spent  0.35355567932128906
local to global src and eids time spent  0.504871129989624
time gen tails  0.05864691734313965
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11004066467285156  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042795181274414  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041984558105469  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11377239227294922  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.778231620788574  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78395128250122  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1232914924621582  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0319390296936035
pure train time :  0.4454917907714844
train time :  0.6042602062225342
end to end time :  4.0698561668396
connection check time:  1.7792103290557861
block generation time  0.9429657459259033
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005147457122802734
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01582813262939453
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6255202293395996
len local_batched_seeds_list  2
partition total batch output list spend :  0.6698203086853027
self.buckets_partition() spend  sec:  0.6413826942443848
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04116201400756836

in edges time spent  0.144883394241333
local to global src and eids time spent  0.2605299949645996
time gen tails  0.05266284942626953
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08878493309020996

in edges time spent  0.3418416976928711
local to global src and eids time spent  0.5421643257141113
time gen tails  0.08357739448547363
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10986328125  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00592041015625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.005285263061523  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11322832107543945  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786087989807129  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791807651519775  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1246027946472168  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0342892408370972
pure train time :  0.44601869583129883
train time :  0.6246037483215332
end to end time :  4.057780027389526
connection check time:  1.8019440174102783
block generation time  0.9484584331512451
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004839897155761719
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014417409896850586
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6609499454498291
len local_batched_seeds_list  2
partition total batch output list spend :  0.7463204860687256
self.buckets_partition() spend  sec:  0.6754021644592285
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043943166732788086

in edges time spent  0.14568662643432617
local to global src and eids time spent  0.26221299171447754
time gen tails  0.052947282791137695
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09081673622131348

in edges time spent  0.3609752655029297
local to global src and eids time spent  0.566474199295044
time gen tails  0.08246397972106934
res  length 2
block collection to dataloader spend  1.430511474609375e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11028480529785156  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00015640258789  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999096870422363  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1145930290222168  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788514614105225  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.794234275817871  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12442255020141602  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0307552814483643
pure train time :  0.44745707511901855
train time :  0.6087846755981445
end to end time :  4.212551116943359
connection check time:  1.8678743839263916
block generation time  0.9716010093688965
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005848407745361328
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014425516128540039
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7036304473876953
len local_batched_seeds_list  2
partition total batch output list spend :  0.7876114845275879
self.buckets_partition() spend  sec:  0.7180938720703125
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04483175277709961

in edges time spent  0.14727210998535156
local to global src and eids time spent  0.26195240020751953
time gen tails  0.052669525146484375
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09044861793518066

in edges time spent  0.3538706302642822
local to global src and eids time spent  0.5372097492218018
time gen tails  0.08085966110229492
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11001729965209961  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997611045837402  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.996868133544922  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11342906951904297  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788622379302979  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.794342041015625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12424278259277344  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0329519510269165
pure train time :  0.43866753578186035
train time :  0.5971465110778809
end to end time :  4.175039768218994
connection check time:  1.8198113441467285
block generation time  0.9571325778961182
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005645751953125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014245986938476562
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6432080268859863
len local_batched_seeds_list  2
partition total batch output list spend :  0.7271265983581543
self.buckets_partition() spend  sec:  0.6575348377227783
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04339170455932617

in edges time spent  0.14312434196472168
local to global src and eids time spent  0.26053404808044434
time gen tails  0.052375078201293945
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09058260917663574

in edges time spent  0.36284732818603516
local to global src and eids time spent  0.5673196315765381
time gen tails  0.08394122123718262
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11038637161254883  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997403621673584  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.996513366699219  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11265134811401367  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785869598388672  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791589260101318  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12320661544799805  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.033963918685913
pure train time :  0.4482898712158203
train time :  0.6154108047485352
end to end time :  4.1990790367126465
connection check time:  1.862764835357666
block generation time  0.9754445552825928
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005459785461425781
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014597654342651367
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6932806968688965
len local_batched_seeds_list  2
partition total batch output list spend :  0.7768566608428955
self.buckets_partition() spend  sec:  0.7079129219055176
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04268527030944824

in edges time spent  0.14476346969604492
local to global src and eids time spent  0.2622661590576172
time gen tails  0.05281853675842285
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09136581420898438

in edges time spent  0.36061906814575195
local to global src and eids time spent  0.547398567199707
time gen tails  0.0846407413482666
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11085224151611328  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043250560760498  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043454647064209  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1146235466003418  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.782366275787354  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.7880859375  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12465143203735352  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0310447216033936
pure train time :  0.4476146697998047
train time :  0.6097221374511719
end to end time :  4.203204870223999
connection check time:  1.8408520221710205
block generation time  0.9587349891662598
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0006885528564453125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015311956405639648
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.64967942237854
len local_batched_seeds_list  2
partition total batch output list spend :  0.7360031604766846
self.buckets_partition() spend  sec:  0.6650261878967285
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.044449567794799805

in edges time spent  0.15516090393066406
local to global src and eids time spent  0.27077198028564453
time gen tails  0.0539851188659668
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09425473213195801

in edges time spent  0.39649486541748047
local to global src and eids time spent  0.5570247173309326
time gen tails  0.0831000804901123
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11080598831176758  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003916263580322  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003243446350098  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11363887786865234  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.753498077392578  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.759217739105225  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12436151504516602  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.029946208000183
pure train time :  0.4519352912902832
train time :  0.6151285171508789
end to end time :  4.2920286655426025
connection check time:  1.917755365371704
block generation time  1.0053036212921143
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005064010620117188
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014554023742675781
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.579993724822998
len local_batched_seeds_list  2
partition total batch output list spend :  0.6689221858978271
self.buckets_partition() spend  sec:  0.5945837497711182
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.044136762619018555

in edges time spent  0.15079379081726074
local to global src and eids time spent  0.26449036598205566
time gen tails  0.05275988578796387
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08996939659118652

in edges time spent  0.34973955154418945
local to global src and eids time spent  0.5582749843597412
time gen tails  0.08308267593383789
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11006689071655273  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00282335281372  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002845764160156  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11469268798828125  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784624099731445  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790343761444092  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12420654296875  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0287405252456665
pure train time :  0.45066213607788086
train time :  0.6108403205871582
end to end time :  4.123844623565674
connection check time:  1.8523964881896973
block generation time  0.9758772850036621
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005717277526855469
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014693260192871094
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6604149341583252
len local_batched_seeds_list  2
partition total batch output list spend :  0.7466411590576172
self.buckets_partition() spend  sec:  0.6751418113708496
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04462409019470215

in edges time spent  0.14897871017456055
local to global src and eids time spent  0.26927685737609863
time gen tails  0.0539705753326416
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09321045875549316

in edges time spent  0.3565640449523926
local to global src and eids time spent  0.5570313930511475
time gen tails  0.0839691162109375
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10979223251342773  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.993254661560059  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.992671489715576  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11435413360595703  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.767364025115967  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.773083686828613  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12421607971191406  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0323272943496704
pure train time :  0.44077563285827637
train time :  0.6062817573547363
end to end time :  4.222815275192261
connection check time:  1.8700623512268066
block generation time  0.9864382743835449
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005159378051757812
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014566898345947266
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6619153022766113
len local_batched_seeds_list  2
partition total batch output list spend :  0.7477145195007324
self.buckets_partition() spend  sec:  0.6765220165252686
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04467582702636719

in edges time spent  0.14868974685668945
local to global src and eids time spent  0.26891016960144043
time gen tails  0.05309271812438965
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09429264068603516

in edges time spent  0.3555443286895752
local to global src and eids time spent  0.560593843460083
time gen tails  0.08399820327758789
res  length 2
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11027908325195312  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999189376831055  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.99841022491455  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11268377304077148  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.777137279510498  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.782856941223145  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1232762336730957  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.028283953666687
pure train time :  0.4486722946166992
train time :  0.6088714599609375
end to end time :  4.221154689788818
connection check time:  1.868485450744629
block generation time  0.9827897548675537
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005717277526855469
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014374256134033203
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6613540649414062
len local_batched_seeds_list  2
partition total batch output list spend :  0.7468791007995605
self.buckets_partition() spend  sec:  0.6757643222808838
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04457402229309082

in edges time spent  0.14932990074157715
local to global src and eids time spent  0.26914310455322266
time gen tails  0.053650617599487305
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09329700469970703

in edges time spent  0.36008572578430176
local to global src and eids time spent  0.5803663730621338
time gen tails  0.08556509017944336
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11088371276855469  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998240947723389  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997538566589355  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11516189575195312  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.800585269927979  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.806304931640625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1250467300415039  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0271222591400146
pure train time :  0.4510824680328369
train time :  0.6264641284942627
end to end time :  4.286246061325073
connection check time:  1.908212423324585
block generation time  0.9856200218200684
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005304813385009766
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.022665739059448242
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.712888240814209
len local_batched_seeds_list  2
partition total batch output list spend :  0.8065743446350098
self.buckets_partition() spend  sec:  0.7355990409851074
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.044547080993652344

in edges time spent  0.14825677871704102
local to global src and eids time spent  0.26317596435546875
time gen tails  0.05282425880432129
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09042525291442871

in edges time spent  0.34719157218933105
local to global src and eids time spent  0.5437896251678467
time gen tails  0.08147740364074707
res  length 2
block collection to dataloader spend  1.1205673217773438e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1100606918334961  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003737926483154  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002895832061768  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1145792007446289  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792328357696533  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79804801940918  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12438488006591797  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0280342102050781
pure train time :  0.4458003044128418
train time :  0.6063427925109863
end to end time :  4.2105584144592285
connection check time:  1.8233542442321777
block generation time  0.9505786895751953
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005979537963867188
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014681816101074219
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6514556407928467
len local_batched_seeds_list  2
partition total batch output list spend :  0.7356066703796387
self.buckets_partition() spend  sec:  0.6661741733551025
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04368138313293457

in edges time spent  0.146531343460083
local to global src and eids time spent  0.2637293338775635
time gen tails  0.05372881889343262
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09381508827209473

in edges time spent  0.356522798538208
local to global src and eids time spent  0.5555038452148438
time gen tails  0.08293581008911133
res  length 2
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1099390983581543  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997982025146484  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997255802154541  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11370611190795898  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785433769226074  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79115343093872  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12351369857788086  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0290558338165283
pure train time :  0.44888734817504883
train time :  0.6136887073516846
end to end time :  4.216546535491943
connection check time:  1.857224702835083
block generation time  0.9936122894287109
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005540847778320312
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014408349990844727
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6727211475372314
len local_batched_seeds_list  2
partition total batch output list spend :  0.757993221282959
self.buckets_partition() spend  sec:  0.6871743202209473
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04481172561645508

in edges time spent  0.1494312286376953
local to global src and eids time spent  0.26900196075439453
time gen tails  0.05417370796203613
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09390521049499512

in edges time spent  0.3666524887084961
local to global src and eids time spent  0.5534083843231201
time gen tails  0.08032059669494629
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11022090911865234  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.992846488952637  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.99183464050293  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11386442184448242  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780101299285889  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785820960998535  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12378931045532227  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0273332595825195
pure train time :  0.44356489181518555
train time :  0.6029479503631592
end to end time :  4.20318078994751
connection check time:  1.8660962581634521
block generation time  0.9600968360900879
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005474090576171875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014523029327392578
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6728127002716064
len local_batched_seeds_list  2
partition total batch output list spend :  0.7580931186676025
self.buckets_partition() spend  sec:  0.6873693466186523
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04284262657165527

in edges time spent  0.1447005271911621
local to global src and eids time spent  0.2633969783782959
time gen tails  0.05257773399353027
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08899784088134766

in edges time spent  0.3561105728149414
local to global src and eids time spent  0.5365424156188965
time gen tails  0.08126711845397949
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11014604568481445  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04555082321167  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.045797348022461  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1149296760559082  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78626298904419  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791982650756836  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12577295303344727  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.027939796447754
pure train time :  0.4423367977142334
train time :  0.6021027565002441
end to end time :  4.139214515686035
connection check time:  1.8167967796325684
block generation time  0.9464833736419678
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00054168701171875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014329671859741211
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6451184749603271
len local_batched_seeds_list  2
partition total batch output list spend :  0.7301745414733887
self.buckets_partition() spend  sec:  0.6594839096069336
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04347968101501465

in edges time spent  0.1450810432434082
local to global src and eids time spent  0.26079225540161133
time gen tails  0.052153825759887695
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0923006534576416

in edges time spent  0.3495626449584961
local to global src and eids time spent  0.5362787246704102
time gen tails  0.08138179779052734
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11155223846435547  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039645195007324  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.03801965713501  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11460447311401367  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793255805969238  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.798975467681885  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12453889846801758  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0267186164855957
pure train time :  0.44432568550109863
train time :  0.6051323413848877
end to end time :  4.113547325134277
connection check time:  1.8115592002868652
block generation time  0.9489407539367676
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0006375312805175781
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014095783233642578
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5870170593261719
len local_batched_seeds_list  2
partition total batch output list spend :  0.6731293201446533
self.buckets_partition() spend  sec:  0.6011519432067871
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0438990592956543

in edges time spent  0.1534581184387207
local to global src and eids time spent  0.26941466331481934
time gen tails  0.05283236503601074
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08925580978393555

in edges time spent  0.34107494354248047
local to global src and eids time spent  0.5630970001220703
time gen tails  0.08603978157043457
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11008501052856445  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003775596618652  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00319528579712  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11327266693115234  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786698341369629  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792418003082275  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12396478652954102  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0262795686721802
pure train time :  0.44714856147766113
train time :  0.6085686683654785
end to end time :  4.144059419631958
connection check time:  1.851945400238037
block generation time  0.9939665794372559
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005631446838378906
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014359712600708008
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6330046653747559
len local_batched_seeds_list  2
partition total batch output list spend :  0.7183213233947754
self.buckets_partition() spend  sec:  0.6474783420562744
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04567837715148926

in edges time spent  0.15992498397827148
local to global src and eids time spent  0.2741556167602539
time gen tails  0.05382251739501953
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09312844276428223

in edges time spent  0.39755988121032715
local to global src and eids time spent  0.5739145278930664
time gen tails  0.0835103988647461
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11030197143554688  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04615592956543  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.045372009277344  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11504745483398438  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78075122833252  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786470890045166  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1260228157043457  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.027694582939148
pure train time :  0.44811439514160156
train time :  0.6088666915893555
end to end time :  4.292428731918335
connection check time:  1.9441323280334473
block generation time  0.9982147216796875
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005490779876708984
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01573324203491211
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6442704200744629
len local_batched_seeds_list  2
partition total batch output list spend :  0.6892216205596924
self.buckets_partition() spend  sec:  0.6600377559661865
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04242253303527832

in edges time spent  0.14908337593078613
local to global src and eids time spent  0.2710402011871338
time gen tails  0.0539853572845459
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09535455703735352

in edges time spent  0.35683679580688477
local to global src and eids time spent  0.5122284889221191
time gen tails  0.05890655517578125
res  length 2
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11168479919433594  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004733085632324  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002985000610352  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11419200897216797  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785621643066406  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791341304779053  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12402725219726562  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.026505947113037
pure train time :  0.44451045989990234
train time :  0.6074504852294922
end to end time :  4.065583944320679
connection check time:  1.7894389629364014
block generation time  0.9621829986572266
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005259513854980469
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01573944091796875
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6124434471130371
len local_batched_seeds_list  2
partition total batch output list spend :  0.6570210456848145
self.buckets_partition() spend  sec:  0.628218412399292
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04010462760925293

in edges time spent  0.1394178867340088
local to global src and eids time spent  0.2615327835083008
time gen tails  0.05249810218811035
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09116339683532715

in edges time spent  0.35799455642700195
local to global src and eids time spent  0.5398671627044678
time gen tails  0.08010220527648926
res  length 2
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11099481582641602  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00023365020752  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999424457550049  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11444807052612305  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79993724822998  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.805656909942627  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12532997131347656  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.027968406677246
pure train time :  0.43998289108276367
train time :  0.5999727249145508
end to end time :  4.0268354415893555
connection check time:  1.8071305751800537
block generation time  0.948775053024292
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005474090576171875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014261245727539062
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6376376152038574
len local_batched_seeds_list  2
partition total batch output list spend :  0.7216391563415527
self.buckets_partition() spend  sec:  0.6519327163696289
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043442487716674805

in edges time spent  0.14476490020751953
local to global src and eids time spent  0.2642369270324707
time gen tails  0.05292057991027832
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08939456939697266

in edges time spent  0.3441426753997803
local to global src and eids time spent  0.5460324287414551
time gen tails  0.08296346664428711
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11044454574584961  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041445255279541  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040510177612305  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11360645294189453  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791023254394531  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796742916107178  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.123291015625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0239310264587402
pure train time :  0.435579776763916
train time :  0.5964055061340332
end to end time :  4.138177871704102
connection check time:  1.8243441581726074
block generation time  0.9799566268920898
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005059242248535156
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014206171035766602
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6670265197753906
len local_batched_seeds_list  2
partition total batch output list spend :  0.7535312175750732
self.buckets_partition() spend  sec:  0.681267499923706
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04272818565368652

in edges time spent  0.14426445960998535
local to global src and eids time spent  0.260770320892334
time gen tails  0.053009748458862305
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09014511108398438

in edges time spent  0.35541844367980957
local to global src and eids time spent  0.5384244918823242
time gen tails  0.08233308792114258
res  length 2
block collection to dataloader spend  1.1444091796875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11045265197753906  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000107765197754  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.99950885772705  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1145787239074707  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.811670780181885  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.817390441894531  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12437248229980469  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.022530436515808
pure train time :  0.44632482528686523
train time :  0.6254067420959473
end to end time :  4.1683831214904785
connection check time:  1.8207027912139893
block generation time  0.9492142200469971
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005002021789550781
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014065265655517578
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6761531829833984
len local_batched_seeds_list  2
partition total batch output list spend :  0.7584896087646484
self.buckets_partition() spend  sec:  0.6902568340301514
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042395830154418945

in edges time spent  0.1431422233581543
local to global src and eids time spent  0.26195359230041504
time gen tails  0.052327871322631836
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09085559844970703

in edges time spent  0.33959531784057617
local to global src and eids time spent  0.5415322780609131
time gen tails  0.08062601089477539
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10999822616577148  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042654037475586  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041905403137207  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1145787239074707  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784192085266113  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78991174697876  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12424230575561523  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0256083011627197
pure train time :  0.4474947452545166
train time :  0.6148006916046143
end to end time :  4.145107984542847
connection check time:  1.8012828826904297
block generation time  0.9548995494842529
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005254745483398438
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014269828796386719
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6568007469177246
len local_batched_seeds_list  2
partition total batch output list spend :  0.7413725852966309
self.buckets_partition() spend  sec:  0.6711091995239258
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0422511100769043

in edges time spent  0.14433598518371582
local to global src and eids time spent  0.2615838050842285
time gen tails  0.05288124084472656
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09069585800170898

in edges time spent  0.35088276863098145
local to global src and eids time spent  0.5109617710113525
time gen tails  0.05869889259338379
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10980796813964844  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003005981445312  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003288269042969  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11447620391845703  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791099071502686  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796818733215332  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12486553192138672  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0239417552947998
pure train time :  0.43427157402038574
train time :  0.5943336486816406
end to end time :  4.066053152084351
connection check time:  1.7617604732513428
block generation time  0.9522609710693359
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005087852478027344
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015467166900634766
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6259276866912842
len local_batched_seeds_list  2
partition total batch output list spend :  0.6717188358306885
self.buckets_partition() spend  sec:  0.6414332389831543
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04059123992919922

in edges time spent  0.1446666717529297
local to global src and eids time spent  0.2619612216949463
time gen tails  0.052877187728881836
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08848953247070312

in edges time spent  0.3427886962890625
local to global src and eids time spent  0.534658670425415
time gen tails  0.08017253875732422
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11026382446289062  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002272605895996  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001508712768555  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11472892761230469  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781658172607422  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787377834320068  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1252431869506836  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0219188928604126
pure train time :  0.4468710422515869
train time :  0.6067409515380859
end to end time :  4.034793853759766
connection check time:  1.7933518886566162
block generation time  0.94663405418396
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005044937133789062
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01413416862487793
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5488109588623047
len local_batched_seeds_list  2
partition total batch output list spend :  0.6333000659942627
self.buckets_partition() spend  sec:  0.5629804134368896
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04394721984863281

in edges time spent  0.1445772647857666
local to global src and eids time spent  0.2627232074737549
time gen tails  0.05268549919128418
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08986735343933105

in edges time spent  0.3402233123779297
local to global src and eids time spent  0.5363643169403076
time gen tails  0.08132791519165039
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11040163040161133  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.033650875091553  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.032754898071289  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11377477645874023  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796780109405518  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.802499771118164  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1236119270324707  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0225334167480469
pure train time :  0.43684816360473633
train time :  0.5965280532836914
end to end time :  3.996344566345215
connection check time:  1.801992654800415
block generation time  0.9483282566070557
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005190372467041016
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014224767684936523
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6277933120727539
len local_batched_seeds_list  2
partition total batch output list spend :  0.7127017974853516
self.buckets_partition() spend  sec:  0.642052412033081
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043051958084106445

in edges time spent  0.14409303665161133
local to global src and eids time spent  0.2598121166229248
time gen tails  0.052503347396850586
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09088420867919922

in edges time spent  0.3409121036529541
local to global src and eids time spent  0.5438284873962402
time gen tails  0.08386802673339844
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11027669906616211  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001457691192627  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000680923461914  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.113128662109375  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.7861008644104  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791820526123047  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12373495101928711  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.020994782447815
pure train time :  0.44313740730285645
train time :  0.6065173149108887
end to end time :  4.097639083862305
connection check time:  1.8130004405975342
block generation time  0.9522345066070557
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005481243133544922
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014867067337036133
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6372666358947754
len local_batched_seeds_list  2
partition total batch output list spend :  0.7216870784759521
self.buckets_partition() spend  sec:  0.6521673202514648
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04457426071166992

in edges time spent  0.14862704277038574
local to global src and eids time spent  0.2685203552246094
time gen tails  0.05269622802734375
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09801268577575684

in edges time spent  0.36626267433166504
local to global src and eids time spent  0.5432243347167969
time gen tails  0.07992148399353027
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11016416549682617  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.99436092376709  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.993408679962158  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11358642578125  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791440486907959  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.797160148620605  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1242375373840332  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0240896940231323
pure train time :  0.43933749198913574
train time :  0.6030995845794678
end to end time :  4.148459196090698
connection check time:  1.8527424335479736
block generation time  0.9522929191589355
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005869865417480469
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.016289949417114258
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6337976455688477
len local_batched_seeds_list  2
partition total batch output list spend :  0.718815803527832
self.buckets_partition() spend  sec:  0.6501209735870361
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042717695236206055

in edges time spent  0.18947720527648926
local to global src and eids time spent  0.25882625579833984
time gen tails  0.052117109298706055
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09129571914672852

in edges time spent  0.34593987464904785
local to global src and eids time spent  0.5359725952148438
time gen tails  0.08076310157775879
res  length 2
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11056661605834961  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04239273071289  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041921138763428  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11480855941772461  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78875207901001  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.794471740722656  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12523317337036133  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0234102010726929
pure train time :  0.4347074031829834
train time :  0.5968749523162842
end to end time :  4.131277799606323
connection check time:  1.8475568294525146
block generation time  0.9496622085571289
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005810260772705078
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01469731330871582
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.634868860244751
len local_batched_seeds_list  2
partition total batch output list spend :  0.719214916229248
self.buckets_partition() spend  sec:  0.6496007442474365
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0432436466217041

in edges time spent  0.14538311958312988
local to global src and eids time spent  0.2589106559753418
time gen tails  0.052178144454956055
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09482073783874512

in edges time spent  0.3418855667114258
local to global src and eids time spent  0.5382969379425049
time gen tails  0.08003401756286621
res  length 2
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11112737655639648  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040395736694336  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038932800292969  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11500883102416992  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785935401916504  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79165506362915  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12486124038696289  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0204100608825684
pure train time :  0.43734216690063477
train time :  0.6076042652130127
end to end time :  4.107701301574707
connection check time:  1.8073484897613525
block generation time  0.9563708305358887
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005135536193847656
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.016020774841308594
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6574337482452393
len local_batched_seeds_list  2
partition total batch output list spend :  0.7026784420013428
self.buckets_partition() spend  sec:  0.6734941005706787
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04235076904296875

in edges time spent  0.14432501792907715
local to global src and eids time spent  0.2635202407836914
time gen tails  0.05315446853637695
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09008955955505371

in edges time spent  0.33806753158569336
local to global src and eids time spent  0.53334641456604
time gen tails  0.07991218566894531
res  length 2
block collection to dataloader spend  1.0967254638671875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11001062393188477  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042306900024414  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042398929595947  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11448383331298828  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786674499511719  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792394161224365  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12500476837158203  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.021685004234314
pure train time :  0.44437623023986816
train time :  0.6046237945556641
end to end time :  4.056790828704834
connection check time:  1.7897543907165527
block generation time  0.9430506229400635
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005567073822021484
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014390230178833008
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6665213108062744
len local_batched_seeds_list  2
partition total batch output list spend :  0.7500035762786865
self.buckets_partition() spend  sec:  0.6809492111206055
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0422968864440918

in edges time spent  0.14385080337524414
local to global src and eids time spent  0.2608506679534912
time gen tails  0.05223345756530762
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08964204788208008

in edges time spent  0.34112095832824707
local to global src and eids time spent  0.5336320400238037
time gen tails  0.08029294013977051
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11039209365844727  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041151523590088  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040267944335938  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11347436904907227  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787785053253174  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79350471496582  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12418031692504883  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0212481021881104
pure train time :  0.4464709758758545
train time :  0.610105037689209
end to end time :  4.116057395935059
connection check time:  1.7928051948547363
block generation time  0.9501545429229736
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005900859832763672
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01426076889038086
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6548771858215332
len local_batched_seeds_list  2
partition total batch output list spend :  0.7378332614898682
self.buckets_partition() spend  sec:  0.6691732406616211
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04262685775756836

in edges time spent  0.14457178115844727
local to global src and eids time spent  0.26084232330322266
time gen tails  0.05257415771484375
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09117674827575684

in edges time spent  0.34812045097351074
local to global src and eids time spent  0.53774094581604
time gen tails  0.08073019981384277
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1102900505065918  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.993732929229736  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.992931365966797  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11334848403930664  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.810879230499268  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.816598892211914  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1239461898803711  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.020447015762329
pure train time :  0.4470205307006836
train time :  0.6078994274139404
end to end time :  4.112428903579712
connection check time:  1.809072732925415
block generation time  0.9431848526000977
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005471706390380859
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014539957046508789
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5770092010498047
len local_batched_seeds_list  2
partition total batch output list spend :  0.6625773906707764
self.buckets_partition() spend  sec:  0.5915935039520264
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04401516914367676

in edges time spent  0.14524602890014648
local to global src and eids time spent  0.263460636138916
time gen tails  0.052388906478881836
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09074664115905762

in edges time spent  0.3657341003417969
local to global src and eids time spent  0.5550830364227295
time gen tails  0.08053445816040039
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11014747619628906  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003139972686768  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002220630645752  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11370658874511719  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.779856204986572  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785575866699219  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1237645149230957  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.018473505973816
pure train time :  0.4470956325531006
train time :  0.6133711338043213
end to end time :  4.081005334854126
connection check time:  1.8467953205108643
block generation time  0.943758487701416
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005221366882324219
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014655828475952148
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6225950717926025
len local_batched_seeds_list  2
partition total batch output list spend :  0.7075588703155518
self.buckets_partition() spend  sec:  0.6372859477996826
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043205976486206055

in edges time spent  0.14444899559020996
local to global src and eids time spent  0.26099729537963867
time gen tails  0.05312681198120117
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09030938148498535

in edges time spent  0.3528110980987549
local to global src and eids time spent  0.5360257625579834
time gen tails  0.08172035217285156
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11025810241699219  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039295673370361  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039405345916748  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11485719680786133  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796597480773926  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.802317142486572  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12511777877807617  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0215421915054321
pure train time :  0.4363698959350586
train time :  0.5969240665435791
end to end time :  4.078211307525635
connection check time:  1.8117470741271973
block generation time  0.9458110332489014
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005660057067871094
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014636516571044922
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6286873817443848
len local_batched_seeds_list  2
partition total batch output list spend :  0.7146446704864502
self.buckets_partition() spend  sec:  0.6433653831481934
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04380393028259277

in edges time spent  0.15026354789733887
local to global src and eids time spent  0.26595377922058105
time gen tails  0.05758833885192871
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09162521362304688

in edges time spent  0.385906457901001
local to global src and eids time spent  0.5686113834381104
time gen tails  0.08474254608154297
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1109619140625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004589080810547  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003298282623291  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11524820327758789  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.766302108764648  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.772021770477295  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12508296966552734  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0201689004898071
pure train time :  0.45062971115112305
train time :  0.6147503852844238
end to end time :  4.200289249420166
connection check time:  1.9001266956329346
block generation time  0.9513039588928223
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005161762237548828
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01477670669555664
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6312801837921143
len local_batched_seeds_list  2
partition total batch output list spend :  0.715245246887207
self.buckets_partition() spend  sec:  0.6460902690887451
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.044463396072387695

in edges time spent  0.15021657943725586
local to global src and eids time spent  0.26201438903808594
time gen tails  0.05247974395751953
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0924980640411377

in edges time spent  0.3603212833404541
local to global src and eids time spent  0.5580687522888184
time gen tails  0.08321332931518555
res  length 2
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11144733428955078  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003238677978516  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00145959854126  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11375665664672852  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785627365112305  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791347026824951  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12410211563110352  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0187585353851318
pure train time :  0.44445204734802246
train time :  0.6043312549591064
end to end time :  4.170488595962524
connection check time:  1.8585305213928223
block generation time  0.9758796691894531
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005426406860351562
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014624834060668945
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6793913841247559
len local_batched_seeds_list  2
partition total batch output list spend :  0.7642269134521484
self.buckets_partition() spend  sec:  0.6940507888793945
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0425417423248291

in edges time spent  0.14536619186401367
local to global src and eids time spent  0.2644016742706299
time gen tails  0.052964210510253906
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09278154373168945

in edges time spent  0.3472003936767578
local to global src and eids time spent  0.5399830341339111
time gen tails  0.08107233047485352
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11087751388549805  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.996552467346191  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.99586009979248  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11498165130615234  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78277063369751  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788490295410156  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12482404708862305  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0189831256866455
pure train time :  0.4382772445678711
train time :  0.5982367992401123
end to end time :  4.144236087799072
connection check time:  1.8159801959991455
block generation time  0.9486191272735596
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005626678466796875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01440739631652832
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6327786445617676
len local_batched_seeds_list  2
partition total batch output list spend :  0.7178177833557129
self.buckets_partition() spend  sec:  0.6472194194793701
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04311180114746094

in edges time spent  0.14953899383544922
local to global src and eids time spent  0.2703695297241211
time gen tails  0.05334830284118652
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09142398834228516

in edges time spent  0.33925414085388184
local to global src and eids time spent  0.5393233299255371
time gen tails  0.08077692985534668
res  length 2
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11061573028564453  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001246452331543  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000484466552734  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11533069610595703  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785380840301514  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79110050201416  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1250934600830078  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0170872211456299
pure train time :  0.4460599422454834
train time :  0.6154272556304932
end to end time :  4.133468151092529
connection check time:  1.82277250289917
block generation time  0.9574434757232666
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005733966827392578
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014534473419189453
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.670835018157959
len local_batched_seeds_list  2
partition total batch output list spend :  0.7553911209106445
self.buckets_partition() spend  sec:  0.6855013370513916
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04320359230041504

in edges time spent  0.1442101001739502
local to global src and eids time spent  0.26021265983581543
time gen tails  0.05280017852783203
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09153866767883301

in edges time spent  0.33989644050598145
local to global src and eids time spent  0.5362706184387207
time gen tails  0.08087420463562012
res  length 2
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11087226867675781  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042980194091797  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042298793792725  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1149148941040039  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780253887176514  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78597354888916  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12456035614013672  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0184423923492432
pure train time :  0.4370880126953125
train time :  0.5985062122344971
end to end time :  4.129240989685059
connection check time:  1.8000099658966064
block generation time  0.9585223197937012
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005590915679931641
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014392614364624023
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.65360426902771
len local_batched_seeds_list  2
partition total batch output list spend :  0.737393856048584
self.buckets_partition() spend  sec:  0.6680347919464111
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04275059700012207

in edges time spent  0.14468741416931152
local to global src and eids time spent  0.2594335079193115
time gen tails  0.052371978759765625
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09092903137207031

in edges time spent  0.35866737365722656
local to global src and eids time spent  0.5380876064300537
time gen tails  0.08040714263916016
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11080312728881836  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997942924499512  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997321605682373  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11521625518798828  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78936243057251  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.795082092285156  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12497186660766602  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0191941261291504
pure train time :  0.43746066093444824
train time :  0.5967550277709961
end to end time :  4.119495630264282
connection check time:  1.8176913261413574
block generation time  0.9471964836120605
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005340576171875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014470100402832031
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6454222202301025
len local_batched_seeds_list  2
partition total batch output list spend :  0.7298147678375244
self.buckets_partition() spend  sec:  0.6599292755126953
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042870283126831055

in edges time spent  0.1438922882080078
local to global src and eids time spent  0.2595391273498535
time gen tails  0.0524601936340332
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09229755401611328

in edges time spent  0.34912657737731934
local to global src and eids time spent  0.5473954677581787
time gen tails  0.08592915534973145
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10994243621826172  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999637603759766  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.99891185760498  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11303091049194336  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.794915199279785  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.800634860992432  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12373113632202148  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.017235279083252
pure train time :  0.4392101764678955
train time :  0.6053485870361328
end to end time :  4.125511169433594
connection check time:  1.8241095542907715
block generation time  0.9520726203918457
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005314350128173828
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014983177185058594
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5499041080474854
len local_batched_seeds_list  2
partition total batch output list spend :  0.6712796688079834
self.buckets_partition() spend  sec:  0.5649216175079346
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04555034637451172

in edges time spent  0.15195226669311523
local to global src and eids time spent  0.2698795795440674
time gen tails  0.05301094055175781
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09574508666992188

in edges time spent  0.3201584815979004
local to global src and eids time spent  0.5571088790893555
time gen tails  0.08115005493164062
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11004924774169922  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043545246124268  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04301118850708  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11310386657714844  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.782010555267334  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78773021697998  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12440872192382812  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.01412832736969
pure train time :  0.4448559284210205
train time :  0.6134481430053711
end to end time :  4.091217756271362
connection check time:  1.8244640827178955
block generation time  0.9576296806335449
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005488395690917969
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01446223258972168
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6479983329772949
len local_batched_seeds_list  2
partition total batch output list spend :  0.7328827381134033
self.buckets_partition() spend  sec:  0.6624937057495117
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04318594932556152

in edges time spent  0.1505284309387207
local to global src and eids time spent  0.26148104667663574
time gen tails  0.05301356315612793
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09167957305908203

in edges time spent  0.34911632537841797
local to global src and eids time spent  0.5570688247680664
time gen tails  0.08315300941467285
res  length 2
block collection to dataloader spend  1.0967254638671875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11104631423950195  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040335655212402  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039478778839111  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11466217041015625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.776477813720703  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78219747543335  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12486553192138672  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0164101123809814
pure train time :  0.43727564811706543
train time :  0.6030170917510986
end to end time :  4.150152683258057
connection check time:  1.8498990535736084
block generation time  0.9462239742279053
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005357265472412109
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01584458351135254
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6861295700073242
len local_batched_seeds_list  2
partition total batch output list spend :  0.7726984024047852
self.buckets_partition() spend  sec:  0.7020137310028076
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04332089424133301

in edges time spent  0.1435542106628418
local to global src and eids time spent  0.27849912643432617
time gen tails  0.05537104606628418
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09662675857543945

in edges time spent  0.3677401542663574
local to global src and eids time spent  0.5572628974914551
time gen tails  0.08156919479370117
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11098575592041016  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038051128387451  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037198543548584  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11513090133666992  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.768683433532715  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.774403095245361  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12467527389526367  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0166716575622559
pure train time :  0.44724059104919434
train time :  0.6085290908813477
end to end time :  4.245598793029785
connection check time:  1.8838186264038086
block generation time  0.9635419845581055
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005474090576171875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014599084854125977
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6719212532043457
len local_batched_seeds_list  2
partition total batch output list spend :  0.7563836574554443
self.buckets_partition() spend  sec:  0.6865551471710205
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04284381866455078

in edges time spent  0.14463543891906738
local to global src and eids time spent  0.26230835914611816
time gen tails  0.05306601524353027
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09154129028320312

in edges time spent  0.347611665725708
local to global src and eids time spent  0.4988846778869629
time gen tails  0.059125661849975586
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10970258712768555  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041772365570068  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041298866271973  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11315584182739258  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.768218994140625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.773938655853271  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12379217147827148  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.014681100845337
pure train time :  0.44530463218688965
train time :  0.6088905334472656
end to end time :  4.083500385284424
connection check time:  1.75008225440979
block generation time  0.9519162178039551
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005385875701904297
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01567363739013672
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6153206825256348
len local_batched_seeds_list  2
partition total batch output list spend :  0.6599218845367432
self.buckets_partition() spend  sec:  0.6310279369354248
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04099774360656738

in edges time spent  0.13831257820129395
local to global src and eids time spent  0.26283907890319824
time gen tails  0.052973031997680664
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09135079383850098

in edges time spent  0.34096312522888184
local to global src and eids time spent  0.5359325408935547
time gen tails  0.08049988746643066
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11023616790771484  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00395679473877  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00322437286377  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11310482025146484  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780836582183838  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786556243896484  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12372207641601562  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.018187165260315
pure train time :  0.4414074420928955
train time :  0.6021380424499512
end to end time :  4.009030103683472
connection check time:  1.787482738494873
block generation time  0.9434473514556885
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005204677581787109
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013929128646850586
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6671998500823975
len local_batched_seeds_list  2
partition total batch output list spend :  0.7499523162841797
self.buckets_partition() spend  sec:  0.6811630725860596
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04248929023742676

in edges time spent  0.14313697814941406
local to global src and eids time spent  0.2605907917022705
time gen tails  0.05260467529296875
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09003424644470215

in edges time spent  0.34963440895080566
local to global src and eids time spent  0.5410969257354736
time gen tails  0.08092164993286133
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1102452278137207  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040850162506104  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040698051452637  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11369180679321289  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79452896118164  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.800248622894287  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12400579452514648  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0150952339172363
pure train time :  0.4423818588256836
train time :  0.599761962890625
end to end time :  4.121608018875122
connection check time:  1.8100612163543701
block generation time  0.9449131488800049
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005645751953125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014231681823730469
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6414194107055664
len local_batched_seeds_list  2
partition total batch output list spend :  0.7241544723510742
self.buckets_partition() spend  sec:  0.6556870937347412
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042732954025268555

in edges time spent  0.14418911933898926
local to global src and eids time spent  0.26015162467956543
time gen tails  0.05231523513793945
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09007620811462402

in edges time spent  0.3467597961425781
local to global src and eids time spent  0.5431885719299316
time gen tails  0.08565068244934082
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10985898971557617  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003794193267822  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003289222717285  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11331033706665039  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786902904510498  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792622566223145  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12459421157836914  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0158743858337402
pure train time :  0.44587206840515137
train time :  0.6101698875427246
end to end time :  4.115831136703491
connection check time:  1.8163695335388184
block generation time  0.9501512050628662
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000499725341796875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014876604080200195
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6436972618103027
len local_batched_seeds_list  2
partition total batch output list spend :  0.7284836769104004
self.buckets_partition() spend  sec:  0.6586103439331055
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04528522491455078

in edges time spent  0.1547398567199707
local to global src and eids time spent  0.26706624031066895
time gen tails  0.05309796333312988
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09132862091064453

in edges time spent  0.3931257724761963
local to global src and eids time spent  0.5639886856079102
time gen tails  0.08251738548278809
res  length 2
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11020469665527344  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004637241363525  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003787517547607  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11454391479492188  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78255558013916  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788275241851807  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12465667724609375  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0154333114624023
pure train time :  0.44515347480773926
train time :  0.6120035648345947
end to end time :  4.218278646469116
connection check time:  1.9016177654266357
block generation time  0.9503283500671387
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004887580871582031
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014294147491455078
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6465730667114258
len local_batched_seeds_list  2
partition total batch output list spend :  0.7313311100006104
self.buckets_partition() spend  sec:  0.6609015464782715
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042730093002319336

in edges time spent  0.14778399467468262
local to global src and eids time spent  0.25891828536987305
time gen tails  0.052832603454589844
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09097766876220703

in edges time spent  0.34020209312438965
local to global src and eids time spent  0.4973738193511963
time gen tails  0.05936431884765625
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1101369857788086  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039995193481445  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.03909683227539  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11409664154052734  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788102149963379  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793821811676025  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12414026260375977  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0146148204803467
pure train time :  0.4398164749145508
train time :  0.5987527370452881
end to end time :  4.033971071243286
connection check time:  1.740013837814331
block generation time  0.9476726055145264
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005404949188232422
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01576089859008789
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5258004665374756
len local_batched_seeds_list  2
partition total batch output list spend :  0.5716986656188965
self.buckets_partition() spend  sec:  0.5415992736816406
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.040842533111572266

in edges time spent  0.1508328914642334
local to global src and eids time spent  0.271939754486084
time gen tails  0.0537567138671875
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.090850830078125

in edges time spent  0.36334991455078125
local to global src and eids time spent  0.5517404079437256
time gen tails  0.0806727409362793
res  length 2
block collection to dataloader spend  1.1682510375976562e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11020660400390625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043007373809814  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042319774627686  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11442327499389648  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.75910472869873  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.764824390411377  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1242833137512207  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0136923789978027
pure train time :  0.44764041900634766
train time :  0.6212952136993408
end to end time :  4.0178022384643555
connection check time:  1.8554534912109375
block generation time  0.9494144916534424
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005373954772949219
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014493227005004883
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6602392196655273
len local_batched_seeds_list  2
partition total batch output list spend :  0.744657039642334
self.buckets_partition() spend  sec:  0.6747727394104004
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04281449317932129

in edges time spent  0.14363455772399902
local to global src and eids time spent  0.25975918769836426
time gen tails  0.05256843566894531
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0916905403137207

in edges time spent  0.34960150718688965
local to global src and eids time spent  0.5370655059814453
time gen tails  0.08098888397216797
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11004209518432617  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000788688659668  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000004291534424  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1129765510559082  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.794270515441895  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.799990177154541  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12379312515258789  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.01162850856781
pure train time :  0.44684743881225586
train time :  0.6139023303985596
end to end time :  4.127737045288086
connection check time:  1.807436466217041
block generation time  0.9451925754547119
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005598068237304688
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014562368392944336
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6611723899841309
len local_batched_seeds_list  2
partition total batch output list spend :  0.7462160587310791
self.buckets_partition() spend  sec:  0.675774097442627
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04246377944946289

in edges time spent  0.14438104629516602
local to global src and eids time spent  0.2615394592285156
time gen tails  0.05310416221618652
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09064888954162598

in edges time spent  0.34798359870910645
local to global src and eids time spent  0.5356419086456299
time gen tails  0.08123302459716797
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1101388931274414  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999488353729248  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998851299285889  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1146097183227539  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787991523742676  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793711185455322  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12428426742553711  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0105643272399902
pure train time :  0.4466409683227539
train time :  0.6128561496734619
end to end time :  4.140126943588257
connection check time:  1.807983160018921
block generation time  0.9567794799804688
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000522613525390625
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014484405517578125
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6730167865753174
len local_batched_seeds_list  2
partition total batch output list spend :  0.7583408355712891
self.buckets_partition() spend  sec:  0.6875367164611816
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04363679885864258

in edges time spent  0.1447587013244629
local to global src and eids time spent  0.2598550319671631
time gen tails  0.05261540412902832
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09069180488586426

in edges time spent  0.34925127029418945
local to global src and eids time spent  0.5396394729614258
time gen tails  0.07951498031616211
res  length 2
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10996055603027344  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044207096099854  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043483257293701  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11454343795776367  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781128883361816  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786848545074463  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12451648712158203  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.011897087097168
pure train time :  0.4456052780151367
train time :  0.6110131740570068
end to end time :  4.140158414840698
connection check time:  1.8088979721069336
block generation time  0.9488167762756348
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005147457122802734
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014037132263183594
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6340208053588867
len local_batched_seeds_list  2
partition total batch output list spend :  0.7168748378753662
self.buckets_partition() spend  sec:  0.6480972766876221
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04301190376281738

in edges time spent  0.14580464363098145
local to global src and eids time spent  0.2602858543395996
time gen tails  0.05266928672790527
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09061598777770996

in edges time spent  0.3307535648345947
local to global src and eids time spent  0.49474501609802246
time gen tails  0.05896806716918945
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11027050018310547  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04283618927002  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042943000793457  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11470603942871094  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790221214294434  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79594087600708  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12443733215332031  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0120668411254883
pure train time :  0.43933582305908203
train time :  0.6050691604614258
end to end time :  4.020271301269531
connection check time:  1.7276225090026855
block generation time  0.9567797183990479
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005426406860351562
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.016144990921020508
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6170921325683594
len local_batched_seeds_list  2
partition total batch output list spend :  0.6624314785003662
self.buckets_partition() spend  sec:  0.6332719326019287
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.041091203689575195

in edges time spent  0.14270257949829102
local to global src and eids time spent  0.26824116706848145
time gen tails  0.05357170104980469
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09060025215148926

in edges time spent  0.37244105339050293
local to global src and eids time spent  0.5589373111724854
time gen tails  0.08085894584655762
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11002635955810547  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043242454528809  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042452812194824  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11372137069702148  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.782308578491211  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788028240203857  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12339258193969727  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0135385990142822
pure train time :  0.45053648948669434
train time :  0.6097631454467773
end to end time :  4.092246770858765
connection check time:  1.8525855541229248
block generation time  0.9483458995819092
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005640983581542969
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01460409164428711
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6420793533325195
len local_batched_seeds_list  2
partition total batch output list spend :  0.7271132469177246
self.buckets_partition() spend  sec:  0.6567192077636719
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04277348518371582

in edges time spent  0.14478349685668945
local to global src and eids time spent  0.2589609622955322
time gen tails  0.0524749755859375
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09086275100708008

in edges time spent  0.3436250686645508
local to global src and eids time spent  0.5380079746246338
time gen tails  0.08283305168151855
res  length 2
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1100149154663086  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041776180267334  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041857242584229  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11456584930419922  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.77974796295166  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785467624664307  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12466049194335938  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.012442946434021
pure train time :  0.44664645195007324
train time :  0.6069836616516113
end to end time :  4.101386070251465
connection check time:  1.8036296367645264
block generation time  0.945868730545044
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005369186401367188
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014619827270507812
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6431398391723633
len local_batched_seeds_list  2
partition total batch output list spend :  0.7282497882843018
self.buckets_partition() spend  sec:  0.6577949523925781
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042847633361816406

in edges time spent  0.14491558074951172
local to global src and eids time spent  0.26182031631469727
time gen tails  0.05254936218261719
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09074234962463379

in edges time spent  0.3528599739074707
local to global src and eids time spent  0.5163815021514893
time gen tails  0.05878090858459473
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11039876937866211  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043005466461182  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042121887207031  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11456727981567383  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78077745437622  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786497116088867  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12425518035888672  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0123586654663086
pure train time :  0.4462618827819824
train time :  0.6070256233215332
end to end time :  4.071816444396973
connection check time:  1.7709107398986816
block generation time  0.9499294757843018
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005238056182861328
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01600337028503418
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6293895244598389
len local_batched_seeds_list  2
partition total batch output list spend :  0.6749155521392822
self.buckets_partition() spend  sec:  0.6454236507415771
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04257392883300781

in edges time spent  0.15246295928955078
local to global src and eids time spent  0.2635781764984131
time gen tails  0.053087711334228516
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09168744087219238

in edges time spent  0.36456298828125
local to global src and eids time spent  0.5391013622283936
time gen tails  0.08202314376831055
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10996103286743164  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.994706153869629  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.993957996368408  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11461544036865234  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78772497177124  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793444633483887  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1244955062866211  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0081814527511597
pure train time :  0.44141268730163574
train time :  0.6078176498413086
end to end time :  4.0796959400177
connection check time:  1.8341038227081299
block generation time  0.9498844146728516
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000530242919921875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014676332473754883
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5477633476257324
len local_batched_seeds_list  2
partition total batch output list spend :  0.6329195499420166
self.buckets_partition() spend  sec:  0.5624744892120361
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042552947998046875

in edges time spent  0.14373111724853516
local to global src and eids time spent  0.25991368293762207
time gen tails  0.05289959907531738
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09058904647827148

in edges time spent  0.3583662509918213
local to global src and eids time spent  0.562793493270874
time gen tails  0.08286809921264648
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11015081405639648  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000450611114502  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999519348144531  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11386871337890625  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78274393081665  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788463592529297  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12384510040283203  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0073645114898682
pure train time :  0.4415411949157715
train time :  0.6013216972351074
end to end time :  4.047079086303711
connection check time:  1.8463294506072998
block generation time  0.9540350437164307
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000553131103515625
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014734029769897461
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6281306743621826
len local_batched_seeds_list  2
partition total batch output list spend :  0.7132508754730225
self.buckets_partition() spend  sec:  0.6429769992828369
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04418754577636719

in edges time spent  0.14431357383728027
local to global src and eids time spent  0.26141858100891113
time gen tails  0.052999019622802734
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09162640571594238

in edges time spent  0.33966612815856934
local to global src and eids time spent  0.5345430374145508
time gen tails  0.08105778694152832
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11031341552734375  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.036171913146973  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.035365104675293  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11414098739624023  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784407615661621  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790127277374268  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12404632568359375  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.010774850845337
pure train time :  0.44518041610717773
train time :  0.6056075096130371
end to end time :  4.0803351402282715
connection check time:  1.7992193698883057
block generation time  0.9496047496795654
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005359649658203125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014811992645263672
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.625852108001709
len local_batched_seeds_list  2
partition total batch output list spend :  0.7109358310699463
self.buckets_partition() spend  sec:  0.6406974792480469
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04253506660461426

in edges time spent  0.14447855949401855
local to global src and eids time spent  0.26011133193969727
time gen tails  0.05274844169616699
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0910031795501709

in edges time spent  0.3583407402038574
local to global src and eids time spent  0.5531554222106934
time gen tails  0.08087921142578125
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11023330688476562  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998922348022461  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998190879821777  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11354351043701172  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.775555610656738  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781275272369385  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1247854232788086  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0088270902633667
pure train time :  0.4467589855194092
train time :  0.6074569225311279
end to end time :  4.108990669250488
connection check time:  1.8319847583770752
block generation time  0.9458727836608887
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005791187286376953
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014872074127197266
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6327626705169678
len local_batched_seeds_list  2
partition total batch output list spend :  0.7181451320648193
self.buckets_partition() spend  sec:  0.647667407989502
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04254341125488281

in edges time spent  0.14519214630126953
local to global src and eids time spent  0.2598435878753662
time gen tails  0.05251121520996094
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09247493743896484

in edges time spent  0.3515026569366455
local to global src and eids time spent  0.5400552749633789
time gen tails  0.08096885681152344
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11112022399902344  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041053771972656  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040987014770508  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11529827117919922  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.782097816467285  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787817478179932  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12590932846069336  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.009460210800171
pure train time :  0.4490647315979004
train time :  0.6137053966522217
end to end time :  4.1061012744903564
connection check time:  1.8150744438171387
block generation time  0.9466331005096436
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005156993865966797
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014757394790649414
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6406276226043701
len local_batched_seeds_list  2
partition total batch output list spend :  0.7252006530761719
self.buckets_partition() spend  sec:  0.6554245948791504
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0425715446472168

in edges time spent  0.1441028118133545
local to global src and eids time spent  0.2609579563140869
time gen tails  0.052596092224121094
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09134268760681152

in edges time spent  0.36520838737487793
local to global src and eids time spent  0.5441973209381104
time gen tails  0.08111381530761719
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11060905456542969  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041178703308105  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039798736572266  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11533641815185547  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78305435180664  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788774013519287  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1253523826599121  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.007101058959961
pure train time :  0.4468214511871338
train time :  0.6121711730957031
end to end time :  4.123840808868408
connection check time:  1.8304011821746826
block generation time  0.9434459209442139
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005292892456054688
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014257431030273438
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6453592777252197
len local_batched_seeds_list  2
partition total batch output list spend :  0.7297377586364746
self.buckets_partition() spend  sec:  0.6596527099609375
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04299497604370117

in edges time spent  0.14522576332092285
local to global src and eids time spent  0.25966691970825195
time gen tails  0.05313563346862793
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09053754806518555

in edges time spent  0.3397178649902344
local to global src and eids time spent  0.5361518859863281
time gen tails  0.08087444305419922
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11151599884033203  GigaBytes
Max Memory Allocated: 13.522996425628662  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.048102855682373  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.046542644500732  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11475419998168945  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.779877185821533  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78559684753418  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12504243850708008  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0089681148529053
pure train time :  0.44591259956359863
train time :  0.6144583225250244
end to end time :  4.095009088516235
connection check time:  1.7971382141113281
block generation time  0.9408645629882812
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005035400390625
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014392375946044922
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6358177661895752
len local_batched_seeds_list  2
partition total batch output list spend :  0.7197213172912598
self.buckets_partition() spend  sec:  0.650244951248169
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0431368350982666

in edges time spent  0.1442723274230957
local to global src and eids time spent  0.2596781253814697
time gen tails  0.052875518798828125
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09161639213562012

in edges time spent  0.35115575790405273
local to global src and eids time spent  0.5367259979248047
time gen tails  0.0810708999633789
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11044025421142578  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00126314163208  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000324726104736  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11306190490722656  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79283857345581  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.798558235168457  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12368965148925781  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0093685388565063
pure train time :  0.4441676139831543
train time :  0.6085987091064453
end to end time :  4.1004557609558105
connection check time:  1.8119471073150635
block generation time  0.9476754665374756
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005559921264648438
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01465463638305664
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6796314716339111
len local_batched_seeds_list  2
partition total batch output list spend :  0.7654199600219727
self.buckets_partition() spend  sec:  0.6943302154541016
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04486823081970215

in edges time spent  0.15175080299377441
local to global src and eids time spent  0.26296091079711914
time gen tails  0.053026437759399414
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09065794944763184

in edges time spent  0.34549593925476074
local to global src and eids time spent  0.539071798324585
time gen tails  0.08078527450561523
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11020040512084961  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.034352779388428  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.034523010253906  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11471033096313477  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790157318115234  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79587697982788  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12460184097290039  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0104528665542603
pure train time :  0.44695591926574707
train time :  0.6134445667266846
end to end time :  4.1624274253845215
connection check time:  1.8208770751953125
block generation time  0.9456510543823242
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00047469139099121094
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01408839225769043
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6455588340759277
len local_batched_seeds_list  2
partition total batch output list spend :  0.7280373573303223
self.buckets_partition() spend  sec:  0.6596837043762207
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042618513107299805

in edges time spent  0.14383292198181152
local to global src and eids time spent  0.26108288764953613
time gen tails  0.053139448165893555
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09068679809570312

in edges time spent  0.3498964309692383
local to global src and eids time spent  0.5727493762969971
time gen tails  0.08462667465209961
res  length 2
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10979175567626953  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043709754943848  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043159484863281  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11453390121459961  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.782038688659668  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787758350372314  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12480020523071289  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0077228546142578
pure train time :  0.44646263122558594
train time :  0.6140899658203125
end to end time :  4.196924209594727
connection check time:  1.8582236766815186
block generation time  0.9835085868835449
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005028247833251953
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014298677444458008
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5789070129394531
len local_batched_seeds_list  2
partition total batch output list spend :  0.6645801067352295
self.buckets_partition() spend  sec:  0.5932412147521973
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.044441938400268555

in edges time spent  0.14874958992004395
local to global src and eids time spent  0.2690243721008301
time gen tails  0.054001808166503906
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09458303451538086

in edges time spent  0.3604872226715088
local to global src and eids time spent  0.5561745166778564
time gen tails  0.08316230773925781
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1110987663269043  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.036247730255127  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.035340785980225  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1150827407836914  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.773544311523438  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.779263973236084  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12468814849853516  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0083072185516357
pure train time :  0.44592809677124023
train time :  0.6067214012145996
end to end time :  4.144583225250244
connection check time:  1.87158203125
block generation time  0.9850788116455078
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005152225494384766
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01445317268371582
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6272130012512207
len local_batched_seeds_list  2
partition total batch output list spend :  0.7109849452972412
self.buckets_partition() spend  sec:  0.6416995525360107
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042517900466918945

in edges time spent  0.14410138130187988
local to global src and eids time spent  0.2613992691040039
time gen tails  0.05271744728088379
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09018373489379883

in edges time spent  0.3624839782714844
local to global src and eids time spent  0.5369653701782227
time gen tails  0.0591738224029541
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1097569465637207  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003766059875488  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003231525421143  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11377763748168945  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.777777671813965  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.783497333526611  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1237640380859375  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0077283382415771
pure train time :  0.44443368911743164
train time :  0.6105945110321045
end to end time :  4.077568054199219
connection check time:  1.800837516784668
block generation time  0.9425358772277832
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005025863647460938
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015834569931030273
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6055705547332764
len local_batched_seeds_list  2
partition total batch output list spend :  0.6502285003662109
self.buckets_partition() spend  sec:  0.6214406490325928
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04069972038269043

in edges time spent  0.14450478553771973
local to global src and eids time spent  0.2158796787261963
time gen tails  0.03969979286193848
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0917367935180664

in edges time spent  0.3322641849517822
local to global src and eids time spent  0.49274325370788574
time gen tails  0.059366464614868164
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1102304458618164  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.036478519439697  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.035795211791992  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11455965042114258  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786040782928467  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791760444641113  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12410211563110352  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0075610876083374
pure train time :  0.44663166999816895
train time :  0.6105544567108154
end to end time :  3.8901448249816895
connection check time:  1.6623454093933105
block generation time  0.951340913772583
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0006375312805175781
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015738248825073242
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6247420310974121
len local_batched_seeds_list  2
partition total batch output list spend :  0.6690959930419922
self.buckets_partition() spend  sec:  0.6405143737792969
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04081273078918457

in edges time spent  0.13275575637817383
local to global src and eids time spent  0.2143850326538086
time gen tails  0.03975939750671387
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09181594848632812

in edges time spent  0.3305513858795166
local to global src and eids time spent  0.4953298568725586
time gen tails  0.05892372131347656
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10968589782714844  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999924659729004  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00032901763916  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11476755142211914  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.77590274810791  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781622409820557  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12467813491821289  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0057086944580078
pure train time :  0.44643664360046387
train time :  0.6140179634094238
end to end time :  3.8886594772338867
connection check time:  1.6482317447662354
block generation time  0.9440383911132812
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00055694580078125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01579880714416504
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6117990016937256
len local_batched_seeds_list  2
partition total batch output list spend :  0.6561555862426758
self.buckets_partition() spend  sec:  0.6276330947875977
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04045414924621582

in edges time spent  0.13277053833007812
local to global src and eids time spent  0.21392178535461426
time gen tails  0.04006028175354004
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09141898155212402

in edges time spent  0.33937859535217285
local to global src and eids time spent  0.49731874465942383
time gen tails  0.05922651290893555
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1097865104675293  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003171443939209  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002606391906738  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11461973190307617  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79085922241211  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796578884124756  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12450647354125977  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0032548904418945
pure train time :  0.4338517189025879
train time :  0.592271089553833
end to end time :  3.880760669708252
connection check time:  1.6586620807647705
block generation time  0.9535696506500244
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005712509155273438
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.016025543212890625
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6266815662384033
len local_batched_seeds_list  2
partition total batch output list spend :  0.6713685989379883
self.buckets_partition() spend  sec:  0.6427781581878662
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.040700435638427734

in edges time spent  0.13210296630859375
local to global src and eids time spent  0.21265792846679688
time gen tails  0.040346384048461914
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09106731414794922

in edges time spent  0.33006978034973145
local to global src and eids time spent  0.49294400215148926
time gen tails  0.05958414077758789
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1097869873046875  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044095039367676  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044411659240723  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1144108772277832  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.750465869903564  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.756185531616211  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12422895431518555  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0030617713928223
pure train time :  0.4409768581390381
train time :  0.6020762920379639
end to end time :  3.87225341796875
connection check time:  1.6433029174804688
block generation time  0.9429798126220703
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005521774291992188
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01600813865661621
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6488981246948242
len local_batched_seeds_list  2
partition total batch output list spend :  0.6943366527557373
self.buckets_partition() spend  sec:  0.664940357208252
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04192924499511719

in edges time spent  0.13222503662109375
local to global src and eids time spent  0.21452021598815918
time gen tails  0.040384531021118164
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09085988998413086

in edges time spent  0.3508033752441406
local to global src and eids time spent  0.5019431114196777
time gen tails  0.05899786949157715
res  length 2
block collection to dataloader spend  1.1205673217773438e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10969257354736328  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.034914016723633  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.034453392028809  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11275625228881836  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788071155548096  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793790817260742  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12326574325561523  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0043495893478394
pure train time :  0.4409632682800293
train time :  0.6027157306671143
end to end time :  3.938718318939209
connection check time:  1.6765289306640625
block generation time  0.9489200115203857
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000553131103515625
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015928268432617188
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6340758800506592
len local_batched_seeds_list  2
partition total batch output list spend :  0.6800780296325684
self.buckets_partition() spend  sec:  0.6500382423400879
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.040149688720703125

in edges time spent  0.11311960220336914
local to global src and eids time spent  0.2556929588317871
time gen tails  0.0531010627746582
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09048295021057129

in edges time spent  0.33795928955078125
local to global src and eids time spent  0.4990065097808838
time gen tails  0.05946612358093262
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11074495315551758  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998073101043701  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997353076934814  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11460733413696289  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.782701969146729  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788421630859375  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12422513961791992  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0044699907302856
pure train time :  0.4379432201385498
train time :  0.5968132019042969
end to end time :  3.946521520614624
connection check time:  1.6937942504882812
block generation time  0.9575035572052002
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005574226379394531
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015721797943115234
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5262634754180908
len local_batched_seeds_list  2
partition total batch output list spend :  0.5718734264373779
self.buckets_partition() spend  sec:  0.5420262813568115
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0404055118560791

in edges time spent  0.14493465423583984
local to global src and eids time spent  0.2589378356933594
time gen tails  0.05295610427856445
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09140205383300781

in edges time spent  0.36350083351135254
local to global src and eids time spent  0.5548591613769531
time gen tails  0.08105707168579102
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1097712516784668  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042333126068115  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04179573059082  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1145792007446289  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791455745697021  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.797175407409668  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12435293197631836  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0055770874023438
pure train time :  0.4443035125732422
train time :  0.6125912666320801
end to end time :  3.986525297164917
connection check time:  1.8338699340820312
block generation time  0.9506142139434814
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004949569702148438
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014580726623535156
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6215589046478271
len local_batched_seeds_list  2
partition total batch output list spend :  0.706404447555542
self.buckets_partition() spend  sec:  0.636174201965332
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04308032989501953

in edges time spent  0.14483213424682617
local to global src and eids time spent  0.26065921783447266
time gen tails  0.05255270004272461
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09159231185913086

in edges time spent  0.34018969535827637
local to global src and eids time spent  0.5417027473449707
time gen tails  0.08008337020874023
res  length 2
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1108851432800293  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999826431274414  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.99912405014038  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11512374877929688  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788317680358887  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.794037342071533  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12487649917602539  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0021321773529053
pure train time :  0.4377620220184326
train time :  0.5987789630889893
end to end time :  4.0727643966674805
connection check time:  1.8060269355773926
block generation time  0.9488558769226074
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005540847778320312
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014464139938354492
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6616711616516113
len local_batched_seeds_list  2
partition total batch output list spend :  0.7462999820709229
self.buckets_partition() spend  sec:  0.6761834621429443
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04319930076599121

in edges time spent  0.14395904541015625
local to global src and eids time spent  0.2611653804779053
time gen tails  0.053090810775756836
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09121251106262207

in edges time spent  0.33506155014038086
local to global src and eids time spent  0.4965629577636719
time gen tails  0.0590512752532959
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1099553108215332  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042633533477783  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041913986206055  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1145782470703125  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781901359558105  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787621021270752  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12437248229980469  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0010327100753784
pure train time :  0.446307897567749
train time :  0.606957197189331
end to end time :  4.041321039199829
connection check time:  1.73152494430542
block generation time  0.9435389041900635
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005297660827636719
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015738487243652344
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6098947525024414
len local_batched_seeds_list  2
partition total batch output list spend :  0.6542303562164307
self.buckets_partition() spend  sec:  0.6256682872772217
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04066038131713867

in edges time spent  0.1448822021484375
local to global src and eids time spent  0.26317763328552246
time gen tails  0.0528566837310791
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09300422668457031

in edges time spent  0.34983277320861816
local to global src and eids time spent  0.5545868873596191
time gen tails  0.0818779468536377
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10996294021606445  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039383888244629  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039522647857666  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11449909210205078  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790506839752197  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796226501464844  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12457466125488281  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0038318634033203
pure train time :  0.44887375831604004
train time :  0.6183876991271973
end to end time :  4.081096410751343
connection check time:  1.8249711990356445
block generation time  0.9697659015655518
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000759124755859375
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015002012252807617
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6450891494750977
len local_batched_seeds_list  2
partition total batch output list spend :  0.7292277812957764
self.buckets_partition() spend  sec:  0.6601250171661377
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04445600509643555

in edges time spent  0.15715909004211426
local to global src and eids time spent  0.2690558433532715
time gen tails  0.05321645736694336
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09443855285644531

in edges time spent  0.38184046745300293
local to global src and eids time spent  0.5504105091094971
time gen tails  0.08118915557861328
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10996198654174805  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039525508880615  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.03908634185791  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11434602737426758  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.779860019683838  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785579681396484  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12427473068237305  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.002763032913208
pure train time :  0.447742223739624
train time :  0.6086664199829102
end to end time :  4.186428070068359
connection check time:  1.8813138008117676
block generation time  0.9528052806854248
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005600452423095703
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014812707901000977
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6332342624664307
len local_batched_seeds_list  2
partition total batch output list spend :  0.7175838947296143
self.buckets_partition() spend  sec:  0.648118257522583
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04271292686462402

in edges time spent  0.1455214023590088
local to global src and eids time spent  0.2605886459350586
time gen tails  0.0535275936126709
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09123921394348145

in edges time spent  0.34340882301330566
local to global src and eids time spent  0.5338330268859863
time gen tails  0.08129668235778809
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11007165908813477  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002356052398682  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00178337097168  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11437511444091797  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.801210880279541  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.806930541992188  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12445592880249023  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0031732320785522
pure train time :  0.4485299587249756
train time :  0.6102273464202881
end to end time :  4.091257333755493
connection check time:  1.8007774353027344
block generation time  0.9501609802246094
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005869865417480469
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014643192291259766
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.640662431716919
len local_batched_seeds_list  2
partition total batch output list spend :  0.7247104644775391
self.buckets_partition() spend  sec:  0.6554226875305176
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043082475662231445

in edges time spent  0.14393305778503418
local to global src and eids time spent  0.26215267181396484
time gen tails  0.05288553237915039
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09058427810668945

in edges time spent  0.33939146995544434
local to global src and eids time spent  0.5376684665679932
time gen tails  0.08006572723388672
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11052179336547852  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002321720123291  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00130558013916  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11391401290893555  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.77843189239502  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784151554107666  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12359952926635742  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.003434658050537
pure train time :  0.4463825225830078
train time :  0.6116786003112793
end to end time :  4.094301700592041
connection check time:  1.7990970611572266
block generation time  0.946173906326294
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005896091461181641
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014626026153564453
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6425256729125977
len local_batched_seeds_list  2
partition total batch output list spend :  0.7265474796295166
self.buckets_partition() spend  sec:  0.6571860313415527
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043057918548583984

in edges time spent  0.14472246170043945
local to global src and eids time spent  0.2618601322174072
time gen tails  0.05309343338012695
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09069156646728516

in edges time spent  0.3446946144104004
local to global src and eids time spent  0.5405075550079346
time gen tails  0.08144450187683105
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11014747619628906  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997343063354492  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.996411323547363  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1144261360168457  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785924911499023  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79164457321167  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12450361251831055  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9985203742980957
pure train time :  0.44707536697387695
train time :  0.614241361618042
end to end time :  4.114464044570923
connection check time:  1.8115909099578857
block generation time  0.9493408203125
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005426406860351562
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014733314514160156
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6469748020172119
len local_batched_seeds_list  2
partition total batch output list spend :  0.7313711643218994
self.buckets_partition() spend  sec:  0.6617443561553955
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04348444938659668

in edges time spent  0.14530730247497559
local to global src and eids time spent  0.25983166694641113
time gen tails  0.052715301513671875
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0921792984008789

in edges time spent  0.34913015365600586
local to global src and eids time spent  0.5098047256469727
time gen tails  0.05866360664367676
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10997533798217773  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042080402374268  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041340827941895  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11452484130859375  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781529426574707  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787249088287354  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12450599670410156  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.002151608467102
pure train time :  0.4370851516723633
train time :  0.5958642959594727
end to end time :  4.050664663314819
connection check time:  1.7606050968170166
block generation time  0.9500234127044678
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005650520324707031
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015985488891601562
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5222671031951904
len local_batched_seeds_list  2
partition total batch output list spend :  0.5676181316375732
self.buckets_partition() spend  sec:  0.5382959842681885
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.040859222412109375

in edges time spent  0.1392066478729248
local to global src and eids time spent  0.25941038131713867
time gen tails  0.05251717567443848
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09135866165161133

in edges time spent  0.3517875671386719
local to global src and eids time spent  0.546776294708252
time gen tails  0.08112859725952148
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10984992980957031  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000380039215088  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999753475189209  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1133427619934082  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785695552825928  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791415214538574  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12421798706054688  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9993045330047607
pure train time :  0.4377436637878418
train time :  0.5977814197540283
end to end time :  3.936286211013794
connection check time:  1.8080275058746338
block generation time  0.9498260021209717
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005466938018798828
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014495849609375
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6340253353118896
len local_batched_seeds_list  2
partition total batch output list spend :  0.7189972400665283
self.buckets_partition() spend  sec:  0.6485569477081299
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04282712936401367

in edges time spent  0.14581036567687988
local to global src and eids time spent  0.26043128967285156
time gen tails  0.053492069244384766
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09084129333496094

in edges time spent  0.36130547523498535
local to global src and eids time spent  0.555858850479126
time gen tails  0.08060050010681152
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11047935485839844  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004010200500488  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00303840637207  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11423349380493164  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790984153747559  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796703815460205  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12457704544067383  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0018739700317383
pure train time :  0.4363088607788086
train time :  0.6095311641693115
end to end time :  4.1422278881073
connection check time:  1.8513150215148926
block generation time  0.9496753215789795
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004990100860595703
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01427316665649414
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6516122817993164
len local_batched_seeds_list  2
partition total batch output list spend :  0.7353532314300537
self.buckets_partition() spend  sec:  0.6659255027770996
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04314136505126953

in edges time spent  0.14372038841247559
local to global src and eids time spent  0.26194190979003906
time gen tails  0.053035736083984375
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09128117561340332

in edges time spent  0.3437929153442383
local to global src and eids time spent  0.516472578048706
time gen tails  0.059119462966918945
res  length 2
block collection to dataloader spend  1.5974044799804688e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11095619201660156  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044464111328125  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043179035186768  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1136317253112793  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.765623092651367  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.771342754364014  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12424707412719727  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9997653961181641
pure train time :  0.4331963062286377
train time :  0.5936262607574463
end to end time :  4.052331447601318
connection check time:  1.7624025344848633
block generation time  0.9423863887786865
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005180835723876953
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01409459114074707
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6484279632568359
len local_batched_seeds_list  2
partition total batch output list spend :  0.7321643829345703
self.buckets_partition() spend  sec:  0.6625564098358154
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042973995208740234

in edges time spent  0.14423346519470215
local to global src and eids time spent  0.2602412700653076
time gen tails  0.05278730392456055
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09240937232971191

in edges time spent  0.32901883125305176
local to global src and eids time spent  0.41504454612731934
time gen tails  0.048923492431640625
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11118650436401367  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00329065322876  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002291679382324  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1141500473022461  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790865898132324  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79658555984497  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12482070922851562  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9999628067016602
pure train time :  0.44544100761413574
train time :  0.6037654876708984
end to end time :  3.6851727962493896
connection check time:  1.552367925643921
block generation time  0.786409854888916
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005354881286621094
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015863656997680664
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6069772243499756
len local_batched_seeds_list  2
partition total batch output list spend :  0.6508591175079346
self.buckets_partition() spend  sec:  0.6228773593902588
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.040482282638549805

in edges time spent  0.14438939094543457
local to global src and eids time spent  0.26024293899536133
time gen tails  0.053017616271972656
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09119701385498047

in edges time spent  0.34838223457336426
local to global src and eids time spent  0.5589766502380371
time gen tails  0.08366990089416504
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11060953140258789  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998455047607422  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997958183288574  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11458539962768555  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796778678894043  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.80249834060669  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12461280822753906  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9979812502861023
pure train time :  0.4490633010864258
train time :  0.6141366958618164
end to end time :  4.086114406585693
connection check time:  1.8308143615722656
block generation time  0.977149486541748
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005285739898681641
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014399051666259766
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6667437553405762
len local_batched_seeds_list  2
partition total batch output list spend :  0.7522063255310059
self.buckets_partition() spend  sec:  0.6811764240264893
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04423236846923828

in edges time spent  0.14968657493591309
local to global src and eids time spent  0.26546788215637207
time gen tails  0.053676605224609375
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09185934066772461

in edges time spent  0.34896159172058105
local to global src and eids time spent  0.5365426540374756
time gen tails  0.08115816116333008
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11020565032958984  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997458934783936  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.996752262115479  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11326456069946289  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780454158782959  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786173820495605  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12473154067993164  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9987980127334595
pure train time :  0.44714832305908203
train time :  0.6106874942779541
end to end time :  4.141786098480225
connection check time:  1.822221040725708
block generation time  0.9432985782623291
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005505084991455078
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014151573181152344
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6405031681060791
len local_batched_seeds_list  2
partition total batch output list spend :  0.7246804237365723
self.buckets_partition() spend  sec:  0.6546909809112549
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04305720329284668

in edges time spent  0.14395928382873535
local to global src and eids time spent  0.261974573135376
time gen tails  0.052947282791137695
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09045076370239258

in edges time spent  0.34041714668273926
local to global src and eids time spent  0.5356109142303467
time gen tails  0.08052635192871094
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11037397384643555  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002420425415039  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001266956329346  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11319971084594727  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781824111938477  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787543773651123  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12397289276123047  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9990537762641907
pure train time :  0.44717931747436523
train time :  0.6148793697357178
end to end time :  4.095919609069824
connection check time:  1.799013376235962
block generation time  0.9450912475585938
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0010035037994384766
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01441335678100586
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6447713375091553
len local_batched_seeds_list  2
partition total batch output list spend :  0.7290048599243164
self.buckets_partition() spend  sec:  0.6592192649841309
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04274463653564453

in edges time spent  0.1513049602508545
local to global src and eids time spent  0.26492881774902344
time gen tails  0.05494332313537598
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09120559692382812

in edges time spent  0.35994648933410645
local to global src and eids time spent  0.5451531410217285
time gen tails  0.08413076400756836
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11010551452636719  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001934051513672  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001054763793945  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11423015594482422  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.767249584197998  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.772969245910645  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12438535690307617  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9982247352600098
pure train time :  0.44878625869750977
train time :  0.6139411926269531
end to end time :  4.152445077896118
connection check time:  1.8445014953613281
block generation time  0.9516797065734863
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005698204040527344
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015135526657104492
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6472258567810059
len local_batched_seeds_list  2
partition total batch output list spend :  0.7323575019836426
self.buckets_partition() spend  sec:  0.6623966693878174
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0470271110534668

in edges time spent  0.15564489364624023
local to global src and eids time spent  0.2678210735321045
time gen tails  0.05255770683288574
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08958554267883301

in edges time spent  0.36443448066711426
local to global src and eids time spent  0.5410678386688232
time gen tails  0.08134865760803223
res  length 2
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11033201217651367  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04094123840332  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040124416351318  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11450862884521484  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787869453430176  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793589115142822  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12463951110839844  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9996500015258789
pure train time :  0.445681095123291
train time :  0.6084685325622559
end to end time :  4.157977104187012
connection check time:  1.847930669784546
block generation time  0.953488826751709
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004954338073730469
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014711141586303711
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5496349334716797
len local_batched_seeds_list  2
partition total batch output list spend :  0.6348779201507568
self.buckets_partition() spend  sec:  0.5643823146820068
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04292917251586914

in edges time spent  0.1470932960510254
local to global src and eids time spent  0.26137638092041016
time gen tails  0.0531613826751709
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0902862548828125

in edges time spent  0.36588549613952637
local to global src and eids time spent  0.5480246543884277
time gen tails  0.0810854434967041
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11001253128051758  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001074314117432  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000576972961426  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11463022232055664  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.798549175262451  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.804268836975098  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12453889846801758  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9979326725006104
pure train time :  0.44837117195129395
train time :  0.6151652336120605
end to end time :  4.047375917434692
connection check time:  1.838921308517456
block generation time  0.9456155300140381
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004994869232177734
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014470338821411133
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6249775886535645
len local_batched_seeds_list  2
partition total batch output list spend :  0.7093081474304199
self.buckets_partition() spend  sec:  0.6394827365875244
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043154001235961914

in edges time spent  0.14429998397827148
local to global src and eids time spent  0.26017260551452637
time gen tails  0.05282330513000488
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09074997901916504

in edges time spent  0.3432648181915283
local to global src and eids time spent  0.5393106937408447
time gen tails  0.08180618286132812
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10981035232543945  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.047058582305908  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.046489715576172  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1136317253112793  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.77789306640625  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.783612728118896  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12342596054077148  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9975155591964722
pure train time :  0.4399740695953369
train time :  0.6047759056091309
end to end time :  4.081961154937744
connection check time:  1.8054614067077637
block generation time  0.9492900371551514
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005013942718505859
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014573335647583008
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6306893825531006
len local_batched_seeds_list  2
partition total batch output list spend :  0.715069055557251
self.buckets_partition() spend  sec:  0.6453044414520264
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04291105270385742

in edges time spent  0.14372587203979492
local to global src and eids time spent  0.26184582710266113
time gen tails  0.05311894416809082
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09078168869018555

in edges time spent  0.3468475341796875
local to global src and eids time spent  0.5426151752471924
time gen tails  0.07971024513244629
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11000871658325195  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039237022399902  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038459300994873  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11306381225585938  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780849933624268  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786569595336914  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12368297576904297  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9978208541870117
pure train time :  0.4419543743133545
train time :  0.6014626026153564
end to end time :  4.07869291305542
connection check time:  1.8097765445709229
block generation time  0.9397943019866943
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005130767822265625
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014462471008300781
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6297323703765869
len local_batched_seeds_list  2
partition total batch output list spend :  0.7138526439666748
self.buckets_partition() spend  sec:  0.6442279815673828
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04258155822753906

in edges time spent  0.1438148021697998
local to global src and eids time spent  0.2597541809082031
time gen tails  0.052942514419555664
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09126949310302734

in edges time spent  0.3348374366760254
local to global src and eids time spent  0.49495434761047363
time gen tails  0.0591127872467041
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11091756820678711  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000791072845459  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000921249389648  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11484909057617188  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.76019811630249  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.765917778015137  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12462568283081055  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9961858987808228
pure train time :  0.44684863090515137
train time :  0.6124770641326904
end to end time :  4.012131690979004
connection check time:  1.7271504402160645
block generation time  0.9460630416870117
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005319118499755859
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01579761505126953
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6111810207366943
len local_batched_seeds_list  2
partition total batch output list spend :  0.6559438705444336
self.buckets_partition() spend  sec:  0.6270220279693604
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04068493843078613

in edges time spent  0.1386880874633789
local to global src and eids time spent  0.2606518268585205
time gen tails  0.05303144454956055
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09224963188171387

in edges time spent  0.34815359115600586
local to global src and eids time spent  0.5499362945556641
time gen tails  0.08181452751159668
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11055707931518555  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040948867797852  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040245532989502  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11511707305908203  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787847995758057  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793567657470703  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12476730346679688  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9933075904846191
pure train time :  0.4391796588897705
train time :  0.606858491897583
end to end time :  4.039618968963623
connection check time:  1.8167121410369873
block generation time  0.9472141265869141
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005548000335693359
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014417886734008789
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6380412578582764
len local_batched_seeds_list  2
partition total batch output list spend :  0.7222731113433838
self.buckets_partition() spend  sec:  0.6525406837463379
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04269146919250488

in edges time spent  0.14422869682312012
local to global src and eids time spent  0.2618131637573242
time gen tails  0.052939653396606445
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09132194519042969

in edges time spent  0.337719202041626
local to global src and eids time spent  0.5400540828704834
time gen tails  0.08006429672241211
res  length 2
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10978221893310547  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997193813323975  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.996623516082764  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11430931091308594  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.783595561981201  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789315223693848  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1242055892944336  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9964139461517334
pure train time :  0.4433727264404297
train time :  0.6032073497772217
end to end time :  4.094945192337036
connection check time:  1.8000800609588623
block generation time  0.9533610343933105
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005393028259277344
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014548778533935547
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6638176441192627
len local_batched_seeds_list  2
partition total batch output list spend :  0.7468469142913818
self.buckets_partition() spend  sec:  0.6784124374389648
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042435407638549805

in edges time spent  0.14352965354919434
local to global src and eids time spent  0.26147937774658203
time gen tails  0.05331063270568848
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09195995330810547

in edges time spent  0.3553333282470703
local to global src and eids time spent  0.5540211200714111
time gen tails  0.0809330940246582
res  length 2
block collection to dataloader spend  1.3828277587890625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11033344268798828  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001599311828613  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000490188598633  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11338615417480469  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787302494049072  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793022155761719  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12413978576660156  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9938169717788696
pure train time :  0.4411594867706299
train time :  0.602257490158081
end to end time :  4.152091979980469
connection check time:  1.8322083950042725
block generation time  0.9579176902770996
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005931854248046875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014966487884521484
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6511023044586182
len local_batched_seeds_list  2
partition total batch output list spend :  0.736107349395752
self.buckets_partition() spend  sec:  0.6661036014556885
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042560577392578125

in edges time spent  0.1439533233642578
local to global src and eids time spent  0.2613961696624756
time gen tails  0.05316042900085449
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09242892265319824

in edges time spent  0.34021663665771484
local to global src and eids time spent  0.5352752208709717
time gen tails  0.08122634887695312
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11033105850219727  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003725051879883  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002902507781982  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11268234252929688  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.750358581542969  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.756078243255615  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12337779998779297  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9964956045150757
pure train time :  0.4441661834716797
train time :  0.6040160655975342
end to end time :  4.096159934997559
connection check time:  1.7992050647735596
block generation time  0.9440655708312988
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005328655242919922
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014722347259521484
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6467111110687256
len local_batched_seeds_list  2
partition total batch output list spend :  0.7312390804290771
self.buckets_partition() spend  sec:  0.6614689826965332
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042643070220947266

in edges time spent  0.14302849769592285
local to global src and eids time spent  0.260364294052124
time gen tails  0.05294227600097656
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09059619903564453

in edges time spent  0.34645771980285645
local to global src and eids time spent  0.5374767780303955
time gen tails  0.08024096488952637
res  length 2
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11004877090454102  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037798881530762  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037841320037842  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11447906494140625  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785752773284912  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791472434997559  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12428665161132812  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9945899248123169
pure train time :  0.44653820991516113
train time :  0.6074259281158447
end to end time :  4.103665113449097
connection check time:  1.802968978881836
block generation time  0.949303150177002
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0006151199340820312
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014916181564331055
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5521743297576904
len local_batched_seeds_list  2
partition total batch output list spend :  0.6372725963592529
self.buckets_partition() spend  sec:  0.5671262741088867
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04279923439025879

in edges time spent  0.1441206932067871
local to global src and eids time spent  0.26159024238586426
time gen tails  0.05309319496154785
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09102869033813477

in edges time spent  0.3410074710845947
local to global src and eids time spent  0.5398550033569336
time gen tails  0.08058714866638184
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10997629165649414  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038371562957764  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037625312805176  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11321306228637695  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781384944915771  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787104606628418  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12406015396118164  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9931784272193909
pure train time :  0.43666505813598633
train time :  0.5969891548156738
end to end time :  4.002587080001831
connection check time:  1.8036448955535889
block generation time  0.9515938758850098
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005786418914794922
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014768838882446289
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6307640075683594
len local_batched_seeds_list  2
partition total batch output list spend :  0.7152628898620605
self.buckets_partition() spend  sec:  0.6456499099731445
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04287409782409668

in edges time spent  0.14299654960632324
local to global src and eids time spent  0.2616136074066162
time gen tails  0.05337977409362793
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09012031555175781

in edges time spent  0.3402750492095947
local to global src and eids time spent  0.5362043380737305
time gen tails  0.07999897003173828
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11045265197753906  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003026485443115  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002940654754639  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11531686782836914  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.795412540435791  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.801132202148438  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12573671340942383  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9917032718658447
pure train time :  0.44484567642211914
train time :  0.6083333492279053
end to end time :  4.079204082489014
connection check time:  1.7960829734802246
block generation time  0.9467039108276367
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005724430084228516
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015251874923706055
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.630516767501831
len local_batched_seeds_list  2
partition total batch output list spend :  0.7139573097229004
self.buckets_partition() spend  sec:  0.6458008289337158
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0427396297454834

in edges time spent  0.14739489555358887
local to global src and eids time spent  0.26314306259155273
time gen tails  0.05266857147216797
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09039878845214844

in edges time spent  0.3655533790588379
local to global src and eids time spent  0.549546480178833
time gen tails  0.08127260208129883
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11112356185913086  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037017345428467  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.035566329956055  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11542367935180664  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.76686954498291  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.772589206695557  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12497377395629883  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9925380349159241
pure train time :  0.4421074390411377
train time :  0.6037542819976807
end to end time :  4.155278205871582
connection check time:  1.8401825428009033
block generation time  0.9747970104217529
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000530242919921875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014766454696655273
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6356391906738281
len local_batched_seeds_list  2
partition total batch output list spend :  0.7194244861602783
self.buckets_partition() spend  sec:  0.6504387855529785
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04406595230102539

in edges time spent  0.1467576026916504
local to global src and eids time spent  0.2611048221588135
time gen tails  0.053017377853393555
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09136724472045898

in edges time spent  0.36957263946533203
local to global src and eids time spent  0.5543477535247803
time gen tails  0.08251404762268066
res  length 2
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11117410659790039  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.045127391815186  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043635368347168  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11469268798828125  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.769237518310547  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.774957180023193  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12475299835205078  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9929568767547607
pure train time :  0.4368469715118408
train time :  0.5977258682250977
end to end time :  4.127592086791992
connection check time:  1.8509197235107422
block generation time  0.9438009262084961
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005536079406738281
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014456748962402344
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6659040451049805
len local_batched_seeds_list  2
partition total batch output list spend :  0.7496335506439209
self.buckets_partition() spend  sec:  0.6803960800170898
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04291796684265137

in edges time spent  0.14493608474731445
local to global src and eids time spent  0.26123881340026855
time gen tails  0.052608489990234375
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09270977973937988

in edges time spent  0.3352322578430176
local to global src and eids time spent  0.4974997043609619
time gen tails  0.058884382247924805
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11021661758422852  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040865421295166  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040156364440918  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11328983306884766  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785506248474121  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791225910186768  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12391376495361328  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9916987419128418
pure train time :  0.4433290958404541
train time :  0.6022870540618896
end to end time :  4.048793315887451
connection check time:  1.7344701290130615
block generation time  0.9412450790405273
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005037784576416016
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015769481658935547
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6156442165374756
len local_batched_seeds_list  2
partition total batch output list spend :  0.6592907905578613
self.buckets_partition() spend  sec:  0.6314489841461182
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04097628593444824

in edges time spent  0.14580869674682617
local to global src and eids time spent  0.2602062225341797
time gen tails  0.05297374725341797
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09106278419494629

in edges time spent  0.34926605224609375
local to global src and eids time spent  0.5394604206085205
time gen tails  0.08086490631103516
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10968255996704102  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000604152679443  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000138282775879  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11450338363647461  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788367748260498  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.794087409973145  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12420368194580078  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9931526184082031
pure train time :  0.4476890563964844
train time :  0.6160681247711182
end to end time :  4.042730093002319
connection check time:  1.803433895111084
block generation time  0.9464006423950195
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005109310150146484
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014313936233520508
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6387081146240234
len local_batched_seeds_list  2
partition total batch output list spend :  0.7222862243652344
self.buckets_partition() spend  sec:  0.6530585289001465
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04290270805358887

in edges time spent  0.14430975914001465
local to global src and eids time spent  0.2606804370880127
time gen tails  0.053134918212890625
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09049105644226074

in edges time spent  0.33753442764282227
local to global src and eids time spent  0.5375573635101318
time gen tails  0.08093595504760742
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1098628044128418  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.005687236785889  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.005053520202637  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11392450332641602  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.77942943572998  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785149097442627  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12369585037231445  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9923383593559265
pure train time :  0.43617820739746094
train time :  0.5942575931549072
end to end time :  4.070035457611084
connection check time:  1.7980930805206299
block generation time  0.9429762363433838
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005156993865966797
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014207601547241211
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6491520404815674
len local_batched_seeds_list  2
partition total batch output list spend :  0.7318284511566162
self.buckets_partition() spend  sec:  0.6633951663970947
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04267764091491699

in edges time spent  0.1429123878479004
local to global src and eids time spent  0.26036667823791504
time gen tails  0.05274510383605957
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09078836441040039

in edges time spent  0.33694934844970703
local to global src and eids time spent  0.5600707530975342
time gen tails  0.08108878135681152
res  length 2
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11025238037109375  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00080156326294  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.99977445602417  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11292457580566406  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.77665090560913  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.782370567321777  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12425756454467773  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9908015727996826
pure train time :  0.43793630599975586
train time :  0.6130800247192383
end to end time :  4.128040313720703
connection check time:  1.82271409034729
block generation time  0.9437062740325928
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005319118499755859
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014439821243286133
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.668816328048706
len local_batched_seeds_list  2
partition total batch output list spend :  0.7537927627563477
self.buckets_partition() spend  sec:  0.6832993030548096
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04363584518432617

in edges time spent  0.14360618591308594
local to global src and eids time spent  0.260817289352417
time gen tails  0.05308198928833008
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0903017520904541

in edges time spent  0.34806203842163086
local to global src and eids time spent  0.49282145500183105
time gen tails  0.0587763786315918
res  length 2
block collection to dataloader spend  1.430511474609375e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1101675033569336  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042211532592773  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041410446166992  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11418628692626953  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788809776306152  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.794529438018799  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12416839599609375  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9913980960845947
pure train time :  0.4440927505493164
train time :  0.6021544933319092
end to end time :  4.058612585067749
connection check time:  1.7400715351104736
block generation time  0.946526050567627
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005090236663818359
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015894174575805664
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5562882423400879
len local_batched_seeds_list  2
partition total batch output list spend :  0.6005947589874268
self.buckets_partition() spend  sec:  0.5722174644470215
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.02741694450378418

in edges time spent  0.07892704010009766
local to global src and eids time spent  0.11026978492736816
time gen tails  0.03266119956970215
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.059411048889160156

in edges time spent  0.32986879348754883
local to global src and eids time spent  0.4988422393798828
time gen tails  0.05983734130859375
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11043930053710938  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039443016052246  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038647651672363  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1141500473022461  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.778865814208984  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78458547592163  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12419509887695312  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9890992641448975
pure train time :  0.44580769538879395
train time :  0.6089718341827393
end to end time :  3.481902599334717
connection check time:  1.3884856700897217
block generation time  0.8708555698394775
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005190372467041016
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015974760055541992
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6152987480163574
len local_batched_seeds_list  2
partition total batch output list spend :  0.6604509353637695
self.buckets_partition() spend  sec:  0.6313083171844482
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04046750068664551

in edges time spent  0.1444106101989746
local to global src and eids time spent  0.2613511085510254
time gen tails  0.05284571647644043
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0909879207611084

in edges time spent  0.3599128723144531
local to global src and eids time spent  0.5443611145019531
time gen tails  0.08180356025695801
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11051416397094727  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002979278564453  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002105236053467  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11333942413330078  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793623924255371  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.799343585968018  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12473344802856445  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9915011525154114
pure train time :  0.43710994720458984
train time :  0.5968923568725586
end to end time :  4.036601543426514
connection check time:  1.8204758167266846
block generation time  0.9467754364013672
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005145072937011719
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014428138732910156
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6290092468261719
len local_batched_seeds_list  2
partition total batch output list spend :  0.7132117748260498
self.buckets_partition() spend  sec:  0.6434729099273682
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04292869567871094

in edges time spent  0.14377355575561523
local to global src and eids time spent  0.26059508323669434
time gen tails  0.05337333679199219
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09073853492736816

in edges time spent  0.34859466552734375
local to global src and eids time spent  0.5356063842773438
time gen tails  0.08116269111633301
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11112117767333984  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00273609161377  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001803398132324  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1147923469543457  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786356925964355  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792076587677002  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12436532974243164  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.98737633228302
pure train time :  0.44373250007629395
train time :  0.6045668125152588
end to end time :  4.086999416351318
connection check time:  1.8052668571472168
block generation time  0.9479224681854248
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000518798828125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01449131965637207
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.633638858795166
len local_batched_seeds_list  2
partition total batch output list spend :  0.717177152633667
self.buckets_partition() spend  sec:  0.64817214012146
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042864084243774414

in edges time spent  0.1442852020263672
local to global src and eids time spent  0.2609434127807617
time gen tails  0.05263662338256836
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0910801887512207

in edges time spent  0.35332393646240234
local to global src and eids time spent  0.5398519039154053
time gen tails  0.08064985275268555
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10972261428833008  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038023471832275  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037527084350586  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11400985717773438  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.799130916595459  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.804850578308105  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12476587295532227  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9910235404968262
pure train time :  0.446002721786499
train time :  0.605402946472168
end to end time :  4.096901178359985
connection check time:  1.8142435550689697
block generation time  0.9474608898162842
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00048661231994628906
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014419317245483398
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6354601383209229
len local_batched_seeds_list  2
partition total batch output list spend :  0.7193324565887451
self.buckets_partition() spend  sec:  0.6499147415161133
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04247260093688965

in edges time spent  0.14498662948608398
local to global src and eids time spent  0.26029396057128906
time gen tails  0.05281567573547363
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09042024612426758

in edges time spent  0.3463928699493408
local to global src and eids time spent  0.5417561531066895
time gen tails  0.08167552947998047
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1113734245300293  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04499101638794  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044154167175293  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11493349075317383  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.7880859375  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793805599212646  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1256561279296875  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9906629323959351
pure train time :  0.44818902015686035
train time :  0.6123976707458496
end to end time :  4.1170690059661865
connection check time:  1.8128471374511719
block generation time  0.9529292583465576
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005054473876953125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01524496078491211
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6414031982421875
len local_batched_seeds_list  2
partition total batch output list spend :  0.7260417938232422
self.buckets_partition() spend  sec:  0.6566853523254395
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042786598205566406

in edges time spent  0.15697288513183594
local to global src and eids time spent  0.262148380279541
time gen tails  0.054781436920166016
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09108328819274902

in edges time spent  0.36063385009765625
local to global src and eids time spent  0.5582475662231445
time gen tails  0.0829613208770752
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10988855361938477  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000368595123291  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000569343566895  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1144704818725586  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784181594848633  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78990125656128  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12475872039794922  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9903981685638428
pure train time :  0.4450216293334961
train time :  0.6064045429229736
end to end time :  4.16164493560791
connection check time:  1.8604979515075684
block generation time  0.9470024108886719
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000518798828125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014941930770874023
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6414859294891357
len local_batched_seeds_list  2
partition total batch output list spend :  0.7248568534851074
self.buckets_partition() spend  sec:  0.6564645767211914
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04229283332824707

in edges time spent  0.1593320369720459
local to global src and eids time spent  0.2677755355834961
time gen tails  0.05321931838989258
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09017276763916016

in edges time spent  0.36661195755004883
local to global src and eids time spent  0.5556755065917969
time gen tails  0.08186864852905273
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11018037796020508  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039464950561523  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038800716400146  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11465835571289062  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788068294525146  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793787956237793  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12507247924804688  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9897971749305725
pure train time :  0.43697690963745117
train time :  0.5974540710449219
end to end time :  4.158243894577026
connection check time:  1.86808443069458
block generation time  0.9487242698669434
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005154609680175781
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014499187469482422
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6466917991638184
len local_batched_seeds_list  2
partition total batch output list spend :  0.7314720153808594
self.buckets_partition() spend  sec:  0.6612260341644287
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0430750846862793

in edges time spent  0.14444184303283691
local to global src and eids time spent  0.2592737674713135
time gen tails  0.05331230163574219
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0905466079711914

in edges time spent  0.35181164741516113
local to global src and eids time spent  0.49068641662597656
time gen tails  0.05819535255432129
res  length 2
block collection to dataloader spend  6.67572021484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11029291152954102  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04193115234375  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042014598846436  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11452436447143555  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781746864318848  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787466526031494  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12478876113891602  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9896200299263
pure train time :  0.4402790069580078
train time :  0.5988583564758301
end to end time :  4.024726152420044
connection check time:  1.7417709827423096
block generation time  0.9402790069580078
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00046515464782714844
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015338420867919922
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.526444673538208
len local_batched_seeds_list  2
partition total batch output list spend :  0.5712499618530273
self.buckets_partition() spend  sec:  0.5418250560760498
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0405735969543457

in edges time spent  0.1440262794494629
local to global src and eids time spent  0.27539920806884766
time gen tails  0.05261659622192383
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09175443649291992

in edges time spent  0.3385193347930908
local to global src and eids time spent  0.5375795364379883
time gen tails  0.08096647262573242
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11014175415039062  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04154348373413  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040910243988037  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11336231231689453  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.797289371490479  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.803009033203125  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12394142150878906  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9886202812194824
pure train time :  0.43954896926879883
train time :  0.5973351001739502
end to end time :  3.9306390285491943
connection check time:  1.8051934242248535
block generation time  0.9406423568725586
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005097389221191406
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01521611213684082
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6012468338012695
len local_batched_seeds_list  2
partition total batch output list spend :  0.6454615592956543
self.buckets_partition() spend  sec:  0.6164960861206055
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04062485694885254

in edges time spent  0.145371675491333
local to global src and eids time spent  0.2596762180328369
time gen tails  0.05277276039123535
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09041666984558105

in edges time spent  0.33032894134521484
local to global src and eids time spent  0.5167727470397949
time gen tails  0.05847620964050293
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1101675033569336  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004872798919678  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003932476043701  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11315679550170898  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786670207977295  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792389869689941  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12371587753295898  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9872039556503296
pure train time :  0.4365420341491699
train time :  0.6033914089202881
end to end time :  3.946615695953369
connection check time:  1.745506763458252
block generation time  0.9370756149291992
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005009174346923828
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015330314636230469
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6100740432739258
len local_batched_seeds_list  2
partition total batch output list spend :  0.6542689800262451
self.buckets_partition() spend  sec:  0.6254408359527588
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04080080986022949

in edges time spent  0.13733625411987305
local to global src and eids time spent  0.25911426544189453
time gen tails  0.05290365219116211
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0905599594116211

in edges time spent  0.3381340503692627
local to global src and eids time spent  0.5309875011444092
time gen tails  0.07995033264160156
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11016511917114258  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044329643249512  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043403148651123  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11375570297241211  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780768871307373  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78648853302002  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12381792068481445  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9872899651527405
pure train time :  0.4306933879852295
train time :  0.5900037288665771
end to end time :  3.9883782863616943
connection check time:  1.7785205841064453
block generation time  0.9433140754699707
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005085468292236328
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01454782485961914
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.656825065612793
len local_batched_seeds_list  2
partition total batch output list spend :  0.7398409843444824
self.buckets_partition() spend  sec:  0.6714098453521729
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0433497428894043

in edges time spent  0.14326143264770508
local to global src and eids time spent  0.26444482803344727
time gen tails  0.05302238464355469
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09143781661987305

in edges time spent  0.3568103313446045
local to global src and eids time spent  0.551802396774292
time gen tails  0.08109045028686523
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1102595329284668  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001765727996826  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00101089477539  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11532449722290039  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787968635559082  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793688297271729  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1251978874206543  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.987561821937561
pure train time :  0.4343874454498291
train time :  0.6012334823608398
end to end time :  4.14377236366272
connection check time:  1.8345468044281006
block generation time  0.9552500247955322
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004949569702148438
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01434636116027832
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.645500659942627
len local_batched_seeds_list  2
partition total batch output list spend :  0.7306406497955322
self.buckets_partition() spend  sec:  0.6598801612854004
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04290962219238281

in edges time spent  0.14362740516662598
local to global src and eids time spent  0.25885486602783203
time gen tails  0.05225062370300293
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08967828750610352

in edges time spent  0.34941697120666504
local to global src and eids time spent  0.5013120174407959
time gen tails  0.05902719497680664
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11135721206665039  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.035223484039307  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.033537864685059  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11387777328491211  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791048049926758  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796767711639404  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12512922286987305  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9850537776947021
pure train time :  0.4364786148071289
train time :  0.593557596206665
end to end time :  4.020427942276001
connection check time:  1.7447175979614258
block generation time  0.9383325576782227
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005490779876708984
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015579462051391602
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6100687980651855
len local_batched_seeds_list  2
partition total batch output list spend :  0.6541047096252441
self.buckets_partition() spend  sec:  0.6256794929504395
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04098343849182129

in edges time spent  0.15616440773010254
local to global src and eids time spent  0.2599046230316162
time gen tails  0.053020477294921875
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09009885787963867

in edges time spent  0.35309410095214844
local to global src and eids time spent  0.5379278659820557
time gen tails  0.08048653602600098
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1101837158203125  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.006118774414062  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00516128540039  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11402368545532227  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786681652069092  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792401313781738  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1238398551940918  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9856649041175842
pure train time :  0.4342803955078125
train time :  0.5973865985870361
end to end time :  4.017611265182495
connection check time:  1.814866304397583
block generation time  0.939197301864624
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005195140838623047
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.019335031509399414
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6560871601104736
len local_batched_seeds_list  2
partition total batch output list spend :  0.7454910278320312
self.buckets_partition() spend  sec:  0.6755392551422119
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.044649600982666016

in edges time spent  0.1913471221923828
local to global src and eids time spent  0.26911115646362305
time gen tails  0.05586075782775879
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0910954475402832

in edges time spent  0.3890986442565918
local to global src and eids time spent  0.5527935028076172
time gen tails  0.08168888092041016
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11027717590332031  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.045628547668457  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04459285736084  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11362028121948242  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.767300605773926  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.773020267486572  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1233067512512207  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9849713444709778
pure train time :  0.44034814834594727
train time :  0.5999529361724854
end to end time :  4.2453248500823975
connection check time:  1.9303960800170898
block generation time  0.9566123485565186
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.003128528594970703
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014709711074829102
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6493949890136719
len local_batched_seeds_list  2
partition total batch output list spend :  0.7339661121368408
self.buckets_partition() spend  sec:  0.6641390323638916
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.044660329818725586

in edges time spent  0.14780092239379883
local to global src and eids time spent  0.26093554496765137
time gen tails  0.052655696868896484
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0928049087524414

in edges time spent  0.3636047840118408
local to global src and eids time spent  0.5580432415008545
time gen tails  0.08150076866149902
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10984420776367188  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.006383895874023  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.005765914916992  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11397504806518555  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.780222415924072  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785942077636719  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12487363815307617  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9836058616638184
pure train time :  0.4362215995788574
train time :  0.5957415103912354
end to end time :  4.137971639633179
connection check time:  1.852611780166626
block generation time  0.9428544044494629
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00048279762268066406
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013800621032714844
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6462101936340332
len local_batched_seeds_list  2
partition total batch output list spend :  0.7326915264129639
self.buckets_partition() spend  sec:  0.6600453853607178
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042603254318237305

in edges time spent  0.1492621898651123
local to global src and eids time spent  0.2618286609649658
time gen tails  0.05304694175720215
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0900874137878418

in edges time spent  0.360809326171875
local to global src and eids time spent  0.5489199161529541
time gen tails  0.08037805557250977
res  length 2
block collection to dataloader spend  1.0967254638671875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11152267456054688  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003735065460205  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002156734466553  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11522150039672852  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79575777053833  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.801477432250977  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12487936019897461  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9864538908004761
pure train time :  0.43289947509765625
train time :  0.5997869968414307
end to end time :  4.150872230529785
connection check time:  1.8358359336853027
block generation time  0.9467108249664307
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005176067352294922
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014442920684814453
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5447156429290771
len local_batched_seeds_list  2
partition total batch output list spend :  0.6291203498840332
self.buckets_partition() spend  sec:  0.5592057704925537
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04285383224487305

in edges time spent  0.14307260513305664
local to global src and eids time spent  0.2607908248901367
time gen tails  0.05337214469909668
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09067344665527344

in edges time spent  0.3417794704437256
local to global src and eids time spent  0.5592772960662842
time gen tails  0.08143234252929688
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1112661361694336  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044862270355225  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044145107269287  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11481475830078125  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.76180124282837  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.767520904541016  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12468194961547852  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9829462766647339
pure train time :  0.44281697273254395
train time :  0.6061174869537354
end to end time :  4.02208948135376
connection check time:  1.8210561275482178
block generation time  0.9504501819610596
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005655288696289062
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014166116714477539
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6618125438690186
len local_batched_seeds_list  2
partition total batch output list spend :  0.7456164360046387
self.buckets_partition() spend  sec:  0.6760120391845703
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04255867004394531

in edges time spent  0.14287900924682617
local to global src and eids time spent  0.26030755043029785
time gen tails  0.05272960662841797
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09005498886108398

in edges time spent  0.35817813873291016
local to global src and eids time spent  0.5344393253326416
time gen tails  0.0800788402557373
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1100320816040039  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038381576538086  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038440704345703  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11424684524536133  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786618709564209  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792338371276855  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12435102462768555  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9832296967506409
pure train time :  0.4417152404785156
train time :  0.6039621829986572
end to end time :  4.119117021560669
connection check time:  1.8089311122894287
block generation time  0.9439892768859863
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005846023559570312
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014267921447753906
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6347343921661377
len local_batched_seeds_list  2
partition total batch output list spend :  0.7180004119873047
self.buckets_partition() spend  sec:  0.6490366458892822
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04296612739562988

in edges time spent  0.14445090293884277
local to global src and eids time spent  0.2576131820678711
time gen tails  0.052490234375
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0983576774597168

in edges time spent  0.3789253234863281
local to global src and eids time spent  0.5518412590026855
time gen tails  0.08697628974914551
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10998201370239258  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000074863433838  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.0001802444458  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11439323425292969  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784894466400146  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790614128112793  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12434196472167969  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9842327237129211
pure train time :  0.4431314468383789
train time :  0.6103870868682861
end to end time :  4.160224914550781
connection check time:  1.864199161529541
block generation time  0.9529292583465576
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005109310150146484
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01423192024230957
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6364250183105469
len local_batched_seeds_list  2
partition total batch output list spend :  0.720482349395752
self.buckets_partition() spend  sec:  0.6506941318511963
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04637265205383301

in edges time spent  0.16120266914367676
local to global src and eids time spent  0.267244815826416
time gen tails  0.05370306968688965
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09073066711425781

in edges time spent  0.37598299980163574
local to global src and eids time spent  0.5554931163787842
time gen tails  0.08060741424560547
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10981988906860352  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997896671295166  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.99729061126709  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1142277717590332  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792971134185791  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.798690795898438  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12393808364868164  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9843871593475342
pure train time :  0.4354665279388428
train time :  0.5969028472900391
end to end time :  4.17724871635437
connection check time:  1.8817474842071533
block generation time  0.9540977478027344
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005326271057128906
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01412820816040039
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6366837024688721
len local_batched_seeds_list  2
partition total batch output list spend :  0.7431986331939697
self.buckets_partition() spend  sec:  0.6508462429046631
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04345703125

in edges time spent  0.14506292343139648
local to global src and eids time spent  0.26676154136657715
time gen tails  0.05224871635437012
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09144425392150879

in edges time spent  0.35966968536376953
local to global src and eids time spent  0.5163650512695312
time gen tails  0.059027671813964844
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1111140251159668  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04442834854126  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043505191802979  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11466217041015625  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.778552532196045  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784272193908691  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12447929382324219  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.984302818775177
pure train time :  0.43373990058898926
train time :  0.6017625331878662
end to end time :  4.109853506088257
connection check time:  1.8067364692687988
block generation time  0.9371755123138428
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000545501708984375
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015244722366333008
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6366028785705566
len local_batched_seeds_list  2
partition total batch output list spend :  0.6799461841583252
self.buckets_partition() spend  sec:  0.6518864631652832
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.040596723556518555

in edges time spent  0.13746142387390137
local to global src and eids time spent  0.2597033977508545
time gen tails  0.05281972885131836
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09000611305236816

in edges time spent  0.3460099697113037
local to global src and eids time spent  0.5367989540100098
time gen tails  0.08034539222717285
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11002445220947266  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04158639907837  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04079294204712  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11339902877807617  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781509399414062  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787229061126709  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12388849258422852  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9835042953491211
pure train time :  0.4428136348724365
train time :  0.6074256896972656
end to end time :  4.0365893840789795
connection check time:  1.7868618965148926
block generation time  0.9416396617889404
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005369186401367188
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014018535614013672
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6520521640777588
len local_batched_seeds_list  2
partition total batch output list spend :  0.7344498634338379
self.buckets_partition() spend  sec:  0.6661033630371094
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04293942451477051

in edges time spent  0.14611291885375977
local to global src and eids time spent  0.25951290130615234
time gen tails  0.052670955657958984
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09178709983825684

in edges time spent  0.3523402214050293
local to global src and eids time spent  0.5379831790924072
time gen tails  0.08044290542602539
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11106395721435547  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04252576828003  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041651725769043  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11495590209960938  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791228771209717  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796948432922363  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12471628189086914  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.984656572341919
pure train time :  0.4425621032714844
train time :  0.6079347133636475
end to end time :  4.121741056442261
connection check time:  1.8132948875427246
block generation time  0.9531421661376953
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004851818084716797
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01420140266418457
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6483809947967529
len local_batched_seeds_list  2
partition total batch output list spend :  0.7322337627410889
self.buckets_partition() spend  sec:  0.6626152992248535
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04317736625671387

in edges time spent  0.1450345516204834
local to global src and eids time spent  0.2598001956939697
time gen tails  0.05319070816040039
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09169721603393555

in edges time spent  0.34274983406066895
local to global src and eids time spent  0.5366015434265137
time gen tails  0.08046579360961914
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11052751541137695  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.995895862579346  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.995222091674805  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11355018615722656  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786195755004883  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79191541671753  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12411928176879883  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9809613823890686
pure train time :  0.4418604373931885
train time :  0.6086742877960205
end to end time :  4.110125780105591
connection check time:  1.8072755336761475
block generation time  0.9429101943969727
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005197525024414062
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013918161392211914
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6408846378326416
len local_batched_seeds_list  2
partition total batch output list spend :  0.7246191501617432
self.buckets_partition() spend  sec:  0.6548378467559814
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04233980178833008

in edges time spent  0.1442570686340332
local to global src and eids time spent  0.26955270767211914
time gen tails  0.05632185935974121
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09180545806884766

in edges time spent  0.36402106285095215
local to global src and eids time spent  0.5342874526977539
time gen tails  0.06324315071105957
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10990047454833984  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003688335418701  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00301218032837  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11440134048461914  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78629732131958  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792016983032227  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12436819076538086  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9816034436225891
pure train time :  0.4422760009765625
train time :  0.613910436630249
end to end time :  4.130794286727905
connection check time:  1.823678731918335
block generation time  0.9554824829101562
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0006399154663085938
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015942811965942383
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5286705493927002
len local_batched_seeds_list  2
partition total batch output list spend :  0.5738959312438965
self.buckets_partition() spend  sec:  0.5446462631225586
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04129624366760254

in edges time spent  0.14232897758483887
local to global src and eids time spent  0.22089147567749023
time gen tails  0.04085707664489746
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09250617027282715

in edges time spent  0.3393247127532959
local to global src and eids time spent  0.4939303398132324
time gen tails  0.0590059757232666
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11011838912963867  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04177474975586  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041170597076416  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11323404312133789  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.764250755310059  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.769970417022705  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12367963790893555  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.981844425201416
pure train time :  0.43545103073120117
train time :  0.5949599742889404
end to end time :  3.8098297119140625
connection check time:  1.6741623878479004
block generation time  0.948570728302002
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005190372467041016
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015563011169433594
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.609952449798584
len local_batched_seeds_list  2
partition total batch output list spend :  0.6540493965148926
self.buckets_partition() spend  sec:  0.6255500316619873
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04096651077270508

in edges time spent  0.13175320625305176
local to global src and eids time spent  0.2118985652923584
time gen tails  0.040340423583984375
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08954334259033203

in edges time spent  0.33322596549987793
local to global src and eids time spent  0.49493885040283203
time gen tails  0.05933356285095215
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11003923416137695  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002057552337646  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001239776611328  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11458778381347656  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79169750213623  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.797417163848877  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12447071075439453  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9810163974761963
pure train time :  0.44112300872802734
train time :  0.6018247604370117
end to end time :  3.8583221435546875
connection check time:  1.6453800201416016
block generation time  0.9430952072143555
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004985332489013672
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015344858169555664
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6092615127563477
len local_batched_seeds_list  2
partition total batch output list spend :  0.652519941329956
self.buckets_partition() spend  sec:  0.6246380805969238
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04046368598937988

in edges time spent  0.11301517486572266
local to global src and eids time spent  0.11002516746520996
time gen tails  0.03260922431945801
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.05879092216491699

in edges time spent  0.19845867156982422
local to global src and eids time spent  0.23413443565368652
time gen tails  0.04841327667236328
res  length 2
block collection to dataloader spend  5.4836273193359375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10976982116699219  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.038927555084229  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.039247989654541  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1145009994506836  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.760744571685791  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.766464233398438  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12450885772705078  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9804373383522034
pure train time :  0.42774105072021484
train time :  0.5918347835540771
end to end time :  2.88875675201416
connection check time:  0.946108341217041
block generation time  0.6872265338897705
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004527568817138672
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01349186897277832
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.24469590187072754
len local_batched_seeds_list  2
partition total batch output list spend :  0.2799088954925537
self.buckets_partition() spend  sec:  0.25821471214294434
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.023533344268798828

in edges time spent  0.07853937149047852
local to global src and eids time spent  0.10970282554626465
time gen tails  0.05115652084350586
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09097146987915039

in edges time spent  0.3442423343658447
local to global src and eids time spent  0.5353877544403076
time gen tails  0.08249425888061523
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11016702651977539  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043351173400879  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042694568634033  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1132345199584961  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785792827606201  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791512489318848  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12460851669311523  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9831937551498413
pure train time :  0.4393131732940674
train time :  0.5987682342529297
end to end time :  3.3869199752807617
connection check time:  1.5582869052886963
block generation time  0.9406642913818359
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005640983581542969
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014259576797485352
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6357090473175049
len local_batched_seeds_list  2
partition total batch output list spend :  0.7191867828369141
self.buckets_partition() spend  sec:  0.6500084400177002
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0428769588470459

in edges time spent  0.14454221725463867
local to global src and eids time spent  0.26314210891723633
time gen tails  0.05305218696594238
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09353351593017578

in edges time spent  0.3508725166320801
local to global src and eids time spent  0.5557875633239746
time gen tails  0.0825803279876709
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11122512817382812  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042105674743652  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.0419340133667  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11473846435546875  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.783119678497314  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788839340209961  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12473487854003906  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9800062775611877
pure train time :  0.44031596183776855
train time :  0.6093385219573975
end to end time :  4.121638298034668
connection check time:  1.8354406356811523
block generation time  0.9446926116943359
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000507354736328125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014165639877319336
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6411182880401611
len local_batched_seeds_list  2
partition total batch output list spend :  0.72532057762146
self.buckets_partition() spend  sec:  0.6553256511688232
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.045813798904418945

in edges time spent  0.14288783073425293
local to global src and eids time spent  0.25941944122314453
time gen tails  0.053183555603027344
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09043359756469727

in edges time spent  0.3388230800628662
local to global src and eids time spent  0.5329146385192871
time gen tails  0.08064603805541992
res  length 2
block collection to dataloader spend  2.5272369384765625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11077880859375  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997979640960693  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997334003448486  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1144266128540039  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784244537353516  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789964199066162  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12451648712158203  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9801754951477051
pure train time :  0.4424724578857422
train time :  0.6045322418212891
end to end time :  4.092284202575684
connection check time:  1.7995660305023193
block generation time  0.944305419921875
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004992485046386719
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014641761779785156
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.700761079788208
len local_batched_seeds_list  2
partition total batch output list spend :  0.7857024669647217
self.buckets_partition() spend  sec:  0.7154428958892822
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042952775955200195

in edges time spent  0.14408373832702637
local to global src and eids time spent  0.26045846939086914
time gen tails  0.05259227752685547
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09064674377441406

in edges time spent  0.3394598960876465
local to global src and eids time spent  0.5382828712463379
time gen tails  0.0812532901763916
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11027765274047852  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999637603759766  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998862743377686  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11320781707763672  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786030292510986  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791749954223633  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12376642227172852  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9823576211929321
pure train time :  0.4399750232696533
train time :  0.6015424728393555
end to end time :  4.155678749084473
connection check time:  1.797922134399414
block generation time  0.9572408199310303
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004937648773193359
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013910531997680664
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6530029773712158
len local_batched_seeds_list  2
partition total batch output list spend :  0.7363541126251221
self.buckets_partition() spend  sec:  0.6669495105743408
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04280424118041992

in edges time spent  0.14345955848693848
local to global src and eids time spent  0.2611217498779297
time gen tails  0.05315065383911133
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08995175361633301

in edges time spent  0.3423776626586914
local to global src and eids time spent  0.5329985618591309
time gen tails  0.08077263832092285
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11003732681274414  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042701244354248  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041895866394043  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1129751205444336  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.782158851623535  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787878513336182  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12372159957885742  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9762604832649231
pure train time :  0.4420440196990967
train time :  0.6056544780731201
end to end time :  4.090449094772339
connection check time:  1.7950797080993652
block generation time  0.9408719539642334
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004930496215820312
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01415109634399414
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6484768390655518
len local_batched_seeds_list  2
partition total batch output list spend :  0.7324924468994141
self.buckets_partition() spend  sec:  0.6626625061035156
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04299616813659668

in edges time spent  0.14550566673278809
local to global src and eids time spent  0.2625448703765869
time gen tails  0.05349016189575195
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09007692337036133

in edges time spent  0.35487985610961914
local to global src and eids time spent  0.502683162689209
time gen tails  0.05896472930908203
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11022329330444336  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037172794342041  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.03646183013916  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1129598617553711  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784209728240967  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789929389953613  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12349224090576172  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.978661298751831
pure train time :  0.42825984954833984
train time :  0.5852072238922119
end to end time :  4.040207624435425
connection check time:  1.7608404159545898
block generation time  0.9489891529083252
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005528926849365234
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015506982803344727
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5379133224487305
len local_batched_seeds_list  2
partition total batch output list spend :  0.5832102298736572
self.buckets_partition() spend  sec:  0.5534555912017822
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04415750503540039

in edges time spent  0.1502363681793213
local to global src and eids time spent  0.26076626777648926
time gen tails  0.053496360778808594
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09323358535766602

in edges time spent  0.35858154296875
local to global src and eids time spent  0.554785966873169
time gen tails  0.08365750312805176
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10999536514282227  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.993800163269043  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.993019580841064  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1140127182006836  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.797054767608643  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.802774429321289  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12374496459960938  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9774520993232727
pure train time :  0.4457573890686035
train time :  0.6173303127288818
end to end time :  4.005197286605835
connection check time:  1.8292794227600098
block generation time  0.9627320766448975
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005121231079101562
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0141754150390625
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6301169395446777
len local_batched_seeds_list  2
partition total batch output list spend :  0.7143621444702148
self.buckets_partition() spend  sec:  0.6444060802459717
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.044501543045043945

in edges time spent  0.14997649192810059
local to global src and eids time spent  0.2705066204071045
time gen tails  0.053403615951538086
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09369611740112305

in edges time spent  0.36685872077941895
local to global src and eids time spent  0.5569784641265869
time gen tails  0.0832662582397461
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10991859436035156  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.996889114379883  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.996192932128906  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11330986022949219  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78006887435913  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785788536071777  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12491369247436523  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9781398177146912
pure train time :  0.44033265113830566
train time :  0.6015200614929199
end to end time :  4.168797254562378
connection check time:  1.8770368099212646
block generation time  0.9627580642700195
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004994869232177734
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014239788055419922
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6305739879608154
len local_batched_seeds_list  2
partition total batch output list spend :  0.7147376537322998
self.buckets_partition() spend  sec:  0.6448459625244141
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04324078559875488

in edges time spent  0.14604997634887695
local to global src and eids time spent  0.2648346424102783
time gen tails  0.052834510803222656
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09221339225769043

in edges time spent  0.3485569953918457
local to global src and eids time spent  0.5367386341094971
time gen tails  0.08144092559814453
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11053085327148438  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037358283996582  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.036065101623535  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11347436904907227  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.767717361450195  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.773437023162842  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1229395866394043  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9782043695449829
pure train time :  0.44345998764038086
train time :  0.604534387588501
end to end time :  4.098473072052002
connection check time:  1.814016342163086
block generation time  0.9523289203643799
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005261898040771484
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014260292053222656
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6730802059173584
len local_batched_seeds_list  2
partition total batch output list spend :  0.7583134174346924
self.buckets_partition() spend  sec:  0.6873741149902344
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04460906982421875

in edges time spent  0.14978909492492676
local to global src and eids time spent  0.2704348564147949
time gen tails  0.0541224479675293
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09296345710754395

in edges time spent  0.3559715747833252
local to global src and eids time spent  0.5397911071777344
time gen tails  0.08136510848999023
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1096792221069336  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041737079620361  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041293621063232  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11467742919921875  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.778829574584961  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784549236297607  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12459945678710938  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9777950644493103
pure train time :  0.43753790855407715
train time :  0.5973184108734131
end to end time :  4.172050952911377
connection check time:  1.8447821140289307
block generation time  0.9499905109405518
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005109310150146484
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014204740524291992
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6371736526489258
len local_batched_seeds_list  2
partition total batch output list spend :  0.7212235927581787
self.buckets_partition() spend  sec:  0.6514124870300293
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04283499717712402

in edges time spent  0.14323949813842773
local to global src and eids time spent  0.2653341293334961
time gen tails  0.06700682640075684
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09102368354797363

in edges time spent  0.344834566116333
local to global src and eids time spent  0.5052704811096191
time gen tails  0.05891609191894531
res  length 2
block collection to dataloader spend  1.0967254638671875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11023807525634766  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.045740127563477  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.045022010803223  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1143045425415039  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.765608787536621  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.771328449249268  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12420368194580078  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9753202199935913
pure train time :  0.44059109687805176
train time :  0.6080148220062256
end to end time :  4.063501358032227
connection check time:  1.7670700550079346
block generation time  0.9491956233978271
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005185604095458984
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015448331832885742
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6162328720092773
len local_batched_seeds_list  2
partition total batch output list spend :  0.6609046459197998
self.buckets_partition() spend  sec:  0.6317203044891357
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04066038131713867

in edges time spent  0.13690710067749023
local to global src and eids time spent  0.2600729465484619
time gen tails  0.05281805992126465
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09061717987060547

in edges time spent  0.34178781509399414
local to global src and eids time spent  0.540135383605957
time gen tails  0.08007097244262695
res  length 2
block collection to dataloader spend  1.33514404296875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10978174209594727  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00005578994751  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000377655029297  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11454105377197266  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784603118896484  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79032278060913  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12445449829101562  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9775117635726929
pure train time :  0.4330434799194336
train time :  0.5933544635772705
end to end time :  4.000502109527588
connection check time:  1.7870879173278809
block generation time  0.9463257789611816
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005347728729248047
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014052629470825195
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6692445278167725
len local_batched_seeds_list  2
partition total batch output list spend :  0.751544713973999
self.buckets_partition() spend  sec:  0.6833353042602539
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04262804985046387

in edges time spent  0.14359807968139648
local to global src and eids time spent  0.2603883743286133
time gen tails  0.05322408676147461
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09018373489379883

in edges time spent  0.34363532066345215
local to global src and eids time spent  0.5387632846832275
time gen tails  0.08197283744812012
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10981321334838867  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999622344970703  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999912738800049  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11459589004516602  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787673950195312  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793393611907959  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12461996078491211  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9767035245895386
pure train time :  0.43407702445983887
train time :  0.5925476551055908
end to end time :  4.121673107147217
connection check time:  1.804004192352295
block generation time  0.9583215713500977
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005333423614501953
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014086723327636719
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6439661979675293
len local_batched_seeds_list  2
partition total batch output list spend :  0.7260301113128662
self.buckets_partition() spend  sec:  0.658085823059082
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042938947677612305

in edges time spent  0.14358758926391602
local to global src and eids time spent  0.25842928886413574
time gen tails  0.052971601486206055
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0912010669708252

in edges time spent  0.3425586223602295
local to global src and eids time spent  0.541179895401001
time gen tails  0.08082008361816406
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10992670059204102  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040204048156738  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040380954742432  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1141366958618164  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787301063537598  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793020725250244  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1242666244506836  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9741392731666565
pure train time :  0.4384777545928955
train time :  0.5976908206939697
end to end time :  4.094688177108765
connection check time:  1.803218126296997
block generation time  0.9550957679748535
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005314350128173828
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014066696166992188
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6447670459747314
len local_batched_seeds_list  2
partition total batch output list spend :  0.7291414737701416
self.buckets_partition() spend  sec:  0.6589064598083496
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04381895065307617

in edges time spent  0.14520931243896484
local to global src and eids time spent  0.26117897033691406
time gen tails  0.052947282791137695
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09273242950439453

in edges time spent  0.344893217086792
local to global src and eids time spent  0.5377042293548584
time gen tails  0.08017611503601074
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11001920700073242  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999732494354248  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998953819274902  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11355352401733398  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788135051727295  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.793854713439941  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12419366836547852  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9740538597106934
pure train time :  0.441699743270874
train time :  0.600649356842041
end to end time :  4.0954389572143555
connection check time:  1.8081648349761963
block generation time  0.9445950984954834
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005202293395996094
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014360666275024414
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5493273735046387
len local_batched_seeds_list  2
partition total batch output list spend :  0.6339011192321777
self.buckets_partition() spend  sec:  0.5637238025665283
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04305887222290039

in edges time spent  0.14500212669372559
local to global src and eids time spent  0.21244144439697266
time gen tails  0.040508270263671875
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09281277656555176

in edges time spent  0.3412489891052246
local to global src and eids time spent  0.4906432628631592
time gen tails  0.05998373031616211
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11026525497436523  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04501724243164  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.044019222259521  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11366128921508789  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.775739192962646  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781458854675293  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12351274490356445  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9764527082443237
pure train time :  0.4412064552307129
train time :  0.6097514629364014
end to end time :  3.895033121109009
connection check time:  1.6775469779968262
block generation time  0.9608261585235596
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005097389221191406
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015665531158447266
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.602062463760376
len local_batched_seeds_list  2
partition total batch output list spend :  0.6883978843688965
self.buckets_partition() spend  sec:  0.6177623271942139
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04578566551208496

in edges time spent  0.09795379638671875
local to global src and eids time spent  0.11382555961608887
time gen tails  0.034580230712890625
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.05972170829772949

in edges time spent  0.22261691093444824
local to global src and eids time spent  0.44864487648010254
time gen tails  0.08122467994689941
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1100473403930664  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000110626220703  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999279022216797  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11524581909179688  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.794330596923828  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.800050258636475  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1259479522705078  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9758189916610718
pure train time :  0.44265031814575195
train time :  0.6090424060821533
end to end time :  3.496314287185669
connection check time:  1.2996232509613037
block generation time  0.8819820880889893
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005207061767578125
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014256715774536133
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6299302577972412
len local_batched_seeds_list  2
partition total batch output list spend :  0.7135741710662842
self.buckets_partition() spend  sec:  0.6442198753356934
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04253053665161133

in edges time spent  0.15539264678955078
local to global src and eids time spent  0.269054651260376
time gen tails  0.0534214973449707
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09134316444396973

in edges time spent  0.36414098739624023
local to global src and eids time spent  0.5667402744293213
time gen tails  0.08324289321899414
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11141157150268555  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04241418838501  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040968894958496  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11477231979370117  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.784915447235107  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790635108947754  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12546682357788086  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9724131226539612
pure train time :  0.4412245750427246
train time :  0.6010491847991943
end to end time :  4.1635777950286865
connection check time:  1.8814189434051514
block generation time  0.9483349323272705
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004487037658691406
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01777815818786621
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6315531730651855
len local_batched_seeds_list  2
partition total batch output list spend :  0.7185721397399902
self.buckets_partition() spend  sec:  0.6493651866912842
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.042732954025268555

in edges time spent  0.14417672157287598
local to global src and eids time spent  0.2611713409423828
time gen tails  0.05405306816101074
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09134292602539062

in edges time spent  0.362591028213501
local to global src and eids time spent  0.5501196384429932
time gen tails  0.08092999458312988
res  length 2
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10987281799316406  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041542053222656  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.040900230407715  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11319255828857422  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.777705669403076  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.783425331115723  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12392377853393555  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9740924835205078
pure train time :  0.4413318634033203
train time :  0.6120772361755371
end to end time :  4.130810737609863
connection check time:  1.8348071575164795
block generation time  0.9509778022766113
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004889965057373047
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013889551162719727
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6567482948303223
len local_batched_seeds_list  2
partition total batch output list spend :  0.7402257919311523
self.buckets_partition() spend  sec:  0.6707172393798828
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04270529747009277

in edges time spent  0.14281678199768066
local to global src and eids time spent  0.2652289867401123
time gen tails  0.05312824249267578
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09035682678222656

in edges time spent  0.36080265045166016
local to global src and eids time spent  0.5492916107177734
time gen tails  0.0817418098449707
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11130523681640625  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002094745635986  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000974178314209  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11438226699829102  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791090488433838  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796810150146484  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12505531311035156  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9713762998580933
pure train time :  0.440654993057251
train time :  0.6011874675750732
end to end time :  4.1437060832977295
connection check time:  1.834075927734375
block generation time  0.9528651237487793
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005290508270263672
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014322996139526367
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6457393169403076
len local_batched_seeds_list  2
partition total batch output list spend :  0.7294871807098389
self.buckets_partition() spend  sec:  0.6600966453552246
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04369926452636719

in edges time spent  0.14498472213745117
local to global src and eids time spent  0.26009035110473633
time gen tails  0.052958011627197266
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09063267707824707

in edges time spent  0.3484842777252197
local to global src and eids time spent  0.5355062484741211
time gen tails  0.08019018173217773
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11121320724487305  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041814804077148  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04079294204712  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11379766464233398  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781245231628418  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786964893341064  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12441682815551758  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9727002382278442
pure train time :  0.44189453125
train time :  0.6009781360626221
end to end time :  4.10123348236084
connection check time:  1.805088996887207
block generation time  0.9527418613433838
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005035400390625
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014183282852172852
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6418147087097168
len local_batched_seeds_list  2
partition total batch output list spend :  0.7251174449920654
self.buckets_partition() spend  sec:  0.6560425758361816
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04302477836608887

in edges time spent  0.1438593864440918
local to global src and eids time spent  0.25773119926452637
time gen tails  0.052721500396728516
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08987784385681152

in edges time spent  0.34561753273010254
local to global src and eids time spent  0.5332858562469482
time gen tails  0.0798647403717041
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10996627807617188  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041794300079346  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04105806350708  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11390066146850586  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.755936622619629  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.761656284332275  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1235966682434082  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9741576313972473
pure train time :  0.44359421730041504
train time :  0.611276388168335
end to end time :  4.103416919708252
connection check time:  1.793487787246704
block generation time  0.9612059593200684
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00047516822814941406
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014412879943847656
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6490006446838379
len local_batched_seeds_list  2
partition total batch output list spend :  0.7328300476074219
self.buckets_partition() spend  sec:  0.6634511947631836
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043134212493896484

in edges time spent  0.1541123390197754
local to global src and eids time spent  0.2663757801055908
time gen tails  0.05388927459716797
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0906529426574707

in edges time spent  0.36203980445861816
local to global src and eids time spent  0.5452373027801514
time gen tails  0.08373713493347168
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11017847061157227  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998351573944092  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997390747070312  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11319923400878906  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791176795959473  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79689645767212  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12389373779296875  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9742735624313354
pure train time :  0.44205474853515625
train time :  0.6036508083343506
end to end time :  4.164897441864014
connection check time:  1.851515769958496
block generation time  0.9549877643585205
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005421638488769531
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014247417449951172
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5504615306854248
len local_batched_seeds_list  2
partition total batch output list spend :  0.6344146728515625
self.buckets_partition() spend  sec:  0.564751148223877
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043093204498291016

in edges time spent  0.14762639999389648
local to global src and eids time spent  0.26575803756713867
time gen tails  0.053427696228027344
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0911562442779541

in edges time spent  0.3720231056213379
local to global src and eids time spent  0.5611505508422852
time gen tails  0.08121633529663086
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11124515533447266  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999529361724854  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998470783233643  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11497163772583008  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789876937866211  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.795596599578857  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12468767166137695  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9735962152481079
pure train time :  0.4418966770172119
train time :  0.6032674312591553
end to end time :  4.067009449005127
connection check time:  1.8636462688446045
block generation time  0.9480841159820557
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005574226379394531
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014644622802734375
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6241850852966309
len local_batched_seeds_list  2
partition total batch output list spend :  0.7080814838409424
self.buckets_partition() spend  sec:  0.6388635635375977
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043424367904663086

in edges time spent  0.1470484733581543
local to global src and eids time spent  0.2665395736694336
time gen tails  0.0529935359954834
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09131741523742676

in edges time spent  0.34131956100463867
local to global src and eids time spent  0.5353970527648926
time gen tails  0.0812079906463623
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10990095138549805  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000309467315674  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000492095947266  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1142582893371582  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791738510131836  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.797458171844482  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12398624420166016  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9732481241226196
pure train time :  0.4419536590576172
train time :  0.6104991436004639
end to end time :  4.093033075332642
connection check time:  1.8103461265563965
block generation time  0.9483888149261475
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004706382751464844
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013972759246826172
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6317074298858643
len local_batched_seeds_list  2
partition total batch output list spend :  0.7132034301757812
self.buckets_partition() spend  sec:  0.6457152366638184
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04284262657165527

in edges time spent  0.14516448974609375
local to global src and eids time spent  0.2594175338745117
time gen tails  0.052793264389038086
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09154343605041504

in edges time spent  0.34569692611694336
local to global src and eids time spent  0.5387887954711914
time gen tails  0.08094286918640137
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10986900329589844  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002241134643555  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001592636108398  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11422443389892578  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781129360198975  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786849021911621  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12431907653808594  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9737919569015503
pure train time :  0.42926740646362305
train time :  0.5909056663513184
end to end time :  4.0681312084198
connection check time:  1.8069477081298828
block generation time  0.9442477226257324
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00046706199645996094
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014055013656616211
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6318612098693848
len local_batched_seeds_list  2
partition total batch output list spend :  0.7133517265319824
self.buckets_partition() spend  sec:  0.6459498405456543
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04297924041748047

in edges time spent  0.14376592636108398
local to global src and eids time spent  0.25988125801086426
time gen tails  0.053659915924072266
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0905296802520752

in edges time spent  0.3629598617553711
local to global src and eids time spent  0.5763545036315918
time gen tails  0.08367633819580078
res  length 2
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11054420471191406  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.997194766998291  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.996145725250244  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11370086669921875  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792346000671387  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.798065662384033  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12414884567260742  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.970606803894043
pure train time :  0.44210243225097656
train time :  0.6200904846191406
end to end time :  4.166078805923462
connection check time:  1.8739216327667236
block generation time  0.9431395530700684
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005106925964355469
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014285564422607422
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6554198265075684
len local_batched_seeds_list  2
partition total batch output list spend :  0.7389585971832275
self.buckets_partition() spend  sec:  0.669745922088623
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04288363456726074

in edges time spent  0.14565205574035645
local to global src and eids time spent  0.2592203617095947
time gen tails  0.05304861068725586
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09013700485229492

in edges time spent  0.3579103946685791
local to global src and eids time spent  0.5383923053741455
time gen tails  0.08030486106872559
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1100006103515625  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.047716617584229  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.04707670211792  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11450767517089844  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.75231122970581  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.758030891418457  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1243429183959961  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9698525667190552
pure train time :  0.4414541721343994
train time :  0.6085495948791504
end to end time :  4.137636184692383
connection check time:  1.8179824352264404
block generation time  0.9570660591125488
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00048661231994628906
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014045476913452148
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6418554782867432
len local_batched_seeds_list  2
partition total batch output list spend :  0.7235383987426758
self.buckets_partition() spend  sec:  0.6559336185455322
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04265141487121582

in edges time spent  0.14477300643920898
local to global src and eids time spent  0.26093578338623047
time gen tails  0.052956581115722656
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09080243110656738

in edges time spent  0.35811948776245117
local to global src and eids time spent  0.5601310729980469
time gen tails  0.08527135848999023
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.109832763671875  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.002039432525635  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001427173614502  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11329030990600586  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.800790309906006  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.806509971618652  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1254868507385254  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9706814885139465
pure train time :  0.4445338249206543
train time :  0.637840747833252
end to end time :  4.181715726852417
connection check time:  1.8606266975402832
block generation time  0.9452757835388184
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005583763122558594
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.041170358657836914
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6469054222106934
len local_batched_seeds_list  2
partition total batch output list spend :  0.7791075706481934
self.buckets_partition() spend  sec:  0.6881880760192871
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04506683349609375

in edges time spent  0.1559586524963379
local to global src and eids time spent  0.2677640914916992
time gen tails  0.05303549766540527
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0922236442565918

in edges time spent  0.37698960304260254
local to global src and eids time spent  0.5504798889160156
time gen tails  0.06008100509643555
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11027860641479492  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00212287902832  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001071453094482  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11475992202758789  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.790895938873291  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.796615600585938  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12483453750610352  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9712429046630859
pure train time :  0.4314911365509033
train time :  0.5976805686950684
end to end time :  4.203517198562622
connection check time:  1.8522253036499023
block generation time  0.9493257999420166
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005950927734375
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015761375427246094
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6202192306518555
len local_batched_seeds_list  2
partition total batch output list spend :  0.6689746379852295
self.buckets_partition() spend  sec:  0.6360137462615967
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04059934616088867

in edges time spent  0.13753008842468262
local to global src and eids time spent  0.25949549674987793
time gen tails  0.0545201301574707
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09785962104797363

in edges time spent  0.37381577491760254
local to global src and eids time spent  0.5576822757720947
time gen tails  0.08370351791381836
res  length 2
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11058664321899414  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.001462459564209  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.000100135803223  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11433982849121094  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791708946228027  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.797428607940674  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12499809265136719  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9724520444869995
pure train time :  0.4309372901916504
train time :  0.5998404026031494
end to end time :  4.078698396682739
connection check time:  1.8493053913116455
block generation time  0.9450368881225586
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000514984130859375
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014105558395385742
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6672935485839844
len local_batched_seeds_list  2
partition total batch output list spend :  0.7513601779937744
self.buckets_partition() spend  sec:  0.6814398765563965
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04285764694213867

in edges time spent  0.14444947242736816
local to global src and eids time spent  0.25852251052856445
time gen tails  0.05318260192871094
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08996987342834473

in edges time spent  0.3264806270599365
local to global src and eids time spent  0.4901602268218994
time gen tails  0.05911755561828613
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1112675666809082  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00903034210205  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.00743293762207  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11485815048217773  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.786755084991455  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.792474746704102  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12553787231445312  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9679086804389954
pure train time :  0.4401276111602783
train time :  0.6015110015869141
end to end time :  4.0376551151275635
connection check time:  1.7138655185699463
block generation time  0.9508287906646729
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005435943603515625
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015446901321411133
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5213220119476318
len local_batched_seeds_list  2
partition total batch output list spend :  0.5661420822143555
self.buckets_partition() spend  sec:  0.5368053913116455
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04092836380004883

in edges time spent  0.14464092254638672
local to global src and eids time spent  0.2601301670074463
time gen tails  0.052842140197753906
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0919187068939209

in edges time spent  0.3503694534301758
local to global src and eids time spent  0.5428133010864258
time gen tails  0.08087038993835449
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10986137390136719  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043624877929688  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043861389160156  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1145176887512207  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785988807678223  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79170846939087  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12489843368530273  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.968026876449585
pure train time :  0.44011592864990234
train time :  0.5995492935180664
end to end time :  3.932551622390747
connection check time:  1.8085484504699707
block generation time  0.9422249794006348
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0013191699981689453
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014529705047607422
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6388716697692871
len local_batched_seeds_list  2
partition total batch output list spend :  0.7235767841339111
self.buckets_partition() spend  sec:  0.6534337997436523
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04300832748413086

in edges time spent  0.14464187622070312
local to global src and eids time spent  0.2613964080810547
time gen tails  0.05293011665344238
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09073901176452637

in edges time spent  0.35589599609375
local to global src and eids time spent  0.5425589084625244
time gen tails  0.08088445663452148
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11025190353393555  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.004676342010498  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.003928184509277  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11447572708129883  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.797089576721191  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.802809238433838  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12448835372924805  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9698512554168701
pure train time :  0.4411468505859375
train time :  0.5994439125061035
end to end time :  4.10087513923645
connection check time:  1.8206212520599365
block generation time  0.9445934295654297
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005087852478027344
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014400243759155273
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6290206909179688
len local_batched_seeds_list  2
partition total batch output list spend :  0.7123613357543945
self.buckets_partition() spend  sec:  0.643455982208252
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04260134696960449

in edges time spent  0.14450383186340332
local to global src and eids time spent  0.2586987018585205
time gen tails  0.05268979072570801
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09008383750915527

in edges time spent  0.3473076820373535
local to global src and eids time spent  0.538877010345459
time gen tails  0.08356547355651855
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10990238189697266  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042821884155273  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042152404785156  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11402034759521484  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.781357288360596  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.787076950073242  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12398576736450195  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9691640138626099
pure train time :  0.44582486152648926
train time :  0.615020751953125
end to end time :  4.0913245677948
connection check time:  1.8077168464660645
block generation time  0.943354606628418
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.00046372413635253906
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01705622673034668
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6345007419586182
len local_batched_seeds_list  2
partition total batch output list spend :  0.7210679054260254
self.buckets_partition() spend  sec:  0.651599645614624
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.044836997985839844

in edges time spent  0.16347503662109375
local to global src and eids time spent  0.2689640522003174
time gen tails  0.05333423614501953
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09077906608581543

in edges time spent  0.3486173152923584
local to global src and eids time spent  0.5339877605438232
time gen tails  0.08191561698913574
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11141252517700195  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043730735778809  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042510032653809  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11488199234008789  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.785080909729004  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.79080057144165  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12441682815551758  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9689135551452637
pure train time :  0.4425487518310547
train time :  0.6034436225891113
end to end time :  4.126772165298462
connection check time:  1.8332948684692383
block generation time  0.952329158782959
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004799365997314453
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013902664184570312
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6315453052520752
len local_batched_seeds_list  2
partition total batch output list spend :  0.7211277484893799
self.buckets_partition() spend  sec:  0.6454813480377197
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04309511184692383

in edges time spent  0.14575600624084473
local to global src and eids time spent  0.2585623264312744
time gen tails  0.05234718322753906
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09274721145629883

in edges time spent  0.3567659854888916
local to global src and eids time spent  0.5612828731536865
time gen tails  0.08271527290344238
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10968542098999023  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037445545196533  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.0369873046875  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11379766464233398  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.80717658996582  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.812896251678467  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12401056289672852  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.968757688999176
pure train time :  0.4402964115142822
train time :  0.6094188690185547
end to end time :  4.1371681690216064
connection check time:  1.8515403270721436
block generation time  0.9382436275482178
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0004534721374511719
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014000654220581055
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6945712566375732
len local_batched_seeds_list  2
partition total batch output list spend :  0.7789509296417236
self.buckets_partition() spend  sec:  0.7086102962493896
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04271221160888672

in edges time spent  0.14322972297668457
local to global src and eids time spent  0.2590048313140869
time gen tails  0.05313611030578613
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09066033363342285

in edges time spent  0.3653097152709961
local to global src and eids time spent  0.5502996444702148
time gen tails  0.0812523365020752
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11039543151855469  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999184131622314  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998286724090576  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11470174789428711  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.78249740600586  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.788217067718506  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.1243753433227539  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9690030813217163
pure train time :  0.43525171279907227
train time :  0.5960073471069336
end to end time :  4.163691997528076
connection check time:  1.8331315517425537
block generation time  0.9389936923980713
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005624294281005859
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014713048934936523
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6484909057617188
len local_batched_seeds_list  2
partition total batch output list spend :  0.7325677871704102
self.buckets_partition() spend  sec:  0.6632394790649414
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043036460876464844

in edges time spent  0.14636850357055664
local to global src and eids time spent  0.2586250305175781
time gen tails  0.052890777587890625
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09145045280456543

in edges time spent  0.3458592891693115
local to global src and eids time spent  0.5329453945159912
time gen tails  0.08043980598449707
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.10994815826416016  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.999044418334961  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 12.998316764831543  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11339759826660156  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.791380405426025  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.797100067138672  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12487602233886719  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9671951532363892
pure train time :  0.43805456161499023
train time :  0.5983190536499023
end to end time :  4.096582889556885
connection check time:  1.8006322383880615
block generation time  0.9523580074310303
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.000499725341796875
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014489412307739258
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.641324520111084
len local_batched_seeds_list  2
partition total batch output list spend :  0.7253017425537109
self.buckets_partition() spend  sec:  0.6558487415313721
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04291701316833496

in edges time spent  0.14540457725524902
local to global src and eids time spent  0.26051902770996094
time gen tails  0.05304741859436035
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09141993522644043

in edges time spent  0.3409121036529541
local to global src and eids time spent  0.530907154083252
time gen tails  0.08104586601257324
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11039400100708008  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042643070220947  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.041481018066406  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11365222930908203  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.765414237976074  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.77113389968872  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12383365631103516  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9699134826660156
pure train time :  0.44179439544677734
train time :  0.6037478446960449
end to end time :  4.081862926483154
connection check time:  1.7960968017578125
block generation time  0.9444117546081543
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005407333374023438
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014148473739624023
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6425042152404785
len local_batched_seeds_list  2
partition total batch output list spend :  0.72464919090271
self.buckets_partition() spend  sec:  0.6566879749298096
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04300689697265625

in edges time spent  0.14481830596923828
local to global src and eids time spent  0.25890326499938965
time gen tails  0.052996158599853516
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09009027481079102

in edges time spent  0.3390038013458252
local to global src and eids time spent  0.5340926647186279
time gen tails  0.08074617385864258
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11040496826171875  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.037360668182373  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.036475658416748  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11396265029907227  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.768919944763184  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.77463960647583  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12352228164672852  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.9668687582015991
pure train time :  0.4424102306365967
train time :  0.6086351871490479
end to end time :  4.087671756744385
connection check time:  1.7940387725830078
block generation time  0.947113037109375
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  12700
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960]

remove bucket_id:  [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 14]
original bucket_id :,  [4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16]
remove weights:  [1237 1233 1219 1211 1206 1184 1176 1121 1092 1061  960], 		------------sum 12700

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]
G_BUCKET_ID_list [[4, 5, 6, 7, 3, 8, 9, 11, 1, 12, 16], [2, 10, 13, 14, 15, 0, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[1237, 1233, 1219, 1211, 1206, 1184, 1176, 1121, 1092, 1061, 960], [1174, 1116, 1035, 1013, 955, 928, 928, 916, 900, 868, 800, 795, 787]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  12.70481234632202
current group_mem  12.222497969071618
batches output list generation spend  0.0005407333374023438
self.weights_list  [0.577968133185252, 0.422031866814748]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014208078384399414
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5528266429901123
len local_batched_seeds_list  2
partition total batch output list spend :  0.6387572288513184
self.buckets_partition() spend  sec:  0.5670685768127441
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043181657791137695

in edges time spent  0.15322327613830566
local to global src and eids time spent  0.26603245735168457
time gen tails  0.05511593818664551
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0944669246673584

in edges time spent  0.3694608211517334
local to global src and eids time spent  0.5519313812255859
time gen tails  0.08525204658508301
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11088180541992188  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.043673038482666  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 13.042981147766113  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.11381721496582031  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.789498805999756  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 11.795218467712402  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.333984375 GB
    Memory Allocated: 0.12430191040039062  GigaBytes
Max Memory Allocated: 13.524272918701172  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 0.964890718460083
pure train time :  0.44418978691101074
train time :  0.6154670715332031
end to end time :  4.109345197677612
connection check time:  1.8749616146087646
block generation time  0.9665818214416504
end to end time  4.206135272979736
Total (block generation + training)time/epoch 4.206135272979736
pure train time per /epoch  [0.9651284217834473, 0.44863462448120117, 0.44850826263427734, 0.4445061683654785, 0.4478788375854492, 0.4348881244659424, 0.44220781326293945, 0.45001816749572754, 0.44281554222106934, 0.44395947456359863, 0.45136094093322754, 0.4491255283355713, 0.44811558723449707, 0.45092153549194336, 0.45255279541015625, 0.4506967067718506, 0.44815778732299805, 0.44922900199890137, 0.4485933780670166, 0.4468724727630615, 0.44508790969848633, 0.439422607421875, 0.44585728645324707, 0.43734312057495117, 0.4467349052429199, 0.4316720962524414, 0.4432508945465088, 0.43174266815185547, 0.4401719570159912, 0.4317173957824707, 0.4358551502227783, 0.44555044174194336, 0.4452648162841797, 0.43999719619750977, 0.4463183879852295, 0.4391136169433594, 0.4381887912750244, 0.4543466567993164, 0.44612836837768555, 0.43624353408813477, 0.4397003650665283, 0.4410536289215088, 0.44072461128234863, 0.4433906078338623, 0.43953394889831543, 0.4416470527648926, 0.443936824798584, 0.43866848945617676, 0.43140459060668945, 0.44212818145751953, 0.4371180534362793, 0.44234585762023926, 0.4406743049621582, 0.455935001373291, 0.43711113929748535, 0.4395112991333008, 0.44011735916137695, 0.4394419193267822, 0.44267749786376953, 0.43532252311706543, 0.43401503562927246, 0.42907094955444336, 0.43603992462158203, 0.4423253536224365, 0.4400637149810791, 0.44133925437927246, 0.4410285949707031, 0.4419560432434082, 0.4358515739440918, 0.43191075325012207, 0.4424705505371094, 0.44259047508239746, 0.4366481304168701, 0.4312887191772461, 0.4417083263397217, 0.44209861755371094, 0.4418966770172119, 0.441331148147583, 0.44106125831604004, 0.44129037857055664, 0.44046854972839355, 0.44202566146850586, 0.4289357662200928, 0.43998098373413086, 0.4461071491241455, 0.43329930305480957, 0.4384794235229492, 0.42958950996398926, 0.4384040832519531, 0.4330124855041504, 0.4399130344390869, 0.4433858394622803, 0.4432499408721924, 0.4335775375366211, 0.4439699649810791, 0.45119738578796387, 0.4400770664215088, 0.43708133697509766, 0.43587422370910645, 0.4411172866821289, 0.43657708168029785, 0.44202184677124023, 0.4296553134918213, 0.4334752559661865, 0.4445633888244629, 0.4402322769165039, 0.4398026466369629, 0.4272477626800537, 0.4216182231903076, 0.4397754669189453, 0.43271327018737793, 0.4395780563354492, 0.43035197257995605, 0.4308779239654541, 0.4378316402435303, 0.43992018699645996, 0.4419898986816406, 0.4389939308166504, 0.435927152633667, 0.44091033935546875, 0.44100069999694824, 0.43286657333374023, 0.4348750114440918, 0.44129490852355957, 0.4298417568206787, 0.4412848949432373, 0.42981863021850586, 0.44414734840393066, 0.43311142921447754, 0.44278669357299805, 0.44295454025268555, 0.4418172836303711, 0.44031286239624023, 0.44382715225219727, 0.4427645206451416, 0.4347376823425293, 0.43242883682250977, 0.4305155277252197, 0.4410989284515381, 0.4414074420928955, 0.4416799545288086, 0.4338111877441406, 0.44470787048339844, 0.43928980827331543, 0.44347286224365234, 0.4474496841430664, 0.44942259788513184, 0.45104336738586426, 0.43579936027526855, 0.44777536392211914, 0.4438037872314453, 0.44931912422180176, 0.44912219047546387, 0.44965052604675293, 0.4489140510559082, 0.4502577781677246, 0.4483363628387451, 0.4492313861846924, 0.44066667556762695, 0.44860267639160156, 0.4384455680847168, 0.448026180267334, 0.4495716094970703, 0.4482238292694092, 0.44590067863464355, 0.45026516914367676, 0.44686198234558105, 0.44925856590270996, 0.4490687847137451, 0.4396247863769531, 0.43837952613830566, 0.44718098640441895, 0.44457459449768066, 0.4476604461669922, 0.446826696395874, 0.44638729095458984, 0.4434549808502197, 0.44074130058288574, 0.4399240016937256, 0.44019627571105957, 0.43639111518859863, 0.4412519931793213, 0.44959473609924316, 0.43650341033935547, 0.44440627098083496, 0.4462721347808838, 0.4451425075531006, 0.44898080825805664, 0.44909024238586426, 0.438554048538208, 0.4489762783050537, 0.44087958335876465, 0.43987202644348145, 0.43814587593078613, 0.44532155990600586, 0.4529228210449219, 0.4480001926422119, 0.44827985763549805, 0.4368109703063965, 0.44988083839416504, 0.4401564598083496, 0.4483351707458496, 0.4353299140930176, 0.450162410736084, 0.4439103603363037, 0.44895195960998535, 0.44841814041137695, 0.45110201835632324, 0.4611222743988037, 0.4496028423309326, 0.4512491226196289, 0.4503052234649658, 0.45239901542663574, 0.45171403884887695, 0.4506189823150635, 0.4452090263366699, 0.4454917907714844, 0.44601869583129883, 0.44745707511901855, 0.43866753578186035, 0.4482898712158203, 0.4476146697998047, 0.4519352912902832, 0.45066213607788086, 0.44077563285827637, 0.4486722946166992, 0.4510824680328369, 0.4458003044128418, 0.44888734817504883, 0.44356489181518555, 0.4423367977142334, 0.44432568550109863, 0.44714856147766113, 0.44811439514160156, 0.44451045989990234, 0.43998289108276367, 0.435579776763916, 0.44632482528686523, 0.4474947452545166, 0.43427157402038574, 0.4468710422515869, 0.43684816360473633, 0.44313740730285645, 0.43933749198913574, 0.4347074031829834, 0.43734216690063477, 0.44437623023986816, 0.4464709758758545, 0.4470205307006836, 0.4470956325531006, 0.4363698959350586, 0.45062971115112305, 0.44445204734802246, 0.4382772445678711, 0.4460599422454834, 0.4370880126953125, 0.43746066093444824, 0.4392101764678955, 0.4448559284210205, 0.43727564811706543, 0.44724059104919434, 0.44530463218688965, 0.4414074420928955, 0.4423818588256836, 0.44587206840515137, 0.44515347480773926, 0.4398164749145508, 0.44764041900634766, 0.44684743881225586, 0.4466409683227539, 0.4456052780151367, 0.43933582305908203, 0.45053648948669434, 0.44664645195007324, 0.4462618827819824, 0.44141268730163574, 0.4415411949157715, 0.44518041610717773, 0.4467589855194092, 0.4490647315979004, 0.4468214511871338, 0.44591259956359863, 0.4441676139831543, 0.44695591926574707, 0.44646263122558594, 0.44592809677124023, 0.44443368911743164, 0.44663166999816895, 0.44643664360046387, 0.4338517189025879, 0.4409768581390381, 0.4409632682800293, 0.4379432201385498, 0.4443035125732422, 0.4377620220184326, 0.446307897567749, 0.44887375831604004, 0.447742223739624, 0.4485299587249756, 0.4463825225830078, 0.44707536697387695, 0.4370851516723633, 0.4377436637878418, 0.4363088607788086, 0.4331963062286377, 0.44544100761413574, 0.4490633010864258, 0.44714832305908203, 0.44717931747436523, 0.44878625869750977, 0.445681095123291, 0.44837117195129395, 0.4399740695953369, 0.4419543743133545, 0.44684863090515137, 0.4391796588897705, 0.4433727264404297, 0.4411594867706299, 0.4441661834716797, 0.44653820991516113, 0.43666505813598633, 0.44484567642211914, 0.4421074390411377, 0.4368469715118408, 0.4433290958404541, 0.4476890563964844, 0.43617820739746094, 0.43793630599975586, 0.4440927505493164, 0.44580769538879395, 0.43710994720458984, 0.44373250007629395, 0.446002721786499, 0.44818902015686035, 0.4450216293334961, 0.43697690963745117, 0.4402790069580078, 0.43954896926879883, 0.4365420341491699, 0.4306933879852295, 0.4343874454498291, 0.4364786148071289, 0.4342803955078125, 0.44034814834594727, 0.4362215995788574, 0.43289947509765625, 0.44281697273254395, 0.4417152404785156, 0.4431314468383789, 0.4354665279388428, 0.43373990058898926, 0.4428136348724365, 0.4425621032714844, 0.4418604373931885, 0.4422760009765625, 0.43545103073120117, 0.44112300872802734, 0.42774105072021484, 0.4393131732940674, 0.44031596183776855, 0.4424724578857422, 0.4399750232696533, 0.4420440196990967, 0.42825984954833984, 0.4457573890686035, 0.44033265113830566, 0.44345998764038086, 0.43753790855407715, 0.44059109687805176, 0.4330434799194336, 0.43407702445983887, 0.4384777545928955, 0.441699743270874, 0.4412064552307129, 0.44265031814575195, 0.4412245750427246, 0.4413318634033203, 0.440654993057251, 0.44189453125, 0.44359421730041504, 0.44205474853515625, 0.4418966770172119, 0.4419536590576172, 0.42926740646362305, 0.44210243225097656, 0.4414541721343994, 0.4445338249206543, 0.4314911365509033, 0.4309372901916504, 0.4401276111602783, 0.44011592864990234, 0.4411468505859375, 0.44582486152648926, 0.4425487518310547, 0.4402964115142822, 0.43525171279907227, 0.43805456161499023, 0.44179439544677734, 0.4424102306365967, 0.44418978691101074]
pure train time average  0.4420853720770942
