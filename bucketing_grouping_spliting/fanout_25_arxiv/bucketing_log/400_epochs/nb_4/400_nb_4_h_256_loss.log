main start at this time 1697671042.6459389
-----------------------------------------before load data 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

----------------------------------------start of run function 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0010502338409423828
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014765739440917969
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.826991081237793
len local_batched_seeds_list  4
partition total batch output list spend :  0.9872102737426758
self.buckets_partition() spend  sec:  0.8417878150939941
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.05179882049560547

in edges time spent  0.15771794319152832
local to global src and eids time spent  0.31015658378601074
time gen tails  0.06943726539611816
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13093137741088867

in edges time spent  0.6042821407318115
local to global src and eids time spent  0.9411683082580566
time gen tails  0.14044451713562012
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.525390625 GB
    Memory Allocated: 0.07785320281982422  GigaBytes
Max Memory Allocated: 0.07785320281982422  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 10.021484375 GB
    Memory Allocated: 8.195083618164062  GigaBytes
Max Memory Allocated: 8.41289758682251  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 10.021484375 GB
    Memory Allocated: 8.198942184448242  GigaBytes
Max Memory Allocated: 8.41289758682251  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 10.39453125 GB
    Memory Allocated: 0.08889484405517578  GigaBytes
Max Memory Allocated: 8.41289758682251  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 10.4375 GB
    Memory Allocated: 8.03583288192749  GigaBytes
Max Memory Allocated: 8.41289758682251  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 10.4375 GB
    Memory Allocated: 8.039585590362549  GigaBytes
Max Memory Allocated: 8.41289758682251  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 10.615234375 GB
    Memory Allocated: 0.09685325622558594  GigaBytes
Max Memory Allocated: 8.41289758682251  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 10.982421875 GB
    Memory Allocated: 8.433666706085205  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 10.982421875 GB
    Memory Allocated: 8.438962459564209  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 11.169921875 GB
    Memory Allocated: 0.10059499740600586  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 11.185546875 GB
    Memory Allocated: 8.009245872497559  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 11.185546875 GB
    Memory Allocated: 8.012279987335205  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 11.189453125 GB
    Memory Allocated: 0.11127567291259766  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 4.356420516967773
pure train time :  1.0084848403930664
train time :  1.815256118774414
end to end time :  7.06791877746582
connection check time:  2.7775588035583496
block generation time  1.4641847610473633
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005879402160644531
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014417886734008789
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7643473148345947
len local_batched_seeds_list  4
partition total batch output list spend :  0.9226381778717041
self.buckets_partition() spend  sec:  0.778799295425415
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.049315452575683594

in edges time spent  0.17081332206726074
local to global src and eids time spent  0.2996535301208496
time gen tails  0.07323503494262695
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13912200927734375

in edges time spent  0.6433794498443604
local to global src and eids time spent  0.9564151763916016
time gen tails  0.15258359909057617
res  length 4
block collection to dataloader spend  1.4781951904296875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 11.189453125 GB
    Memory Allocated: 0.09357213973999023  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 11.189453125 GB
    Memory Allocated: 8.183670997619629  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 11.189453125 GB
    Memory Allocated: 8.183332920074463  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 11.189453125 GB
    Memory Allocated: 0.09481620788574219  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 12.724609375 GB
    Memory Allocated: 8.053441047668457  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 12.724609375 GB
    Memory Allocated: 8.057193756103516  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 12.900390625 GB
    Memory Allocated: 0.10234689712524414  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 12.900390625 GB
    Memory Allocated: 8.399025440216064  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 12.900390625 GB
    Memory Allocated: 8.404321193695068  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 12.900390625 GB
    Memory Allocated: 0.10463714599609375  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 12.904296875 GB
    Memory Allocated: 7.978672504425049  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 12.904296875 GB
    Memory Allocated: 7.982416152954102  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 0.11106300354003906  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 4.0885910987854
pure train time :  0.5356738567352295
train time :  0.8135068416595459
end to end time :  6.1035778522491455
connection check time:  2.9198639392852783
block generation time  1.4249401092529297
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006666183471679688
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01770472526550293
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7834901809692383
len local_batched_seeds_list  4
partition total batch output list spend :  0.9455842971801758
self.buckets_partition() spend  sec:  0.8012323379516602
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.05350995063781738

in edges time spent  0.16808104515075684
local to global src and eids time spent  0.3042771816253662
time gen tails  0.07201480865478516
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13909316062927246

in edges time spent  0.6092545986175537
local to global src and eids time spent  0.9445226192474365
time gen tails  0.1476147174835205
res  length 4
block collection to dataloader spend  1.33514404296875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 0.09395027160644531  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 8.194124221801758  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 8.193787574768066  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 0.09541845321655273  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 8.036649703979492  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 8.040849685668945  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 0.10233640670776367  GigaBytes
Max Memory Allocated: 8.67682409286499  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 8.437646389007568  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 8.442942142486572  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 0.10464286804199219  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 7.983207702636719  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 7.987016201019287  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 0.11157894134521484  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.8680169582366943
pure train time :  0.5655438899993896
train time :  0.787935733795166
end to end time :  6.0414206981658936
connection check time:  2.8175132274627686
block generation time  1.461176872253418
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006227493286132812
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014494657516479492
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7693297863006592
len local_batched_seeds_list  4
partition total batch output list spend :  0.9279253482818604
self.buckets_partition() spend  sec:  0.7838575839996338
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04981207847595215

in edges time spent  0.1648552417755127
local to global src and eids time spent  0.30423712730407715
time gen tails  0.07153129577636719
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13952875137329102

in edges time spent  0.5643937587738037
local to global src and eids time spent  0.9240775108337402
time gen tails  0.14643287658691406
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 0.09409141540527344  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 8.184136390686035  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 8.183852672576904  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 0.09516525268554688  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 8.044036865234375  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 12.90625 GB
    Memory Allocated: 8.04813814163208  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1024785041809082  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.386961936950684  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.392350673675537  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058201789855957  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.01624584197998  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.019989490509033  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1114816665649414  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.7103254795074463
pure train time :  0.5717451572418213
train time :  0.7992410659790039
end to end time :  5.944843292236328
connection check time:  2.7439677715301514
block generation time  1.4565987586975098
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006346702575683594
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014390707015991211
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7379469871520996
len local_batched_seeds_list  4
partition total batch output list spend :  0.8944401741027832
self.buckets_partition() spend  sec:  0.752371072769165
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.049504756927490234

in edges time spent  0.15852856636047363
local to global src and eids time spent  0.3016953468322754
time gen tails  0.07126927375793457
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13826799392700195

in edges time spent  0.5763566493988037
local to global src and eids time spent  0.9377861022949219
time gen tails  0.14990234375
res  length 4
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09407949447631836  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.179826259613037  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.178845405578613  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09521627426147461  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043274402618408  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.047027111053467  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10240936279296875  GigaBytes
Max Memory Allocated: 8.682506561279297  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.454234600067139  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.459530353546143  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464143753051758  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.978782653808594  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9820942878723145  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11126947402954102  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.651446580886841
pure train time :  0.5643541812896729
train time :  0.8144223690032959
end to end time :  5.9549171924591064
connection check time:  2.7706124782562256
block generation time  1.4586622714996338
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006210803985595703
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015514135360717773
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7345936298370361
len local_batched_seeds_list  4
partition total batch output list spend :  0.8906552791595459
self.buckets_partition() spend  sec:  0.7501423358917236
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04937028884887695

in edges time spent  0.17253613471984863
local to global src and eids time spent  0.3244292736053467
time gen tails  0.07097268104553223
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1361980438232422

in edges time spent  0.5940752029418945
local to global src and eids time spent  0.9393813610076904
time gen tails  0.1431255340576172
res  length 4
block collection to dataloader spend  1.2874603271484375e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09379148483276367  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184438705444336  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184101581573486  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09482383728027344  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.042256355285645  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046009063720703  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10233449935913086  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.39466381072998  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.399959564208984  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464239120483398  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.982280254364014  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.986088752746582  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11139488220214844  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.599611759185791
pure train time :  0.5564873218536377
train time :  0.8045144081115723
end to end time :  5.965421915054321
connection check time:  2.8343758583068848
block generation time  1.421107530593872
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006406307220458984
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014761924743652344
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7626843452453613
len local_batched_seeds_list  4
partition total batch output list spend :  0.9178366661071777
self.buckets_partition() spend  sec:  0.7774832248687744
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04840660095214844

in edges time spent  0.15488100051879883
local to global src and eids time spent  0.29941320419311523
time gen tails  0.07024645805358887
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13847589492797852

in edges time spent  0.56577467918396
local to global src and eids time spent  0.9097745418548584
time gen tails  0.14319181442260742
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09398031234741211  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.151286602020264  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.150949001312256  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09476566314697266  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040660381317139  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044413089752197  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1021728515625  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.389437675476074  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.394733428955078  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10555362701416016  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.012180805206299  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.01549243927002  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11067628860473633  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.5312411785125732
pure train time :  0.5406918525695801
train time :  0.7858078479766846
end to end time :  5.851975679397583
connection check time:  2.697603225708008
block generation time  1.4330945014953613
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005891323089599609
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01424407958984375
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.74918532371521
len local_batched_seeds_list  4
partition total batch output list spend :  0.9034852981567383
self.buckets_partition() spend  sec:  0.7634623050689697
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.048348426818847656

in edges time spent  0.15340709686279297
local to global src and eids time spent  0.2954368591308594
time gen tails  0.06905317306518555
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13579797744750977

in edges time spent  0.5524837970733643
local to global src and eids time spent  0.9046595096588135
time gen tails  0.14008688926696777
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09394359588623047  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184990882873535  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184653759002686  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09462118148803711  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.041134357452393  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044887065887451  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10235595703125  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.402661323547363  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.407957077026367  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464620590209961  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.015641689300537  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018953323364258  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11087465286254883  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.4713563919067383
pure train time :  0.5374317169189453
train time :  0.7931699752807617
end to end time :  5.760525465011597
connection check time:  2.6572654247283936
block generation time  1.3925232887268066
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005452632904052734
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014269351959228516
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7372581958770752
len local_batched_seeds_list  4
partition total batch output list spend :  0.8909332752227783
self.buckets_partition() spend  sec:  0.7515594959259033
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.0483090877532959

in edges time spent  0.15267133712768555
local to global src and eids time spent  0.29602885246276855
time gen tails  0.06927299499511719
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13722443580627441

in edges time spent  0.5554900169372559
local to global src and eids time spent  0.9068558216094971
time gen tails  0.140366792678833
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09379863739013672  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.187036514282227  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186698913574219  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0947256088256836  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.03642749786377  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040180206298828  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10247945785522461  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.399113655090332  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.404479503631592  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.104644775390625  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.013998985290527  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.017807483673096  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11128568649291992  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.4197452068328857
pure train time :  0.5374090671539307
train time :  0.7902736663818359
end to end time :  5.756200790405273
connection check time:  2.666449546813965
block generation time  1.392462968826294
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006394386291503906
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014443159103393555
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7410478591918945
len local_batched_seeds_list  4
partition total batch output list spend :  0.8959238529205322
self.buckets_partition() spend  sec:  0.7555263042449951
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.047657012939453125

in edges time spent  0.15310335159301758
local to global src and eids time spent  0.2963411808013916
time gen tails  0.06963658332824707
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13472533226013184

in edges time spent  0.554473876953125
local to global src and eids time spent  0.8997423648834229
time gen tails  0.14213299751281738
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09405660629272461  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18526029586792  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18492317199707  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09473609924316406  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.037529468536377  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.041282176971436  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1025991439819336  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.390554904937744  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.3959379196167  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058206558227539  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.016109466552734  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.019421100616455  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11115312576293945  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.371812582015991
pure train time :  0.5396294593811035
train time :  0.7872822284698486
end to end time :  5.745625257492065
connection check time:  2.6577489376068115
block generation time  1.3905608654022217
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005514621734619141
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014430522918701172
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7358474731445312
len local_batched_seeds_list  4
partition total batch output list spend :  0.8913311958312988
self.buckets_partition() spend  sec:  0.750316858291626
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.047682762145996094

in edges time spent  0.15225601196289062
local to global src and eids time spent  0.29622554779052734
time gen tails  0.06930303573608398
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1352243423461914

in edges time spent  0.5724678039550781
local to global src and eids time spent  0.9294376373291016
time gen tails  0.14706635475158691
res  length 4
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09372329711914062  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182455062866211  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.181474208831787  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09513235092163086  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043651103973389  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.047403812408447  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10248994827270508  GigaBytes
Max Memory Allocated: 8.69830322265625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.455428123474121  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.460723876953125  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10491466522216797  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.97697639465332  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.980720043182373  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1118459701538086  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.3188626766204834
pure train time :  0.5202474594116211
train time :  0.7926592826843262
end to end time :  5.819088697433472
connection check time:  2.723482608795166
block generation time  1.3973238468170166
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005602836608886719
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01544642448425293
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7613441944122314
len local_batched_seeds_list  4
partition total batch output list spend :  0.9280550479888916
self.buckets_partition() spend  sec:  0.776824951171875
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.051526546478271484

in edges time spent  0.16381216049194336
local to global src and eids time spent  0.3008840084075928
time gen tails  0.06951761245727539
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13489294052124023

in edges time spent  0.6014692783355713
local to global src and eids time spent  0.9408214092254639
time gen tails  0.1454164981842041
res  length 4
block collection to dataloader spend  1.5735626220703125e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09429311752319336  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186556339263916  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186219215393066  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09557390213012695  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.051349639892578  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.055851936340332  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10258293151855469  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.390817642211914  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.396202564239502  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10515737533569336  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.983160018920898  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.986903667449951  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11154556274414062  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.2669951915740967
pure train time :  0.5399210453033447
train time :  0.8080203533172607
end to end time :  5.9507224559783936
connection check time:  2.7958106994628906
block generation time  1.3991649150848389
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005819797515869141
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014782428741455078
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7866382598876953
len local_batched_seeds_list  4
partition total batch output list spend :  0.9407987594604492
self.buckets_partition() spend  sec:  0.8014607429504395
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04729509353637695

in edges time spent  0.13501453399658203
local to global src and eids time spent  0.2952735424041748
time gen tails  0.06954765319824219
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13532066345214844

in edges time spent  0.5600037574768066
local to global src and eids time spent  0.9067409038543701
time gen tails  0.14102649688720703
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09401416778564453  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184675216674805  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184338092803955  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09453821182250977  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043690204620361  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.047575950622559  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10230350494384766  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.433832168579102  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.439127922058105  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10555791854858398  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.011401653289795  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.015210151672363  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11109352111816406  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.2075226306915283
pure train time :  0.4730539321899414
train time :  0.7579991817474365
end to end time :  5.76954197883606
connection check time:  2.652186393737793
block generation time  1.4028120040893555
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006105899810791016
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014338016510009766
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7464025020599365
len local_batched_seeds_list  4
partition total batch output list spend :  0.9010622501373291
self.buckets_partition() spend  sec:  0.7607736587524414
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.047162771224975586

in edges time spent  0.1532001495361328
local to global src and eids time spent  0.303483247756958
time gen tails  0.06892919540405273
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13497281074523926

in edges time spent  0.5621030330657959
local to global src and eids time spent  0.9177389144897461
time gen tails  0.14344573020935059
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09409332275390625  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186035633087158  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18569803237915  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09493064880371094  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.059835433959961  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.06358814239502  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1024012565612793  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.385910511016846  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.39120626449585  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464096069335938  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.983595848083496  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9874043464660645  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11175918579101562  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.1469993591308594
pure train time :  0.5622568130493164
train time :  0.792940616607666
end to end time :  5.816076755523682
connection check time:  2.6975157260894775
block generation time  1.410656452178955
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005869865417480469
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014606237411499023
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7515783309936523
len local_batched_seeds_list  4
partition total batch output list spend :  0.9067184925079346
self.buckets_partition() spend  sec:  0.7662169933319092
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04846525192260742

in edges time spent  0.15700697898864746
local to global src and eids time spent  0.2989802360534668
time gen tails  0.07063865661621094
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13541626930236816

in edges time spent  0.5823287963867188
local to global src and eids time spent  0.9537270069122314
time gen tails  0.15246844291687012
res  length 4
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09411859512329102  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18539047241211  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185053825378418  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09542703628540039  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04567575454712  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.049551963806152  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10226821899414062  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.394373893737793  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.399669647216797  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10465097427368164  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.016589164733887  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.02033281326294  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11110734939575195  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.0902814865112305
pure train time :  0.5532205104827881
train time :  0.8079013824462891
end to end time :  5.979780435562134
connection check time:  2.830773115158081
block generation time  1.4191880226135254
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005404949188232422
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015179872512817383
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7827224731445312
len local_batched_seeds_list  4
partition total batch output list spend :  0.9408831596374512
self.buckets_partition() spend  sec:  0.7979402542114258
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.05052447319030762

in edges time spent  0.1576380729675293
local to global src and eids time spent  0.29871535301208496
time gen tails  0.07041788101196289
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1385340690612793

in edges time spent  0.6054854393005371
local to global src and eids time spent  0.9263019561767578
time gen tails  0.14434456825256348
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09395694732666016  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183647155761719  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183309078216553  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09487056732177734  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.054672718048096  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.058425426483154  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1023716926574707  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.391971588134766  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.39726734161377  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058206558227539  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.985716342926025  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.989459991455078  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11203765869140625  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.035377025604248
pure train time :  0.5625498294830322
train time :  0.799480676651001
end to end time :  5.951448678970337
connection check time:  2.760812282562256
block generation time  1.430156946182251
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005564689636230469
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014417171478271484
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.767169713973999
len local_batched_seeds_list  4
partition total batch output list spend :  0.9234111309051514
self.buckets_partition() spend  sec:  0.7816212177276611
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.048429012298583984

in edges time spent  0.15512299537658691
local to global src and eids time spent  0.29677748680114746
time gen tails  0.06956028938293457
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.135422945022583

in edges time spent  0.5636699199676514
local to global src and eids time spent  0.92612624168396
time gen tails  0.143662691116333
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09393739700317383  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183166980743408  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.1828293800354  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09451818466186523  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04468822479248  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.048440933227539  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10231828689575195  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.40320348739624  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.409202575683594  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10528182983398438  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.008724689483643  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.011758804321289  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11094045639038086  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.9759202003479004
pure train time :  0.5673534870147705
train time :  0.8034839630126953
end to end time :  5.900349855422974
connection check time:  2.7075929641723633
block generation time  1.4461798667907715
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005633831024169922
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014417171478271484
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7342007160186768
len local_batched_seeds_list  4
partition total batch output list spend :  0.8904058933258057
self.buckets_partition() spend  sec:  0.7486498355865479
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04823017120361328

in edges time spent  0.15521717071533203
local to global src and eids time spent  0.29784679412841797
time gen tails  0.07051491737365723
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13463783264160156

in edges time spent  0.5633499622344971
local to global src and eids time spent  0.9150021076202393
time gen tails  0.14372587203979492
res  length 4
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09344768524169922  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.1470365524292  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.146698951721191  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.094482421875  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046453952789307  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.050206661224365  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10243082046508789  GigaBytes
Max Memory Allocated: 8.700149536132812  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.458870887756348  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.464166641235352  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058201789855957  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.971911907196045  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.974946022033691  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11092662811279297  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.91851806640625
pure train time :  0.5384256839752197
train time :  0.7880213260650635
end to end time :  5.811614990234375
connection check time:  2.697345495223999
block generation time  1.4214725494384766
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005519390106201172
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014446496963500977
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7385125160217285
len local_batched_seeds_list  4
partition total batch output list spend :  0.8937938213348389
self.buckets_partition() spend  sec:  0.752993106842041
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.048037052154541016

in edges time spent  0.15640592575073242
local to global src and eids time spent  0.2974996566772461
time gen tails  0.07035517692565918
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1371018886566162

in edges time spent  0.5658040046691895
local to global src and eids time spent  0.9162321090698242
time gen tails  0.14358139038085938
res  length 4
block collection to dataloader spend  1.0967254638671875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09363317489624023  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.213687896728516  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.213351249694824  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09466743469238281  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.037519454956055  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.041272163391113  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10245084762573242  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.392414093017578  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.397709846496582  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10529375076293945  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.014689922332764  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018498420715332  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11112403869628906  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.86081600189209
pure train time :  0.5692136287689209
train time :  0.7876653671264648
end to end time :  5.81938099861145
connection check time:  2.703183889389038
block generation time  1.417262077331543
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0008380413055419922
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.019878625869750977
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.737785816192627
len local_batched_seeds_list  4
partition total batch output list spend :  0.8125898838043213
self.buckets_partition() spend  sec:  0.757702112197876
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.049240827560424805

in edges time spent  0.16391873359680176
local to global src and eids time spent  0.3046715259552002
time gen tails  0.07158279418945312
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13779330253601074

in edges time spent  0.5811562538146973
local to global src and eids time spent  0.9199998378753662
time gen tails  0.14657950401306152
res  length 4
block collection to dataloader spend  1.4781951904296875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09390640258789062  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183874607086182  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183671951293945  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09514093399047852  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043132305145264  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046885013580322  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1023702621459961  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.39941930770874  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.404715061187744  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464191436767578  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.983911037445068  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.986945152282715  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11102437973022461  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.818789482116699
pure train time :  0.5747761726379395
train time :  0.8224074840545654
end to end time :  5.8474204540252686
connection check time:  2.7407443523406982
block generation time  1.4533803462982178
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006594657897949219
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01726245880126953
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7875120639801025
len local_batched_seeds_list  4
partition total batch output list spend :  0.9528639316558838
self.buckets_partition() spend  sec:  0.8048198223114014
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.05149984359741211

in edges time spent  0.1693120002746582
local to global src and eids time spent  0.3126099109649658
time gen tails  0.07157444953918457
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1367933750152588

in edges time spent  0.607428789138794
local to global src and eids time spent  0.93414306640625
time gen tails  0.14566612243652344
res  length 4
block collection to dataloader spend  1.5020370483398438e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09350109100341797  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.149103164672852  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.148765563964844  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09474706649780273  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.041379928588867  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.045132637023926  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10283899307250977  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.395599365234375  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.400895118713379  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058201789855957  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.021714210510254  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.025522708892822  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11136245727539062  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.772662401199341
pure train time :  0.5708491802215576
train time :  0.8183612823486328
end to end time :  6.038309097290039
connection check time:  2.797689199447632
block generation time  1.4519803524017334
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006043910980224609
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01496124267578125
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7903869152069092
len local_batched_seeds_list  4
partition total batch output list spend :  0.9461832046508789
self.buckets_partition() spend  sec:  0.8053877353668213
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.050638675689697266

in edges time spent  0.1596231460571289
local to global src and eids time spent  0.29964613914489746
time gen tails  0.07193493843078613
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14021611213684082

in edges time spent  0.5824398994445801
local to global src and eids time spent  0.9350278377532959
time gen tails  0.153123140335083
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0940709114074707  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18662691116333  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186288833618164  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09480905532836914  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.041143417358398  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044896125793457  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10222148895263672  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.384644508361816  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.38994026184082  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1046457290649414  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.016440391540527  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.02018404006958  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11112785339355469  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.7283973693847656
pure train time :  0.5632851123809814
train time :  0.8212108612060547
end to end time :  6.037134170532227
connection check time:  2.7803242206573486
block generation time  1.464043378829956
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006625652313232422
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014688968658447266
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.775327205657959
len local_batched_seeds_list  4
partition total batch output list spend :  0.9309356212615967
self.buckets_partition() spend  sec:  0.7900540828704834
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.0511782169342041

in edges time spent  0.15938043594360352
local to global src and eids time spent  0.3016219139099121
time gen tails  0.07227587699890137
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13646435737609863

in edges time spent  0.5777561664581299
local to global src and eids time spent  0.9275987148284912
time gen tails  0.14629292488098145
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0940546989440918  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186567783355713  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185586929321289  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09511613845825195  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.041422367095947  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.045175075531006  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10259675979614258  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.404415130615234  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.409773349761963  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10463714599609375  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.969213008880615  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.972524642944336  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11065959930419922  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.688556671142578
pure train time :  0.5522608757019043
train time :  0.8037245273590088
end to end time :  5.930229425430298
connection check time:  2.738471031188965
block generation time  1.434704303741455
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006268024444580078
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015235662460327148
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7448680400848389
len local_batched_seeds_list  4
partition total batch output list spend :  0.9004759788513184
self.buckets_partition() spend  sec:  0.7601356506347656
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.048539161682128906

in edges time spent  0.15619564056396484
local to global src and eids time spent  0.29956531524658203
time gen tails  0.07088112831115723
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13595271110534668

in edges time spent  0.565920352935791
local to global src and eids time spent  0.9295399188995361
time gen tails  0.14874720573425293
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09352731704711914  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184305667877197  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183968544006348  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09511804580688477  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04129695892334  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.045299053192139  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1022181510925293  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.386649131774902  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.391944885253906  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.104644775390625  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.989246845245361  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.992990493774414  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11126470565795898  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.648399829864502
pure train time :  0.560704231262207
train time :  0.7983620166778564
end to end time :  5.919786691665649
connection check time:  2.732394218444824
block generation time  1.4711153507232666
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005815029144287109
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014611244201660156
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7501757144927979
len local_batched_seeds_list  4
partition total batch output list spend :  0.9068968296051025
self.buckets_partition() spend  sec:  0.764826774597168
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04902529716491699

in edges time spent  0.1572418212890625
local to global src and eids time spent  0.2995293140411377
time gen tails  0.07325124740600586
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1359260082244873

in edges time spent  0.5749120712280273
local to global src and eids time spent  0.9338266849517822
time gen tails  0.15111804008483887
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09395360946655273  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.15602970123291  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.155691623687744  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09478425979614258  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044831275939941  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.048583984375  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10234880447387695  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.397200584411621  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.402496337890625  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464763641357422  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.016504287719727  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.02024793624878  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11140012741088867  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.5959105491638184
pure train time :  0.5717859268188477
train time :  0.8065476417541504
end to end time :  5.9447877407073975
connection check time:  2.758244752883911
block generation time  1.4580671787261963
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006048679351806641
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014336109161376953
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7523596286773682
len local_batched_seeds_list  4
partition total batch output list spend :  0.906364917755127
self.buckets_partition() spend  sec:  0.7667319774627686
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.05063438415527344

in edges time spent  0.15807771682739258
local to global src and eids time spent  0.31099581718444824
time gen tails  0.07404279708862305
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13785004615783691

in edges time spent  0.5920121669769287
local to global src and eids time spent  0.9256536960601807
time gen tails  0.14513540267944336
res  length 4
block collection to dataloader spend  1.2874603271484375e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0939488410949707  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18364667892456  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183385848999023  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09522438049316406  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.042366981506348  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046119689941406  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10234880447387695  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.450955867767334  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.456251621246338  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10555267333984375  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9773850440979  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.981193542480469  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11107397079467773  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.5575530529022217
pure train time :  0.5629012584686279
train time :  0.8022465705871582
end to end time :  5.939759731292725
connection check time:  2.781097888946533
block generation time  1.4279236793518066
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005838871002197266
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014605283737182617
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7677185535430908
len local_batched_seeds_list  4
partition total batch output list spend :  0.9228379726409912
self.buckets_partition() spend  sec:  0.7823653221130371
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.048850059509277344

in edges time spent  0.1562952995300293
local to global src and eids time spent  0.3004469871520996
time gen tails  0.07141518592834473
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13994336128234863

in edges time spent  0.5631070137023926
local to global src and eids time spent  0.9207408428192139
time gen tails  0.14804625511169434
res  length 4
block collection to dataloader spend  1.1205673217773438e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09408283233642578  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18587350845337  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185536861419678  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09474992752075195  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04298210144043  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046734809875488  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10249948501586914  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.400062561035156  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.405434131622314  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058201789855957  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.020829200744629  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.024572849273682  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11136817932128906  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.5081214904785156
pure train time :  0.6516292095184326
train time :  0.8902304172515869
end to end time :  6.008694648742676
connection check time:  2.7240567207336426
block generation time  1.4570720195770264
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005886554718017578
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014572381973266602
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7603731155395508
len local_batched_seeds_list  4
partition total batch output list spend :  0.9155519008636475
self.buckets_partition() spend  sec:  0.7749831676483154
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04829764366149902

in edges time spent  0.15785765647888184
local to global src and eids time spent  0.30156803131103516
time gen tails  0.07215166091918945
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1361849308013916

in edges time spent  0.5687017440795898
local to global src and eids time spent  0.9394032955169678
time gen tails  0.14948821067810059
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09398794174194336  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18463945388794  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184300899505615  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09478759765625  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.05320930480957  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.056962013244629  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1030879020690918  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.386974334716797  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.3922700881958  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464620590209961  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.016635417938232  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.0204439163208  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11109209060668945  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.4668185710906982
pure train time :  0.5404064655303955
train time :  0.7821691036224365
end to end time :  5.916852712631226
connection check time:  2.747776508331299
block generation time  1.4566261768341064
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005664825439453125
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014919281005859375
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7620253562927246
len local_batched_seeds_list  4
partition total batch output list spend :  0.916731595993042
self.buckets_partition() spend  sec:  0.7769806385040283
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04966902732849121

in edges time spent  0.16382575035095215
local to global src and eids time spent  0.30313801765441895
time gen tails  0.0726308822631836
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14023065567016602

in edges time spent  0.6054036617279053
local to global src and eids time spent  0.9395015239715576
time gen tails  0.14591693878173828
res  length 4
block collection to dataloader spend  1.3589859008789062e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0939631462097168  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.151895523071289  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.151557922363281  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0947108268737793  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040399551391602  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04415225982666  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1023097038269043  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.45030164718628  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.456300735473633  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464239120483398  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.986968040466309  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.990711688995361  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11144685745239258  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.4235105514526367
pure train time :  0.578441858291626
train time :  0.8100271224975586
end to end time :  5.988305330276489
connection check time:  2.797793388366699
block generation time  1.4472177028656006
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005490779876708984
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014317035675048828
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7837026119232178
len local_batched_seeds_list  4
partition total batch output list spend :  0.9388337135314941
self.buckets_partition() spend  sec:  0.7980577945709229
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04892277717590332

in edges time spent  0.15674257278442383
local to global src and eids time spent  0.2988889217376709
time gen tails  0.07116842269897461
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13727498054504395

in edges time spent  0.5636672973632812
local to global src and eids time spent  0.9274563789367676
time gen tails  0.14476323127746582
res  length 4
block collection to dataloader spend  1.2874603271484375e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09397745132446289  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183585166931152  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183247566223145  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09477996826171875  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044602394104004  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.048355102539062  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10221004486083984  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.391386032104492  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.396681785583496  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10556554794311523  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.01532793045044  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.019136428833008  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11112308502197266  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.3831071853637695
pure train time :  0.5406174659729004
train time :  0.7950494289398193
end to end time :  5.8890228271484375
connection check time:  2.7175302505493164
block generation time  1.422943115234375
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005588531494140625
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014345645904541016
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7679212093353271
len local_batched_seeds_list  4
partition total batch output list spend :  0.9232280254364014
self.buckets_partition() spend  sec:  0.782299280166626
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.048564910888671875

in edges time spent  0.15557312965393066
local to global src and eids time spent  0.2990560531616211
time gen tails  0.07129526138305664
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1359705924987793

in edges time spent  0.5683512687683105
local to global src and eids time spent  0.93113112449646
time gen tails  0.14711451530456543
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09387493133544922  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184806823730469  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184468269348145  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09470748901367188  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.03324556350708  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.036998271942139  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10227537155151367  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.389907836914062  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.395203590393066  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1046438217163086  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.014699935913086  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018011569976807  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11068344116210938  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.3447508811950684
pure train time :  0.5784988403320312
train time :  0.8128843307495117
end to end time :  5.943968296051025
connection check time:  2.7323951721191406
block generation time  1.4615199565887451
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005662441253662109
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014365196228027344
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7591614723205566
len local_batched_seeds_list  4
partition total batch output list spend :  0.9156093597412109
self.buckets_partition() spend  sec:  0.7735600471496582
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04932355880737305

in edges time spent  0.15651845932006836
local to global src and eids time spent  0.29940271377563477
time gen tails  0.07129836082458496
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13960599899291992

in edges time spent  0.569892406463623
local to global src and eids time spent  0.918445348739624
time gen tails  0.14602923393249512
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09353256225585938  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18302297592163  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182685375213623  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09491395950317383  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.054893016815186  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.058645725250244  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10253524780273438  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.431941032409668  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.437236785888672  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10582208633422852  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.981388092041016  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.985131740570068  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11213064193725586  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.299619436264038
pure train time :  0.5667445659637451
train time :  0.7942423820495605
end to end time :  5.878548622131348
connection check time:  2.718649387359619
block generation time  1.4356327056884766
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005826950073242188
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014480352401733398
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7603046894073486
len local_batched_seeds_list  4
partition total batch output list spend :  0.9153494834899902
self.buckets_partition() spend  sec:  0.7748191356658936
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04868793487548828

in edges time spent  0.1559443473815918
local to global src and eids time spent  0.2989957332611084
time gen tails  0.07106518745422363
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13655447959899902

in edges time spent  0.5665113925933838
local to global src and eids time spent  0.922022819519043
time gen tails  0.10563778877258301
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09408903121948242  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184984683990479  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184003829956055  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09531116485595703  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.05421257019043  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.057965278625488  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10234880447387695  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.427873134613037  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.433168888092041  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464334487915039  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9792799949646  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.983088493347168  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11107969284057617  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.26884388923645
pure train time :  0.5448791980743408
train time :  0.78080153465271
end to end time :  5.805978059768677
connection check time:  2.673643112182617
block generation time  1.4216523170471191
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005817413330078125
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01448512077331543
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7536249160766602
len local_batched_seeds_list  4
partition total batch output list spend :  0.9090197086334229
self.buckets_partition() spend  sec:  0.7681431770324707
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.0483243465423584

in edges time spent  0.15529894828796387
local to global src and eids time spent  0.2976963520050049
time gen tails  0.07082915306091309
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13730883598327637

in edges time spent  0.571293830871582
local to global src and eids time spent  0.9433259963989258
time gen tails  0.1475999355316162
res  length 4
block collection to dataloader spend  1.1205673217773438e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09382104873657227  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.148211479187012  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.147231101989746  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09514427185058594  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043409824371338  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.047511100769043  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10225963592529297  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.409005165100098  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.414300918579102  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058201789855957  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.01463270187378  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018441200256348  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11135578155517578  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.2388792037963867
pure train time :  0.5845544338226318
train time :  0.8050205707550049
end to end time :  5.921372413635254
connection check time:  2.7447025775909424
block generation time  1.445049524307251
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005748271942138672
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01435542106628418
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7529118061065674
len local_batched_seeds_list  4
partition total batch output list spend :  0.9092409610748291
self.buckets_partition() spend  sec:  0.7672996520996094
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04962873458862305

in edges time spent  0.15692448616027832
local to global src and eids time spent  0.30461978912353516
time gen tails  0.07189249992370605
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14435529708862305

in edges time spent  0.5705854892730713
local to global src and eids time spent  0.9405965805053711
time gen tails  0.1493372917175293
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0939173698425293  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.151364803314209  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.150383949279785  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09505224227905273  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.038637638092041  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.0423903465271  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10236644744873047  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.43331003189087  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.438605785369873  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10555791854858398  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.013944149017334  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.017255783081055  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11069202423095703  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.206843852996826
pure train time :  0.5649464130401611
train time :  0.8021025657653809
end to end time :  5.962873697280884
connection check time:  2.7672433853149414
block generation time  1.4665565490722656
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006389617919921875
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01437687873840332
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7460846900939941
len local_batched_seeds_list  4
partition total batch output list spend :  0.9017400741577148
self.buckets_partition() spend  sec:  0.7604951858520508
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.049161672592163086

in edges time spent  0.1573023796081543
local to global src and eids time spent  0.29917120933532715
time gen tails  0.07164287567138672
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13895034790039062

in edges time spent  0.546746015548706
local to global src and eids time spent  0.83085036277771
time gen tails  0.11167144775390625
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09362077713012695  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184634685516357  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.1843581199646  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0950932502746582  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.039299011230469  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043051719665527  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10250329971313477  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.425909519195557  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.43120527267456  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10463190078735352  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.969292640686035  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.972604274749756  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11064291000366211  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.1732335090637207
pure train time :  0.5444142818450928
train time :  0.7826297283172607
end to end time :  5.7151124477386475
connection check time:  2.5850369930267334
block generation time  1.4309616088867188
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005466938018798828
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015737295150756836
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.718714714050293
len local_batched_seeds_list  4
partition total batch output list spend :  0.7898502349853516
self.buckets_partition() spend  sec:  0.7344849109649658
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04844045639038086

in edges time spent  0.16106677055358887
local to global src and eids time spent  0.18998932838439941
time gen tails  0.052223920822143555
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13973593711853027

in edges time spent  0.5742380619049072
local to global src and eids time spent  0.9222080707550049
time gen tails  0.144575834274292
res  length 4
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09352493286132812  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184924125671387  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184587955474854  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09497880935668945  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.053953647613525  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.057706356048584  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10230684280395508  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.372674942016602  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.377970695495605  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464668273925781  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.021991729736328  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.025303363800049  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11069202423095703  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.143726348876953
pure train time :  0.5466008186340332
train time :  0.7908947467803955
end to end time :  5.648029804229736
connection check time:  2.5993354320526123
block generation time  1.4540462493896484
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005466938018798828
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014321327209472656
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7601335048675537
len local_batched_seeds_list  4
partition total batch output list spend :  0.9156448841094971
self.buckets_partition() spend  sec:  0.7744958400726318
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.05012774467468262

in edges time spent  0.15648555755615234
local to global src and eids time spent  0.30128979682922363
time gen tails  0.07197165489196777
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13909602165222168

in edges time spent  0.5702064037322998
local to global src and eids time spent  0.9263532161712646
time gen tails  0.14441275596618652
res  length 4
block collection to dataloader spend  1.3589859008789062e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09357023239135742  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.204890727996826  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.20455265045166  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09479761123657227  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.048161506652832  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.05191421508789  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10247993469238281  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.424794673919678  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.430090427398682  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1046438217163086  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.978482246398926  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9817938804626465  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11068153381347656  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.1115922927856445
pure train time :  0.5359487533569336
train time :  0.795534610748291
end to end time :  5.912887334823608
connection check time:  2.7360920906066895
block generation time  1.4495282173156738
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006291866302490234
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014652729034423828
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7502381801605225
len local_batched_seeds_list  4
partition total batch output list spend :  0.9047374725341797
self.buckets_partition() spend  sec:  0.7649228572845459
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04850292205810547

in edges time spent  0.15546751022338867
local to global src and eids time spent  0.3015928268432617
time gen tails  0.07234025001525879
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.139129638671875

in edges time spent  0.5432016849517822
local to global src and eids time spent  0.8179075717926025
time gen tails  0.10560178756713867
res  length 4
block collection to dataloader spend  1.3828277587890625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09337139129638672  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.149860382080078  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.148879051208496  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0952153205871582  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.051692485809326  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.055445194244385  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10223197937011719  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.398848533630371  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.404144287109375  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058197021484375  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.020763397216797  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.02450704574585  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11135530471801758  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.082561492919922
pure train time :  0.5638554096221924
train time :  0.7948269844055176
end to end time :  5.7158732414245605
connection check time:  2.55444598197937
block generation time  1.4465429782867432
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005745887756347656
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015476465225219727
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7575540542602539
len local_batched_seeds_list  4
partition total batch output list spend :  0.8268063068389893
self.buckets_partition() spend  sec:  0.7730667591094971
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.045777320861816406

in edges time spent  0.15497636795043945
local to global src and eids time spent  0.29777097702026367
time gen tails  0.07088613510131836
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1347646713256836

in edges time spent  0.571373701095581
local to global src and eids time spent  0.9340591430664062
time gen tails  0.14573287963867188
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09392547607421875  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.203336238861084  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.202998161315918  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09476423263549805  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044106483459473  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.047859191894531  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10241413116455078  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.432292938232422  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.437588691711426  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10634374618530273  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.015007972717285  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018319606781006  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11203193664550781  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.057593584060669
pure train time :  0.578789472579956
train time :  0.8042280673980713
end to end time :  5.8062944412231445
connection check time:  2.719060182571411
block generation time  1.4390144348144531
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005476474761962891
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014335870742797852
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.772031307220459
len local_batched_seeds_list  4
partition total batch output list spend :  0.9272124767303467
self.buckets_partition() spend  sec:  0.7864069938659668
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.049628496170043945

in edges time spent  0.15698480606079102
local to global src and eids time spent  0.302675724029541
time gen tails  0.07217240333557129
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13862347602844238

in edges time spent  0.5673942565917969
local to global src and eids time spent  0.9419760704040527
time gen tails  0.147247314453125
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09380197525024414  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185768127441406  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185437679290771  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09514713287353516  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.049433708190918  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.053186416625977  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1023869514465332  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.396022319793701  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.401318073272705  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10582113265991211  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.01968765258789  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.023496150970459  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11136436462402344  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.031635284423828
pure train time :  0.5762100219726562
train time :  0.8014819622039795
end to end time :  5.947774410247803
connection check time:  2.752894639968872
block generation time  1.4515275955200195
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005476474761962891
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014627695083618164
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7576563358306885
len local_batched_seeds_list  4
partition total batch output list spend :  0.9133884906768799
self.buckets_partition() spend  sec:  0.7723166942596436
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04951930046081543

in edges time spent  0.15751981735229492
local to global src and eids time spent  0.3022346496582031
time gen tails  0.07227325439453125
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14664864540100098

in edges time spent  0.561835765838623
local to global src and eids time spent  0.8200581073760986
time gen tails  0.10657858848571777
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09402894973754883  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.181814193725586  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18150806427002  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09504985809326172  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043616771697998  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.047369480133057  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10262918472290039  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.401046752929688  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.406403064727783  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10465335845947266  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018210411071777  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.021522045135498  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11071205139160156  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.004115581512451
pure train time :  0.5476925373077393
train time :  0.7763605117797852
end to end time :  5.7800257205963135
connection check time:  2.5874881744384766
block generation time  1.4879965782165527
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005779266357421875
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0160367488861084
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7241299152374268
len local_batched_seeds_list  4
partition total batch output list spend :  0.794342041015625
self.buckets_partition() spend  sec:  0.7401974201202393
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04675936698913574

in edges time spent  0.1553661823272705
local to global src and eids time spent  0.2986264228820801
time gen tails  0.07164835929870605
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1365656852722168

in edges time spent  0.5860593318939209
local to global src and eids time spent  0.8679580688476562
time gen tails  0.12044215202331543
res  length 4
block collection to dataloader spend  1.0967254638671875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09423160552978516  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.187119007110596  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186780452728271  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0944814682006836  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.01222562789917  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.01609992980957  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10236740112304688  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.456768989562988  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.462064743041992  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10465049743652344  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.014542579650879  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018351078033447  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11110496520996094  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.9832450151443481
pure train time :  0.5469205379486084
train time :  0.7924137115478516
end to end time :  5.715702533721924
connection check time:  2.658472776412964
block generation time  1.4521167278289795
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006110668182373047
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015732765197753906
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7348346710205078
len local_batched_seeds_list  4
partition total batch output list spend :  0.8042275905609131
self.buckets_partition() spend  sec:  0.7505972385406494
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04680442810058594

in edges time spent  0.15906143188476562
local to global src and eids time spent  0.308469295501709
time gen tails  0.07279849052429199
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14035797119140625

in edges time spent  0.6056056022644043
local to global src and eids time spent  0.94447922706604
time gen tails  0.14867353439331055
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0939640998840332  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.181187152862549  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.180205821990967  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0951547622680664  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.039258003234863  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043010711669922  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10231256484985352  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.432028770446777  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.437324523925781  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10523605346679688  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.976400852203369  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.97971248626709  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11123085021972656  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.9597008228302002
pure train time :  0.5723178386688232
train time :  0.7971146106719971
end to end time :  5.852440118789673
connection check time:  2.797665596008301
block generation time  1.4337196350097656
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005588531494140625
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01443171501159668
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7560844421386719
len local_batched_seeds_list  4
partition total batch output list spend :  0.911689043045044
self.buckets_partition() spend  sec:  0.770550012588501
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.049323320388793945

in edges time spent  0.15825772285461426
local to global src and eids time spent  0.30021190643310547
time gen tails  0.07219409942626953
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1387639045715332

in edges time spent  0.5892879962921143
local to global src and eids time spent  0.9236178398132324
time gen tails  0.1445906162261963
res  length 4
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09409332275390625  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184776306152344  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184535026550293  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09519100189208984  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044803619384766  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04890489578247  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10232114791870117  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.433294773101807  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.43859052658081  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10555887222290039  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018699645996094  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.02173376083374  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11069202423095703  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.938361644744873
pure train time :  0.5719780921936035
train time :  0.8022201061248779
end to end time :  5.920274972915649
connection check time:  2.7470691204071045
block generation time  1.4396042823791504
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005364418029785156
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014176368713378906
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7546133995056152
len local_batched_seeds_list  4
partition total batch output list spend :  0.9130933284759521
self.buckets_partition() spend  sec:  0.7688231468200684
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.049349308013916016

in edges time spent  0.15695548057556152
local to global src and eids time spent  0.30300211906433105
time gen tails  0.0724790096282959
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13782429695129395

in edges time spent  0.581712007522583
local to global src and eids time spent  0.9770221710205078
time gen tails  0.14731478691101074
res  length 4
block collection to dataloader spend  1.2874603271484375e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09355592727661133  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185259819030762  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184921741485596  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09483957290649414  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.05040168762207  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.054154396057129  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1023554801940918  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.432108879089355  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.43740463256836  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10463714599609375  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.973105430603027  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.976139545440674  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1106576919555664  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.917480230331421
pure train time :  0.5758845806121826
train time :  0.815575361251831
end to end time :  5.997105121612549
connection check time:  2.809755563735962
block generation time  1.4380054473876953
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.00054168701171875
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014546632766723633
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7783029079437256
len local_batched_seeds_list  4
partition total batch output list spend :  0.9338836669921875
self.buckets_partition() spend  sec:  0.7928869724273682
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.049543142318725586

in edges time spent  0.1565389633178711
local to global src and eids time spent  0.3008871078491211
time gen tails  0.0724186897277832
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14022541046142578

in edges time spent  0.5750565528869629
local to global src and eids time spent  0.9362897872924805
time gen tails  0.14827227592468262
res  length 4
block collection to dataloader spend  1.7642974853515625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09344673156738281  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.188448905944824  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.188112258911133  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09479236602783203  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.039731502532959  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043484210968018  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1024165153503418  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.457553386688232  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.462849140167236  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1046438217163086  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.01341962814331  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.017228126525879  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1110830307006836  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.888381004333496
pure train time :  0.5805947780609131
train time :  0.8028020858764648
end to end time :  5.972341060638428
connection check time:  2.7563838958740234
block generation time  1.459235429763794
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006148815155029297
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014373302459716797
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7712142467498779
len local_batched_seeds_list  4
partition total batch output list spend :  0.9268002510070801
self.buckets_partition() spend  sec:  0.7856240272521973
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04926609992980957

in edges time spent  0.157196044921875
local to global src and eids time spent  0.30056333541870117
time gen tails  0.07108879089355469
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13710737228393555

in edges time spent  0.5754830837249756
local to global src and eids time spent  0.9160158634185791
time gen tails  0.14404058456420898
res  length 4
block collection to dataloader spend  1.1205673217773438e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0940098762512207  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183957576751709  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183757781982422  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09515094757080078  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04073190689087  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044484615325928  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10237360000610352  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.429015159606934  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.434310913085938  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10556221008300781  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.016932964324951  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.019967079162598  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11070489883422852  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.8705494403839111
pure train time :  0.5649075508117676
train time :  0.7999799251556396
end to end time :  5.9048755168914795
connection check time:  2.7184908390045166
block generation time  1.44230318069458
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006740093231201172
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01445317268371582
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7349817752838135
len local_batched_seeds_list  4
partition total batch output list spend :  0.8884530067443848
self.buckets_partition() spend  sec:  0.7494673728942871
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04872488975524902

in edges time spent  0.1553483009338379
local to global src and eids time spent  0.3006608486175537
time gen tails  0.07126903533935547
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13831758499145508

in edges time spent  0.5639522075653076
local to global src and eids time spent  0.9397842884063721
time gen tails  0.1448817253112793
res  length 4
block collection to dataloader spend  1.1444091796875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09340763092041016  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.148332118988037  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.147350311279297  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09514522552490234  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.041444778442383  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.045349597930908  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10235786437988281  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.400453567504883  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.405749320983887  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10465240478515625  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.022097110748291  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.02590560913086  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11111640930175781  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.8575094938278198
pure train time :  0.5867657661437988
train time :  0.8142802715301514
end to end time :  5.89316987991333
connection check time:  2.730646848678589
block generation time  1.4457573890686035
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005373954772949219
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014099359512329102
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7534165382385254
len local_batched_seeds_list  4
partition total batch output list spend :  0.9094588756561279
self.buckets_partition() spend  sec:  0.7675497531890869
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04876589775085449

in edges time spent  0.1553637981414795
local to global src and eids time spent  0.2981076240539551
time gen tails  0.07157540321350098
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13982772827148438

in edges time spent  0.563593864440918
local to global src and eids time spent  0.9363296031951904
time gen tails  0.14816904067993164
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09396600723266602  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184078693389893  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183772087097168  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09513139724731445  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.042089939117432  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04584264755249  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10252761840820312  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.398561477661133  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.403936862945557  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464859008789062  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.0164475440979  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.020256042480469  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11110210418701172  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.830808162689209
pure train time :  0.5564494132995605
train time :  0.7937490940093994
end to end time :  5.917131662368774
connection check time:  2.7363879680633545
block generation time  1.457218885421753
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005424022674560547
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014209747314453125
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7539496421813965
len local_batched_seeds_list  4
partition total batch output list spend :  0.8227040767669678
self.buckets_partition() spend  sec:  0.768195390701294
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.0474090576171875

in edges time spent  0.15712714195251465
local to global src and eids time spent  0.2979416847229004
time gen tails  0.07113957405090332
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14050745964050293

in edges time spent  0.5746970176696777
local to global src and eids time spent  0.9300923347473145
time gen tails  0.14580130577087402
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09392642974853516  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183401584625244  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183063507080078  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.094757080078125  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.036369800567627  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040122509002686  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10233211517333984  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.397248268127441  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.402544021606445  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464620590209961  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.009229183197021  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.012972831726074  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1111607551574707  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.815870761871338
pure train time :  0.5839183330535889
train time :  0.812110185623169
end to end time :  5.840572357177734
connection check time:  2.7331979274749756
block generation time  1.457984447479248
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005509853363037109
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014225006103515625
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7569634914398193
len local_batched_seeds_list  4
partition total batch output list spend :  0.9149298667907715
self.buckets_partition() spend  sec:  0.7712228298187256
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.049301862716674805

in edges time spent  0.15702605247497559
local to global src and eids time spent  0.29956936836242676
time gen tails  0.07120275497436523
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14324474334716797

in edges time spent  0.5673177242279053
local to global src and eids time spent  0.8726160526275635
time gen tails  0.10973238945007324
res  length 4
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09406518936157227  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183963298797607  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18374490737915  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09528160095214844  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.06862497329712  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.072377681732178  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10236644744873047  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.394885540008545  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.400181293487549  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464286804199219  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.976693630218506  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.980502128601074  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11108016967773438  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.8027944564819336
pure train time :  0.5462737083435059
train time :  0.7984387874603271
end to end time :  5.797887325286865
connection check time:  2.633852481842041
block generation time  1.432769536972046
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006289482116699219
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014426708221435547
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7410809993743896
len local_batched_seeds_list  4
partition total batch output list spend :  0.8956258296966553
self.buckets_partition() spend  sec:  0.7555482387542725
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04996538162231445

in edges time spent  0.16056585311889648
local to global src and eids time spent  0.297595739364624
time gen tails  0.07161450386047363
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13842415809631348

in edges time spent  0.6042883396148682
local to global src and eids time spent  0.9888453483581543
time gen tails  0.1457817554473877
res  length 4
block collection to dataloader spend  1.6689300537109375e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0941152572631836  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18425178527832  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183943271636963  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09502696990966797  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.03325080871582  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.037003517150879  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10265111923217773  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.434943199157715  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.440301418304443  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058206558227539  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018924713134766  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.022733211517334  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11136484146118164  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.783828854560852
pure train time :  0.5685205459594727
train time :  0.805384635925293
end to end time :  6.064090013504028
connection check time:  2.888441324234009
block generation time  1.4544188976287842
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005574226379394531
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014725685119628906
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7883203029632568
len local_batched_seeds_list  4
partition total batch output list spend :  0.944779634475708
self.buckets_partition() spend  sec:  0.8030815124511719
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04849720001220703

in edges time spent  0.15693116188049316
local to global src and eids time spent  0.30420732498168945
time gen tails  0.07266712188720703
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1423020362854004

in edges time spent  0.5757405757904053
local to global src and eids time spent  0.930305004119873
time gen tails  0.14612841606140137
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09385251998901367  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183692455291748  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182996273040771  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09485435485839844  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04527473449707  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.049027442932129  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10223722457885742  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.403408527374268  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.408704280853271  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058206558227539  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9860453605651855  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.989853858947754  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11157846450805664  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.7670788764953613
pure train time :  0.5637292861938477
train time :  0.7898597717285156
end to end time :  5.975395202636719
connection check time:  2.748599052429199
block generation time  1.4744598865509033
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005481243133544922
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.016173601150512695
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.753248929977417
len local_batched_seeds_list  4
partition total batch output list spend :  0.9171180725097656
self.buckets_partition() spend  sec:  0.7694547176361084
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.05279111862182617

in edges time spent  0.1703624725341797
local to global src and eids time spent  0.31036949157714844
time gen tails  0.0763406753540039
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1388993263244629

in edges time spent  0.6165006160736084
local to global src and eids time spent  0.9625604152679443
time gen tails  0.1493978500366211
res  length 4
block collection to dataloader spend  1.7642974853515625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09401750564575195  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183008670806885  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182671070098877  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09545135498046875  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.041752338409424  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.045505046844482  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10222578048706055  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.38862133026123  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.39482831954956  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10534811019897461  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.01466703414917  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.01797866821289  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11092710494995117  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.7588406801223755
pure train time :  0.5659310817718506
train time :  0.8103413581848145
end to end time :  6.1476452350616455
connection check time:  2.9199113845825195
block generation time  1.4845340251922607
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005731582641601562
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.016298770904541016
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7978470325469971
len local_batched_seeds_list  4
partition total batch output list spend :  0.956498384475708
self.buckets_partition() spend  sec:  0.8141803741455078
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.049253225326538086

in edges time spent  0.157151460647583
local to global src and eids time spent  0.3005976676940918
time gen tails  0.07174086570739746
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14082098007202148

in edges time spent  0.5819096565246582
local to global src and eids time spent  0.9279017448425293
time gen tails  0.14678955078125
res  length 4
block collection to dataloader spend  1.2159347534179688e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0936579704284668  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182585716247559  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.181604862213135  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09524726867675781  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.055811882019043  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.059564590454102  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10238265991210938  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.381325721740723  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.386621475219727  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10463619232177734  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.975777626037598  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.978811740875244  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11065673828125  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.7391819953918457
pure train time :  0.5729882717132568
train time :  0.8120269775390625
end to end time :  6.00138521194458
connection check time:  2.746460437774658
block generation time  1.4680497646331787
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005452632904052734
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014685630798339844
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7575249671936035
len local_batched_seeds_list  4
partition total batch output list spend :  0.9136524200439453
self.buckets_partition() spend  sec:  0.7722420692443848
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04839634895324707

in edges time spent  0.15528464317321777
local to global src and eids time spent  0.18984174728393555
time gen tails  0.05267739295959473
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13813090324401855

in edges time spent  0.5630514621734619
local to global src and eids time spent  0.9261088371276855
time gen tails  0.14614415168762207
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09356975555419922  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185978412628174  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185641765594482  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09490203857421875  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044536113739014  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.048288822174072  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10222959518432617  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.370872020721436  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.37616777420044  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10465002059936523  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018238544464111  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.02204704284668  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11110639572143555  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.724770188331604
pure train time :  0.5730152130126953
train time :  0.8090908527374268
end to end time :  5.77348780632019
connection check time:  2.58978533744812
block generation time  1.446772575378418
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005886554718017578
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014310359954833984
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.755399227142334
len local_batched_seeds_list  4
partition total batch output list spend :  0.9116353988647461
self.buckets_partition() spend  sec:  0.7697434425354004
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04888653755187988

in edges time spent  0.15562081336975098
local to global src and eids time spent  0.2982308864593506
time gen tails  0.07161951065063477
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13857054710388184

in edges time spent  0.5646142959594727
local to global src and eids time spent  0.9158480167388916
time gen tails  0.14597773551940918
res  length 4
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09389591217041016  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.149136543273926  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.14879846572876  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09488058090209961  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.047813892364502  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.05156660079956  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1023406982421875  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.391931056976318  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.397226810455322  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10463476181030273  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.975666522979736  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.978978157043457  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11083841323852539  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.7137478590011597
pure train time :  0.5398941040039062
train time :  0.7828514575958252
end to end time :  5.878895998001099
connection check time:  2.7117297649383545
block generation time  1.4584336280822754
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005981922149658203
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014434337615966797
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7378208637237549
len local_batched_seeds_list  4
partition total batch output list spend :  0.8930137157440186
self.buckets_partition() spend  sec:  0.7522883415222168
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.048435211181640625

in edges time spent  0.15689730644226074
local to global src and eids time spent  0.29880285263061523
time gen tails  0.07190108299255371
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1369788646697998

in edges time spent  0.5869131088256836
local to global src and eids time spent  0.935577392578125
time gen tails  0.1533973217010498
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09378194808959961  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.193642139434814  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.192662715911865  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09511709213256836  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040197372436523  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043950080871582  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10224628448486328  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.388180255889893  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.393476009368896  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10555791854858398  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.020404815673828  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.02414846420288  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11109638214111328  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.702324390411377
pure train time :  0.5477766990661621
train time :  0.8100690841674805
end to end time :  5.962249755859375
connection check time:  2.76822829246521
block generation time  1.4723689556121826
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005619525909423828
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01463937759399414
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7577664852142334
len local_batched_seeds_list  4
partition total batch output list spend :  0.9130301475524902
self.buckets_partition() spend  sec:  0.7724459171295166
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.05130887031555176

in edges time spent  0.1608872413635254
local to global src and eids time spent  0.30004167556762695
time gen tails  0.07238912582397461
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13701820373535156

in edges time spent  0.5905697345733643
local to global src and eids time spent  0.9384210109710693
time gen tails  0.14809894561767578
res  length 4
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09390878677368164  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182850360870361  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182512283325195  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09444904327392578  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.042295455932617  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046048164367676  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1025080680847168  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.43004846572876  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.435406684875488  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058187484741211  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.010979175567627  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.01472282409668  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11143064498901367  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.6906272172927856
pure train time :  0.5748224258422852
train time :  0.7986767292022705
end to end time :  5.967077732086182
connection check time:  2.7692058086395264
block generation time  1.4704456329345703
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005559921264648438
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01475977897644043
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.755347728729248
len local_batched_seeds_list  4
partition total batch output list spend :  0.917288064956665
self.buckets_partition() spend  sec:  0.7701427936553955
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04876708984375

in edges time spent  0.16543340682983398
local to global src and eids time spent  0.30478858947753906
time gen tails  0.07285261154174805
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1367950439453125

in edges time spent  0.5691080093383789
local to global src and eids time spent  0.9422311782836914
time gen tails  0.14707422256469727
res  length 4
block collection to dataloader spend  1.33514404296875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0940089225769043  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184309005737305  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183970928192139  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09453821182250977  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.045037746429443  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.048790454864502  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10243940353393555  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.394224166870117  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.399519920349121  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10465240478515625  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.019670963287354  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.023479461669922  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.111114501953125  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.673858642578125
pure train time :  0.5370798110961914
train time :  0.7896170616149902
end to end time :  5.937342643737793
connection check time:  2.7600622177124023
block generation time  1.4544212818145752
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006413459777832031
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014114141464233398
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7786595821380615
len local_batched_seeds_list  4
partition total batch output list spend :  0.9350440502166748
self.buckets_partition() spend  sec:  0.7928085327148438
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04928946495056152

in edges time spent  0.15915894508361816
local to global src and eids time spent  0.29977869987487793
time gen tails  0.07173514366149902
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13818907737731934

in edges time spent  0.5733320713043213
local to global src and eids time spent  0.93222975730896
time gen tails  0.1475813388824463
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09384918212890625  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183038711547852  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182700157165527  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0948491096496582  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.033961772918701  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.03771448135376  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10255622863769531  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.397866249084473  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.40323781967163  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058201789855957  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.02001428604126  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.023757934570312  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11137199401855469  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.668472409248352
pure train time :  0.5542500019073486
train time :  0.7887189388275146
end to end time :  5.950135231018066
connection check time:  2.746306896209717
block generation time  1.4622161388397217
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005915164947509766
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01452326774597168
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7404847145080566
len local_batched_seeds_list  4
partition total batch output list spend :  0.896172285079956
self.buckets_partition() spend  sec:  0.7550396919250488
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04882168769836426

in edges time spent  0.15557026863098145
local to global src and eids time spent  0.30003833770751953
time gen tails  0.07172012329101562
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13805031776428223

in edges time spent  0.5697298049926758
local to global src and eids time spent  0.9251768589019775
time gen tails  0.14881110191345215
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09391021728515625  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.147855758666992  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.146874904632568  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09510660171508789  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.047954559326172  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.05170726776123  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1030573844909668  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.446655750274658  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.451951503753662  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464096069335938  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.981735706329346  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.985047340393066  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11138916015625  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.657268762588501
pure train time :  0.591853141784668
train time :  0.8183419704437256
end to end time :  5.931595325469971
connection check time:  2.733544111251831
block generation time  1.4663059711456299
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005397796630859375
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014357805252075195
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7524478435516357
len local_batched_seeds_list  4
partition total batch output list spend :  0.9081161022186279
self.buckets_partition() spend  sec:  0.7668459415435791
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.048769474029541016

in edges time spent  0.15581178665161133
local to global src and eids time spent  0.29869556427001953
time gen tails  0.07207107543945312
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13741230964660645

in edges time spent  0.5672802925109863
local to global src and eids time spent  0.9185938835144043
time gen tails  0.14672327041625977
res  length 4
block collection to dataloader spend  1.0967254638671875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0937662124633789  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184648990631104  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184311389923096  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09470033645629883  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.039612293243408  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043365001678467  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1023106575012207  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.387946128845215  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.394153118133545  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1053462028503418  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.013368606567383  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.017177104949951  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11136150360107422  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.641570806503296
pure train time :  0.6128067970275879
train time :  0.8179714679718018
end to end time :  5.898757457733154
connection check time:  2.7143352031707764
block generation time  1.437666416168213
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005946159362792969
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.016098499298095703
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7248413562774658
len local_batched_seeds_list  4
partition total batch output list spend :  0.795917272567749
self.buckets_partition() spend  sec:  0.7409732341766357
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04704856872558594

in edges time spent  0.15596508979797363
local to global src and eids time spent  0.29790449142456055
time gen tails  0.07119321823120117
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1375868320465088

in edges time spent  0.5617458820343018
local to global src and eids time spent  0.9169776439666748
time gen tails  0.14431381225585938
res  length 4
block collection to dataloader spend  1.0967254638671875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09397602081298828  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184143543243408  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18390703201294  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09506511688232422  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.033944129943848  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.037696838378906  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10274314880371094  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.39633321762085  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.401628971099854  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10465049743652344  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.01884937286377  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.022657871246338  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11111068725585938  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.6360790729522705
pure train time :  0.5661532878875732
train time :  0.7946732044219971
end to end time :  5.740377187728882
connection check time:  2.696398973464966
block generation time  1.437281847000122
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005793571472167969
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014423370361328125
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7493855953216553
len local_batched_seeds_list  4
partition total batch output list spend :  0.9044957160949707
self.buckets_partition() spend  sec:  0.7638504505157471
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.05026721954345703

in edges time spent  0.16094112396240234
local to global src and eids time spent  0.30060315132141113
time gen tails  0.07247734069824219
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13933253288269043

in edges time spent  0.5821473598480225
local to global src and eids time spent  0.9479825496673584
time gen tails  0.1509687900543213
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0940103530883789  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.187075138092041  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186736583709717  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09544992446899414  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040628433227539  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044381141662598  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10257863998413086  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.455808162689209  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.461149215698242  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10465049743652344  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.019124507904053  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.022436141967773  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11069965362548828  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.622873306274414
pure train time :  0.5753817558288574
train time :  0.8023314476013184
end to end time :  5.968334674835205
connection check time:  2.776974678039551
block generation time  1.4705796241760254
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005724430084228516
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015392303466796875
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7319433689117432
len local_batched_seeds_list  4
partition total batch output list spend :  0.888634443283081
self.buckets_partition() spend  sec:  0.7473788261413574
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.049851417541503906

in edges time spent  0.15851449966430664
local to global src and eids time spent  0.305525541305542
time gen tails  0.07273983955383301
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14205527305603027

in edges time spent  0.5939438343048096
local to global src and eids time spent  0.9351956844329834
time gen tails  0.14884042739868164
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09345674514770508  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182164192199707  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.181826114654541  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09440994262695312  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.038288593292236  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.042041301727295  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10229730606079102  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.399083137512207  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.404378890991211  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464763641357422  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.019354343414307  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.023162841796875  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1110992431640625  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.612978219985962
pure train time :  0.5857572555541992
train time :  0.807452917098999
end to end time :  5.963162660598755
connection check time:  2.783951997756958
block generation time  1.4691123962402344
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005528926849365234
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014545679092407227
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7502553462982178
len local_batched_seeds_list  4
partition total batch output list spend :  0.9245491027832031
self.buckets_partition() spend  sec:  0.7648940086364746
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.05031085014343262

in edges time spent  0.1553633213043213
local to global src and eids time spent  0.2991456985473633
time gen tails  0.07218050956726074
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14042305946350098

in edges time spent  0.5719811916351318
local to global src and eids time spent  0.9243326187133789
time gen tails  0.14811038970947266
res  length 4
block collection to dataloader spend  1.33514404296875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09397315979003906  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184403419494629  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184065341949463  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09471940994262695  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.036502361297607  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040255069732666  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10247230529785156  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.3741135597229  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.379409313201904  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1046442985534668  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.014380931854248  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.017692565917969  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11088418960571289  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.6073721647262573
pure train time :  0.5550065040588379
train time :  0.7963156700134277
end to end time :  5.9244513511657715
connection check time:  2.7334861755371094
block generation time  1.4562554359436035
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005567073822021484
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014375925064086914
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7506256103515625
len local_batched_seeds_list  4
partition total batch output list spend :  0.9063076972961426
self.buckets_partition() spend  sec:  0.765042781829834
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.049822092056274414

in edges time spent  0.1656355857849121
local to global src and eids time spent  0.3046572208404541
time gen tails  0.07316946983337402
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.141035795211792

in edges time spent  0.5701432228088379
local to global src and eids time spent  0.9386773109436035
time gen tails  0.14732122421264648
res  length 4
block collection to dataloader spend  1.4543533325195312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09377670288085938  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.193617343902588  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.19327974319458  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09482765197753906  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04253339767456  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04628610610962  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10237455368041992  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.378541946411133  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.383837699890137  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1046438217163086  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.012014389038086  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.015822887420654  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11137104034423828  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.5964981317520142
pure train time :  0.562002420425415
train time :  0.7907483577728271
end to end time :  5.970307111740112
connection check time:  2.76814866065979
block generation time  1.4889917373657227
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005829334259033203
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014374971389770508
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7860329151153564
len local_batched_seeds_list  4
partition total batch output list spend :  0.9414451122283936
self.buckets_partition() spend  sec:  0.8004436492919922
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04864382743835449

in edges time spent  0.15572357177734375
local to global src and eids time spent  0.2995171546936035
time gen tails  0.07198667526245117
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14087462425231934

in edges time spent  0.5653746128082275
local to global src and eids time spent  0.9340031147003174
time gen tails  0.1492900848388672
res  length 4
block collection to dataloader spend  1.1444091796875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09385204315185547  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.141699314117432  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.14100456237793  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09486198425292969  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04725980758667  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.051012516021729  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10258245468139648  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.432103633880615  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.438310623168945  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10528850555419922  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.010499000549316  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.013810634613037  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1107029914855957  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.5856149196624756
pure train time :  0.563096284866333
train time :  0.7865157127380371
end to end time :  5.95899510383606
connection check time:  2.742377758026123
block generation time  1.4738919734954834
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005428791046142578
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014049530029296875
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7241652011871338
len local_batched_seeds_list  4
partition total batch output list spend :  0.8789997100830078
self.buckets_partition() spend  sec:  0.7382490634918213
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04830765724182129

in edges time spent  0.15499162673950195
local to global src and eids time spent  0.298325777053833
time gen tails  0.07189607620239258
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13953232765197754

in edges time spent  0.5648853778839111
local to global src and eids time spent  0.9284870624542236
time gen tails  0.14842820167541504
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09362983703613281  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18402910232544  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.1830472946167  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09513711929321289  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044474601745605  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04857587814331  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10255193710327148  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.458298206329346  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.46364688873291  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10527753829956055  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.021686553955078  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.02543020248413  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11121463775634766  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.580519676208496
pure train time :  0.6495144367218018
train time :  0.8836705684661865
end to end time :  5.96200966835022
connection check time:  2.7247371673583984
block generation time  1.4535329341888428
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005865097045898438
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014296293258666992
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7628958225250244
len local_batched_seeds_list  4
partition total batch output list spend :  0.9177906513214111
self.buckets_partition() spend  sec:  0.7772266864776611
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04994368553161621

in edges time spent  0.1566922664642334
local to global src and eids time spent  0.3015921115875244
time gen tails  0.07317113876342773
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14176249504089355

in edges time spent  0.5805819034576416
local to global src and eids time spent  0.9270763397216797
time gen tails  0.14746618270874023
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09410476684570312  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18535041809082  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185012817382812  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09435415267944336  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.036234855651855  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040154933929443  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10225725173950195  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.403873443603516  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.40916919708252  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10528278350830078  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.013795375823975  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.017603874206543  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11121368408203125  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.5716438293457031
pure train time :  0.5278887748718262
train time :  0.7865593433380127
end to end time :  5.921716928482056
connection check time:  2.7492728233337402
block generation time  1.4533941745758057
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005624294281005859
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014690399169921875
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7609233856201172
len local_batched_seeds_list  4
partition total batch output list spend :  0.915534496307373
self.buckets_partition() spend  sec:  0.7756545543670654
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.048650503158569336

in edges time spent  0.16272926330566406
local to global src and eids time spent  0.3076190948486328
time gen tails  0.0793156623840332
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14332938194274902

in edges time spent  0.6047587394714355
local to global src and eids time spent  0.9486019611358643
time gen tails  0.14818835258483887
res  length 4
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09416055679321289  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186737060546875  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186399459838867  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09474897384643555  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.03837537765503  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.042128086090088  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10240936279296875  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.457931995391846  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.46322774887085  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10554695129394531  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.971707820892334  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.975516319274902  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11105775833129883  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.5631695985794067
pure train time :  0.5318160057067871
train time :  0.7814972400665283
end to end time :  5.99689507484436
connection check time:  2.8213112354278564
block generation time  1.4633405208587646
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005898475646972656
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01537775993347168
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7564480304718018
len local_batched_seeds_list  4
partition total batch output list spend :  0.9114677906036377
self.buckets_partition() spend  sec:  0.7718591690063477
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.05263233184814453

in edges time spent  0.1592566967010498
local to global src and eids time spent  0.29968690872192383
time gen tails  0.07226395606994629
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14613962173461914

in edges time spent  0.5835874080657959
local to global src and eids time spent  0.9242510795593262
time gen tails  0.1493675708770752
res  length 4
block collection to dataloader spend  1.1205673217773438e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09401559829711914  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184969425201416  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184632301330566  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0947265625  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044408798217773  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.048161506652832  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10228157043457031  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.389363288879395  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.394659042358398  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1046457290649414  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.016767501831055  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.020511150360107  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1110987663269043  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.5558372735977173
pure train time :  0.5189802646636963
train time :  0.7827849388122559
end to end time :  5.923119306564331
connection check time:  2.7565360069274902
block generation time  1.454223871231079
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006642341613769531
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014391422271728516
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7570364475250244
len local_batched_seeds_list  4
partition total batch output list spend :  0.9115347862243652
self.buckets_partition() spend  sec:  0.7714622020721436
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04867219924926758

in edges time spent  0.15692615509033203
local to global src and eids time spent  0.2999885082244873
time gen tails  0.07203006744384766
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13866782188415527

in edges time spent  0.5643434524536133
local to global src and eids time spent  0.9225728511810303
time gen tails  0.15020489692687988
res  length 4
block collection to dataloader spend  1.239776611328125e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09400367736816406  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183634281158447  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18329668045044  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09502410888671875  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.037858486175537  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.041937828063965  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10223627090454102  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.403182983398438  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.409182071685791  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10527944564819336  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9827561378479  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.986067771911621  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1112675666809082  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.5477299690246582
pure train time :  0.5687360763549805
train time :  0.8124785423278809
end to end time :  5.939279317855835
connection check time:  2.746814250946045
block generation time  1.4524943828582764
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.00057220458984375
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014335870742797852
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7802329063415527
len local_batched_seeds_list  4
partition total batch output list spend :  0.9357576370239258
self.buckets_partition() spend  sec:  0.7946069240570068
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04840874671936035

in edges time spent  0.1559760570526123
local to global src and eids time spent  0.29906439781188965
time gen tails  0.07261157035827637
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14058709144592285

in edges time spent  0.5663127899169922
local to global src and eids time spent  0.9236056804656982
time gen tails  0.14730405807495117
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0938720703125  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.152615547180176  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.152278423309326  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09486913681030273  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.042195796966553  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.045948505401611  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10250520706176758  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.456040859222412  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.461336612701416  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10582113265991211  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.015772819519043  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.019581317901611  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11135578155517578  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.53963303565979
pure train time :  0.5857462882995605
train time :  0.814948320388794
end to end time :  5.973405122756958
connection check time:  2.7246878147125244
block generation time  1.4803168773651123
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005433559417724609
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014531612396240234
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7677652835845947
len local_batched_seeds_list  4
partition total batch output list spend :  0.9242026805877686
self.buckets_partition() spend  sec:  0.7823367118835449
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04950904846191406

in edges time spent  0.1573331356048584
local to global src and eids time spent  0.3009631633758545
time gen tails  0.07308816909790039
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14144325256347656

in edges time spent  0.5775294303894043
local to global src and eids time spent  0.9391601085662842
time gen tails  0.15016818046569824
res  length 4
block collection to dataloader spend  1.1205673217773438e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09400224685668945  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184853076934814  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184515476226807  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09487009048461914  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.036259651184082  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04001235961914  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10259342193603516  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.42726182937622  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.432623863220215  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464096069335938  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.981756210327148  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.985564708709717  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11107540130615234  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.5337729454040527
pure train time :  0.5771327018737793
train time :  0.812183141708374
end to end time :  6.004288196563721
connection check time:  2.7674102783203125
block generation time  1.4830751419067383
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005731582641601562
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014508962631225586
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7525713443756104
len local_batched_seeds_list  4
partition total batch output list spend :  0.9096601009368896
self.buckets_partition() spend  sec:  0.7671146392822266
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04870963096618652

in edges time spent  0.1557633876800537
local to global src and eids time spent  0.29894208908081055
time gen tails  0.07274389266967773
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13806676864624023

in edges time spent  0.5675199031829834
local to global src and eids time spent  0.9265210628509521
time gen tails  0.1475365161895752
res  length 4
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09392404556274414  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.156558990478516  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.156221866607666  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09482860565185547  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.051219940185547  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.054972648620605  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1023111343383789  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.430382251739502  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.435678005218506  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10582113265991211  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.004991054534912  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.00879955291748  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11194992065429688  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.5240765810012817
pure train time :  0.5789172649383545
train time :  0.8080508708953857
end to end time :  5.942070245742798
connection check time:  2.72713565826416
block generation time  1.4777638912200928
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005724430084228516
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014507770538330078
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7562000751495361
len local_batched_seeds_list  4
partition total batch output list spend :  0.9126427173614502
self.buckets_partition() spend  sec:  0.7707524299621582
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.049959421157836914

in edges time spent  0.15681672096252441
local to global src and eids time spent  0.29833436012268066
time gen tails  0.07268428802490234
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1376485824584961

in edges time spent  0.573122501373291
local to global src and eids time spent  0.9385390281677246
time gen tails  0.1500101089477539
res  length 4
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09396028518676758  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.150760650634766  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.150424003601074  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09484577178955078  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040796756744385  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044549465179443  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10233497619628906  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.398531436920166  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.40382719039917  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464334487915039  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.982203960418701  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9860124588012695  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11108541488647461  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.5229318141937256
pure train time :  0.5619354248046875
train time :  0.7999024391174316
end to end time :  5.95224404335022
connection check time:  2.7524807453155518
block generation time  1.4699151515960693
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005533695220947266
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014497518539428711
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7555520534515381
len local_batched_seeds_list  4
partition total batch output list spend :  0.9125707149505615
self.buckets_partition() spend  sec:  0.770089864730835
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.0497744083404541

in edges time spent  0.15636372566223145
local to global src and eids time spent  0.29877591133117676
time gen tails  0.07211971282958984
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14167380332946777

in edges time spent  0.5711953639984131
local to global src and eids time spent  0.9389646053314209
time gen tails  0.15016818046569824
res  length 4
block collection to dataloader spend  1.239776611328125e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09404134750366211  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18467092514038  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184333324432373  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09552621841430664  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.049871921539307  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.053624629974365  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10273361206054688  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.453536033630371  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.458831787109375  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464620590209961  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.012435913085938  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.015747547149658  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11081933975219727  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.5129469633102417
pure train time :  0.5672817230224609
train time :  0.8055362701416016
end to end time :  5.954212188720703
connection check time:  2.755150079727173
block generation time  1.4625952243804932
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005805492401123047
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014376401901245117
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.745941162109375
len local_batched_seeds_list  4
partition total batch output list spend :  0.9013674259185791
self.buckets_partition() spend  sec:  0.760359525680542
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04887056350708008

in edges time spent  0.1555492877960205
local to global src and eids time spent  0.2982449531555176
time gen tails  0.072296142578125
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14008474349975586

in edges time spent  0.5678882598876953
local to global src and eids time spent  0.9242174625396729
time gen tails  0.1469721794128418
res  length 4
block collection to dataloader spend  1.0967254638671875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09415483474731445  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185171127319336  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184833526611328  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09550666809082031  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.047048568725586  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.050801277160645  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10233259201049805  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.426970958709717  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.43226671218872  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464000701904297  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.975396156311035  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.978707790374756  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11067008972167969  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.5088344812393188
pure train time :  0.5574386119842529
train time :  0.8017354011535645
end to end time :  5.921740293502808
connection check time:  2.7232906818389893
block generation time  1.477046251296997
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005712509155273438
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014572858810424805
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7464089393615723
len local_batched_seeds_list  4
partition total batch output list spend :  0.9022212028503418
self.buckets_partition() spend  sec:  0.7610139846801758
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.05002284049987793

in edges time spent  0.1573472023010254
local to global src and eids time spent  0.3020315170288086
time gen tails  0.07373619079589844
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.14103984832763672

in edges time spent  0.5766594409942627
local to global src and eids time spent  0.9233591556549072
time gen tails  0.15284085273742676
res  length 4
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09344720840454102  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185146808624268  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184998035430908  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09509038925170898  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.039048194885254  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.042800903320312  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10279035568237305  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.431468963623047  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.436815738677979  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1046442985534668  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.98406982421875  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9871039390563965  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11068391799926758  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.501254677772522
pure train time :  0.554466724395752
train time :  0.7860698699951172
end to end time :  5.9489195346832275
connection check time:  2.756382942199707
block generation time  1.486429214477539
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005509853363037109
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014364480972290039
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7412087917327881
len local_batched_seeds_list  4
partition total batch output list spend :  0.9088327884674072
self.buckets_partition() spend  sec:  0.7556073665618896
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.054767608642578125

in edges time spent  0.16012930870056152
local to global src and eids time spent  0.30301523208618164
time gen tails  0.07299494743347168
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13671326637268066

in edges time spent  0.5624563694000244
local to global src and eids time spent  0.8285689353942871
time gen tails  0.10812234878540039
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09356021881103516  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184022903442383  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183684825897217  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09458780288696289  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046351432800293  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.050104141235352  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10252952575683594  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.4320707321167  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.437366485595703  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10555410385131836  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.981997489929199  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.98530912399292  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11067581176757812  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4954756498336792
pure train time :  0.54288649559021
train time :  0.7738873958587646
end to end time :  5.749533414840698
connection check time:  2.5965631008148193
block generation time  1.4524025917053223
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005533695220947266
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015593528747558594
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7336933612823486
len local_batched_seeds_list  4
partition total batch output list spend :  0.8036236763000488
self.buckets_partition() spend  sec:  0.7493183612823486
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04888486862182617

in edges time spent  0.15589261054992676
local to global src and eids time spent  0.29798173904418945
time gen tails  0.07212352752685547
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13893365859985352

in edges time spent  0.5712902545928955
local to global src and eids time spent  0.9073853492736816
time gen tails  0.14470362663269043
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09420013427734375  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.187164783477783  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18661117553711  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0943760871887207  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.033401012420654  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.037153720855713  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10245847702026367  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.400447368621826  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.405820846557617  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058206558227539  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018046379089355  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.021790027618408  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1113581657409668  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4924466609954834
pure train time :  0.5178711414337158
train time :  0.769493818283081
end to end time :  5.7238664627075195
connection check time:  2.6973371505737305
block generation time  1.4341702461242676
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005588531494140625
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014142513275146484
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7413280010223389
len local_batched_seeds_list  4
partition total batch output list spend :  0.8942215442657471
self.buckets_partition() spend  sec:  0.7555043697357178
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04857182502746582

in edges time spent  0.15389657020568848
local to global src and eids time spent  0.2961857318878174
time gen tails  0.07125067710876465
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1356523036956787

in edges time spent  0.5640857219696045
local to global src and eids time spent  0.92344069480896
time gen tails  0.1465308666229248
res  length 4
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09391355514526367  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.147956848144531  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.146975994110107  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09509611129760742  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.042051315307617  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046152591705322  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10256338119506836  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.454237461090088  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.459586143493652  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058201789855957  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.979990005493164  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.983733654022217  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11133861541748047  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4872572422027588
pure train time :  0.5370090007781982
train time :  0.7881348133087158
end to end time :  5.843968152999878
connection check time:  2.705029010772705
block generation time  1.4359543323516846
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0007789134979248047
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014287710189819336
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7258138656616211
len local_batched_seeds_list  4
partition total batch output list spend :  0.8789432048797607
self.buckets_partition() spend  sec:  0.740149974822998
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04749345779418945

in edges time spent  0.15299606323242188
local to global src and eids time spent  0.2959926128387451
time gen tails  0.0709230899810791
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13460683822631836

in edges time spent  0.5292353630065918
local to global src and eids time spent  0.7405846118927002
time gen tails  0.09494900703430176
res  length 4
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09406709671020508  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186800956726074  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186463832855225  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0950465202331543  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043742179870605  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.047494888305664  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10234403610229492  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.399858474731445  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.40515422821045  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.104644775390625  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.981861114501953  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.985172748565674  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11068344116210938  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4826042652130127
pure train time :  0.5202679634094238
train time :  0.7995929718017578
end to end time :  5.574306011199951
connection check time:  2.4327785968780518
block generation time  1.4399256706237793
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005919933319091797
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01466512680053711
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.762885570526123
len local_batched_seeds_list  4
partition total batch output list spend :  0.9175176620483398
self.buckets_partition() spend  sec:  0.7775824069976807
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04785728454589844

in edges time spent  0.15355730056762695
local to global src and eids time spent  0.29566383361816406
time gen tails  0.07145190238952637
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1360464096069336

in edges time spent  0.5542800426483154
local to global src and eids time spent  0.9012954235076904
time gen tails  0.14399361610412598
res  length 4
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09417438507080078  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186125755310059  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18578815460205  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09552812576293945  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.054748058319092  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.059295654296875  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10253190994262695  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.399833679199219  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.405209064483643  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10510873794555664  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.972066402435303  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.975100517272949  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11065959930419922  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4731303453445435
pure train time :  0.5457963943481445
train time :  0.8011863231658936
end to end time :  5.826014995574951
connection check time:  2.6647956371307373
block generation time  1.4284934997558594
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006380081176757812
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014699697494506836
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.73634934425354
len local_batched_seeds_list  4
partition total batch output list spend :  0.8910050392150879
self.buckets_partition() spend  sec:  0.751082181930542
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04764413833618164

in edges time spent  0.15350890159606934
local to global src and eids time spent  0.29585957527160645
time gen tails  0.07100939750671387
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13567304611206055

in edges time spent  0.5611894130706787
local to global src and eids time spent  0.919539213180542
time gen tails  0.14737844467163086
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09351062774658203  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.181371212005615  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.181034564971924  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09475946426391602  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043196678161621  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04694938659668  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10261201858520508  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.430312156677246  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.435670375823975  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464096069335938  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.98026704788208  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.983578681945801  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11110544204711914  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4656635522842407
pure train time :  0.5393044948577881
train time :  0.777829647064209
end to end time :  5.838343143463135
connection check time:  2.697953701019287
block generation time  1.4564995765686035
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005490779876708984
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014550924301147461
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7412176132202148
len local_batched_seeds_list  4
partition total batch output list spend :  0.8960366249084473
self.buckets_partition() spend  sec:  0.7558014392852783
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.0485231876373291

in edges time spent  0.15546655654907227
local to global src and eids time spent  0.29540562629699707
time gen tails  0.07180619239807129
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13798165321350098

in edges time spent  0.556511640548706
local to global src and eids time spent  0.9180634021759033
time gen tails  0.14697813987731934
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09379339218139648  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.181215763092041  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.180878162384033  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0945281982421875  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.048975944519043  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.052728652954102  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10231304168701172  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.391138553619385  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.396434307098389  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1051325798034668  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.974733829498291  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9777679443359375  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1114654541015625  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.463962197303772
pure train time :  0.5702919960021973
train time :  0.8067474365234375
end to end time :  5.869364500045776
connection check time:  2.6977710723876953
block generation time  1.451143741607666
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005781650543212891
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014488697052001953
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7391295433044434
len local_batched_seeds_list  4
partition total batch output list spend :  0.8926982879638672
self.buckets_partition() spend  sec:  0.7536602020263672
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04938173294067383

in edges time spent  0.1551969051361084
local to global src and eids time spent  0.29671406745910645
time gen tails  0.07150983810424805
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13860416412353516

in edges time spent  0.5695154666900635
local to global src and eids time spent  0.9181525707244873
time gen tails  0.1474475860595703
res  length 4
block collection to dataloader spend  1.1205673217773438e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09354639053344727  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185653686523438  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185316562652588  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0947713851928711  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04130506515503  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.045057773590088  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10232400894165039  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.397112846374512  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.402408599853516  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10534095764160156  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.97302770614624  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.976061820983887  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11065912246704102  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4609272480010986
pure train time :  0.5424625873565674
train time :  0.7813501358032227
end to end time :  5.854547739028931
connection check time:  2.71449613571167
block generation time  1.448737621307373
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006012916564941406
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01470184326171875
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7334418296813965
len local_batched_seeds_list  4
partition total batch output list spend :  0.8875701427459717
self.buckets_partition() spend  sec:  0.7481746673583984
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04894900321960449

in edges time spent  0.1545095443725586
local to global src and eids time spent  0.298673152923584
time gen tails  0.07243847846984863
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13828682899475098

in edges time spent  0.571648120880127
local to global src and eids time spent  0.9212968349456787
time gen tails  0.14709758758544922
res  length 4
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09342384338378906  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184078216552734  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183098316192627  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09521102905273438  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.048909664154053  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.052662372589111  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1022796630859375  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.40403699874878  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.409332752227783  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10582113265991211  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.987887382507324  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.991199016571045  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11134195327758789  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4531774520874023
pure train time :  0.5518050193786621
train time :  0.7924883365631104
end to end time :  5.869508266448975
connection check time:  2.7222070693969727
block generation time  1.4535470008850098
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005393028259277344
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014302253723144531
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7360916137695312
len local_batched_seeds_list  4
partition total batch output list spend :  0.8902771472930908
self.buckets_partition() spend  sec:  0.7504479885101318
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04858827590942383

in edges time spent  0.1550586223602295
local to global src and eids time spent  0.2987837791442871
time gen tails  0.07229018211364746
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13783693313598633

in edges time spent  0.5643265247344971
local to global src and eids time spent  0.9193027019500732
time gen tails  0.14730381965637207
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09372282028198242  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.181595802307129  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.181257724761963  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09475994110107422  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.041822910308838  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.045575618743896  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10228586196899414  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.40633773803711  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.411633491516113  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1052861213684082  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.013447284698486  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.017255783081055  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1110992431640625  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4492990970611572
pure train time :  0.5643212795257568
train time :  0.7999367713928223
end to end time :  5.8717873096466064
connection check time:  2.7130963802337646
block generation time  1.4512302875518799
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005986690521240234
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014527082443237305
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7399752140045166
len local_batched_seeds_list  4
partition total batch output list spend :  0.894355297088623
self.buckets_partition() spend  sec:  0.75453782081604
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.048393964767456055

in edges time spent  0.15480446815490723
local to global src and eids time spent  0.2981984615325928
time gen tails  0.07252287864685059
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1391282081604004

in edges time spent  0.5689523220062256
local to global src and eids time spent  0.9214422702789307
time gen tails  0.14743280410766602
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09417867660522461  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.193615913391113  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.193277835845947  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09477043151855469  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040003776550293  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043756484985352  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10225057601928711  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.434823989868164  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.440119743347168  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464096069335938  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.980076313018799  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.983884811401367  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11177968978881836  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4431769847869873
pure train time :  0.5045268535614014
train time :  0.7866437435150146
end to end time :  5.885839223861694
connection check time:  2.719907522201538
block generation time  1.4672446250915527
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005731582641601562
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01477670669555664
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7263534069061279
len local_batched_seeds_list  4
partition total batch output list spend :  0.8803987503051758
self.buckets_partition() spend  sec:  0.7411649227142334
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.048933982849121094

in edges time spent  0.15697312355041504
local to global src and eids time spent  0.2984616756439209
time gen tails  0.07255053520202637
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13804960250854492

in edges time spent  0.5659768581390381
local to global src and eids time spent  0.912407636642456
time gen tails  0.14449357986450195
res  length 4
block collection to dataloader spend  1.1682510375976562e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09401798248291016  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183584690093994  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18337106704712  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09512186050415039  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040404796600342  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.0441575050354  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10236215591430664  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.394960880279541  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.400256633758545  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058197021484375  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.011451244354248  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.015259742736816  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11144399642944336  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4387086629867554
pure train time :  0.5295431613922119
train time :  0.7841997146606445
end to end time :  5.8400866985321045
connection check time:  2.7053322792053223
block generation time  1.4524445533752441
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005905628204345703
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014288187026977539
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7379541397094727
len local_batched_seeds_list  4
partition total batch output list spend :  0.8920636177062988
self.buckets_partition() spend  sec:  0.7522764205932617
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04787731170654297

in edges time spent  0.15505027770996094
local to global src and eids time spent  0.2991034984588623
time gen tails  0.07227206230163574
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1387193202972412

in edges time spent  0.5777208805084229
local to global src and eids time spent  0.9195826053619385
time gen tails  0.1468641757965088
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09409046173095703  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.187471866607666  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.187134265899658  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09444856643676758  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.035009860992432  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.03876256942749  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10231828689575195  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.394721031188965  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.400016784667969  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10465049743652344  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018089771270752  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.021833419799805  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11110877990722656  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4333512783050537
pure train time :  0.5657727718353271
train time :  0.8069696426391602
end to end time :  5.917511224746704
connection check time:  2.7268447875976562
block generation time  1.4729578495025635
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005297660827636719
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015450716018676758
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7185909748077393
len local_batched_seeds_list  4
partition total batch output list spend :  0.7887411117553711
self.buckets_partition() spend  sec:  0.7340729236602783
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04764986038208008

in edges time spent  0.13660573959350586
local to global src and eids time spent  0.2980008125305176
time gen tails  0.07257914543151855
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1382753849029541

in edges time spent  0.5479633808135986
local to global src and eids time spent  0.8160848617553711
time gen tails  0.10748505592346191
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09395790100097656  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184957027435303  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184618949890137  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09475898742675781  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04222059249878  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.045973300933838  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10243797302246094  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.385690689086914  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.390986442565918  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10465288162231445  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.019004344940186  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.022315979003906  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11071252822875977  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4296348094940186
pure train time :  0.5147590637207031
train time :  0.770505428314209
end to end time :  5.56331467628479
connection check time:  2.529233455657959
block generation time  1.4545984268188477
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005676746368408203
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015274524688720703
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7167198657989502
len local_batched_seeds_list  4
partition total batch output list spend :  0.7859413623809814
self.buckets_partition() spend  sec:  0.7320287227630615
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04628419876098633

in edges time spent  0.1568434238433838
local to global src and eids time spent  0.298231840133667
time gen tails  0.07257723808288574
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13677215576171875

in edges time spent  0.5588269233703613
local to global src and eids time spent  0.916661262512207
time gen tails  0.1475992202758789
res  length 4
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09412193298339844  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184456825256348  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184177875518799  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09517383575439453  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.03949499130249  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043247699737549  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10254859924316406  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.429068088531494  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.434432029724121  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058206558227539  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.014811992645264  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018123626708984  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11155271530151367  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4273474216461182
pure train time :  0.5236544609069824
train time :  0.78360915184021
end to end time :  5.736570119857788
connection check time:  2.69685435295105
block generation time  1.4531457424163818
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005710124969482422
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01433253288269043
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7384166717529297
len local_batched_seeds_list  4
partition total batch output list spend :  0.8918673992156982
self.buckets_partition() spend  sec:  0.7527823448181152
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04849362373352051

in edges time spent  0.15467596054077148
local to global src and eids time spent  0.29814696311950684
time gen tails  0.07240104675292969
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1389014720916748

in edges time spent  0.5517027378082275
local to global src and eids time spent  0.8792402744293213
time gen tails  0.13936161994934082
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09365987777709961  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.1846022605896  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184394359588623  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09520149230957031  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.060293674468994  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.064046382904053  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10241937637329102  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.43637990951538  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.441675662994385  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10582113265991211  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.978316783905029  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.982125282287598  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11228466033935547  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4212195873260498
pure train time :  0.5156853199005127
train time :  0.7796664237976074
end to end time :  5.716402769088745
connection check time:  2.635222911834717
block generation time  1.393075942993164
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005638599395751953
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01428675651550293
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7104592323303223
len local_batched_seeds_list  4
partition total batch output list spend :  0.8631577491760254
self.buckets_partition() spend  sec:  0.724780797958374
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04785943031311035

in edges time spent  0.15350103378295898
local to global src and eids time spent  0.29497671127319336
time gen tails  0.07167577743530273
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13689517974853516

in edges time spent  0.5578906536102295
local to global src and eids time spent  0.9021832942962646
time gen tails  0.14499855041503906
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0939340591430664  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186275959014893  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185938358306885  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09474945068359375  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044072151184082  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04782485961914  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10249614715576172  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.380368709564209  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.385664463043213  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1046442985534668  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.01074743270874  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.014059066772461  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11080789566040039  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.418342113494873
pure train time :  0.519197940826416
train time :  0.7838549613952637
end to end time :  5.750460624694824
connection check time:  2.6696510314941406
block generation time  1.4209156036376953
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005574226379394531
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014449834823608398
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7394793033599854
len local_batched_seeds_list  4
partition total batch output list spend :  0.8931894302368164
self.buckets_partition() spend  sec:  0.7539622783660889
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.047774553298950195

in edges time spent  0.15357685089111328
local to global src and eids time spent  0.2954518795013428
time gen tails  0.07105660438537598
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1365959644317627

in edges time spent  0.5201916694641113
local to global src and eids time spent  0.7924835681915283
time gen tails  0.10568881034851074
res  length 4
block collection to dataloader spend  1.239776611328125e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09341192245483398  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.14249563217163  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.142158031463623  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09557294845581055  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.055381774902344  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.059134483337402  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10242271423339844  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.440338134765625  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.445633888244629  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10463857650756836  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.973761558532715  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9770731925964355  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11066579818725586  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4125959873199463
pure train time :  0.5040576457977295
train time :  0.7634975910186768
end to end time :  5.576879262924194
connection check time:  2.482774257659912
block generation time  1.423854112625122
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006170272827148438
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015358448028564453
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7337393760681152
len local_batched_seeds_list  4
partition total batch output list spend :  0.8039937019348145
self.buckets_partition() spend  sec:  0.7491295337677002
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04599881172180176

in edges time spent  0.15123486518859863
local to global src and eids time spent  0.292816162109375
time gen tails  0.07020044326782227
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13100671768188477

in edges time spent  0.5383317470550537
local to global src and eids time spent  0.8708305358886719
time gen tails  0.13952040672302246
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09383678436279297  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183868885040283  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182888507843018  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0951690673828125  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04521131515503  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.049312591552734  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10262298583984375  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.457354068756104  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.462649822235107  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10582160949707031  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.01682424545288  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.020567893981934  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11145353317260742  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.411327838897705
pure train time :  0.48992371559143066
train time :  0.7653210163116455
end to end time :  5.537715435028076
connection check time:  2.5811095237731934
block generation time  1.371272325515747
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005843639373779297
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014155149459838867
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.73699951171875
len local_batched_seeds_list  4
partition total batch output list spend :  0.8881511688232422
self.buckets_partition() spend  sec:  0.7511868476867676
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.0452578067779541

in edges time spent  0.1497187614440918
local to global src and eids time spent  0.29189300537109375
time gen tails  0.06913495063781738
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.12917304039001465

in edges time spent  0.5385241508483887
local to global src and eids time spent  0.8679690361022949
time gen tails  0.140641450881958
res  length 4
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09398221969604492  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185900211334229  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184919357299805  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09522008895874023  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043038845062256  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046791553497314  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10257673263549805  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.3924241065979  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.397807121276855  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058197021484375  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.984866619110107  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.988675117492676  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11171817779541016  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4078410863876343
pure train time :  0.49494385719299316
train time :  0.7685277462005615
end to end time :  5.617602348327637
connection check time:  2.580359697341919
block generation time  1.3674581050872803
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005488395690917969
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014487743377685547
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6806321144104004
len local_batched_seeds_list  4
partition total batch output list spend :  0.8325648307800293
self.buckets_partition() spend  sec:  0.6951603889465332
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.046816349029541016

in edges time spent  0.14925432205200195
local to global src and eids time spent  0.28812360763549805
time gen tails  0.06885337829589844
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13034605979919434

in edges time spent  0.5345628261566162
local to global src and eids time spent  0.8676443099975586
time gen tails  0.1393907070159912
res  length 4
block collection to dataloader spend  1.0967254638671875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09404611587524414  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182962417602539  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.181981563568115  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09513139724731445  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.042641639709473  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046742916107178  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10253334045410156  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.398781299591064  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.404077053070068  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058206558227539  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018840789794922  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.022152423858643  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11113882064819336  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.402439832687378
pure train time :  0.49298739433288574
train time :  0.7654509544372559
end to end time :  5.544519662857056
connection check time:  2.568817377090454
block generation time  1.3650383949279785
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005486011505126953
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013961553573608398
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6839501857757568
len local_batched_seeds_list  4
partition total batch output list spend :  0.8350050449371338
self.buckets_partition() spend  sec:  0.6979446411132812
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04577970504760742

in edges time spent  0.1494121551513672
local to global src and eids time spent  0.28833532333374023
time gen tails  0.06911873817443848
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1299142837524414

in edges time spent  0.5333554744720459
local to global src and eids time spent  0.8699142932891846
time gen tails  0.13892626762390137
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0936737060546875  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182600021362305  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18230152130127  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09523200988769531  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046093463897705  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.05019474029541  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10220766067504883  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.382990837097168  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.388286590576172  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10582113265991211  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.975980758666992  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9797892570495605  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11133766174316406  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3989943265914917
pure train time :  0.4969780445098877
train time :  0.7641890048980713
end to end time :  5.556345462799072
connection check time:  2.568958282470703
block generation time  1.3703501224517822
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005788803100585938
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014195442199707031
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.684396505355835
len local_batched_seeds_list  4
partition total batch output list spend :  0.8358592987060547
self.buckets_partition() spend  sec:  0.6986334323883057
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04558253288269043

in edges time spent  0.14824771881103516
local to global src and eids time spent  0.28910255432128906
time gen tails  0.06895112991333008
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13063621520996094

in edges time spent  0.5433719158172607
local to global src and eids time spent  0.8676557540893555
time gen tails  0.13952946662902832
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09400510787963867  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184384822845459  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183404445648193  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09520339965820312  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04069709777832  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044449806213379  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10230159759521484  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.399593353271484  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.404889106750488  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464334487915039  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.00701093673706  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.010754585266113  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1110835075378418  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.400190830230713
pure train time :  0.4935314655303955
train time :  0.7679777145385742
end to end time :  5.571392774581909
connection check time:  2.57926607131958
block generation time  1.366410493850708
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005617141723632812
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014259815216064453
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7078428268432617
len local_batched_seeds_list  4
partition total batch output list spend :  0.8593099117279053
self.buckets_partition() spend  sec:  0.7221400737762451
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.045746803283691406

in edges time spent  0.14901471138000488
local to global src and eids time spent  0.2881779670715332
time gen tails  0.06914806365966797
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1316087245941162

in edges time spent  0.5433940887451172
local to global src and eids time spent  0.8780899047851562
time gen tails  0.13938593864440918
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0939321517944336  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182307243347168  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182124614715576  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09521102905273438  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.047000885009766  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.050753593444824  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10245370864868164  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.431117057800293  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.436412811279297  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10463905334472656  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.976478099822998  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.980286598205566  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11188220977783203  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.397017002105713
pure train time :  0.4818696975708008
train time :  0.7567968368530273
end to end time :  5.596987724304199
connection check time:  2.589160442352295
block generation time  1.378391981124878
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005786418914794922
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014409065246582031
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.723376989364624
len local_batched_seeds_list  4
partition total batch output list spend :  0.8767015933990479
self.buckets_partition() spend  sec:  0.7378368377685547
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04567122459411621

in edges time spent  0.15027165412902832
local to global src and eids time spent  0.29056596755981445
time gen tails  0.0697469711303711
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13121366500854492

in edges time spent  0.5423159599304199
local to global src and eids time spent  0.8726339340209961
time gen tails  0.13944625854492188
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0942525863647461  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.189519882202148  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.189182758331299  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09551095962524414  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.041231632232666  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044984340667725  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10230398178100586  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.456047534942627  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.46134328842163  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464286804199219  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.980498313903809  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.983809947967529  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11117792129516602  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3985824584960938
pure train time :  0.5055100917816162
train time :  0.7789261341094971
end to end time :  5.637516260147095
connection check time:  2.5898797512054443
block generation time  1.3739173412322998
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005867481231689453
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014442682266235352
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7344474792480469
len local_batched_seeds_list  4
partition total batch output list spend :  0.8879146575927734
self.buckets_partition() spend  sec:  0.7489223480224609
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.045639991760253906

in edges time spent  0.14922356605529785
local to global src and eids time spent  0.2886672019958496
time gen tails  0.06937289237976074
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.12973523139953613

in edges time spent  0.5536463260650635
local to global src and eids time spent  0.8701522350311279
time gen tails  0.1391582489013672
res  length 4
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09409523010253906  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.180960655212402  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.180623531341553  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09484434127807617  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.053068161010742  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.0568208694458  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1024312973022461  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.397143363952637  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.40243911743164  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10465669631958008  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.017476558685303  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.021220207214355  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11141109466552734  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3937314748764038
pure train time :  0.4812443256378174
train time :  0.7663400173187256
end to end time :  5.627305507659912
connection check time:  2.5923666954040527
block generation time  1.3647887706756592
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005414485931396484
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01415705680847168
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6809487342834473
len local_batched_seeds_list  4
partition total batch output list spend :  0.8301959037780762
self.buckets_partition() spend  sec:  0.6951403617858887
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04622364044189453

in edges time spent  0.14928483963012695
local to global src and eids time spent  0.2884345054626465
time gen tails  0.06902003288269043
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13245105743408203

in edges time spent  0.5294942855834961
local to global src and eids time spent  0.8696513175964355
time gen tails  0.138930082321167
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09390449523925781  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184726238250732  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183744430541992  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09506654739379883  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.039546012878418  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043647289276123  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10231637954711914  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.429246425628662  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.434542179107666  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464859008789062  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.016926765441895  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.020735263824463  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11110305786132812  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3921152353286743
pure train time :  0.4971940517425537
train time :  0.7641799449920654
end to end time :  5.5465803146362305
connection check time:  2.5677032470703125
block generation time  1.3682847023010254
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005407333374023438
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01455378532409668
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6817471981048584
len local_batched_seeds_list  4
partition total batch output list spend :  0.8324675559997559
self.buckets_partition() spend  sec:  0.6963346004486084
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04616546630859375

in edges time spent  0.1476428508758545
local to global src and eids time spent  0.29673242568969727
time gen tails  0.0744624137878418
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13342618942260742

in edges time spent  0.5558106899261475
local to global src and eids time spent  0.9030711650848389
time gen tails  0.14278578758239746
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09414911270141602  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184939861297607  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184601783752441  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09479761123657227  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044285297393799  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.048038005828857  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1023416519165039  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.452176094055176  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.45747184753418  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464811325073242  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.020743370056152  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.02455186843872  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11110067367553711  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3893520832061768
pure train time :  0.48747777938842773
train time :  0.7582447528839111
end to end time :  5.62768030166626
connection check time:  2.65200138092041
block generation time  1.3713207244873047
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005550384521484375
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01474618911743164
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6787388324737549
len local_batched_seeds_list  4
partition total batch output list spend :  0.8288109302520752
self.buckets_partition() spend  sec:  0.6935193538665771
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.0474390983581543

in edges time spent  0.1517195701599121
local to global src and eids time spent  0.29367899894714355
time gen tails  0.06936025619506836
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1304340362548828

in edges time spent  0.5694103240966797
local to global src and eids time spent  0.8759875297546387
time gen tails  0.13881611824035645
res  length 4
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09392547607421875  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186884880065918  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186546802520752  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09546995162963867  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.054205894470215  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.05884075164795  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10294961929321289  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.43093204498291  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.436227798461914  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10582160949707031  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.014676094055176  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018484592437744  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1117701530456543  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3891944885253906
pure train time :  0.49820542335510254
train time :  0.7762925624847412
end to end time :  5.604279518127441
connection check time:  2.620710849761963
block generation time  1.3642387390136719
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005562305450439453
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014475822448730469
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6789438724517822
len local_batched_seeds_list  4
partition total batch output list spend :  0.8303637504577637
self.buckets_partition() spend  sec:  0.6934552192687988
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.0459439754486084

in edges time spent  0.14863061904907227
local to global src and eids time spent  0.2893795967102051
time gen tails  0.06941938400268555
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13045740127563477

in edges time spent  0.5357208251953125
local to global src and eids time spent  0.8772292137145996
time gen tails  0.143113374710083
res  length 4
block collection to dataloader spend  1.5735626220703125e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0939321517944336  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186268329620361  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185931205749512  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09457159042358398  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.051796436309814  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.055549144744873  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10222959518432617  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.390358448028564  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.395654201507568  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10582208633422852  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.006139278411865  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.009947776794434  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11174726486206055  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.384682536125183
pure train time :  0.501354455947876
train time :  0.7797439098358154
end to end time :  5.636258602142334
connection check time:  2.6360654830932617
block generation time  1.3680453300476074
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005862712860107422
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01430821418762207
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7042291164398193
len local_batched_seeds_list  4
partition total batch output list spend :  0.8549952507019043
self.buckets_partition() spend  sec:  0.7185752391815186
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04623723030090332

in edges time spent  0.1495344638824463
local to global src and eids time spent  0.2901029586791992
time gen tails  0.06916379928588867
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13001394271850586

in edges time spent  0.5425369739532471
local to global src and eids time spent  0.8721015453338623
time gen tails  0.13969731330871582
res  length 4
block collection to dataloader spend  1.6450881958007812e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09414291381835938  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.190320014953613  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.189339637756348  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09514379501342773  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043974876403809  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.048076152801514  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10234355926513672  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.431040287017822  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.436336040496826  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1046438217163086  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.982213973999023  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.985957622528076  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11151313781738281  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3833917379379272
pure train time :  0.48958301544189453
train time :  0.7571256160736084
end to end time :  5.580723762512207
connection check time:  2.583444356918335
block generation time  1.3654065132141113
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.000667572021484375
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014505147933959961
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6884095668792725
len local_batched_seeds_list  4
partition total batch output list spend :  0.8400173187255859
self.buckets_partition() spend  sec:  0.7029473781585693
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04569196701049805

in edges time spent  0.15012383460998535
local to global src and eids time spent  0.28977537155151367
time gen tails  0.0692586898803711
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13051843643188477

in edges time spent  0.5646445751190186
local to global src and eids time spent  0.880878210067749
time gen tails  0.14049100875854492
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09389734268188477  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184657096862793  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184319496154785  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0946664810180664  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.031641483306885  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.035394191741943  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10234975814819336  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.436588764190674  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.441884517669678  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464620590209961  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.022047519683838  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.025359153747559  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11068964004516602  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.384544014930725
pure train time :  0.5296211242675781
train time :  0.7788901329040527
end to end time :  5.629560470581055
connection check time:  2.615976333618164
block generation time  1.3786168098449707
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005826950073242188
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014399290084838867
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6743564605712891
len local_batched_seeds_list  4
partition total batch output list spend :  0.8261299133300781
self.buckets_partition() spend  sec:  0.6887900829315186
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04569244384765625

in edges time spent  0.14948225021362305
local to global src and eids time spent  0.2887873649597168
time gen tails  0.06917953491210938
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13064050674438477

in edges time spent  0.5344722270965576
local to global src and eids time spent  0.8703515529632568
time gen tails  0.13890600204467773
res  length 4
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09344911575317383  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.147976398468018  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.147638320922852  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09448385238647461  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.041337490081787  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.045090198516846  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10251140594482422  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.435122966766357  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.440479278564453  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464668273925781  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018192768096924  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.021504402160645  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11069202423095703  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.378183126449585
pure train time :  0.569981575012207
train time :  0.8402369022369385
end to end time :  5.627424716949463
connection check time:  2.572072744369507
block generation time  1.369081974029541
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005807876586914062
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014502763748168945
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7339596748352051
len local_batched_seeds_list  4
partition total batch output list spend :  0.8829076290130615
self.buckets_partition() spend  sec:  0.748497724533081
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04597306251525879

in edges time spent  0.1486520767211914
local to global src and eids time spent  0.28976011276245117
time gen tails  0.06904840469360352
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.12950873374938965

in edges time spent  0.533982515335083
local to global src and eids time spent  0.8708181381225586
time gen tails  0.13934063911437988
res  length 4
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09360551834106445  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.193655967712402  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.193317890167236  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09519004821777344  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.052442073822021  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.056526184082031  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1024174690246582  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.390092849731445  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.39538860321045  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10555410385131836  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.010889053344727  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.014697551727295  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11108016967773438  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3790419101715088
pure train time :  0.4920840263366699
train time :  0.7644062042236328
end to end time :  5.593090772628784
connection check time:  2.569800615310669
block generation time  1.360377311706543
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005605220794677734
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014499187469482422
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6941711902618408
len local_batched_seeds_list  4
partition total batch output list spend :  0.8522906303405762
self.buckets_partition() spend  sec:  0.7087037563323975
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.047882080078125

in edges time spent  0.1596078872680664
local to global src and eids time spent  0.29790449142456055
time gen tails  0.07470226287841797
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13141679763793945

in edges time spent  0.5703761577606201
local to global src and eids time spent  0.8729441165924072
time gen tails  0.14072918891906738
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0939788818359375  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184916973114014  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184646129608154  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09518146514892578  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.045693397521973  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.049794673919678  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10243654251098633  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.396131038665771  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.401512145996094  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058206558227539  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018468379974365  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.022276878356934  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11137533187866211  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3750251531600952
pure train time :  0.4909052848815918
train time :  0.7767143249511719
end to end time :  5.664340019226074
connection check time:  2.644954204559326
block generation time  1.3760809898376465
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005800724029541016
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.018613576889038086
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7440826892852783
len local_batched_seeds_list  4
partition total batch output list spend :  0.8989720344543457
self.buckets_partition() spend  sec:  0.7627406120300293
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04653286933898926

in edges time spent  0.15678691864013672
local to global src and eids time spent  0.2882225513458252
time gen tails  0.06941938400268555
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1315622329711914

in edges time spent  0.5535717010498047
local to global src and eids time spent  0.7961328029632568
time gen tails  0.1039283275604248
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09386205673217773  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182319164276123  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.181337356567383  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09515094757080078  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04080867767334  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044561386108398  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10241270065307617  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.45509672164917  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.460392475128174  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464763641357422  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.988436222076416  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9914703369140625  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11069679260253906  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3750368356704712
pure train time :  0.4835057258605957
train time :  0.7677326202392578
end to end time :  5.549727439880371
connection check time:  2.491058349609375
block generation time  1.3708696365356445
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005576610565185547
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015378952026367188
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.714301586151123
len local_batched_seeds_list  4
partition total batch output list spend :  0.7843196392059326
self.buckets_partition() spend  sec:  0.7297248840332031
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.046183109283447266

in edges time spent  0.15019011497497559
local to global src and eids time spent  0.28980565071105957
time gen tails  0.06935381889343262
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13079619407653809

in edges time spent  0.5336859226226807
local to global src and eids time spent  0.8726193904876709
time gen tails  0.13963890075683594
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0935831069946289  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183318614959717  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182980060577393  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0948643684387207  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04314136505127  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046894073486328  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10235166549682617  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.395370960235596  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.4006667137146  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464763641357422  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.009241580963135  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.013050079345703  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1110982894897461  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3726874589920044
pure train time :  0.5261437892913818
train time :  0.7727038860321045
end to end time :  5.5114426612854
connection check time:  2.5731496810913086
block generation time  1.36777925491333
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006628036499023438
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01447439193725586
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7461533546447754
len local_batched_seeds_list  4
partition total batch output list spend :  0.8985855579376221
self.buckets_partition() spend  sec:  0.7606625556945801
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04575753211975098

in edges time spent  0.14833283424377441
local to global src and eids time spent  0.2890620231628418
time gen tails  0.06925415992736816
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1300358772277832

in edges time spent  0.5531413555145264
local to global src and eids time spent  0.8716368675231934
time gen tails  0.1398003101348877
res  length 4
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09410476684570312  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.190576076507568  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.19023847579956  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09546232223510742  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046521186828613  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.050273895263672  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10242462158203125  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.424827098846436  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.43012285232544  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058206558227539  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.978621006011963  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.981655120849609  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11188030242919922  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3697301149368286
pure train time :  0.4822204113006592
train time :  0.773961067199707
end to end time :  5.65614914894104
connection check time:  2.5916638374328613
block generation time  1.374459981918335
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005979537963867188
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014535665512084961
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.748455286026001
len local_batched_seeds_list  4
partition total batch output list spend :  0.9006154537200928
self.buckets_partition() spend  sec:  0.7630274295806885
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04601860046386719

in edges time spent  0.14809370040893555
local to global src and eids time spent  0.29065728187561035
time gen tails  0.06946992874145508
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1298971176147461

in edges time spent  0.5356132984161377
local to global src and eids time spent  0.8674783706665039
time gen tails  0.138993501663208
res  length 4
block collection to dataloader spend  1.1682510375976562e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09337043762207031  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.153054237365723  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.152073860168457  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09517145156860352  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043848037719727  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.047600746154785  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1022634506225586  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.388284683227539  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.393580436706543  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464954376220703  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.020337104797363  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.024145603179932  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11110973358154297  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3642587661743164
pure train time :  0.503098726272583
train time :  0.7570326328277588
end to end time :  5.612475156784058
connection check time:  2.5713839530944824
block generation time  1.3699922561645508
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005767345428466797
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014341592788696289
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7521445751190186
len local_batched_seeds_list  4
partition total batch output list spend :  0.9039239883422852
self.buckets_partition() spend  sec:  0.7665212154388428
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.0458226203918457

in edges time spent  0.14989233016967773
local to global src and eids time spent  0.289562463760376
time gen tails  0.06930994987487793
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13131213188171387

in edges time spent  0.5277314186096191
local to global src and eids time spent  0.8679437637329102
time gen tails  0.1387948989868164
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09397363662719727  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18588924407959  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18490743637085  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09511518478393555  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.042523860931396  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046276569366455  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1022791862487793  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.380953311920166  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.38624906539917  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10463953018188477  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.978907108306885  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.982715606689453  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11185932159423828  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3640344142913818
pure train time :  0.5000722408294678
train time :  0.772258996963501
end to end time :  5.6399245262146
connection check time:  2.5655407905578613
block generation time  1.382606029510498
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006229877471923828
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014612913131713867
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.719857931137085
len local_batched_seeds_list  4
partition total batch output list spend :  0.8716554641723633
self.buckets_partition() spend  sec:  0.7345049381256104
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04601240158081055

in edges time spent  0.14716744422912598
local to global src and eids time spent  0.2895834445953369
time gen tails  0.0695638656616211
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13101625442504883

in edges time spent  0.5395915508270264
local to global src and eids time spent  0.8693487644195557
time gen tails  0.13956570625305176
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09419584274291992  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183617115020752  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183279991149902  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09468793869018555  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040729999542236  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044482707977295  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10267114639282227  GigaBytes
Max Memory Allocated: 8.702028274536133  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.46180248260498  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.46712064743042  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10523366928100586  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9802751541137695  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.984018802642822  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11187553405761719  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3623721599578857
pure train time :  0.4815835952758789
train time :  0.7599260807037354
end to end time :  5.590381860733032
connection check time:  2.5758206844329834
block generation time  1.3673675060272217
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005848407745361328
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014498710632324219
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6959793567657471
len local_batched_seeds_list  4
partition total batch output list spend :  0.8469541072845459
self.buckets_partition() spend  sec:  0.7105109691619873
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04647469520568848

in edges time spent  0.14760637283325195
local to global src and eids time spent  0.28865671157836914
time gen tails  0.06939244270324707
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13116693496704102

in edges time spent  0.5047271251678467
local to global src and eids time spent  0.7755930423736572
time gen tails  0.1030111312866211
res  length 4
block collection to dataloader spend  1.1444091796875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09395647048950195  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183780670166016  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183516025543213  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09513616561889648  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.036291122436523  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040043830871582  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10252523422241211  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.42830228805542  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.433662414550781  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10582113265991211  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.01304006576538  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.016351699829102  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11114215850830078  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3618967533111572
pure train time :  0.48488569259643555
train time :  0.7521507740020752
end to end time :  5.40283465385437
connection check time:  2.410501003265381
block generation time  1.3760919570922852
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005397796630859375
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015267610549926758
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6694111824035645
len local_batched_seeds_list  4
partition total batch output list spend :  0.739189863204956
self.buckets_partition() spend  sec:  0.6847186088562012
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04322981834411621

in edges time spent  0.14919519424438477
local to global src and eids time spent  0.2889842987060547
time gen tails  0.0694112777709961
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13010072708129883

in edges time spent  0.5352776050567627
local to global src and eids time spent  0.8672826290130615
time gen tails  0.13979673385620117
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09363842010498047  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.1851167678833  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184778690338135  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0945734977722168  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.0459303855896  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.049683094024658  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10257339477539062  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.3960862159729  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.401461601257324  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10463523864746094  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.972474098205566  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.976217746734619  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11105823516845703  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3597785234451294
pure train time :  0.48549699783325195
train time :  0.7680072784423828
end to end time :  5.465545177459717
connection check time:  2.560769557952881
block generation time  1.3840999603271484
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.000545501708984375
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014288187026977539
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6948537826538086
len local_batched_seeds_list  4
partition total batch output list spend :  0.8459360599517822
self.buckets_partition() spend  sec:  0.7091770172119141
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.045671939849853516

in edges time spent  0.15346312522888184
local to global src and eids time spent  0.28960442543029785
time gen tails  0.07110905647277832
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13187026977539062

in edges time spent  0.5941097736358643
local to global src and eids time spent  0.884099006652832
time gen tails  0.1415879726409912
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0940852165222168  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.149702072143555  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.149365425109863  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09472942352294922  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.050838947296143  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.054591655731201  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10223007202148438  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.390822410583496  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.3961181640625  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1055593490600586  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.017892837524414  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.021701335906982  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11110067367553711  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3635809421539307
pure train time :  0.48408031463623047
train time :  0.7664222717285156
end to end time :  5.6628334522247314
connection check time:  2.6574416160583496
block generation time  1.375972032546997
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006527900695800781
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014495849609375
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7537062168121338
len local_batched_seeds_list  4
partition total batch output list spend :  0.9045009613037109
self.buckets_partition() spend  sec:  0.7682347297668457
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.045365095138549805

in edges time spent  0.15161395072937012
local to global src and eids time spent  0.2907271385192871
time gen tails  0.06980562210083008
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13045835494995117

in edges time spent  0.5407023429870605
local to global src and eids time spent  0.7802016735076904
time gen tails  0.10324287414550781
res  length 4
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09391593933105469  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.201810836791992  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.201472759246826  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09538412094116211  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040470600128174  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044223308563232  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1024932861328125  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.452562808990479  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.457858562469482  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464334487915039  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.006726264953613  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.010534763336182  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1110844612121582  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3568862676620483
pure train time :  0.48550844192504883
train time :  0.758537769317627
end to end time :  5.513354063034058
connection check time:  2.456913948059082
block generation time  1.3733782768249512
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005586147308349609
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01567816734313965
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6699075698852539
len local_batched_seeds_list  4
partition total batch output list spend :  0.7395980358123779
self.buckets_partition() spend  sec:  0.6856184005737305
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.044440507888793945

in edges time spent  0.14947175979614258
local to global src and eids time spent  0.2906808853149414
time gen tails  0.06948995590209961
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13022875785827637

in edges time spent  0.37535548210144043
local to global src and eids time spent  0.7340884208679199
time gen tails  0.13998770713806152
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09415388107299805  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.1837797164917  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183464050292969  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09510993957519531  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040748119354248  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044500827789307  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10234260559082031  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.393058776855469  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.398354530334473  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10491371154785156  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9796857833862305  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.983494281768799  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11180925369262695  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3551629781723022
pure train time :  0.495866060256958
train time :  0.7604343891143799
end to end time :  5.156354904174805
connection check time:  2.277608871459961
block generation time  1.3658874034881592
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005643367767333984
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014050960540771484
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7224342823028564
len local_batched_seeds_list  4
partition total batch output list spend :  0.8720042705535889
self.buckets_partition() spend  sec:  0.7365283966064453
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04557323455810547

in edges time spent  0.14967131614685059
local to global src and eids time spent  0.29206061363220215
time gen tails  0.06976437568664551
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13248395919799805

in edges time spent  0.5618665218353271
local to global src and eids time spent  0.8896687030792236
time gen tails  0.13976812362670898
res  length 4
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0941162109375  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183510780334473  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183247566223145  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09524250030517578  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.039870262145996  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043622970581055  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1024785041809082  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.390990257263184  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.396375179290771  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10465192794799805  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.023371696472168  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.027180194854736  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11111211776733398  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3547323942184448
pure train time :  0.4811568260192871
train time :  0.7662413120269775
end to end time :  5.667294502258301
connection check time:  2.6385726928710938
block generation time  1.3770627975463867
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005872249603271484
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014220476150512695
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7026829719543457
len local_batched_seeds_list  4
partition total batch output list spend :  0.8519768714904785
self.buckets_partition() spend  sec:  0.7169361114501953
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04598116874694824

in edges time spent  0.15395808219909668
local to global src and eids time spent  0.28957033157348633
time gen tails  0.06943535804748535
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13225889205932617

in edges time spent  0.5380795001983643
local to global src and eids time spent  0.875713586807251
time gen tails  0.13965225219726562
res  length 4
block collection to dataloader spend  1.1444091796875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09394121170043945  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184632301330566  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183650493621826  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09508466720581055  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.053751468658447  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.057504177093506  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10251188278198242  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.40729284286499  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.412588596343994  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10582113265991211  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.019855499267578  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.022889614105225  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11096858978271484  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.350289225578308
pure train time :  0.48691868782043457
train time :  0.7677855491638184
end to end time :  5.597305059432983
connection check time:  2.588484287261963
block generation time  1.370880365371704
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005481243133544922
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014045953750610352
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6976172924041748
len local_batched_seeds_list  4
partition total batch output list spend :  0.8478059768676758
self.buckets_partition() spend  sec:  0.7117092609405518
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04587578773498535

in edges time spent  0.14969396591186523
local to global src and eids time spent  0.288909912109375
time gen tails  0.06951045989990234
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1315295696258545

in edges time spent  0.5545971393585205
local to global src and eids time spent  0.8705458641052246
time gen tails  0.13971185684204102
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09356260299682617  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185366153717041  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185027599334717  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09454631805419922  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043920040130615  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.047672748565674  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1023111343383789  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.398799896240234  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.404095649719238  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464286804199219  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.011635303497314  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.014946937561035  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11068058013916016  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3517712354660034
pure train time :  0.4868171215057373
train time :  0.7634339332580566
end to end time :  5.6082398891448975
connection check time:  2.5968105792999268
block generation time  1.3862485885620117
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005440711975097656
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014409542083740234
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7001953125
len local_batched_seeds_list  4
partition total batch output list spend :  0.8513133525848389
self.buckets_partition() spend  sec:  0.7146482467651367
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.045862436294555664

in edges time spent  0.15001606941223145
local to global src and eids time spent  0.29078030586242676
time gen tails  0.06970453262329102
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1304166316986084

in edges time spent  0.5328621864318848
local to global src and eids time spent  0.8722388744354248
time gen tails  0.1399068832397461
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0934443473815918  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.143142700195312  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.142805099487305  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09555196762084961  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.053004264831543  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.057554721832275  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10260152816772461  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.396156787872314  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.401524543762207  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058197021484375  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.981548309326172  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.98535680770874  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11194658279418945  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3494887351989746
pure train time :  0.49047207832336426
train time :  0.7622487545013428
end to end time :  5.579357385635376
connection check time:  2.577080249786377
block generation time  1.3737874031066895
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005807876586914062
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01381230354309082
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6880168914794922
len local_batched_seeds_list  4
partition total batch output list spend :  0.8378934860229492
self.buckets_partition() spend  sec:  0.7018647193908691
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04580569267272949

in edges time spent  0.1495988368988037
local to global src and eids time spent  0.2902238368988037
time gen tails  0.06969332695007324
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.12906765937805176

in edges time spent  0.5282268524169922
local to global src and eids time spent  0.8715128898620605
time gen tails  0.13907909393310547
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0942087173461914  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.1942720413208  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.193934440612793  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09531784057617188  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.039429664611816  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04362964630127  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10220098495483398  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.385994911193848  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.391290664672852  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10555553436279297  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.013875007629395  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.017618656158447  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11108636856079102  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.346165657043457
pure train time :  0.4913802146911621
train time :  0.7597217559814453
end to end time :  5.553074359893799
connection check time:  2.56736421585083
block generation time  1.3729572296142578
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005600452423095703
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014589786529541016
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.688152551651001
len local_batched_seeds_list  4
partition total batch output list spend :  0.8401765823364258
self.buckets_partition() spend  sec:  0.7027766704559326
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.045829057693481445

in edges time spent  0.1466069221496582
local to global src and eids time spent  0.2971625328063965
time gen tails  0.07250475883483887
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13054418563842773

in edges time spent  0.5525493621826172
local to global src and eids time spent  0.8732860088348389
time gen tails  0.14288973808288574
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0940098762512207  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.15068244934082  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.15034532546997  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09484148025512695  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.045579433441162  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04933214187622  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10248470306396484  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.446875095367432  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.452170848846436  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10465097427368164  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.020921230316162  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.02472972869873  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11110830307006836  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3461518287658691
pure train time :  0.4994323253631592
train time :  0.7930705547332764
end to end time :  5.647318124771118
connection check time:  2.6108760833740234
block generation time  1.386969804763794
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005478858947753906
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015172719955444336
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6825337409973145
len local_batched_seeds_list  4
partition total batch output list spend :  0.8340544700622559
self.buckets_partition() spend  sec:  0.6977410316467285
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04808926582336426

in edges time spent  0.15564417839050293
local to global src and eids time spent  0.290302038192749
time gen tails  0.06981730461120605
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13055014610290527

in edges time spent  0.5894877910614014
local to global src and eids time spent  0.8890869617462158
time gen tails  0.14037585258483887
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09411287307739258  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.20447826385498  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.204140186309814  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09442949295043945  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.038637638092041  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.0423903465271  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1023721694946289  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.432058334350586  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.43735408782959  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464334487915039  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.984306812286377  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.987618446350098  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11068010330200195  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3424237966537476
pure train time :  0.48038673400878906
train time :  0.7602152824401855
end to end time :  5.643496751785278
connection check time:  2.6595475673675537
block generation time  1.3733291625976562
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005326271057128906
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014632940292358398
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6847503185272217
len local_batched_seeds_list  4
partition total batch output list spend :  0.8352656364440918
self.buckets_partition() spend  sec:  0.699415922164917
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.045958518981933594

in edges time spent  0.1518850326538086
local to global src and eids time spent  0.2890903949737549
time gen tails  0.06964588165283203
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.129974365234375

in edges time spent  0.5492243766784668
local to global src and eids time spent  0.8692986965179443
time gen tails  0.1404728889465332
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09354496002197266  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184358596801758  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18402099609375  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09476375579833984  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.054171085357666  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.057923793792725  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10250377655029297  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.407336235046387  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.41333532333374  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10528039932250977  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9823431968688965  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.985654830932617  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11121892929077148  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3422768115997314
pure train time :  0.4903697967529297
train time :  0.7679998874664307
end to end time :  5.579849004745483
connection check time:  2.5895307064056396
block generation time  1.3707749843597412
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005490779876708984
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013881683349609375
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6852233409881592
len local_batched_seeds_list  4
partition total batch output list spend :  0.8354697227478027
self.buckets_partition() spend  sec:  0.6991393566131592
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04585909843444824

in edges time spent  0.15337562561035156
local to global src and eids time spent  0.29060935974121094
time gen tails  0.0697636604309082
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.12993526458740234

in edges time spent  0.5429699420928955
local to global src and eids time spent  0.8729522228240967
time gen tails  0.14086031913757324
res  length 4
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09354257583618164  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183821678161621  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182840824127197  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09503173828125  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040057182312012  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04380989074707  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10229301452636719  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.435110092163086  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.44040584564209  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10463953018188477  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.977863788604736  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.980897903442383  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11066675186157227  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3416305780410767
pure train time :  0.4940812587738037
train time :  0.7768151760101318
end to end time :  5.5891993045806885
connection check time:  2.591048002243042
block generation time  1.372648000717163
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005505084991455078
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014863252639770508
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6840884685516357
len local_batched_seeds_list  4
partition total batch output list spend :  0.8357341289520264
self.buckets_partition() spend  sec:  0.6989939212799072
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.045762062072753906

in edges time spent  0.15175199508666992
local to global src and eids time spent  0.2894172668457031
time gen tails  0.06987619400024414
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1301286220550537

in edges time spent  0.5643715858459473
local to global src and eids time spent  0.9280910491943359
time gen tails  0.1407322883605957
res  length 4
block collection to dataloader spend  1.5497207641601562e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0936126708984375  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183152675628662  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182815551757812  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09448862075805664  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046435356140137  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.050188064575195  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10253620147705078  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.460663318634033  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.465996742248535  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10518455505371094  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.981199264526367  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.984510898590088  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11113500595092773  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.339181661605835
pure train time :  0.5284161567687988
train time :  0.7910780906677246
end to end time :  5.705384731292725
connection check time:  2.672452211380005
block generation time  1.3915767669677734
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005943775177001953
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014431476593017578
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7304675579071045
len local_batched_seeds_list  4
partition total batch output list spend :  0.8826327323913574
self.buckets_partition() spend  sec:  0.7449362277984619
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.048705339431762695

in edges time spent  0.14847254753112793
local to global src and eids time spent  0.2891383171081543
time gen tails  0.06970810890197754
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1343376636505127

in edges time spent  0.5511493682861328
local to global src and eids time spent  0.9035589694976807
time gen tails  0.14519572257995605
res  length 4
block collection to dataloader spend  1.7642974853515625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09382963180541992  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184008121490479  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18367052078247  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09451103210449219  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04702377319336  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.050776481628418  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10261106491088867  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.455389022827148  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.460726261138916  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1046438217163086  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.982179641723633  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.985988140106201  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11140298843383789  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3359251022338867
pure train time :  0.4919281005859375
train time :  0.7684412002563477
end to end time :  5.715442180633545
connection check time:  2.6444783210754395
block generation time  1.4011852741241455
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006663799285888672
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01436305046081543
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7057487964630127
len local_batched_seeds_list  4
partition total batch output list spend :  0.8573777675628662
self.buckets_partition() spend  sec:  0.7201440334320068
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04543662071228027

in edges time spent  0.14774131774902344
local to global src and eids time spent  0.2904989719390869
time gen tails  0.0696706771850586
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13040995597839355

in edges time spent  0.5389530658721924
local to global src and eids time spent  0.8730261325836182
time gen tails  0.1400585174560547
res  length 4
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09379100799560547  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.180609226226807  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.180271625518799  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09484529495239258  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046048641204834  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.049801349639893  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10260009765625  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.45858097076416  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.463908672332764  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10582113265991211  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.014968395233154  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.0180025100708  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11095714569091797  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3361949920654297
pure train time :  0.4875166416168213
train time :  0.7596631050109863
end to end time :  5.6028828620910645
connection check time:  2.580544948577881
block generation time  1.3889474868774414
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005588531494140625
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014541864395141602
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6897752285003662
len local_batched_seeds_list  4
partition total batch output list spend :  0.8413450717926025
self.buckets_partition() spend  sec:  0.7043514251708984
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.044339656829833984

in edges time spent  0.14805912971496582
local to global src and eids time spent  0.2886812686920166
time gen tails  0.06951618194580078
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.12994980812072754

in edges time spent  0.5312380790710449
local to global src and eids time spent  0.867316484451294
time gen tails  0.139845609664917
res  length 4
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09355306625366211  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185540676116943  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185202598571777  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09447574615478516  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04166030883789  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04541301727295  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10238790512084961  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.435218334197998  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.440514087677002  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464096069335938  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.982753276824951  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.986496925354004  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11166667938232422  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3330936431884766
pure train time :  0.48253822326660156
train time :  0.7609255313873291
end to end time :  5.551248073577881
connection check time:  2.5590689182281494
block generation time  1.376885175704956
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005552768707275391
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014492273330688477
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6884212493896484
len local_batched_seeds_list  4
partition total batch output list spend :  0.8395702838897705
self.buckets_partition() spend  sec:  0.7029592990875244
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04560041427612305

in edges time spent  0.14768743515014648
local to global src and eids time spent  0.2887883186340332
time gen tails  0.06978368759155273
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13072633743286133

in edges time spent  0.5355801582336426
local to global src and eids time spent  0.8719291687011719
time gen tails  0.14041972160339355
res  length 4
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09386014938354492  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.147423267364502  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.146442890167236  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09523725509643555  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.05156135559082  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.055314064025879  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10236930847167969  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.397709369659424  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.403279304504395  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10463619232177734  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.971837997436523  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.97487211227417  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11065864562988281  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3350735902786255
pure train time :  0.48869967460632324
train time :  0.7606513500213623
end to end time :  5.569110631942749
connection check time:  2.5756001472473145
block generation time  1.3808047771453857
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005815029144287109
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014161109924316406
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6851565837860107
len local_batched_seeds_list  4
partition total batch output list spend :  0.8367207050323486
self.buckets_partition() spend  sec:  0.6993510723114014
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.045656442642211914

in edges time spent  0.1496591567993164
local to global src and eids time spent  0.2887248992919922
time gen tails  0.06970548629760742
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.12981200218200684

in edges time spent  0.5566167831420898
local to global src and eids time spent  0.8701457977294922
time gen tails  0.1406564712524414
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09367656707763672  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.20260238647461  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.20226526260376  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09481048583984375  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.042446613311768  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046199321746826  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10234785079956055  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.398889541625977  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.40418529510498  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464143753051758  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9732537269592285  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.977062225341797  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11107587814331055  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.332763433456421
pure train time :  0.49776220321655273
train time :  0.7664923667907715
end to end time :  5.590486764907837
connection check time:  2.5957190990448
block generation time  1.3760535717010498
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005726814270019531
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014167547225952148
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6873345375061035
len local_batched_seeds_list  4
partition total batch output list spend :  0.8382229804992676
self.buckets_partition() spend  sec:  0.7015421390533447
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04594135284423828

in edges time spent  0.14967012405395508
local to global src and eids time spent  0.28836560249328613
time gen tails  0.06966423988342285
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1304614543914795

in edges time spent  0.5293335914611816
local to global src and eids time spent  0.8686857223510742
time gen tails  0.13977527618408203
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0941476821899414  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185590744018555  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185253620147705  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09475469589233398  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.038028717041016  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.041781425476074  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10230493545532227  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.390510559082031  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.395806312561035  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058206558227539  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.015407085418701  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.01921558380127  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11173534393310547  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3289752006530762
pure train time :  0.4890744686126709
train time :  0.7680308818817139
end to end time :  5.563714504241943
connection check time:  2.5681300163269043
block generation time  1.3762764930725098
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005593299865722656
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014309167861938477
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6861793994903564
len local_batched_seeds_list  4
partition total batch output list spend :  0.8371381759643555
self.buckets_partition() spend  sec:  0.7005224227905273
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.045885324478149414

in edges time spent  0.14800214767456055
local to global src and eids time spent  0.28832316398620605
time gen tails  0.0699453353881836
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1326453685760498

in edges time spent  0.5458528995513916
local to global src and eids time spent  0.8705718517303467
time gen tails  0.14027690887451172
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09403562545776367  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.200697898864746  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.200419902801514  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09510517120361328  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040917873382568  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044670581817627  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10262203216552734  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.455110549926758  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.460438251495361  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10582113265991211  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.960821628570557  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.964133262634277  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11092281341552734  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.328179121017456
pure train time :  0.49088215827941895
train time :  0.7668347358703613
end to end time :  5.5822529792785645
connection check time:  2.586259126663208
block generation time  1.3729681968688965
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005753040313720703
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014105081558227539
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.687220573425293
len local_batched_seeds_list  4
partition total batch output list spend :  0.838886022567749
self.buckets_partition() spend  sec:  0.7013604640960693
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.045500993728637695

in edges time spent  0.14904356002807617
local to global src and eids time spent  0.2910017967224121
time gen tails  0.0698237419128418
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13071155548095703

in edges time spent  0.535710334777832
local to global src and eids time spent  0.8757228851318359
time gen tails  0.13994145393371582
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09407949447631836  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18467378616333  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184442520141602  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09505605697631836  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.034491062164307  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.038243770599365  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10280275344848633  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.396586894989014  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.401882648468018  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10465049743652344  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.014643669128418  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018452167510986  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11110782623291016  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3249341249465942
pure train time :  0.5023069381713867
train time :  0.7818706035614014
end to end time :  5.6108481884002686
connection check time:  2.581906318664551
block generation time  1.3952772617340088
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005819797515869141
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01486825942993164
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6884679794311523
len local_batched_seeds_list  4
partition total batch output list spend :  0.8404183387756348
self.buckets_partition() spend  sec:  0.7033689022064209
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.0458674430847168

in edges time spent  0.15239191055297852
local to global src and eids time spent  0.2895667552947998
time gen tails  0.06985974311828613
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.12960529327392578

in edges time spent  0.5737495422363281
local to global src and eids time spent  0.873192548751831
time gen tails  0.14359545707702637
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09397363662719727  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184638023376465  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184299945831299  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09451150894165039  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.05747938156128  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.061232089996338  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1022939682006836  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.395071983337402  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.401278972625732  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464620590209961  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.988993167877197  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.992027282714844  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11075401306152344  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3232004642486572
pure train time :  0.48430657386779785
train time :  0.763831615447998
end to end time :  5.622804641723633
connection check time:  2.6228573322296143
block generation time  1.3777127265930176
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006225109100341797
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015259265899658203
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7087962627410889
len local_batched_seeds_list  4
partition total batch output list spend :  0.8618404865264893
self.buckets_partition() spend  sec:  0.724092960357666
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.049111366271972656

in edges time spent  0.15146374702453613
local to global src and eids time spent  0.29296088218688965
time gen tails  0.06985902786254883
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.12965035438537598

in edges time spent  0.5809535980224609
local to global src and eids time spent  0.8926823139190674
time gen tails  0.1411271095275879
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09354877471923828  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18488883972168  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184550762176514  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0948953628540039  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044725894927979  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.048478603363037  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10231637954711914  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.387041091918945  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.39233684539795  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464239120483398  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9817728996276855  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.984807014465332  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.111053466796875  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.326204776763916
pure train time :  0.4899752140045166
train time :  0.7706260681152344
end to end time :  5.684634447097778
connection check time:  2.6524150371551514
block generation time  1.3855979442596436
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005841255187988281
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01444554328918457
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6861355304718018
len local_batched_seeds_list  4
partition total batch output list spend :  0.8369371891021729
self.buckets_partition() spend  sec:  0.7006144523620605
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04555487632751465

in edges time spent  0.1489884853363037
local to global src and eids time spent  0.2904174327850342
time gen tails  0.07016110420227051
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.12983083724975586

in edges time spent  0.5440027713775635
local to global src and eids time spent  0.884890079498291
time gen tails  0.14051389694213867
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09357023239135742  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.181320190429688  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18098258972168  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09451150894165039  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040970802307129  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044723510742188  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10244035720825195  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.404947757720947  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.410243511199951  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10514450073242188  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.010391235351562  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.014134883880615  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11121320724487305  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3223391771316528
pure train time :  0.48493313789367676
train time :  0.7693250179290771
end to end time :  5.5957911014556885
connection check time:  2.5986058712005615
block generation time  1.37583327293396
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005567073822021484
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014278173446655273
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7373404502868652
len local_batched_seeds_list  4
partition total batch output list spend :  0.8887057304382324
self.buckets_partition() spend  sec:  0.7516543865203857
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.045798301696777344

in edges time spent  0.14746809005737305
local to global src and eids time spent  0.2880563735961914
time gen tails  0.06974196434020996
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1299276351928711

in edges time spent  0.5363800525665283
local to global src and eids time spent  0.8711032867431641
time gen tails  0.13944005966186523
res  length 4
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09409475326538086  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.144738674163818  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.144401550292969  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09556198120117188  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.05442476272583  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.059101104736328  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10291814804077148  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.424755573272705  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.430051326751709  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10465002059936523  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.019364833831787  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.023173332214355  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11110639572143555  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.322256088256836
pure train time :  0.49356532096862793
train time :  0.7666189670562744
end to end time :  5.6190338134765625
connection check time:  2.5714104175567627
block generation time  1.3776378631591797
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005509853363037109
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014554738998413086
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6791033744812012
len local_batched_seeds_list  4
partition total batch output list spend :  0.8297684192657471
self.buckets_partition() spend  sec:  0.6937050819396973
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04575157165527344

in edges time spent  0.14766383171081543
local to global src and eids time spent  0.2893788814544678
time gen tails  0.06975579261779785
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.12912774085998535

in edges time spent  0.49149131774902344
local to global src and eids time spent  0.7805488109588623
time gen tails  0.14107608795166016
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09395360946655273  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.187353134155273  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18701457977295  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09473371505737305  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040798664093018  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044551372528076  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10272645950317383  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.455676078796387  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.461026668548584  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058206558227539  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9774394035339355  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.980751037597656  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11153173446655273  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3157923221588135
pure train time :  0.48749327659606934
train time :  0.7690544128417969
end to end time :  5.431772708892822
connection check time:  2.4398205280303955
block generation time  1.3754661083221436
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005974769592285156
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013985633850097656
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6863863468170166
len local_batched_seeds_list  4
partition total batch output list spend :  0.8377206325531006
self.buckets_partition() spend  sec:  0.7004058361053467
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.046178340911865234

in edges time spent  0.14943337440490723
local to global src and eids time spent  0.2883307933807373
time gen tails  0.06973481178283691
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1299457550048828

in edges time spent  0.5540804862976074
local to global src and eids time spent  0.8516740798950195
time gen tails  0.10435962677001953
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09400558471679688  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18338394165039  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182403564453125  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09506654739379883  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.047733306884766  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.051486015319824  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10306024551391602  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.401082038879395  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.406377792358398  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058197021484375  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.017569065093994  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.02060317993164  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11095285415649414  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3171063661575317
pure train time :  0.5074291229248047
train time :  0.765265941619873
end to end time :  5.528975486755371
connection check time:  2.5374114513397217
block generation time  1.375676155090332
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006461143493652344
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015363216400146484
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6598052978515625
len local_batched_seeds_list  4
partition total batch output list spend :  0.7297329902648926
self.buckets_partition() spend  sec:  0.6752011775970459
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04334449768066406

in edges time spent  0.1496725082397461
local to global src and eids time spent  0.29091572761535645
time gen tails  0.07010149955749512
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1315450668334961

in edges time spent  0.5224795341491699
local to global src and eids time spent  0.7826516628265381
time gen tails  0.10633182525634766
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09357547760009766  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186144828796387  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18580675125122  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09482908248901367  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04611873626709  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.049871444702148  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10240316390991211  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.392010688781738  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.397306442260742  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10463666915893555  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.970363140106201  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.973674774169922  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11065912246704102  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3140075206756592
pure train time :  0.4960017204284668
train time :  0.771101713180542
end to end time :  5.3387603759765625
connection check time:  2.4376964569091797
block generation time  1.381418228149414
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005707740783691406
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015126466751098633
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6822397708892822
len local_batched_seeds_list  4
partition total batch output list spend :  0.762274980545044
self.buckets_partition() spend  sec:  0.6974000930786133
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.043222665786743164

in edges time spent  0.149733304977417
local to global src and eids time spent  0.2896435260772705
time gen tails  0.0701746940612793
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13019323348999023

in edges time spent  0.564399242401123
local to global src and eids time spent  0.8716640472412109
time gen tails  0.1411457061767578
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.093536376953125  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185005187988281  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184668064117432  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09483861923217773  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.038835525512695  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.042588233947754  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10281610488891602  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.393531322479248  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.398827075958252  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058206558227539  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.973252296447754  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.977060794830322  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11133337020874023  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.312406063079834
pure train time :  0.49004125595092773
train time :  0.763336181640625
end to end time :  5.518930435180664
connection check time:  2.6008119583129883
block generation time  1.3790225982666016
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005688667297363281
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014262914657592773
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6802153587341309
len local_batched_seeds_list  4
partition total batch output list spend :  0.8308334350585938
self.buckets_partition() spend  sec:  0.6945171356201172
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.045520782470703125

in edges time spent  0.14889216423034668
local to global src and eids time spent  0.28871774673461914
time gen tails  0.07018661499023438
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13045144081115723

in edges time spent  0.545626163482666
local to global src and eids time spent  0.8837392330169678
time gen tails  0.13999271392822266
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09390878677368164  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.150716781616211  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.15038013458252  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09479713439941406  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.042816638946533  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046569347381592  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10251522064208984  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.434879779815674  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.440175533294678  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058206558227539  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.020098686218262  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.02390718460083  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11136674880981445  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3160361051559448
pure train time :  0.49645400047302246
train time :  0.783247709274292
end to end time :  5.61346697807312
connection check time:  2.604261875152588
block generation time  1.3742926120758057
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006012916564941406
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014068603515625
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6862921714782715
len local_batched_seeds_list  4
partition total batch output list spend :  0.8391706943511963
self.buckets_partition() spend  sec:  0.7003958225250244
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04604911804199219

in edges time spent  0.14987850189208984
local to global src and eids time spent  0.2898228168487549
time gen tails  0.07027745246887207
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13051366806030273

in edges time spent  0.5601882934570312
local to global src and eids time spent  0.8659303188323975
time gen tails  0.14020776748657227
res  length 4
block collection to dataloader spend  1.239776611328125e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09402847290039062  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.187452793121338  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.187114238739014  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09538888931274414  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.039592266082764  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043344974517822  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1026449203491211  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.39659070968628  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.401962280273438  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464763641357422  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.021989345550537  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.025797843933105  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1110992431640625  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3136751651763916
pure train time :  0.48924708366394043
train time :  0.7723729610443115
end to end time :  5.607909679412842
connection check time:  2.5966269969940186
block generation time  1.379425048828125
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0008111000061035156
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014353036880493164
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7090721130371094
len local_batched_seeds_list  4
partition total batch output list spend :  0.8599436283111572
self.buckets_partition() spend  sec:  0.7234756946563721
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04566621780395508

in edges time spent  0.1477980613708496
local to global src and eids time spent  0.2884256839752197
time gen tails  0.07062554359436035
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.12935733795166016

in edges time spent  0.5330591201782227
local to global src and eids time spent  0.8694117069244385
time gen tails  0.14059853553771973
res  length 4
block collection to dataloader spend  1.2159347534179688e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09405851364135742  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18669843673706  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186360359191895  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09447336196899414  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043161869049072  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04691457748413  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10251760482788086  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.45582103729248  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.461116790771484  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464954376220703  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.012425422668457  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.016233921051025  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11110115051269531  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3133368492126465
pure train time :  0.48270440101623535
train time :  0.7664382457733154
end to end time :  5.608365774154663
connection check time:  2.569516658782959
block generation time  1.3939268589019775
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005679130554199219
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014179229736328125
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6910901069641113
len local_batched_seeds_list  4
partition total batch output list spend :  0.8416714668273926
self.buckets_partition() spend  sec:  0.7053158283233643
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04612255096435547

in edges time spent  0.1489853858947754
local to global src and eids time spent  0.2887904644012451
time gen tails  0.07012128829956055
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.12998557090759277

in edges time spent  0.5392520427703857
local to global src and eids time spent  0.869534969329834
time gen tails  0.14185380935668945
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09406042098999023  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183751583099365  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183505535125732  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09508371353149414  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.050727367401123  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.054480075836182  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10251903533935547  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.4608473777771  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.466143131256104  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10515308380126953  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9754743576049805  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.979282855987549  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1118464469909668  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.308037281036377
pure train time :  0.48093390464782715
train time :  0.7629635334014893
end to end time :  5.5767529010772705
connection check time:  2.579927444458008
block generation time  1.3794567584991455
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005764961242675781
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014193058013916016
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6750459671020508
len local_batched_seeds_list  4
partition total batch output list spend :  0.8253676891326904
self.buckets_partition() spend  sec:  0.689272403717041
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04576587677001953

in edges time spent  0.14903855323791504
local to global src and eids time spent  0.287386417388916
time gen tails  0.07024884223937988
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13030290603637695

in edges time spent  0.5325660705566406
local to global src and eids time spent  0.8727569580078125
time gen tails  0.1409308910369873
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0939188003540039  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18373966217041  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183402061462402  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09485149383544922  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.045095443725586  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.048848152160645  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10246610641479492  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.429239273071289  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.434535026550293  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10463666915893555  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9722900390625  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.975601673126221  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1106562614440918  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3078265190124512
pure train time :  0.5556719303131104
train time :  0.8330028057098389
end to end time :  5.628346681594849
connection check time:  2.573004961013794
block generation time  1.3798494338989258
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005755424499511719
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014952421188354492
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7647011280059814
len local_batched_seeds_list  4
partition total batch output list spend :  0.91872239112854
self.buckets_partition() spend  sec:  0.7796869277954102
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04586601257324219

in edges time spent  0.1499004364013672
local to global src and eids time spent  0.28775763511657715
time gen tails  0.06998562812805176
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.12982892990112305

in edges time spent  0.5230011940002441
local to global src and eids time spent  0.776695728302002
time gen tails  0.10653567314147949
res  length 4
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09388494491577148  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183254718780518  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182918071746826  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09452247619628906  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043355464935303  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.047108173370361  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10259389877319336  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.432019710540771  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.437379837036133  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058206558227539  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.017383575439453  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.020695209503174  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11143112182617188  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3069994449615479
pure train time :  0.4877142906188965
train time :  0.7528543472290039
end to end time :  5.501740217208862
connection check time:  2.434751033782959
block generation time  1.3812730312347412
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005805492401123047
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01555776596069336
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6716499328613281
len local_batched_seeds_list  4
partition total batch output list spend :  0.7416057586669922
self.buckets_partition() spend  sec:  0.6872410774230957
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04326939582824707

in edges time spent  0.14782452583312988
local to global src and eids time spent  0.2888448238372803
time gen tails  0.07026219367980957
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.12867140769958496

in edges time spent  0.5260028839111328
local to global src and eids time spent  0.868436336517334
time gen tails  0.14029526710510254
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09365415573120117  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.14858865737915  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.148251056671143  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09468412399291992  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.037211418151855  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040964126586914  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10267210006713867  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.454301834106445  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.459640979766846  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1046442985534668  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.009665489196777  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.012977123260498  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11068201065063477  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.305462121963501
pure train time :  0.5002319812774658
train time :  0.7820971012115479
end to end time :  5.495481014251709
connection check time:  2.565751075744629
block generation time  1.3893482685089111
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006351470947265625
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015112638473510742
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6958754062652588
len local_batched_seeds_list  4
partition total batch output list spend :  0.8478853702545166
self.buckets_partition() spend  sec:  0.7110238075256348
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04798746109008789

in edges time spent  0.15950393676757812
local to global src and eids time spent  0.29219985008239746
time gen tails  0.0716402530670166
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13185882568359375

in edges time spent  0.5898709297180176
local to global src and eids time spent  0.8947861194610596
time gen tails  0.1418766975402832
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0935521125793457  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184022903442383  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18376874923706  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09516477584838867  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.048786163330078  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.052887439727783  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1023550033569336  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.382631778717041  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.387927532196045  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1055612564086914  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.016973495483398  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.020007610321045  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11070394515991211  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3014411926269531
pure train time :  0.5017318725585938
train time :  0.7790806293487549
end to end time :  5.707094669342041
connection check time:  2.674757957458496
block generation time  1.3896732330322266
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.000583648681640625
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01513528823852539
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6898486614227295
len local_batched_seeds_list  4
partition total batch output list spend :  0.8405320644378662
self.buckets_partition() spend  sec:  0.705019474029541
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04604673385620117

in edges time spent  0.14921236038208008
local to global src and eids time spent  0.29109668731689453
time gen tails  0.07038521766662598
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13389921188354492

in edges time spent  0.5478811264038086
local to global src and eids time spent  0.8731656074523926
time gen tails  0.14185237884521484
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09357738494873047  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186243534088135  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185905456542969  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09487438201904297  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.041944980621338  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.045697689056396  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10234880447387695  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.45925521850586  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.464550971984863  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1046452522277832  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.014243125915527  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.017554759979248  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11068487167358398  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.299094319343567
pure train time :  0.510690450668335
train time :  0.7828073501586914
end to end time :  5.624990224838257
connection check time:  2.5994713306427
block generation time  1.3833403587341309
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005805492401123047
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014350414276123047
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7539749145507812
len local_batched_seeds_list  4
partition total batch output list spend :  0.9072625637054443
self.buckets_partition() spend  sec:  0.7683701515197754
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.045653581619262695

in edges time spent  0.15044045448303223
local to global src and eids time spent  0.2903263568878174
time gen tails  0.07007980346679688
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13072562217712402

in edges time spent  0.5382876396179199
local to global src and eids time spent  0.8737761974334717
time gen tails  0.1443469524383545
res  length 4
block collection to dataloader spend  1.5735626220703125e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09366846084594727  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185898303985596  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185560703277588  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09542369842529297  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.041316032409668  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.045068740844727  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10227203369140625  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.393689155578613  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.398984909057617  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10463857650756836  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.975722312927246  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.979033946990967  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11084890365600586  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2994316816329956
pure train time :  0.48963427543640137
train time :  0.7775475978851318
end to end time :  5.680598974227905
connection check time:  2.592005729675293
block generation time  1.3832566738128662
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005953311920166016
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014498233795166016
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7140688896179199
len local_batched_seeds_list  4
partition total batch output list spend :  0.8659591674804688
self.buckets_partition() spend  sec:  0.7286064624786377
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04566001892089844

in edges time spent  0.14833807945251465
local to global src and eids time spent  0.2900056838989258
time gen tails  0.07017350196838379
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13402223587036133

in edges time spent  0.5325076580047607
local to global src and eids time spent  0.8694009780883789
time gen tails  0.14130783081054688
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09362220764160156  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.147155284881592  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.146174907684326  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09526395797729492  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.053842067718506  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.057594776153564  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10263347625732422  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.43681287765503  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.442108631134033  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464286804199219  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.980596542358398  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.983630657196045  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11118745803833008  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3005106449127197
pure train time :  0.4884016513824463
train time :  0.7630219459533691
end to end time :  5.615554571151733
connection check time:  2.5788724422454834
block generation time  1.3925657272338867
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006656646728515625
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014517545700073242
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7040486335754395
len local_batched_seeds_list  4
partition total batch output list spend :  0.8553907871246338
self.buckets_partition() spend  sec:  0.7186002731323242
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04578590393066406

in edges time spent  0.14860153198242188
local to global src and eids time spent  0.2909049987792969
time gen tails  0.0700070858001709
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13111019134521484

in edges time spent  0.538818359375
local to global src and eids time spent  0.8746922016143799
time gen tails  0.1415555477142334
res  length 4
block collection to dataloader spend  1.6689300537109375e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09348917007446289  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183017253875732  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182036399841309  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09511089324951172  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.0471773147583  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.051278591156006  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10226821899414062  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.393213272094727  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.39850902557373  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1046457290649414  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.01581621170044  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.019624710083008  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11111736297607422  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2985892295837402
pure train time :  0.5176694393157959
train time :  0.772719144821167
end to end time :  5.629290342330933
connection check time:  2.586212396621704
block generation time  1.3980567455291748
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006067752838134766
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014305830001831055
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7359817028045654
len local_batched_seeds_list  4
partition total batch output list spend :  0.8896944522857666
self.buckets_partition() spend  sec:  0.7503230571746826
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04563450813293457

in edges time spent  0.14789724349975586
local to global src and eids time spent  0.2910733222961426
time gen tails  0.07007980346679688
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.12924599647521973

in edges time spent  0.540428638458252
local to global src and eids time spent  0.8680570125579834
time gen tails  0.14240813255310059
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0939640998840332  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18489122390747  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183910369873047  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09521484375  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043518543243408  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.047619819641113  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10230398178100586  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.394927501678467  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.40022325515747  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10555601119995117  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.013659954071045  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.017468452453613  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11108875274658203  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2931033372879028
pure train time :  0.49359941482543945
train time :  0.7647004127502441
end to end time :  5.63193678855896
connection check time:  2.579509735107422
block generation time  1.382369041442871
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005972385406494141
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014369964599609375
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6947290897369385
len local_batched_seeds_list  4
partition total batch output list spend :  0.8471946716308594
self.buckets_partition() spend  sec:  0.7091381549835205
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.0460965633392334

in edges time spent  0.14828824996948242
local to global src and eids time spent  0.2910494804382324
time gen tails  0.07606339454650879
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13145017623901367

in edges time spent  0.5452733039855957
local to global src and eids time spent  0.8758878707885742
time gen tails  0.14372539520263672
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09388303756713867  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.149009227752686  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.148671627044678  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0948634147644043  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.055256843566895  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.059009552001953  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10235166549682617  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.434775829315186  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.44007158279419  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10634374618530273  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.016879081726074  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.020687580108643  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11189556121826172  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2926652431488037
pure train time :  0.46232056617736816
train time :  0.7576291561126709
end to end time :  5.635686635971069
connection check time:  2.6117658615112305
block generation time  1.4017879962921143
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005850791931152344
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014692544937133789
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6975388526916504
len local_batched_seeds_list  4
partition total batch output list spend :  0.8525526523590088
self.buckets_partition() spend  sec:  0.7122650146484375
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04843020439147949

in edges time spent  0.15938973426818848
local to global src and eids time spent  0.29186010360717773
time gen tails  0.07060742378234863
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13234353065490723

in edges time spent  0.581404447555542
local to global src and eids time spent  0.8928229808807373
time gen tails  0.14120125770568848
res  length 4
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09405088424682617  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183691501617432  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183454513549805  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.095062255859375  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.040867328643799  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044968605041504  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10261154174804688  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.399736404418945  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.40509843826294  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10527896881103516  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.979793548583984  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.983105182647705  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11136436462402344  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.29501211643219
pure train time :  0.49228382110595703
train time :  0.7648653984069824
end to end time :  5.68815803527832
connection check time:  2.664130926132202
block generation time  1.3903498649597168
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005881786346435547
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014254331588745117
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6964423656463623
len local_batched_seeds_list  4
partition total batch output list spend :  0.8486123085021973
self.buckets_partition() spend  sec:  0.7107434272766113
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04583001136779785

in edges time spent  0.15194416046142578
local to global src and eids time spent  0.28967905044555664
time gen tails  0.07025313377380371
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13117289543151855

in edges time spent  0.5575811862945557
local to global src and eids time spent  0.8846423625946045
time gen tails  0.1412491798400879
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09358501434326172  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184276580810547  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183939456939697  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09511995315551758  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.045133590698242  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.0488862991333  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1023869514465332  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.452620029449463  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.457915782928467  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10463905334472656  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9729390144348145  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.975973129272461  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11066341400146484  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2900687456130981
pure train time :  0.4938547611236572
train time :  0.776069164276123
end to end time :  5.648752450942993
connection check time:  2.617002010345459
block generation time  1.3863976001739502
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006022453308105469
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.017577409744262695
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6925220489501953
len local_batched_seeds_list  4
partition total batch output list spend :  0.8469884395599365
self.buckets_partition() spend  sec:  0.7101335525512695
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.0439298152923584

in edges time spent  0.15106463432312012
local to global src and eids time spent  0.2894017696380615
time gen tails  0.07061171531677246
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13162517547607422

in edges time spent  0.5558619499206543
local to global src and eids time spent  0.8720455169677734
time gen tails  0.14253544807434082
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09350395202636719  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184523582458496  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184255123138428  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09515047073364258  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.048011302947998  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.051764011383057  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10257530212402344  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.437891483306885  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.44324016571045  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10520553588867188  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.979625225067139  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.982936859130859  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11142492294311523  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2892444133758545
pure train time :  0.4991726875305176
train time :  0.7750730514526367
end to end time :  5.63989782333374
connection check time:  2.614379405975342
block generation time  1.3868823051452637
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005946159362792969
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014317512512207031
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.692110538482666
len local_batched_seeds_list  4
partition total batch output list spend :  0.8435397148132324
self.buckets_partition() spend  sec:  0.7064635753631592
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04610633850097656

in edges time spent  0.14995646476745605
local to global src and eids time spent  0.28933167457580566
time gen tails  0.07000017166137695
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1328437328338623

in edges time spent  0.5383491516113281
local to global src and eids time spent  0.8755724430084229
time gen tails  0.14032363891601562
res  length 4
block collection to dataloader spend  1.33514404296875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09412479400634766  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.189208984375  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.188228130340576  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09506607055664062  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.038646221160889  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.042398929595947  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10237741470336914  GigaBytes
Max Memory Allocated: 8.705501079559326  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.463850975036621  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.469146728515625  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10527372360229492  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.021726131439209  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.02503776550293  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11069869995117188  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2919195890426636
pure train time :  0.490938663482666
train time :  0.7708075046539307
end to end time :  5.6058337688446045
connection check time:  2.5903639793395996
block generation time  1.382336139678955
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006036758422851562
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014307975769042969
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.723609209060669
len local_batched_seeds_list  4
partition total batch output list spend :  0.875098705291748
self.buckets_partition() spend  sec:  0.7379560470581055
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04625558853149414

in edges time spent  0.15345215797424316
local to global src and eids time spent  0.2941136360168457
time gen tails  0.07089972496032715
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13236045837402344

in edges time spent  0.5522141456604004
local to global src and eids time spent  0.8707513809204102
time gen tails  0.14093589782714844
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0935211181640625  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183942317962646  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.182960987091064  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09503316879272461  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.034737586975098  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.038490295410156  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10280609130859375  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.453606128692627  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.45890188217163  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464000701904297  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.979880332946777  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.98362398147583  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11174249649047852  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2897758483886719
pure train time :  0.49980854988098145
train time :  0.7754809856414795
end to end time :  5.669502019882202
connection check time:  2.606584072113037
block generation time  1.3993315696716309
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.000545501708984375
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014408588409423828
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7005929946899414
len local_batched_seeds_list  4
partition total batch output list spend :  0.8515045642852783
self.buckets_partition() spend  sec:  0.7150359153747559
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04629015922546387

in edges time spent  0.14829301834106445
local to global src and eids time spent  0.2874324321746826
time gen tails  0.07082629203796387
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1299734115600586

in edges time spent  0.5587801933288574
local to global src and eids time spent  0.8785295486450195
time gen tails  0.14763855934143066
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09408712387084961  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183462619781494  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183125495910645  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0944366455078125  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04311466217041  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046867370605469  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10238122940063477  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.451505661010742  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.456801414489746  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10555410385131836  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.980345726013184  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.983657360076904  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11067867279052734  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.288743257522583
pure train time :  0.5077822208404541
train time :  0.7792918682098389
end to end time :  5.677203416824341
connection check time:  2.617886781692505
block generation time  1.4149305820465088
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005838871002197266
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015058755874633789
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6921608448028564
len local_batched_seeds_list  4
partition total batch output list spend :  0.8428926467895508
self.buckets_partition() spend  sec:  0.7072556018829346
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04817795753479004

in edges time spent  0.15567398071289062
local to global src and eids time spent  0.29779934883117676
time gen tails  0.07103919982910156
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13124990463256836

in edges time spent  0.5732054710388184
local to global src and eids time spent  0.88983154296875
time gen tails  0.1422727108001709
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09363031387329102  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185551166534424  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185213565826416  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09434318542480469  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.03133773803711  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.035090446472168  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1021728515625  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.38665246963501  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.39285945892334  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10535335540771484  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.023227214813232  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.0270357131958  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11110830307006836  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.283341407775879
pure train time :  0.4918053150177002
train time :  0.7619585990905762
end to end time :  5.684988021850586
connection check time:  2.6574196815490723
block generation time  1.4014275074005127
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006456375122070312
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01482391357421875
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6954140663146973
len local_batched_seeds_list  4
partition total batch output list spend :  0.8470942974090576
self.buckets_partition() spend  sec:  0.7102727890014648
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04649496078491211

in edges time spent  0.15288424491882324
local to global src and eids time spent  0.2945575714111328
time gen tails  0.07068514823913574
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13531041145324707

in edges time spent  0.532128095626831
local to global src and eids time spent  0.7918586730957031
time gen tails  0.10385417938232422
res  length 4
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09385538101196289  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.180483341217041  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.180144786834717  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09467411041259766  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.029954433441162  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.03370714187622  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1022348403930664  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.399006843566895  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.404302597045898  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10465002059936523  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.020203113555908  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.023946762084961  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1114044189453125  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2814157009124756
pure train time :  0.49819517135620117
train time :  0.7666902542114258
end to end time :  5.499346017837524
connection check time:  2.475741147994995
block generation time  1.3914940357208252
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005922317504882812
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015257835388183594
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.670295000076294
len local_batched_seeds_list  4
partition total batch output list spend :  0.7406339645385742
self.buckets_partition() spend  sec:  0.6855859756469727
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04432559013366699

in edges time spent  0.1506330966949463
local to global src and eids time spent  0.29004454612731934
time gen tails  0.07043218612670898
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13042640686035156

in edges time spent  0.5433847904205322
local to global src and eids time spent  0.8739712238311768
time gen tails  0.1412217617034912
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09392738342285156  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183807373046875  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183544635772705  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0951685905456543  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04548692703247  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04923963546753  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10217952728271484  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.378516674041748  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.383812427520752  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464811325073242  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.019883632659912  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.023627281188965  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1110997200012207  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2813948392868042
pure train time :  0.4986128807067871
train time :  0.7687234878540039
end to end time :  5.505646467208862
connection check time:  2.5922348499298096
block generation time  1.3862991333007812
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005745887756347656
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01444387435913086
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7234723567962646
len local_batched_seeds_list  4
partition total batch output list spend :  0.876812219619751
self.buckets_partition() spend  sec:  0.7379522323608398
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.046645164489746094

in edges time spent  0.1481311321258545
local to global src and eids time spent  0.300917387008667
time gen tails  0.07439517974853516
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13186383247375488

in edges time spent  0.5487983226776123
local to global src and eids time spent  0.89811110496521
time gen tails  0.1458587646484375
res  length 4
block collection to dataloader spend  1.3589859008789062e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0939168930053711  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183928489685059  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183686256408691  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09520483016967773  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.049737453460693  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.053490161895752  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10254764556884766  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.436291217803955  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.441586971282959  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10582113265991211  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.978796005249023  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.982604503631592  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11133861541748047  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2807586193084717
pure train time :  0.5017745494842529
train time :  0.777381181716919
end to end time :  5.737572193145752
connection check time:  2.6630172729492188
block generation time  1.401611089706421
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006949901580810547
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014572381973266602
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7109251022338867
len local_batched_seeds_list  4
partition total batch output list spend :  0.86326003074646
self.buckets_partition() spend  sec:  0.7255363464355469
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04624009132385254

in edges time spent  0.14876484870910645
local to global src and eids time spent  0.2896590232849121
time gen tails  0.07042241096496582
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1316835880279541

in edges time spent  0.5448768138885498
local to global src and eids time spent  0.8826260566711426
time gen tails  0.14122486114501953
res  length 4
block collection to dataloader spend  1.0967254638671875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09392356872558594  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185722827911377  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18474292755127  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09515094757080078  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.048023700714111  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.05177640914917  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10249614715576172  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.38861608505249  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.393999099731445  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10464763641357422  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.014599800109863  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.017911434173584  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11069488525390625  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2776024341583252
pure train time :  0.5001444816589355
train time :  0.7656519412994385
end to end time :  5.654961109161377
connection check time:  2.604236125946045
block generation time  1.4074532985687256
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005917549133300781
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014440059661865234
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7521624565124512
len local_batched_seeds_list  4
partition total batch output list spend :  0.9051241874694824
self.buckets_partition() spend  sec:  0.7666385173797607
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.046080589294433594

in edges time spent  0.14864230155944824
local to global src and eids time spent  0.2901787757873535
time gen tails  0.07062530517578125
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13168001174926758

in edges time spent  0.5372381210327148
local to global src and eids time spent  0.8748197555541992
time gen tails  0.14151239395141602
res  length 4
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09340763092041016  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.15387487411499  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.152893543243408  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09502887725830078  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.039588451385498  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043341159820557  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1023249626159668  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.453190326690674  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.458486080169678  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10555839538574219  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.008999347686768  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.012310981750488  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11069250106811523  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2785298824310303
pure train time :  0.5278034210205078
train time :  0.7862412929534912
end to end time :  5.677408218383789
connection check time:  2.5860331058502197
block generation time  1.3867039680480957
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.000591278076171875
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014289140701293945
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6884675025939941
len local_batched_seeds_list  4
partition total batch output list spend :  0.8405501842498779
self.buckets_partition() spend  sec:  0.702794075012207
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.0461270809173584

in edges time spent  0.15056896209716797
local to global src and eids time spent  0.2909812927246094
time gen tails  0.07065510749816895
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13057708740234375

in edges time spent  0.5359072685241699
local to global src and eids time spent  0.8729314804077148
time gen tails  0.14113140106201172
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09419441223144531  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186229228973389  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.18589162826538  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09477615356445312  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.044517993927002  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04827070236206  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10236406326293945  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.456313133239746  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.46160888671875  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10463666915893555  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9691009521484375  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.972909450531006  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11105871200561523  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.277881383895874
pure train time :  0.49211883544921875
train time :  0.7649178504943848
end to end time :  5.594744443893433
connection check time:  2.585369348526001
block generation time  1.3911221027374268
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.000614166259765625
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014495134353637695
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6867814064025879
len local_batched_seeds_list  4
partition total batch output list spend :  0.8377838134765625
self.buckets_partition() spend  sec:  0.701312780380249
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.045935630798339844

in edges time spent  0.1502547264099121
local to global src and eids time spent  0.2902820110321045
time gen tails  0.0704808235168457
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1311793327331543

in edges time spent  0.5352990627288818
local to global src and eids time spent  0.8694770336151123
time gen tails  0.14052152633666992
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09408712387084961  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.181077480316162  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.180097579956055  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0951542854309082  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.041601181030273  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.045353889465332  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10276222229003906  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.399112701416016  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.40440845489502  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058206558227539  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.015939712524414  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.019251346588135  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11095380783081055  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2748199701309204
pure train time :  0.500126838684082
train time :  0.7671487331390381
end to end time :  5.623953819274902
connection check time:  2.5860483646392822
block generation time  1.4156391620635986
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006127357482910156
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01634526252746582
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7107880115509033
len local_batched_seeds_list  4
partition total batch output list spend :  0.8661649227142334
self.buckets_partition() spend  sec:  0.7271709442138672
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04967641830444336

in edges time spent  0.16541171073913574
local to global src and eids time spent  0.2949974536895752
time gen tails  0.0722208023071289
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13657712936401367

in edges time spent  0.5800502300262451
local to global src and eids time spent  0.8889474868774414
time gen tails  0.14402508735656738
res  length 4
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09348201751708984  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.178756713867188  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.178418636322021  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09450006484985352  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.042664527893066  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046417236328125  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10226202011108398  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.39270830154419  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.398707389831543  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1052865982055664  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.016977787017822  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.02078628540039  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11110353469848633  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2765138149261475
pure train time :  0.48995280265808105
train time :  0.7689390182495117
end to end time :  5.762920141220093
connection check time:  2.682453155517578
block generation time  1.4255499839782715
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005965232849121094
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014867782592773438
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6975398063659668
len local_batched_seeds_list  4
partition total batch output list spend :  0.849998950958252
self.buckets_partition() spend  sec:  0.7124428749084473
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.046114444732666016

in edges time spent  0.15956592559814453
local to global src and eids time spent  0.2895393371582031
time gen tails  0.07129454612731934
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13017034530639648

in edges time spent  0.5685760974884033
local to global src and eids time spent  0.902111291885376
time gen tails  0.14253830909729004
res  length 4
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0938711166381836  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.186229228973389  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185247421264648  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09505414962768555  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.036034107208252  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.03978681564331  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10238409042358398  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.4623384475708  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.467634201049805  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058206558227539  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.014689445495605  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018497943878174  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11136770248413086  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2710751295089722
pure train time :  0.5100433826446533
train time :  0.7703640460968018
end to end time :  5.685877084732056
connection check time:  2.655230760574341
block generation time  1.3923656940460205
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005931854248046875
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014294147491455078
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.69309401512146
len local_batched_seeds_list  4
partition total batch output list spend :  0.8450846672058105
self.buckets_partition() spend  sec:  0.707421064376831
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04552054405212402

in edges time spent  0.15001559257507324
local to global src and eids time spent  0.29110169410705566
time gen tails  0.07087993621826172
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.1287698745727539

in edges time spent  0.547985315322876
local to global src and eids time spent  0.8872883319854736
time gen tails  0.14574670791625977
res  length 4
block collection to dataloader spend  1.5497207641601562e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09401512145996094  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.144124031066895  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.14378547668457  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09547948837280273  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.055859088897705  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.060325145721436  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.102630615234375  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.398580551147461  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.403944492340088  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10528802871704102  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.012941360473633  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.016749858856201  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11110401153564453  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2711093425750732
pure train time :  0.518380880355835
train time :  0.7803292274475098
end to end time :  5.661861419677734
connection check time:  2.631180763244629
block generation time  1.3904306888580322
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005774497985839844
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014369487762451172
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.7126548290252686
len local_batched_seeds_list  4
partition total batch output list spend :  0.8644747734069824
self.buckets_partition() spend  sec:  0.7270610332489014
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04630899429321289

in edges time spent  0.15461444854736328
local to global src and eids time spent  0.289414644241333
time gen tails  0.07089829444885254
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13020753860473633

in edges time spent  0.5389804840087891
local to global src and eids time spent  0.8743255138397217
time gen tails  0.14357519149780273
res  length 4
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0941767692565918  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183915138244629  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183595657348633  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0950779914855957  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04457950592041  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.048332214355469  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10252523422241211  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.456727504730225  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.462023258209229  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10463094711303711  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.959320545196533  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.962632179260254  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11063814163208008  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2715563774108887
pure train time :  0.5076522827148438
train time :  0.7764976024627686
end to end time :  5.661085367202759
connection check time:  2.5949649810791016
block generation time  1.4045226573944092
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005941390991210938
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014665603637695312
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6973795890808105
len local_batched_seeds_list  4
partition total batch output list spend :  0.8497111797332764
self.buckets_partition() spend  sec:  0.7120795249938965
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04575800895690918

in edges time spent  0.1509253978729248
local to global src and eids time spent  0.2921485900878906
time gen tails  0.07069087028503418
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13249635696411133

in edges time spent  0.5343108177185059
local to global src and eids time spent  0.8741874694824219
time gen tails  0.14118146896362305
res  length 4
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09353017807006836  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184857845306396  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184521675109863  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0947718620300293  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.047260284423828  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.051012992858887  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10260486602783203  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.399805068969727  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.405170917510986  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1046457290649414  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.016422748565674  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.020166397094727  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11109590530395508  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.271713376045227
pure train time :  0.5038282871246338
train time :  0.7683677673339844
end to end time :  5.610451936721802
connection check time:  2.586843967437744
block generation time  1.392467737197876
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005812644958496094
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014467477798461914
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6912758350372314
len local_batched_seeds_list  4
partition total batch output list spend :  0.8407120704650879
self.buckets_partition() spend  sec:  0.7057766914367676
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04580044746398926

in edges time spent  0.1510767936706543
local to global src and eids time spent  0.28894853591918945
time gen tails  0.07023048400878906
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.12999367713928223

in edges time spent  0.5550646781921387
local to global src and eids time spent  0.8851044178009033
time gen tails  0.1385183334350586
res  length 4
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09396076202392578  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.147646427154541  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.146665573120117  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.0950770378112793  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043200016021729  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.046952724456787  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10239982604980469  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.380883693695068  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.387090682983398  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10535478591918945  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.017024993896484  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.020336627960205  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11070919036865234  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.266456127166748
pure train time :  0.5213732719421387
train time :  0.781226634979248
end to end time :  5.624208211898804
connection check time:  2.5944409370422363
block generation time  1.3944354057312012
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0006048679351806641
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.016299962997436523
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6962971687316895
len local_batched_seeds_list  4
partition total batch output list spend :  0.8607618808746338
self.buckets_partition() spend  sec:  0.7126355171203613
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.053835153579711914

in edges time spent  0.16805696487426758
local to global src and eids time spent  0.2996182441711426
time gen tails  0.07307291030883789
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13963747024536133

in edges time spent  0.5795478820800781
local to global src and eids time spent  0.7970869541168213
time gen tails  0.11191582679748535
res  length 4
block collection to dataloader spend  1.0013580322265625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09416055679321289  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185596942901611  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.185258388519287  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09481143951416016  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.038262367248535  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.042015075683594  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10256338119506836  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.390504360198975  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.395885467529297  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058206558227539  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.9835100173950195  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 7.987318515777588  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.11176633834838867  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.263098120689392
pure train time :  0.4835388660430908
train time :  0.7612054347991943
end to end time :  5.643589496612549
connection check time:  2.587167978286743
block generation time  1.4212212562561035
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005822181701660156
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015577077865600586
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.677832841873169
len local_batched_seeds_list  4
partition total batch output list spend :  0.747882604598999
self.buckets_partition() spend  sec:  0.6934454441070557
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.043714284896850586

in edges time spent  0.15489482879638672
local to global src and eids time spent  0.29365968704223633
time gen tails  0.0706174373626709
res  length 4
layer  1
num of batch  4
check_connections_block*********************************

the find indices time spent  0.13168025016784668

in edges time spent  0.5835916996002197
local to global src and eids time spent  0.9010686874389648
time gen tails  0.1420300006866455
res  length 4
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09382963180541992  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.184018611907959  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.183831691741943  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.09513711929321289  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.043995380401611  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.04774808883667  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.10226678848266602  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.398295402526855  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.40359115600586  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

step  3
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1058197021484375  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.014996528625488  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 8.018308162689209  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 13.2578125 GB
    Memory Allocated: 0.1112513542175293  GigaBytes
Max Memory Allocated: 8.707294464111328  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2668406963348389
pure train time :  0.520484447479248
train time :  0.7721772193908691
end to end time :  5.601591348648071
connection check time:  2.6619744300842285
block generation time  1.4003896713256836
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  4
the grouping_fanout_arxiv called successfully
capacity  6300
 
sorted_dict  {4: 1237, 5: 1233, 6: 1219, 7: 1211, 3: 1206, 8: 1184, 9: 1176, 2: 1174, 11: 1121, 10: 1116, 1: 1092, 12: 1061, 13: 1035, 14: 1013, 16: 960, 15: 955, 0: 928, 17: 928, 18: 916, 19: 900, 20: 868, 22: 800, 23: 795, 21: 787}

weights after sort [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1219 1092 1061 1013  960  955]

remove bucket_id:  [2, 10, 11, 13, 14, 15]
original bucket_id :,  [6, 1, 12, 14, 16, 15]
remove weights:  [1219 1092 1061 1013  960  955], 		------------sum 6300

before remove weights,  [1237, 1233, 1219, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1092, 1061, 1035, 1013, 960, 955, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
res_tmp  [1184 1121 1116 1035  928  916]

remove bucket_id:  [4, 7, 8, 9, 10, 12]
original bucket_id :,  [8, 11, 10, 13, 0, 18]
remove weights:  [1184 1121 1116 1035  928  916], 		------------sum 6300

before remove weights,  [1237, 1233, 1211, 1206, 1184, 1176, 1174, 1121, 1116, 1035, 928, 928, 916, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
res_tmp  [1237 1233 1206  928  900  795]

remove bucket_id:  [0, 1, 3, 6, 7, 10]
original bucket_id :,  [4, 5, 3, 0, 19, 23]
remove weights:  [1237 1233 1206  928  900  795], 		------------sum 6299

before remove weights,  [1237, 1233, 1211, 1206, 1176, 1174, 928, 900, 868, 800, 795, 787]
after remove pre pack weights,  [1211, 1176, 1174, 868, 800, 787]
G_BUCKET_ID_list [[6, 1, 12, 14, 16, 15], [8, 11, 10, 13, 0, 18], [4, 5, 3, 0, 19, 23], [7, 9, 2, 20, 22, 21]]
Groups_mem_list  [[1219, 1092, 1061, 1013, 960, 955], [1184, 1121, 1116, 1035, 928, 916], [1237, 1233, 1206, 928, 900, 795], [1211, 1176, 1174, 868, 800, 787]]
G_BUCKET_ID_list length 4
len(g_bucket_nids_list)  4
len(local_split_batches_nid_list)  4
current group_mem  6.301913490222002
current group_mem  6.303814864294991
current group_mem  6.302347663239465
current group_mem  6.019397373772354
batches output list generation spend  0.0005984306335449219
self.weights_list  [0.25513244851057276, 0.27687181799188487, 0.39074784750552555, 0.2144797176191157]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01425790786743164
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.6931753158569336
len local_batched_seeds_list  4
partition total batch output list spend :  0.8447632789611816
self.buckets_partition() spend  sec:  0.7074685096740723
layer  0
 the number of batches:  4
check_connections_block*********************************

the find indices time spent  0.04585909843444824

in edges time spent  0.1508007049560547
local to global src and eids time spent  0.2961399555206299
time gen tails  0.07080245018005371
res  length 4
