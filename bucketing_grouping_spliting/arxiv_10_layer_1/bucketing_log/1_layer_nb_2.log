main start at this time 1689121299.076644
-----------------------------------------before load data 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

----------------------------------------start of run function 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.046987056732177734
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  27627
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

len(bkt_dst_nodes_list)  10
sum(estimated_mem)
2.0131845474243164
9
self.K  2
the grouping_fanout_arxiv called successfully
capacity  14000
sorted_dict  {2: 249, 3: 242, 4: 242, 1: 241, 5: 223, 6: 211, 0: 206, 7: 203, 8: 192}

weights after sort [249, 242, 242, 241, 223, 211, 206, 203, 192]
G_BUCKET_ID_list [[2, 3, 4, 1], [5, 6, 0, 7, 8]]
Groups_mem_list  [[249, 242, 242, 241], [223, 211, 206, 203, 192]]
G_BUCKET_ID_list length 2
backpack scheduling spend  0.33586621284484863
[2, 3, 4, 1]
current group_mem  0.9751825332641602
[5, 6, 0, 7, 8]
current group_mem  1.0380020141601562
batches output list generation spend  0.0008542537689208984
self.weights_list  [0.5315424286075587, 0.46845757139244126]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.010439634323120117
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.3369908332824707
len local_batched_seeds_list  2
partition total batch output list spend :  0.46107053756713867
self.buckets_partition() spend  sec:  0.34746861457824707
layer  0
 the number of batches:  2
check_connections_block*********************************
res  length 2
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.490234375 GB
    Memory Allocated: 0.057881832122802734  GigaBytes
Max Memory Allocated: 0.057881832122802734  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.857421875 GB
    Memory Allocated: 1.9573974609375  GigaBytes
Max Memory Allocated: 2.1129512786865234  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.857421875 GB
    Memory Allocated: 1.9646015167236328  GigaBytes
Max Memory Allocated: 2.1129512786865234  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.865234375 GB
    Memory Allocated: 0.06501293182373047  GigaBytes
Max Memory Allocated: 2.1129512786865234  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.9921875 GB
    Memory Allocated: 2.065290927886963  GigaBytes
Max Memory Allocated: 2.2387452125549316  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.9921875 GB
    Memory Allocated: 2.0716495513916016  GigaBytes
Max Memory Allocated: 2.2387452125549316  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.9921875 GB
    Memory Allocated: 0.06760883331298828  GigaBytes
Max Memory Allocated: 2.2387452125549316  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.838052749633789
pure train time :  0.4385561943054199
train time :  1.0230553150177002
end to end time :  2.375086545944214
connection check time:  0.38173604011535645
block generation time  0.48645472526550293
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.04530954360961914
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  27627
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

len(bkt_dst_nodes_list)  10
sum(estimated_mem)
2.0131845474243164
9
self.K  2
the grouping_fanout_arxiv called successfully
capacity  14000
sorted_dict  {2: 249, 3: 242, 4: 242, 1: 241, 5: 223, 6: 211, 0: 206, 7: 203, 8: 192}

weights after sort [249, 242, 242, 241, 223, 211, 206, 203, 192]
G_BUCKET_ID_list [[2, 3, 4, 1], [5, 6, 0, 7, 8]]
Groups_mem_list  [[249, 242, 242, 241], [223, 211, 206, 203, 192]]
G_BUCKET_ID_list length 2
backpack scheduling spend  0.18565917015075684
[2, 3, 4, 1]
current group_mem  0.9751825332641602
[5, 6, 0, 7, 8]
current group_mem  1.0380020141601562
batches output list generation spend  0.0004780292510986328
self.weights_list  [0.5315424286075587, 0.46845757139244126]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.00996851921081543
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.18640565872192383
len local_batched_seeds_list  2
partition total batch output list spend :  0.30811476707458496
self.buckets_partition() spend  sec:  0.19640755653381348
layer  0
 the number of batches:  2
check_connections_block*********************************
res  length 2
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.9921875 GB
    Memory Allocated: 0.06595945358276367  GigaBytes
Max Memory Allocated: 2.2387452125549316  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 1.9594407081604004  GigaBytes
Max Memory Allocated: 2.2387452125549316  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 1.966644287109375  GigaBytes
Max Memory Allocated: 2.2387452125549316  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06583642959594727  GigaBytes
Max Memory Allocated: 2.2387452125549316  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 2.0652198791503906  GigaBytes
Max Memory Allocated: 2.2387452125549316  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 2.0715785026550293  GigaBytes
Max Memory Allocated: 2.2387452125549316  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06737184524536133  GigaBytes
Max Memory Allocated: 2.2387452125549316  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.7642383575439453
pure train time :  0.057462215423583984
train time :  0.11748218536376953
end to end time :  1.3213956356048584
connection check time:  0.3878931999206543
block generation time  0.4909493923187256
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.04557061195373535
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  27627
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

len(bkt_dst_nodes_list)  10
sum(estimated_mem)
2.0131845474243164
9
self.K  2
the grouping_fanout_arxiv called successfully
capacity  14000
sorted_dict  {2: 249, 3: 242, 4: 242, 1: 241, 5: 223, 6: 211, 0: 206, 7: 203, 8: 192}

weights after sort [249, 242, 242, 241, 223, 211, 206, 203, 192]
G_BUCKET_ID_list [[2, 3, 4, 1], [5, 6, 0, 7, 8]]
Groups_mem_list  [[249, 242, 242, 241], [223, 211, 206, 203, 192]]
G_BUCKET_ID_list length 2
backpack scheduling spend  0.266310453414917
[2, 3, 4, 1]
current group_mem  0.9751825332641602
[5, 6, 0, 7, 8]
current group_mem  1.0380020141601562
batches output list generation spend  0.00047707557678222656
self.weights_list  [0.5315424286075587, 0.46845757139244126]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.010017633438110352
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.26701784133911133
len local_batched_seeds_list  2
partition total batch output list spend :  0.3887317180633545
self.buckets_partition() spend  sec:  0.2771492004394531
layer  0
 the number of batches:  2
check_connections_block*********************************
res  length 2
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06595277786254883  GigaBytes
Max Memory Allocated: 2.2387452125549316  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 1.9594340324401855  GigaBytes
Max Memory Allocated: 2.2387452125549316  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 1.9666376113891602  GigaBytes
Max Memory Allocated: 2.2387452125549316  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06599712371826172  GigaBytes
Max Memory Allocated: 2.2387452125549316  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 2.0663514137268066  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 2.0727100372314453  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06753253936767578  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.6938202381134033
pure train time :  0.05724382400512695
train time :  0.11565494537353516
end to end time :  1.3656690120697021
connection check time:  0.37935543060302734
block generation time  0.46419501304626465
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.047107696533203125
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  27627
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

len(bkt_dst_nodes_list)  10
sum(estimated_mem)
2.0131845474243164
9
self.K  2
the grouping_fanout_arxiv called successfully
capacity  14000
sorted_dict  {2: 249, 3: 242, 4: 242, 1: 241, 5: 223, 6: 211, 0: 206, 7: 203, 8: 192}

weights after sort [249, 242, 242, 241, 223, 211, 206, 203, 192]
G_BUCKET_ID_list [[2, 3, 4, 1], [5, 6, 0, 7, 8]]
Groups_mem_list  [[249, 242, 242, 241], [223, 211, 206, 203, 192]]
G_BUCKET_ID_list length 2
backpack scheduling spend  0.27089905738830566
[2, 3, 4, 1]
current group_mem  0.9751825332641602
[5, 6, 0, 7, 8]
current group_mem  1.0380020141601562
batches output list generation spend  0.0004982948303222656
self.weights_list  [0.5315424286075587, 0.46845757139244126]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.010222911834716797
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.2716183662414551
len local_batched_seeds_list  2
partition total batch output list spend :  0.39521193504333496
self.buckets_partition() spend  sec:  0.2818765640258789
layer  0
 the number of batches:  2
check_connections_block*********************************
res  length 2
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06592845916748047  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 1.9594097137451172  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 1.9666132926940918  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06604194641113281  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 2.0663514137268066  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 2.0727100372314453  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06757736206054688  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.625448226928711
pure train time :  0.06544899940490723
train time :  0.11778140068054199
end to end time :  1.373826265335083
connection check time:  0.38061952590942383
block generation time  0.4622502326965332
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.045314788818359375
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  27627
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

len(bkt_dst_nodes_list)  10
sum(estimated_mem)
2.0131845474243164
9
self.K  2
the grouping_fanout_arxiv called successfully
capacity  14000
sorted_dict  {2: 249, 3: 242, 4: 242, 1: 241, 5: 223, 6: 211, 0: 206, 7: 203, 8: 192}

weights after sort [249, 242, 242, 241, 223, 211, 206, 203, 192]
G_BUCKET_ID_list [[2, 3, 4, 1], [5, 6, 0, 7, 8]]
Groups_mem_list  [[249, 242, 242, 241], [223, 211, 206, 203, 192]]
G_BUCKET_ID_list length 2
backpack scheduling spend  0.1836259365081787
[2, 3, 4, 1]
current group_mem  0.9751825332641602
[5, 6, 0, 7, 8]
current group_mem  1.0380020141601562
batches output list generation spend  0.00045418739318847656
self.weights_list  [0.5315424286075587, 0.46845757139244126]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01018381118774414
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.18435072898864746
len local_batched_seeds_list  2
partition total batch output list spend :  0.30597472190856934
self.buckets_partition() spend  sec:  0.19456791877746582
layer  0
 the number of batches:  2
check_connections_block*********************************
res  length 2
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06586503982543945  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 1.9593462944030762  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 1.9665498733520508  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06593942642211914  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 2.0653228759765625  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 2.071681499481201  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.0674748420715332  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.5577807426452637
pure train time :  0.053124427795410156
train time :  0.11339330673217773
end to end time :  1.3128349781036377
connection check time:  0.3932313919067383
block generation time  0.4813218116760254
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.0468747615814209
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  27627
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

len(bkt_dst_nodes_list)  10
sum(estimated_mem)
2.0131845474243164
9
self.K  2
the grouping_fanout_arxiv called successfully
capacity  14000
sorted_dict  {2: 249, 3: 242, 4: 242, 1: 241, 5: 223, 6: 211, 0: 206, 7: 203, 8: 192}

weights after sort [249, 242, 242, 241, 223, 211, 206, 203, 192]
G_BUCKET_ID_list [[2, 3, 4, 1], [5, 6, 0, 7, 8]]
Groups_mem_list  [[249, 242, 242, 241], [223, 211, 206, 203, 192]]
G_BUCKET_ID_list length 2
backpack scheduling spend  0.22090721130371094
[2, 3, 4, 1]
current group_mem  0.9751825332641602
[5, 6, 0, 7, 8]
current group_mem  1.0380020141601562
batches output list generation spend  0.0004742145538330078
self.weights_list  [0.5315424286075587, 0.46845757139244126]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.009873390197753906
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.22160625457763672
len local_batched_seeds_list  2
partition total batch output list spend :  0.3008866310119629
self.buckets_partition() spend  sec:  0.23151421546936035
layer  0
 the number of batches:  2
check_connections_block*********************************
res  length 2
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.0659184455871582  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 1.959399700164795  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 1.9666032791137695  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06596517562866211  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 2.0653486251831055  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 2.071707248687744  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06750059127807617  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.489696502685547
pure train time :  0.06292843818664551
train time :  0.1216120719909668
end to end time :  0.9001655578613281
connection check time:  0.206864595413208
block generation time  0.25817418098449707
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.02659749984741211
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  27627
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

len(bkt_dst_nodes_list)  10
sum(estimated_mem)
2.0131845474243164
9
self.K  2
the grouping_fanout_arxiv called successfully
capacity  14000
sorted_dict  {2: 249, 3: 242, 4: 242, 1: 241, 5: 223, 6: 211, 0: 206, 7: 203, 8: 192}

weights after sort [249, 242, 242, 241, 223, 211, 206, 203, 192]
G_BUCKET_ID_list [[2, 3, 4, 1], [5, 6, 0, 7, 8]]
Groups_mem_list  [[249, 242, 242, 241], [223, 211, 206, 203, 192]]
G_BUCKET_ID_list length 2
backpack scheduling spend  0.1460583209991455
[2, 3, 4, 1]
current group_mem  0.9751825332641602
[5, 6, 0, 7, 8]
current group_mem  1.0380020141601562
batches output list generation spend  0.0004513263702392578
self.weights_list  [0.5315424286075587, 0.46845757139244126]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.009378671646118164
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.14673852920532227
len local_batched_seeds_list  2
partition total batch output list spend :  0.20513343811035156
self.buckets_partition() spend  sec:  0.15614938735961914
layer  0
 the number of batches:  2
check_connections_block*********************************
res  length 2
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06583690643310547  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 1.9593181610107422  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 1.9665217399597168  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06594085693359375  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 2.065324306488037  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 2.071682929992676  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06747627258300781  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.420980930328369
pure train time :  0.05231022834777832
train time :  0.10969018936157227
end to end time :  1.0658953189849854
connection check time:  0.22817754745483398
block generation time  0.5098245143890381
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.028834819793701172
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  27627
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

len(bkt_dst_nodes_list)  10
sum(estimated_mem)
2.0131845474243164
9
self.K  2
the grouping_fanout_arxiv called successfully
capacity  14000
sorted_dict  {2: 249, 3: 242, 4: 242, 1: 241, 5: 223, 6: 211, 0: 206, 7: 203, 8: 192}

weights after sort [249, 242, 242, 241, 223, 211, 206, 203, 192]
G_BUCKET_ID_list [[2, 3, 4, 1], [5, 6, 0, 7, 8]]
Groups_mem_list  [[249, 242, 242, 241], [223, 211, 206, 203, 192]]
G_BUCKET_ID_list length 2
backpack scheduling spend  0.08081459999084473
[2, 3, 4, 1]
current group_mem  0.9751825332641602
[5, 6, 0, 7, 8]
current group_mem  1.0380020141601562
batches output list generation spend  0.0012469291687011719
self.weights_list  [0.5315424286075587, 0.46845757139244126]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.012883424758911133
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.0823662281036377
len local_batched_seeds_list  2
partition total batch output list spend :  0.14711880683898926
self.buckets_partition() spend  sec:  0.09528350830078125
layer  0
 the number of batches:  2
check_connections_block*********************************
res  length 2
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06585550308227539  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 1.959336757659912  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 1.9665403366088867  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06614017486572266  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 2.0663514137268066  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 2.0727100372314453  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06767559051513672  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.351918935775757
pure train time :  0.05425572395324707
train time :  0.12004208564758301
end to end time :  1.0846877098083496
connection check time:  0.2828202247619629
block generation time  0.5066947937011719
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.04405641555786133
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  27627
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

len(bkt_dst_nodes_list)  10
sum(estimated_mem)
2.0131845474243164
9
self.K  2
the grouping_fanout_arxiv called successfully
capacity  14000
sorted_dict  {2: 249, 3: 242, 4: 242, 1: 241, 5: 223, 6: 211, 0: 206, 7: 203, 8: 192}

weights after sort [249, 242, 242, 241, 223, 211, 206, 203, 192]
G_BUCKET_ID_list [[2, 3, 4, 1], [5, 6, 0, 7, 8]]
Groups_mem_list  [[249, 242, 242, 241], [223, 211, 206, 203, 192]]
G_BUCKET_ID_list length 2
backpack scheduling spend  0.29241228103637695
[2, 3, 4, 1]
current group_mem  0.9751825332641602
[5, 6, 0, 7, 8]
current group_mem  1.0380020141601562
batches output list generation spend  0.0005230903625488281
self.weights_list  [0.5315424286075587, 0.46845757139244126]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013755083084106445
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.2931559085845947
len local_batched_seeds_list  2
partition total batch output list spend :  0.3791232109069824
self.buckets_partition() spend  sec:  0.3069477081298828
layer  0
 the number of batches:  2
check_connections_block*********************************
res  length 2
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06590747833251953  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 1.9593887329101562  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 1.9665923118591309  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06601858139038086  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 2.0663514137268066  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 2.0727100372314453  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06755399703979492  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.2845091819763184
pure train time :  0.05274176597595215
train time :  0.11112332344055176
end to end time :  1.371403455734253
connection check time:  0.39267444610595703
block generation time  0.4709136486053467
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  0.04700469970703125
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  27627
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

len(bkt_dst_nodes_list)  10
sum(estimated_mem)
2.0131845474243164
9
self.K  2
the grouping_fanout_arxiv called successfully
capacity  14000
sorted_dict  {2: 249, 3: 242, 4: 242, 1: 241, 5: 223, 6: 211, 0: 206, 7: 203, 8: 192}

weights after sort [249, 242, 242, 241, 223, 211, 206, 203, 192]
G_BUCKET_ID_list [[2, 3, 4, 1], [5, 6, 0, 7, 8]]
Groups_mem_list  [[249, 242, 242, 241], [223, 211, 206, 203, 192]]
G_BUCKET_ID_list length 2
backpack scheduling spend  0.27646875381469727
[2, 3, 4, 1]
current group_mem  0.9751825332641602
[5, 6, 0, 7, 8]
current group_mem  1.0380020141601562
batches output list generation spend  0.0004725456237792969
self.weights_list  [0.5315424286075587, 0.46845757139244126]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.009741783142089844
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.27721118927001953
len local_batched_seeds_list  2
partition total batch output list spend :  0.4014575481414795
self.buckets_partition() spend  sec:  0.2869887351989746
layer  0
 the number of batches:  2
check_connections_block*********************************
res  length 2
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06600189208984375  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 1.9594831466674805  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 1.966686725616455  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06591272354125977  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 2.065296173095703  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 2.071654796600342  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.994140625 GB
    Memory Allocated: 0.06744813919067383  GigaBytes
Max Memory Allocated: 2.2398056983947754  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.223444938659668
pure train time :  0.05539250373840332
train time :  0.11645340919494629
end to end time :  1.4262714385986328
connection check time:  0.39839720726013184
block generation time  0.49480175971984863
end to end time  1.449270486831665
Total (block generation + training)time/epoch 1.449270486831665
pure train time per /epoch  [0.4385561943054199, 0.057462215423583984, 0.05724382400512695, 0.06544899940490723, 0.053124427795410156, 0.06292843818664551, 0.05231022834777832, 0.05425572395324707, 0.05274176597595215, 0.05539250373840332]
pure train time average  0.05660029820033482
input num list  [229839, 229611, 229934, 229977, 229629, 229795, 229573, 230030, 229884, 229860]
