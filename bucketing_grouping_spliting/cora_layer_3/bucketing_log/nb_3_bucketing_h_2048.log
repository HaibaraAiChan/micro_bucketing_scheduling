main start at this time 1689559541.421399
-----------------------------------------before load data 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
success----------------------------------------
140
500
2068
# Nodes: 2708
# Edges: 10556
# Train: 140
# Val: 500
# Test: 2068
# Classes: 7

----------------------------------------start of run function 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  8.726119995117188e-05
len(bkt)  20
len(bkt)  25
len(bkt)  26
len(bkt)  22
len(bkt)  15
len(bkt)  11
len(bkt)  4
len(bkt)  3
len(bkt)  4
len(bkt)  3
len(bkt)  1
len(bkt)  2
len(bkt)  1
len(bkt)  1
len(bkt)  2
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

memory_constraint:  4.8
sum(estimated_mem)
14.19501480460167
15
self.K  3
the grouping_fanout_arxiv called successfully
capacity  4800
 
sorted_dict  {3: 2283, 4: 1878, 2: 1594, 5: 1577, 1: 1374, 14: 1144, 8: 868, 6: 666, 9: 620, 7: 478, 0: 439, 13: 425, 11: 401, 12: 271, 10: 169}

weights after sort [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
res_tmp  [1594 1577  620  439  401  169]

remove bucket_id:  [2, 3, 8, 10, 12, 14]
original bucket_id :,  [2, 5, 9, 0, 11, 10]
remove weights:  [1594 1577  620  439  401  169], 		------------sum 4800

before remove weights,  [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
after remove pre pack weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
res_tmp  [2283 1374  868  271]

remove bucket_id:  [0, 2, 4, 8]
original bucket_id :,  [3, 1, 8, 12]
remove weights:  [2283 1374  868  271], 		------------sum 4796

before remove weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
after remove pre pack weights,  [1878, 1144, 666, 478, 425]
G_BUCKET_ID_list [[2, 5, 9, 0, 11, 10], [3, 1, 8, 12], [4, 14, 6, 7, 13]]
Groups_mem_list  [[1594, 1577, 620, 439, 401, 169], [2283, 1374, 868, 271], [1878, 1144, 666, 478, 425]]
G_BUCKET_ID_list length 3
backpack scheduling spend  0.09348011016845703
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[2, 5, 9, 0, 11, 10]
2
5
9
0
11
10
current group_mem  4.802796587347984
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[3, 1, 8, 12]
3
1
8
12
current group_mem  4.798927769064903
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[4, 14, 6, 7, 13]
4
14
6
7
13
current group_mem  4.593290448188782
batches output list generation spend  0.0006563663482666016
self.weights_list  [0.45, 0.37142857142857144, 0.17857142857142858]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0011892318725585938
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.09420514106750488
len local_batched_seeds_list  3
partition total batch output list spend :  0.09656453132629395
self.buckets_partition() spend  sec:  0.0954282283782959
layer  0
 the number of batches:  3
check_connections_block*********************************
res  length 3
layer  1
num of batch  3
check_connections_block*********************************
res  length 3
layer  2
num of batch  3
check_connections_block*********************************
res  length 3
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.818359375 GB
    Memory Allocated: 0.37551212310791016  GigaBytes
Max Memory Allocated: 0.37551212310791016  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 2.43359375 GB
    Memory Allocated: 0.8944478034973145  GigaBytes
Max Memory Allocated: 0.8974275588989258  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 2.43359375 GB
    Memory Allocated: 0.8944506645202637  GigaBytes
Max Memory Allocated: 0.8974275588989258  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 2.87890625 GB
    Memory Allocated: 0.7413821220397949  GigaBytes
Max Memory Allocated: 1.2609291076660156  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 2.87890625 GB
    Memory Allocated: 1.2534971237182617  GigaBytes
Max Memory Allocated: 1.2609291076660156  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 2.87890625 GB
    Memory Allocated: 1.2534990310668945  GigaBytes
Max Memory Allocated: 1.2609291076660156  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.130859375 GB
    Memory Allocated: 0.7401018142700195  GigaBytes
Max Memory Allocated: 1.501634120941162  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.134765625 GB
    Memory Allocated: 1.2504615783691406  GigaBytes
Max Memory Allocated: 1.501634120941162  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.134765625 GB
    Memory Allocated: 1.2504630088806152  GigaBytes
Max Memory Allocated: 1.501634120941162  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.697265625 GB
    Memory Allocated: 1.4693355560302734  GigaBytes
Max Memory Allocated: 1.6568355560302734  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.9459782838821411
pure train time :  1.4504969120025635
train time :  1.9650452136993408
end to end time :  2.0935020446777344
connection check time:  0.008239507675170898
block generation time  0.02260613441467285
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  7.939338684082031e-05
len(bkt)  20
len(bkt)  25
len(bkt)  26
len(bkt)  22
len(bkt)  15
len(bkt)  11
len(bkt)  4
len(bkt)  3
len(bkt)  4
len(bkt)  3
len(bkt)  1
len(bkt)  2
len(bkt)  1
len(bkt)  1
len(bkt)  2
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

memory_constraint:  4.8
sum(estimated_mem)
14.19501480460167
15
self.K  3
the grouping_fanout_arxiv called successfully
capacity  4800
 
sorted_dict  {3: 2283, 4: 1878, 2: 1594, 5: 1577, 1: 1374, 14: 1144, 8: 868, 6: 666, 9: 620, 7: 478, 0: 439, 13: 425, 11: 401, 12: 271, 10: 169}

weights after sort [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
res_tmp  [1594 1577  620  439  401  169]

remove bucket_id:  [2, 3, 8, 10, 12, 14]
original bucket_id :,  [2, 5, 9, 0, 11, 10]
remove weights:  [1594 1577  620  439  401  169], 		------------sum 4800

before remove weights,  [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
after remove pre pack weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
res_tmp  [2283 1374  868  271]

remove bucket_id:  [0, 2, 4, 8]
original bucket_id :,  [3, 1, 8, 12]
remove weights:  [2283 1374  868  271], 		------------sum 4796

before remove weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
after remove pre pack weights,  [1878, 1144, 666, 478, 425]
G_BUCKET_ID_list [[2, 5, 9, 0, 11, 10], [3, 1, 8, 12], [4, 14, 6, 7, 13]]
Groups_mem_list  [[1594, 1577, 620, 439, 401, 169], [2283, 1374, 868, 271], [1878, 1144, 666, 478, 425]]
G_BUCKET_ID_list length 3
backpack scheduling spend  0.0907282829284668
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[2, 5, 9, 0, 11, 10]
2
5
9
0
11
10
current group_mem  4.802796587347984
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[3, 1, 8, 12]
3
1
8
12
current group_mem  4.798927769064903
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[4, 14, 6, 7, 13]
4
14
6
7
13
current group_mem  4.593290448188782
batches output list generation spend  0.00011539459228515625
self.weights_list  [0.45, 0.37142857142857144, 0.17857142857142858]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0005960464477539062
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.09089159965515137
len local_batched_seeds_list  3
partition total batch output list spend :  0.09228086471557617
self.buckets_partition() spend  sec:  0.09150958061218262
layer  0
 the number of batches:  3
check_connections_block*********************************
res  length 3
layer  1
num of batch  3
check_connections_block*********************************
res  length 3
layer  2
num of batch  3
check_connections_block*********************************
res  length 3
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.697265625 GB
    Memory Allocated: 1.4705557823181152  GigaBytes
Max Memory Allocated: 1.6568355560302734  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.697265625 GB
    Memory Allocated: 1.9947938919067383  GigaBytes
Max Memory Allocated: 1.997774600982666  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.697265625 GB
    Memory Allocated: 1.9947509765625  GigaBytes
Max Memory Allocated: 1.997774600982666  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.822265625 GB
    Memory Allocated: 1.4705557823181152  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.822265625 GB
    Memory Allocated: 1.9821438789367676  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.822265625 GB
    Memory Allocated: 1.9821457862854004  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.822265625 GB
    Memory Allocated: 1.469414234161377  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.822265625 GB
    Memory Allocated: 1.9830188751220703  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.822265625 GB
    Memory Allocated: 1.983020305633545  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.822265625 GB
    Memory Allocated: 1.4694743156433105  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.948786735534668
pure train time :  1.1834712028503418
train time :  1.3623535633087158
end to end time :  1.4829380512237549
connection check time:  0.008735895156860352
block generation time  0.018938064575195312
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  7.390975952148438e-05
len(bkt)  20
len(bkt)  25
len(bkt)  26
len(bkt)  22
len(bkt)  15
len(bkt)  11
len(bkt)  4
len(bkt)  3
len(bkt)  4
len(bkt)  3
len(bkt)  1
len(bkt)  2
len(bkt)  1
len(bkt)  1
len(bkt)  2
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

memory_constraint:  4.8
sum(estimated_mem)
14.19501480460167
15
self.K  3
the grouping_fanout_arxiv called successfully
capacity  4800
 
sorted_dict  {3: 2283, 4: 1878, 2: 1594, 5: 1577, 1: 1374, 14: 1144, 8: 868, 6: 666, 9: 620, 7: 478, 0: 439, 13: 425, 11: 401, 12: 271, 10: 169}

weights after sort [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
res_tmp  [1594 1577  620  439  401  169]

remove bucket_id:  [2, 3, 8, 10, 12, 14]
original bucket_id :,  [2, 5, 9, 0, 11, 10]
remove weights:  [1594 1577  620  439  401  169], 		------------sum 4800

before remove weights,  [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
after remove pre pack weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
res_tmp  [2283 1374  868  271]

remove bucket_id:  [0, 2, 4, 8]
original bucket_id :,  [3, 1, 8, 12]
remove weights:  [2283 1374  868  271], 		------------sum 4796

before remove weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
after remove pre pack weights,  [1878, 1144, 666, 478, 425]
G_BUCKET_ID_list [[2, 5, 9, 0, 11, 10], [3, 1, 8, 12], [4, 14, 6, 7, 13]]
Groups_mem_list  [[1594, 1577, 620, 439, 401, 169], [2283, 1374, 868, 271], [1878, 1144, 666, 478, 425]]
G_BUCKET_ID_list length 3
backpack scheduling spend  0.0892791748046875
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[2, 5, 9, 0, 11, 10]
2
5
9
0
11
10
current group_mem  4.802796587347984
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[3, 1, 8, 12]
3
1
8
12
current group_mem  4.798927769064903
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[4, 14, 6, 7, 13]
4
14
6
7
13
current group_mem  4.593290448188782
batches output list generation spend  0.00012040138244628906
self.weights_list  [0.45, 0.37142857142857144, 0.17857142857142858]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0006048679351806641
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.08945608139038086
len local_batched_seeds_list  3
partition total batch output list spend :  0.09086918830871582
self.buckets_partition() spend  sec:  0.09008216857910156
layer  0
 the number of batches:  3
check_connections_block*********************************
res  length 3
layer  1
num of batch  3
check_connections_block*********************************
res  length 3
layer  2
num of batch  3
check_connections_block*********************************
res  length 3
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.822265625 GB
    Memory Allocated: 1.4705557823181152  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.822265625 GB
    Memory Allocated: 1.9939203262329102  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.822265625 GB
    Memory Allocated: 1.9938774108886719  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.822265625 GB
    Memory Allocated: 1.4705557823181152  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.822265625 GB
    Memory Allocated: 1.9835095405578613  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.822265625 GB
    Memory Allocated: 1.9835114479064941  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.822265625 GB
    Memory Allocated: 1.4693403244018555  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.9893288612365723  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.9893302917480469  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.4694013595581055  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.9513062238693237
pure train time :  1.1765966415405273
train time :  1.355564832687378
end to end time :  1.4743995666503906
connection check time:  0.008251428604125977
block generation time  0.019006967544555664
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  7.271766662597656e-05
len(bkt)  20
len(bkt)  25
len(bkt)  26
len(bkt)  22
len(bkt)  15
len(bkt)  11
len(bkt)  4
len(bkt)  3
len(bkt)  4
len(bkt)  3
len(bkt)  1
len(bkt)  2
len(bkt)  1
len(bkt)  1
len(bkt)  2
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

memory_constraint:  4.8
sum(estimated_mem)
14.19501480460167
15
self.K  3
the grouping_fanout_arxiv called successfully
capacity  4800
 
sorted_dict  {3: 2283, 4: 1878, 2: 1594, 5: 1577, 1: 1374, 14: 1144, 8: 868, 6: 666, 9: 620, 7: 478, 0: 439, 13: 425, 11: 401, 12: 271, 10: 169}

weights after sort [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
res_tmp  [1594 1577  620  439  401  169]

remove bucket_id:  [2, 3, 8, 10, 12, 14]
original bucket_id :,  [2, 5, 9, 0, 11, 10]
remove weights:  [1594 1577  620  439  401  169], 		------------sum 4800

before remove weights,  [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
after remove pre pack weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
res_tmp  [2283 1374  868  271]

remove bucket_id:  [0, 2, 4, 8]
original bucket_id :,  [3, 1, 8, 12]
remove weights:  [2283 1374  868  271], 		------------sum 4796

before remove weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
after remove pre pack weights,  [1878, 1144, 666, 478, 425]
G_BUCKET_ID_list [[2, 5, 9, 0, 11, 10], [3, 1, 8, 12], [4, 14, 6, 7, 13]]
Groups_mem_list  [[1594, 1577, 620, 439, 401, 169], [2283, 1374, 868, 271], [1878, 1144, 666, 478, 425]]
G_BUCKET_ID_list length 3
backpack scheduling spend  0.08992409706115723
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[2, 5, 9, 0, 11, 10]
2
5
9
0
11
10
current group_mem  4.802796587347984
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[3, 1, 8, 12]
3
1
8
12
current group_mem  4.798927769064903
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[4, 14, 6, 7, 13]
4
14
6
7
13
current group_mem  4.593290448188782
batches output list generation spend  0.00011920928955078125
self.weights_list  [0.45, 0.37142857142857144, 0.17857142857142858]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0005881786346435547
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.09009218215942383
len local_batched_seeds_list  3
partition total batch output list spend :  0.0914616584777832
self.buckets_partition() spend  sec:  0.09070181846618652
layer  0
 the number of batches:  3
check_connections_block*********************************
res  length 3
layer  1
num of batch  3
check_connections_block*********************************
res  length 3
layer  2
num of batch  3
check_connections_block*********************************
res  length 3
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.4705557823181152  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.9953932762145996  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.9953503608703613  GigaBytes
Max Memory Allocated: 2.242457866668701  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.4705557823181152  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.9780845642089844  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.9780864715576172  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.4695048332214355  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.98480224609375  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.9848036766052246  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.4695649147033691  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.9473429918289185
pure train time :  1.1809918880462646
train time :  1.3596320152282715
end to end time :  1.4790716171264648
connection check time:  0.008270263671875
block generation time  0.018981456756591797
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  7.62939453125e-05
len(bkt)  20
len(bkt)  25
len(bkt)  26
len(bkt)  22
len(bkt)  15
len(bkt)  11
len(bkt)  4
len(bkt)  3
len(bkt)  4
len(bkt)  3
len(bkt)  1
len(bkt)  2
len(bkt)  1
len(bkt)  1
len(bkt)  2
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

memory_constraint:  4.8
sum(estimated_mem)
14.19501480460167
15
self.K  3
the grouping_fanout_arxiv called successfully
capacity  4800
 
sorted_dict  {3: 2283, 4: 1878, 2: 1594, 5: 1577, 1: 1374, 14: 1144, 8: 868, 6: 666, 9: 620, 7: 478, 0: 439, 13: 425, 11: 401, 12: 271, 10: 169}

weights after sort [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
res_tmp  [1594 1577  620  439  401  169]

remove bucket_id:  [2, 3, 8, 10, 12, 14]
original bucket_id :,  [2, 5, 9, 0, 11, 10]
remove weights:  [1594 1577  620  439  401  169], 		------------sum 4800

before remove weights,  [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
after remove pre pack weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
res_tmp  [2283 1374  868  271]

remove bucket_id:  [0, 2, 4, 8]
original bucket_id :,  [3, 1, 8, 12]
remove weights:  [2283 1374  868  271], 		------------sum 4796

before remove weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
after remove pre pack weights,  [1878, 1144, 666, 478, 425]
G_BUCKET_ID_list [[2, 5, 9, 0, 11, 10], [3, 1, 8, 12], [4, 14, 6, 7, 13]]
Groups_mem_list  [[1594, 1577, 620, 439, 401, 169], [2283, 1374, 868, 271], [1878, 1144, 666, 478, 425]]
G_BUCKET_ID_list length 3
backpack scheduling spend  0.08953595161437988
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[2, 5, 9, 0, 11, 10]
2
5
9
0
11
10
current group_mem  4.802796587347984
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[3, 1, 8, 12]
3
1
8
12
current group_mem  4.798927769064903
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[4, 14, 6, 7, 13]
4
14
6
7
13
current group_mem  4.593290448188782
batches output list generation spend  0.00011992454528808594
self.weights_list  [0.45, 0.37142857142857144, 0.17857142857142858]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0005829334259033203
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.08970260620117188
len local_batched_seeds_list  3
partition total batch output list spend :  0.09106326103210449
self.buckets_partition() spend  sec:  0.09030675888061523
layer  0
 the number of batches:  3
check_connections_block*********************************
res  length 3
layer  1
num of batch  3
check_connections_block*********************************
res  length 3
layer  2
num of batch  3
check_connections_block*********************************
res  length 3
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.4705548286437988  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.9913649559020996  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.9913220405578613  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.4705557823181152  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.9783291816711426  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.9783310890197754  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.4694194793701172  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.9823942184448242  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.9823956489562988  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.4694795608520508  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.9424792528152466
pure train time :  1.1817870140075684
train time :  1.3604676723480225
end to end time :  1.4791910648345947
connection check time:  0.008133888244628906
block generation time  0.0189054012298584
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  7.200241088867188e-05
len(bkt)  20
len(bkt)  25
len(bkt)  26
len(bkt)  22
len(bkt)  15
len(bkt)  11
len(bkt)  4
len(bkt)  3
len(bkt)  4
len(bkt)  3
len(bkt)  1
len(bkt)  2
len(bkt)  1
len(bkt)  1
len(bkt)  2
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

memory_constraint:  4.8
sum(estimated_mem)
14.19501480460167
15
self.K  3
the grouping_fanout_arxiv called successfully
capacity  4800
 
sorted_dict  {3: 2283, 4: 1878, 2: 1594, 5: 1577, 1: 1374, 14: 1144, 8: 868, 6: 666, 9: 620, 7: 478, 0: 439, 13: 425, 11: 401, 12: 271, 10: 169}

weights after sort [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
res_tmp  [1594 1577  620  439  401  169]

remove bucket_id:  [2, 3, 8, 10, 12, 14]
original bucket_id :,  [2, 5, 9, 0, 11, 10]
remove weights:  [1594 1577  620  439  401  169], 		------------sum 4800

before remove weights,  [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
after remove pre pack weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
res_tmp  [2283 1374  868  271]

remove bucket_id:  [0, 2, 4, 8]
original bucket_id :,  [3, 1, 8, 12]
remove weights:  [2283 1374  868  271], 		------------sum 4796

before remove weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
after remove pre pack weights,  [1878, 1144, 666, 478, 425]
G_BUCKET_ID_list [[2, 5, 9, 0, 11, 10], [3, 1, 8, 12], [4, 14, 6, 7, 13]]
Groups_mem_list  [[1594, 1577, 620, 439, 401, 169], [2283, 1374, 868, 271], [1878, 1144, 666, 478, 425]]
G_BUCKET_ID_list length 3
backpack scheduling spend  0.08907532691955566
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[2, 5, 9, 0, 11, 10]
2
5
9
0
11
10
current group_mem  4.802796587347984
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[3, 1, 8, 12]
3
1
8
12
current group_mem  4.798927769064903
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[4, 14, 6, 7, 13]
4
14
6
7
13
current group_mem  4.593290448188782
batches output list generation spend  0.0001761913299560547
self.weights_list  [0.45, 0.37142857142857144, 0.17857142857142858]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0005719661712646484
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.08929729461669922
len local_batched_seeds_list  3
partition total batch output list spend :  0.09064722061157227
self.buckets_partition() spend  sec:  0.0898904800415039
layer  0
 the number of batches:  3
check_connections_block*********************************
res  length 3
layer  1
num of batch  3
check_connections_block*********************************
res  length 3
layer  2
num of batch  3
check_connections_block*********************************
res  length 3
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.4705557823181152  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.9940876960754395  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.9940447807312012  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.4705557823181152  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.9815592765808105  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.9815611839294434  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.826171875 GB
    Memory Allocated: 1.4694676399230957  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.9824185371398926  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.9824199676513672  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.4695277214050293  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.9463998079299927
pure train time :  1.1832587718963623
train time :  1.3628387451171875
end to end time :  1.4812917709350586
connection check time:  0.00824880599975586
block generation time  0.018908023834228516
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  8.153915405273438e-05
len(bkt)  20
len(bkt)  25
len(bkt)  26
len(bkt)  22
len(bkt)  15
len(bkt)  11
len(bkt)  4
len(bkt)  3
len(bkt)  4
len(bkt)  3
len(bkt)  1
len(bkt)  2
len(bkt)  1
len(bkt)  1
len(bkt)  2
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

memory_constraint:  4.8
sum(estimated_mem)
14.19501480460167
15
self.K  3
the grouping_fanout_arxiv called successfully
capacity  4800
 
sorted_dict  {3: 2283, 4: 1878, 2: 1594, 5: 1577, 1: 1374, 14: 1144, 8: 868, 6: 666, 9: 620, 7: 478, 0: 439, 13: 425, 11: 401, 12: 271, 10: 169}

weights after sort [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
res_tmp  [1594 1577  620  439  401  169]

remove bucket_id:  [2, 3, 8, 10, 12, 14]
original bucket_id :,  [2, 5, 9, 0, 11, 10]
remove weights:  [1594 1577  620  439  401  169], 		------------sum 4800

before remove weights,  [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
after remove pre pack weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
res_tmp  [2283 1374  868  271]

remove bucket_id:  [0, 2, 4, 8]
original bucket_id :,  [3, 1, 8, 12]
remove weights:  [2283 1374  868  271], 		------------sum 4796

before remove weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
after remove pre pack weights,  [1878, 1144, 666, 478, 425]
G_BUCKET_ID_list [[2, 5, 9, 0, 11, 10], [3, 1, 8, 12], [4, 14, 6, 7, 13]]
Groups_mem_list  [[1594, 1577, 620, 439, 401, 169], [2283, 1374, 868, 271], [1878, 1144, 666, 478, 425]]
G_BUCKET_ID_list length 3
backpack scheduling spend  0.09172320365905762
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[2, 5, 9, 0, 11, 10]
2
5
9
0
11
10
current group_mem  4.802796587347984
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[3, 1, 8, 12]
3
1
8
12
current group_mem  4.798927769064903
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[4, 14, 6, 7, 13]
4
14
6
7
13
current group_mem  4.593290448188782
batches output list generation spend  0.00013113021850585938
self.weights_list  [0.45, 0.37142857142857144, 0.17857142857142858]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0008435249328613281
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.09191083908081055
len local_batched_seeds_list  3
partition total batch output list spend :  0.09355568885803223
self.buckets_partition() spend  sec:  0.09277987480163574
layer  0
 the number of batches:  3
check_connections_block*********************************
res  length 3
layer  1
num of batch  3
check_connections_block*********************************
res  length 3
layer  2
num of batch  3
check_connections_block*********************************
res  length 3
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.4705557823181152  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.9939265251159668  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.9938836097717285  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.4705557823181152  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.9813642501831055  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.9813661575317383  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.4694623947143555  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.9804563522338867  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.9804577827453613  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.469522476196289  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.9456069469451904
pure train time :  1.1770577430725098
train time :  1.356264591217041
end to end time :  1.4808156490325928
connection check time:  0.00853419303894043
block generation time  0.02146744728088379
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  7.915496826171875e-05
len(bkt)  20
len(bkt)  25
len(bkt)  26
len(bkt)  22
len(bkt)  15
len(bkt)  11
len(bkt)  4
len(bkt)  3
len(bkt)  4
len(bkt)  3
len(bkt)  1
len(bkt)  2
len(bkt)  1
len(bkt)  1
len(bkt)  2
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

memory_constraint:  4.8
sum(estimated_mem)
14.19501480460167
15
self.K  3
the grouping_fanout_arxiv called successfully
capacity  4800
 
sorted_dict  {3: 2283, 4: 1878, 2: 1594, 5: 1577, 1: 1374, 14: 1144, 8: 868, 6: 666, 9: 620, 7: 478, 0: 439, 13: 425, 11: 401, 12: 271, 10: 169}

weights after sort [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
res_tmp  [1594 1577  620  439  401  169]

remove bucket_id:  [2, 3, 8, 10, 12, 14]
original bucket_id :,  [2, 5, 9, 0, 11, 10]
remove weights:  [1594 1577  620  439  401  169], 		------------sum 4800

before remove weights,  [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
after remove pre pack weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
res_tmp  [2283 1374  868  271]

remove bucket_id:  [0, 2, 4, 8]
original bucket_id :,  [3, 1, 8, 12]
remove weights:  [2283 1374  868  271], 		------------sum 4796

before remove weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
after remove pre pack weights,  [1878, 1144, 666, 478, 425]
G_BUCKET_ID_list [[2, 5, 9, 0, 11, 10], [3, 1, 8, 12], [4, 14, 6, 7, 13]]
Groups_mem_list  [[1594, 1577, 620, 439, 401, 169], [2283, 1374, 868, 271], [1878, 1144, 666, 478, 425]]
G_BUCKET_ID_list length 3
backpack scheduling spend  0.08908796310424805
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[2, 5, 9, 0, 11, 10]
2
5
9
0
11
10
current group_mem  4.802796587347984
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[3, 1, 8, 12]
3
1
8
12
current group_mem  4.798927769064903
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[4, 14, 6, 7, 13]
4
14
6
7
13
current group_mem  4.593290448188782
batches output list generation spend  0.00011348724365234375
self.weights_list  [0.45, 0.37142857142857144, 0.17857142857142858]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0005681514739990234
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.08924722671508789
len local_batched_seeds_list  3
partition total batch output list spend :  0.09060478210449219
self.buckets_partition() spend  sec:  0.08983659744262695
layer  0
 the number of batches:  3
check_connections_block*********************************
res  length 3
layer  1
num of batch  3
check_connections_block*********************************
res  length 3
layer  2
num of batch  3
check_connections_block*********************************
res  length 3
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.4705557823181152  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.9952073097229004  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.995164394378662  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.4705548286437988  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.9762020111083984  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.9762039184570312  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.837890625 GB
    Memory Allocated: 1.4695539474487305  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.987055778503418  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.9870572090148926  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.4696149826049805  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.9458304643630981
pure train time :  1.175069808959961
train time :  1.3540687561035156
end to end time :  1.4736659526824951
connection check time:  0.008373022079467773
block generation time  0.020023345947265625
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  7.891654968261719e-05
len(bkt)  20
len(bkt)  25
len(bkt)  26
len(bkt)  22
len(bkt)  15
len(bkt)  11
len(bkt)  4
len(bkt)  3
len(bkt)  4
len(bkt)  3
len(bkt)  1
len(bkt)  2
len(bkt)  1
len(bkt)  1
len(bkt)  2
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

memory_constraint:  4.8
sum(estimated_mem)
14.19501480460167
15
self.K  3
the grouping_fanout_arxiv called successfully
capacity  4800
 
sorted_dict  {3: 2283, 4: 1878, 2: 1594, 5: 1577, 1: 1374, 14: 1144, 8: 868, 6: 666, 9: 620, 7: 478, 0: 439, 13: 425, 11: 401, 12: 271, 10: 169}

weights after sort [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
res_tmp  [1594 1577  620  439  401  169]

remove bucket_id:  [2, 3, 8, 10, 12, 14]
original bucket_id :,  [2, 5, 9, 0, 11, 10]
remove weights:  [1594 1577  620  439  401  169], 		------------sum 4800

before remove weights,  [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
after remove pre pack weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
res_tmp  [2283 1374  868  271]

remove bucket_id:  [0, 2, 4, 8]
original bucket_id :,  [3, 1, 8, 12]
remove weights:  [2283 1374  868  271], 		------------sum 4796

before remove weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
after remove pre pack weights,  [1878, 1144, 666, 478, 425]
G_BUCKET_ID_list [[2, 5, 9, 0, 11, 10], [3, 1, 8, 12], [4, 14, 6, 7, 13]]
Groups_mem_list  [[1594, 1577, 620, 439, 401, 169], [2283, 1374, 868, 271], [1878, 1144, 666, 478, 425]]
G_BUCKET_ID_list length 3
backpack scheduling spend  0.08909463882446289
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[2, 5, 9, 0, 11, 10]
2
5
9
0
11
10
current group_mem  4.802796587347984
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[3, 1, 8, 12]
3
1
8
12
current group_mem  4.798927769064903
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[4, 14, 6, 7, 13]
4
14
6
7
13
current group_mem  4.593290448188782
batches output list generation spend  0.00012254714965820312
self.weights_list  [0.45, 0.37142857142857144, 0.17857142857142858]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0005831718444824219
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.08926749229431152
len local_batched_seeds_list  3
partition total batch output list spend :  0.09065985679626465
self.buckets_partition() spend  sec:  0.08987140655517578
layer  0
 the number of batches:  3
check_connections_block*********************************
res  length 3
layer  1
num of batch  3
check_connections_block*********************************
res  length 3
layer  2
num of batch  3
check_connections_block*********************************
res  length 3
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.4705548286437988  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.9919538497924805  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.9919109344482422  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.4705557823181152  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.9828009605407715  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.9828028678894043  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.4694738388061523  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.986917495727539  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.9869189262390137  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.4695348739624023  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.9403283596038818
pure train time :  1.1826872825622559
train time :  1.3621869087219238
end to end time :  1.4815633296966553
connection check time:  0.008367061614990234
block generation time  0.019736051559448242
generate_dataloader_bucket_block=======
self.global_to_local() spend sec:  7.700920104980469e-05
len(bkt)  20
len(bkt)  25
len(bkt)  26
len(bkt)  22
len(bkt)  15
len(bkt)  11
len(bkt)  4
len(bkt)  3
len(bkt)  4
len(bkt)  3
len(bkt)  1
len(bkt)  2
len(bkt)  1
len(bkt)  1
len(bkt)  2
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--

memory_constraint:  4.8
sum(estimated_mem)
14.19501480460167
15
self.K  3
the grouping_fanout_arxiv called successfully
capacity  4800
 
sorted_dict  {3: 2283, 4: 1878, 2: 1594, 5: 1577, 1: 1374, 14: 1144, 8: 868, 6: 666, 9: 620, 7: 478, 0: 439, 13: 425, 11: 401, 12: 271, 10: 169}

weights after sort [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
res_tmp  [1594 1577  620  439  401  169]

remove bucket_id:  [2, 3, 8, 10, 12, 14]
original bucket_id :,  [2, 5, 9, 0, 11, 10]
remove weights:  [1594 1577  620  439  401  169], 		------------sum 4800

before remove weights,  [2283, 1878, 1594, 1577, 1374, 1144, 868, 666, 620, 478, 439, 425, 401, 271, 169]
after remove pre pack weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
res_tmp  [2283 1374  868  271]

remove bucket_id:  [0, 2, 4, 8]
original bucket_id :,  [3, 1, 8, 12]
remove weights:  [2283 1374  868  271], 		------------sum 4796

before remove weights,  [2283, 1878, 1374, 1144, 868, 666, 478, 425, 271]
after remove pre pack weights,  [1878, 1144, 666, 478, 425]
G_BUCKET_ID_list [[2, 5, 9, 0, 11, 10], [3, 1, 8, 12], [4, 14, 6, 7, 13]]
Groups_mem_list  [[1594, 1577, 620, 439, 401, 169], [2283, 1374, 868, 271], [1878, 1144, 666, 478, 425]]
G_BUCKET_ID_list length 3
backpack scheduling spend  0.08986711502075195
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[2, 5, 9, 0, 11, 10]
2
5
9
0
11
10
current group_mem  4.802796587347984
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[3, 1, 8, 12]
3
1
8
12
current group_mem  4.798927769064903
[0.4396008476614952, 1.374441683292389, 1.5948124453425407, 2.2839434891939163, 1.8786997273564339, 1.5771530494093895, 0.6665662229061127, 0.4780137687921524, 0.8689616918563843, 0.6201625987887383, 0.16984806954860687, 0.40121957659721375, 0.27158090472221375, 0.42578747123479843, 1.1442232578992844]
[4, 14, 6, 7, 13]
4
14
6
7
13
current group_mem  4.593290448188782
batches output list generation spend  0.0001227855682373047
self.weights_list  [0.45, 0.37142857142857144, 0.17857142857142858]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0005764961242675781
self.gen_batches_seeds_list(bkt_dst_nodes_list) spend  0.09004068374633789
len local_batched_seeds_list  3
partition total batch output list spend :  0.09146261215209961
self.buckets_partition() spend  sec:  0.09069228172302246
layer  0
 the number of batches:  3
check_connections_block*********************************
res  length 3
layer  1
num of batch  3
check_connections_block*********************************
res  length 3
layer  2
num of batch  3
check_connections_block*********************************
res  length 3
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.4705557823181152  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.9942493438720703  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.994206428527832  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.4705557823181152  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.9800891876220703  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.9800910949707031  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

step  2
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.4693875312805176  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.9862308502197266  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.9862322807312012  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 3.83984375 GB
    Memory Allocated: 1.4694476127624512  GigaBytes
Max Memory Allocated: 2.2430572509765625  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.9433084726333618
pure train time :  1.1818821430206299
train time :  1.3606162071228027
end to end time :  1.4806146621704102
connection check time:  0.008352279663085938
block generation time  0.0195465087890625
end to end time  1.5697698593139648
Total (block generation + training)time/epoch 1.5697698593139648
pure train time per /epoch  [1.4504969120025635, 1.1834712028503418, 1.1765966415405273, 1.1809918880462646, 1.1817870140075684, 1.1832587718963623, 1.1770577430725098, 1.175069808959961, 1.1826872825622559, 1.1818821430206299]
pure train time average  1.1803906645093645
input num list  [4415, 4435, 4436, 4471, 4449, 4457, 4479, 4496, 4476, 4423]
