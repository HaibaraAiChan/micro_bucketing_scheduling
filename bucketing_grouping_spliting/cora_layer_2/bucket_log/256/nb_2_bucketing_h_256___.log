main start at this time 1691642968.704264
-----------------------------------------before load data 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
success----------------------------------------
140
500
2068
# Nodes: 2708
# Edges: 10556
# Train: 140
# Val: 500
# Test: 2068
# Classes: 7

----------------------------------------start of run function 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

generate_dataloader_bucket_block=======
len(bkt)  20
len(bkt)  25
len(bkt)  26
len(bkt)  22
len(bkt)  15
len(bkt)  11
len(bkt)  4
len(bkt)  3
len(bkt)  4
len(bkt)  3
len(bkt)  1
len(bkt)  2
len(bkt)  1
len(bkt)  1
len(bkt)  2
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
memory_constraint:  0.4
sum(estimated_mem)
0.36848267912864685
15
the grouping_fanout_cora called successfully
capacity  400
 
sorted_dict  {3: 54, 4: 49, 2: 39, 5: 39, 1: 29, 14: 28, 8: 22, 9: 18, 6: 17, 7: 14, 11: 14, 13: 14, 12: 10, 0: 9, 10: 5}

weights after sort [54, 49, 39, 39, 29, 28, 22, 18, 17, 14, 14, 14, 10, 9, 5]
G_BUCKET_ID_list [[3, 4, 2, 5, 1, 14, 8, 9, 6, 7, 11, 13, 12, 0, 10]]
Groups_mem_list  [[54, 49, 39, 39, 29, 28, 22, 18, 17, 14, 14, 14, 10, 9, 5]]
G_BUCKET_ID_list length 1
backpack scheduling spend  0.0009002685546875
current group_mem  0.36848267912864685
batches output list generation spend  0.0007641315460205078
self.weights_list  [1.0]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0015194416046142578
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.0017397403717041016
len local_batched_seeds_list  1
partition total batch output list spend :  0.00406646728515625
self.buckets_partition() spend  sec:  0.0032770633697509766
layer  0
 the number of batches:  1
check_connections_block*********************************

the find indices time spent  0.00014543533325195312

in edges time spent  0.0004210472106933594
local to global src and eids time spent  0.0003466606140136719
time gen tails  0.000125885009765625
res  length 1
layer  1
num of batch  1
check_connections_block*********************************

the find indices time spent  0.00033593177795410156

in edges time spent  0.0009999275207519531
local to global src and eids time spent  0.0011506080627441406
time gen tails  0.0002884864807128906
res  length 1
block collection to dataloader spend  3.337860107421875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.515625 GB
    Memory Allocated: 0.07451200485229492  GigaBytes
Max Memory Allocated: 0.07451200485229492  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.900390625 GB
    Memory Allocated: 0.33754968643188477  GigaBytes
Max Memory Allocated: 0.3491978645324707  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 1.900390625 GB
    Memory Allocated: 0.3375544548034668  GigaBytes
Max Memory Allocated: 0.3491978645324707  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 2.193359375 GB
    Memory Allocated: 0.27669191360473633  GigaBytes
Max Memory Allocated: 0.44469738006591797  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.94451904296875
pure train time :  0.5080575942993164
train time :  1.0303723812103271
end to end time :  1.0509181022644043
connection check time:  0.004563331604003906
block generation time  0.010900020599365234
Total (block generation + training)time/epoch nan
pure train time per /epoch  [0.5080575942993164]
pure train time average  nan
input num list  [1355]
