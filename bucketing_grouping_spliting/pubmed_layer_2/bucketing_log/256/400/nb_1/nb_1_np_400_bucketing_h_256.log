main start at this time 1698796951.605636
-----------------------------------------before load data 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
success----------------------------------------
60
500
19157
# Nodes: 19717
# Edges: 88648
# Train: 60
# Val: 500
# Test: 19157
# Classes: 3

----------------------------------------start of run function 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

full batch src global  1583
full batch dst global  60
full batch train ------ loss 1.0981959104537964

full batch src global  1607
full batch dst global  60
full batch train ------ loss 1.0853861570358276

full batch src global  1605
full batch dst global  60
full batch train ------ loss 1.0680912733078003

full batch src global  1578
full batch dst global  60
full batch train ------ loss 1.059518575668335

full batch src global  1597
full batch dst global  60
full batch train ------ loss 1.0407142639160156

full batch src global  1579
full batch dst global  60
full batch train ------ loss 1.026503324508667

full batch src global  1588
full batch dst global  60
full batch train ------ loss 1.0209320783615112

full batch src global  1593
full batch dst global  60
full batch train ------ loss 1.0004515647888184

full batch src global  1589
full batch dst global  60
full batch train ------ loss 0.9767776131629944

full batch src global  1604
full batch dst global  60
full batch train ------ loss 0.9633859992027283

full batch src global  1570
full batch dst global  60
full batch train ------ loss 0.9265407919883728

full batch src global  1591
full batch dst global  60
full batch train ------ loss 0.920086145401001

full batch src global  1602
full batch dst global  60
full batch train ------ loss 0.8811463713645935

full batch src global  1605
full batch dst global  60
full batch train ------ loss 0.8150613903999329

full batch src global  1620
full batch dst global  60
full batch train ------ loss 0.7790905833244324

full batch src global  1571
full batch dst global  60
full batch train ------ loss 0.7203397154808044

full batch src global  1561
full batch dst global  60
full batch train ------ loss 0.6924422979354858

full batch src global  1579
full batch dst global  60
full batch train ------ loss 0.6381404399871826

full batch src global  1570
full batch dst global  60
full batch train ------ loss 0.612231969833374

full batch src global  1599
full batch dst global  60
full batch train ------ loss 0.623397171497345

full batch src global  1602
full batch dst global  60
full batch train ------ loss 0.5372647047042847

full batch src global  1607
full batch dst global  60
full batch train ------ loss 0.4555613100528717

full batch src global  1601
full batch dst global  60
full batch train ------ loss 0.5099825263023376

full batch src global  1589
full batch dst global  60
full batch train ------ loss 0.42426785826683044

full batch src global  1593
full batch dst global  60
full batch train ------ loss 0.4240633249282837

full batch src global  1598
full batch dst global  60
full batch train ------ loss 0.3957262635231018

full batch src global  1587
full batch dst global  60
full batch train ------ loss 0.3569382131099701

full batch src global  1575
full batch dst global  60
full batch train ------ loss 0.2992402911186218

full batch src global  1587
full batch dst global  60
full batch train ------ loss 0.29518386721611023

full batch src global  1587
full batch dst global  60
full batch train ------ loss 0.2830857038497925

full batch src global  1602
full batch dst global  60
full batch train ------ loss 0.23754769563674927

full batch src global  1584
full batch dst global  60
full batch train ------ loss 0.1771726906299591

full batch src global  1586
full batch dst global  60
full batch train ------ loss 0.13253740966320038

full batch src global  1558
full batch dst global  60
full batch train ------ loss 0.211917906999588

full batch src global  1586
full batch dst global  60
full batch train ------ loss 0.13851629197597504

full batch src global  1611
full batch dst global  60
full batch train ------ loss 0.09617400169372559

full batch src global  1576
full batch dst global  60
full batch train ------ loss 0.16758106648921967

full batch src global  1604
full batch dst global  60
full batch train ------ loss 0.08729284256696701

full batch src global  1597
full batch dst global  60
full batch train ------ loss 0.14808540046215057

full batch src global  1570
full batch dst global  60
full batch train ------ loss 0.06973843276500702

full batch src global  1575
full batch dst global  60
full batch train ------ loss 0.07234286516904831

full batch src global  1578
full batch dst global  60
full batch train ------ loss 0.08314861357212067

full batch src global  1582
full batch dst global  60
full batch train ------ loss 0.0634806752204895

full batch src global  1595
full batch dst global  60
full batch train ------ loss 0.048760298639535904

full batch src global  1618
full batch dst global  60
full batch train ------ loss 0.03866385295987129

full batch src global  1587
full batch dst global  60
full batch train ------ loss 0.04291431978344917

full batch src global  1582
full batch dst global  60
full batch train ------ loss 0.046574197709560394

full batch src global  1567
full batch dst global  60
full batch train ------ loss 0.01859225705265999

full batch src global  1613
full batch dst global  60
full batch train ------ loss 0.02397400140762329

full batch src global  1596
full batch dst global  60
full batch train ------ loss 0.029259512200951576

full batch src global  1583
full batch dst global  60
full batch train ------ loss 0.016435157507658005

full batch src global  1585
full batch dst global  60
full batch train ------ loss 0.028102608397603035

full batch src global  1595
full batch dst global  60
full batch train ------ loss 0.07514826953411102

full batch src global  1584
full batch dst global  60
full batch train ------ loss 0.046844083815813065

full batch src global  1575
full batch dst global  60
full batch train ------ loss 0.04765306040644646

full batch src global  1599
full batch dst global  60
full batch train ------ loss 0.013783703558146954

full batch src global  1592
full batch dst global  60
full batch train ------ loss 0.0777575671672821

full batch src global  1590
full batch dst global  60
full batch train ------ loss 0.04667359218001366

full batch src global  1579
full batch dst global  60
full batch train ------ loss 0.0340302549302578

full batch src global  1605
full batch dst global  60
full batch train ------ loss 0.5787550210952759

full batch src global  1610
full batch dst global  60
full batch train ------ loss 0.021500475704669952

full batch src global  1589
full batch dst global  60
full batch train ------ loss 0.15358826518058777

full batch src global  1579
full batch dst global  60
full batch train ------ loss 0.17603084444999695

full batch src global  1600
full batch dst global  60
full batch train ------ loss 0.104984350502491

full batch src global  1590
full batch dst global  60
full batch train ------ loss 0.008095255121588707

full batch src global  1604
full batch dst global  60
full batch train ------ loss 0.020428935065865517

full batch src global  1588
full batch dst global  60
full batch train ------ loss 0.017147166654467583

full batch src global  1601
full batch dst global  60
full batch train ------ loss 0.09576547145843506

full batch src global  1593
full batch dst global  60
full batch train ------ loss 0.04219602048397064

full batch src global  1609
full batch dst global  60
full batch train ------ loss 0.07277975976467133

full batch src global  1598
full batch dst global  60
full batch train ------ loss 0.03429095447063446

full batch src global  1588
full batch dst global  60
full batch train ------ loss 0.03609202802181244

full batch src global  1592
full batch dst global  60
full batch train ------ loss 0.02193404920399189

full batch src global  1584
full batch dst global  60
full batch train ------ loss 0.01669708825647831

full batch src global  1589
full batch dst global  60
full batch train ------ loss 0.01467612199485302

full batch src global  1601
full batch dst global  60
full batch train ------ loss 0.014245662838220596

full batch src global  1577
full batch dst global  60
full batch train ------ loss 0.02292090654373169

full batch src global  1564
full batch dst global  60
full batch train ------ loss 0.04308035597205162

full batch src global  1578
full batch dst global  60
full batch train ------ loss 0.028845183551311493

full batch src global  1600
full batch dst global  60
full batch train ------ loss 0.04390961676836014

full batch src global  1598
full batch dst global  60
full batch train ------ loss 0.019241025671362877

full batch src global  1574
full batch dst global  60
full batch train ------ loss 0.019579047337174416

full batch src global  1575
full batch dst global  60
full batch train ------ loss 0.015675101429224014

full batch src global  1611
full batch dst global  60
full batch train ------ loss 0.016738174483180046

full batch src global  1577
full batch dst global  60
full batch train ------ loss 0.01535202469676733

full batch src global  1594
full batch dst global  60
full batch train ------ loss 0.013975879177451134

full batch src global  1590
full batch dst global  60
full batch train ------ loss 0.00904069934040308

full batch src global  1592
full batch dst global  60
full batch train ------ loss 0.01685185916721821

full batch src global  1586
full batch dst global  60
full batch train ------ loss 0.006647550035268068

full batch src global  1604
full batch dst global  60
full batch train ------ loss 0.010815308429300785

full batch src global  1598
full batch dst global  60
full batch train ------ loss 0.007404905278235674

full batch src global  1617
full batch dst global  60
full batch train ------ loss 0.008019409142434597

full batch src global  1592
full batch dst global  60
full batch train ------ loss 0.007879948243498802

full batch src global  1594
full batch dst global  60
full batch train ------ loss 0.005399392452090979

full batch src global  1587
full batch dst global  60
full batch train ------ loss 0.0084387781098485

full batch src global  1587
full batch dst global  60
full batch train ------ loss 0.0048698121681809425

full batch src global  1597
full batch dst global  60
full batch train ------ loss 0.01092086173593998

full batch src global  1596
full batch dst global  60
full batch train ------ loss 0.005014559719711542

full batch src global  1574
full batch dst global  60
full batch train ------ loss 0.01273411326110363

full batch src global  1597
full batch dst global  60
full batch train ------ loss 0.004318155348300934

full batch src global  1590
full batch dst global  60
full batch train ------ loss 0.004760033916682005

full batch src global  1595
full batch dst global  60
full batch train ------ loss 0.005569192580878735

full batch src global  1594
full batch dst global  60
full batch train ------ loss 0.0041377549059689045

full batch src global  1597
full batch dst global  60
full batch train ------ loss 0.0039767129346728325

full batch src global  1581
full batch dst global  60
full batch train ------ loss 0.0036570706870406866

full batch src global  1587
full batch dst global  60
full batch train ------ loss 0.002723938785493374

full batch src global  1585
full batch dst global  60
full batch train ------ loss 0.003665405325591564

full batch src global  1577
full batch dst global  60
full batch train ------ loss 0.004228364210575819

full batch src global  1625
full batch dst global  60
full batch train ------ loss 0.0028374227695167065

full batch src global  1581
full batch dst global  60
full batch train ------ loss 0.003027803497388959

full batch src global  1575
full batch dst global  60
full batch train ------ loss 0.0030172124970704317

full batch src global  1597
full batch dst global  60
full batch train ------ loss 0.007473574951291084

full batch src global  1615
full batch dst global  60
full batch train ------ loss 0.002584936562925577

full batch src global  1576
full batch dst global  60
full batch train ------ loss 0.0025653885677456856

full batch src global  1573
full batch dst global  60
full batch train ------ loss 0.00267283758148551

full batch src global  1585
full batch dst global  60
full batch train ------ loss 0.006432625465095043

full batch src global  1597
full batch dst global  60
full batch train ------ loss 0.0019726683385670185

full batch src global  1585
full batch dst global  60
full batch train ------ loss 0.002095834817737341

full batch src global  1597
full batch dst global  60
full batch train ------ loss 0.00278084515593946

full batch src global  1600
full batch dst global  60
full batch train ------ loss 0.0016930134734138846

full batch src global  1590
full batch dst global  60
full batch train ------ loss 0.002557187806814909

full batch src global  1585
full batch dst global  60
full batch train ------ loss 0.0016803719336166978

full batch src global  1596
full batch dst global  60
full batch train ------ loss 0.0017563769361004233

full batch src global  1591
full batch dst global  60
full batch train ------ loss 0.0018406360177323222

full batch src global  1607
full batch dst global  60
full batch train ------ loss 0.0022371860686689615

full batch src global  1580
full batch dst global  60
full batch train ------ loss 0.00209703017026186

full batch src global  1611
full batch dst global  60
full batch train ------ loss 0.0018603213829919696

full batch src global  1599
full batch dst global  60
full batch train ------ loss 0.0014493894996121526

full batch src global  1613
full batch dst global  60
full batch train ------ loss 0.002316084923222661

full batch src global  1602
full batch dst global  60
full batch train ------ loss 0.0013614926720038056

full batch src global  1592
full batch dst global  60
full batch train ------ loss 0.0021790596656501293

full batch src global  1610
full batch dst global  60
full batch train ------ loss 0.0032645491883158684

full batch src global  1587
full batch dst global  60
full batch train ------ loss 0.0014941336121410131

full batch src global  1590
full batch dst global  60
full batch train ------ loss 0.009280908852815628

full batch src global  1591
full batch dst global  60
full batch train ------ loss 0.0009679600480012596

full batch src global  1577
full batch dst global  60
full batch train ------ loss 0.0012480666628107429

full batch src global  1596
full batch dst global  60
full batch train ------ loss 0.0011188050266355276

full batch src global  1605
full batch dst global  60
full batch train ------ loss 0.001125512644648552

full batch src global  1594
full batch dst global  60
full batch train ------ loss 0.001293906825594604

full batch src global  1576
full batch dst global  60
full batch train ------ loss 0.002142772078514099

full batch src global  1593
full batch dst global  60
full batch train ------ loss 0.006551586091518402

full batch src global  1605
full batch dst global  60
full batch train ------ loss 0.0012385161826387048

full batch src global  1587
full batch dst global  60
full batch train ------ loss 0.009261224418878555

full batch src global  1576
full batch dst global  60
full batch train ------ loss 0.001444746390916407

full batch src global  1598
full batch dst global  60
full batch train ------ loss 0.001097209518775344

full batch src global  1584
full batch dst global  60
full batch train ------ loss 0.0009315029601566494

full batch src global  1604
full batch dst global  60
full batch train ------ loss 0.0014179066056385636

full batch src global  1595
full batch dst global  60
full batch train ------ loss 0.0013891159323975444

full batch src global  1589
full batch dst global  60
full batch train ------ loss 0.0014382058288902044

full batch src global  1567
full batch dst global  60
full batch train ------ loss 0.0014665622729808092

full batch src global  1604
full batch dst global  60
full batch train ------ loss 0.00140655436553061

full batch src global  1587
full batch dst global  60
full batch train ------ loss 0.0011019990779459476

full batch src global  1590
full batch dst global  60
full batch train ------ loss 0.002512440551072359

full batch src global  1576
full batch dst global  60
full batch train ------ loss 0.0011309192050248384

full batch src global  1602
full batch dst global  60
full batch train ------ loss 0.014663065783679485

full batch src global  1592
full batch dst global  60
full batch train ------ loss 0.00148492562584579

full batch src global  1600
full batch dst global  60
full batch train ------ loss 0.0012031226651743054

full batch src global  1599
full batch dst global  60
full batch train ------ loss 0.0010291066719219089

full batch src global  1605
full batch dst global  60
full batch train ------ loss 0.032231543213129044

full batch src global  1607
full batch dst global  60
full batch train ------ loss 0.0011676071444526315

full batch src global  1579
full batch dst global  60
full batch train ------ loss 0.003663392970338464

full batch src global  1584
full batch dst global  60
full batch train ------ loss 0.02052013762295246

full batch src global  1588
full batch dst global  60
full batch train ------ loss 0.0009629057021811604

full batch src global  1592
full batch dst global  60
full batch train ------ loss 0.0010847900994122028

full batch src global  1592
full batch dst global  60
full batch train ------ loss 0.0017351115820929408

full batch src global  1590
full batch dst global  60
full batch train ------ loss 0.002188716782256961

full batch src global  1559
full batch dst global  60
full batch train ------ loss 0.024192897602915764

full batch src global  1585
full batch dst global  60
full batch train ------ loss 0.025656629353761673

full batch src global  1575
full batch dst global  60
full batch train ------ loss 0.007851501926779747

full batch src global  1591
full batch dst global  60
full batch train ------ loss 0.0017264912603423

full batch src global  1590
full batch dst global  60
full batch train ------ loss 0.0024764612317085266

full batch src global  1577
full batch dst global  60
full batch train ------ loss 0.0012433088850229979

full batch src global  1580
full batch dst global  60
full batch train ------ loss 0.045052386820316315

full batch src global  1589
full batch dst global  60
full batch train ------ loss 0.005018636584281921

full batch src global  1614
full batch dst global  60
full batch train ------ loss 0.0737159326672554

full batch src global  1592
full batch dst global  60
full batch train ------ loss 0.0017375501338392496

full batch src global  1587
full batch dst global  60
full batch train ------ loss 0.0010042742360383272

full batch src global  1603
full batch dst global  60
full batch train ------ loss 0.2946338355541229

full batch src global  1596
full batch dst global  60
full batch train ------ loss 0.007061769720166922

full batch src global  1580
full batch dst global  60
full batch train ------ loss 0.0483313724398613

full batch src global  1582
full batch dst global  60
full batch train ------ loss 0.03325193002820015

full batch src global  1607
full batch dst global  60
full batch train ------ loss 0.06146613135933876

full batch src global  1585
full batch dst global  60
full batch train ------ loss 0.0785781592130661

full batch src global  1608
full batch dst global  60
full batch train ------ loss 0.008015052415430546

full batch src global  1588
full batch dst global  60
full batch train ------ loss 0.061271391808986664

full batch src global  1600
full batch dst global  60
full batch train ------ loss 0.00919957086443901

full batch src global  1567
full batch dst global  60
full batch train ------ loss 0.005796910263597965

full batch src global  1588
full batch dst global  60
full batch train ------ loss 0.015690967440605164

full batch src global  1595
full batch dst global  60
full batch train ------ loss 0.029092393815517426

full batch src global  1593
full batch dst global  60
full batch train ------ loss 0.050176944583654404

full batch src global  1590
full batch dst global  60
full batch train ------ loss 0.06087305769324303

full batch src global  1604
full batch dst global  60
full batch train ------ loss 0.009377836249768734

full batch src global  1609
full batch dst global  60
full batch train ------ loss 0.018564404919743538

full batch src global  1583
full batch dst global  60
full batch train ------ loss 0.042278535664081573

full batch src global  1584
full batch dst global  60
full batch train ------ loss 0.017755115404725075

full batch src global  1580
full batch dst global  60
full batch train ------ loss 0.00819258764386177

full batch src global  1597
full batch dst global  60
full batch train ------ loss 0.01485593430697918

full batch src global  1590
full batch dst global  60
full batch train ------ loss 0.015699945390224457

full batch src global  1594
full batch dst global  60
full batch train ------ loss 0.010725273750722408

full batch src global  1598
full batch dst global  60
full batch train ------ loss 0.005018364172428846

full batch src global  1603
full batch dst global  60
full batch train ------ loss 0.00848114863038063

full batch src global  1585
full batch dst global  60
full batch train ------ loss 0.00697431480512023

full batch src global  1596
full batch dst global  60
full batch train ------ loss 0.004331620875746012

full batch src global  1595
full batch dst global  60
full batch train ------ loss 0.004571958445012569

full batch src global  1587
full batch dst global  60
full batch train ------ loss 0.035479892045259476

full batch src global  1589
full batch dst global  60
full batch train ------ loss 0.0036114202812314034

full batch src global  1586
full batch dst global  60
full batch train ------ loss 0.0036998577415943146

full batch src global  1605
full batch dst global  60
full batch train ------ loss 0.003744042944163084

full batch src global  1596
full batch dst global  60
full batch train ------ loss 0.0038812560960650444

full batch src global  1594
full batch dst global  60
full batch train ------ loss 0.004812601022422314

full batch src global  1605
full batch dst global  60
full batch train ------ loss 0.014651876874268055

full batch src global  1606
full batch dst global  60
full batch train ------ loss 0.0055165537633001804

full batch src global  1588
full batch dst global  60
full batch train ------ loss 0.004226519726216793

full batch src global  1600
full batch dst global  60
full batch train ------ loss 0.004624451510608196

full batch src global  1592
full batch dst global  60
full batch train ------ loss 0.0033374610356986523

full batch src global  1584
full batch dst global  60
full batch train ------ loss 0.003525301581248641

full batch src global  1572
full batch dst global  60
full batch train ------ loss 0.0037839733995497227

full batch src global  1600
full batch dst global  60
full batch train ------ loss 0.004492901731282473

full batch src global  1593
full batch dst global  60
full batch train ------ loss 0.007152150850743055

full batch src global  1609
full batch dst global  60
full batch train ------ loss 0.004289465025067329

full batch src global  1610
full batch dst global  60
full batch train ------ loss 0.003401597263291478

full batch src global  1597
full batch dst global  60
full batch train ------ loss 0.0030047488398849964

full batch src global  1592
full batch dst global  60
full batch train ------ loss 0.00775656895712018

full batch src global  1597
full batch dst global  60
full batch train ------ loss 0.002899466548115015

full batch src global  1586
full batch dst global  60
full batch train ------ loss 0.002096503507345915

full batch src global  1581
full batch dst global  60
full batch train ------ loss 0.001981050241738558

full batch src global  1605
full batch dst global  60
full batch train ------ loss 0.0022689825855195522

full batch src global  1598
full batch dst global  60
full batch train ------ loss 0.001437999540939927

full batch src global  1601
full batch dst global  60
full batch train ------ loss 0.0017109860200434923

full batch src global  1589
full batch dst global  60
full batch train ------ loss 0.004605913069099188

full batch src global  1598
full batch dst global  60
full batch train ------ loss 0.001604139688424766

full batch src global  1584
full batch dst global  60
full batch train ------ loss 0.0018047370249405503

full batch src global  1602
full batch dst global  60
full batch train ------ loss 0.0017997829709202051

full batch src global  1612
full batch dst global  60
full batch train ------ loss 0.001813143608160317

full batch src global  1605
full batch dst global  60
full batch train ------ loss 0.001729420037008822

full batch src global  1601
full batch dst global  60
full batch train ------ loss 0.0020760793704539537

full batch src global  1575
full batch dst global  60
full batch train ------ loss 0.001158058294095099

full batch src global  1586
full batch dst global  60
full batch train ------ loss 0.0012260028161108494

full batch src global  1601
full batch dst global  60
full batch train ------ loss 0.0030029930640012026

full batch src global  1584
full batch dst global  60
full batch train ------ loss 0.001489577698521316

full batch src global  1591
full batch dst global  60
full batch train ------ loss 0.0012035233667120337

full batch src global  1581
full batch dst global  60
full batch train ------ loss 0.001287329476326704

full batch src global  1597
full batch dst global  60
full batch train ------ loss 0.0010289291385561228

full batch src global  1591
full batch dst global  60
full batch train ------ loss 0.0009732166072353721

full batch src global  1587
full batch dst global  60
full batch train ------ loss 0.000999755458906293

full batch src global  1591
full batch dst global  60
full batch train ------ loss 0.0007062970544211566

full batch src global  1600
full batch dst global  60
full batch train ------ loss 0.001012918772175908

full batch src global  1590
full batch dst global  60
full batch train ------ loss 0.0009309769957326353

full batch src global  1584
full batch dst global  60
full batch train ------ loss 0.0009605016675777733

full batch src global  1599
full batch dst global  60
full batch train ------ loss 0.0012030545622110367

full batch src global  1599
full batch dst global  60
full batch train ------ loss 0.0007244079606607556

full batch src global  1599
full batch dst global  60
full batch train ------ loss 0.0010704293381422758

full batch src global  1609
full batch dst global  60
full batch train ------ loss 0.001129367621615529

full batch src global  1572
full batch dst global  60
full batch train ------ loss 0.0010325118200853467

full batch src global  1597
full batch dst global  60
full batch train ------ loss 0.0008672357653267682

full batch src global  1593
full batch dst global  60
full batch train ------ loss 0.000515832332894206

full batch src global  1588
full batch dst global  60
full batch train ------ loss 0.0006314849015325308

full batch src global  1616
full batch dst global  60
full batch train ------ loss 0.0005495954537764192

full batch src global  1594
full batch dst global  60
full batch train ------ loss 0.0007826624205335975

full batch src global  1584
full batch dst global  60
full batch train ------ loss 0.0007802448817528784

full batch src global  1604
full batch dst global  60
full batch train ------ loss 0.0009332975605502725

full batch src global  1603
full batch dst global  60
full batch train ------ loss 0.001178167061880231

full batch src global  1609
full batch dst global  60
full batch train ------ loss 0.0014125995803624392

full batch src global  1585
full batch dst global  60
full batch train ------ loss 0.0011008131550624967

full batch src global  1594
full batch dst global  60
full batch train ------ loss 0.0006564814830198884

full batch src global  1588
full batch dst global  60
full batch train ------ loss 0.0007974546169862151

full batch src global  1584
full batch dst global  60
full batch train ------ loss 0.0006121786427684128

full batch src global  1587
full batch dst global  60
full batch train ------ loss 0.0008114084484986961

full batch src global  1579
full batch dst global  60
full batch train ------ loss 0.0006695639458484948

full batch src global  1604
full batch dst global  60
full batch train ------ loss 0.00046186105464585125

full batch src global  1583
full batch dst global  60
full batch train ------ loss 0.0006277199718169868

full batch src global  1578
full batch dst global  60
full batch train ------ loss 0.0010061338543891907

full batch src global  1564
full batch dst global  60
full batch train ------ loss 0.0005999190616421402

full batch src global  1591
full batch dst global  60
full batch train ------ loss 0.0007634832290932536

full batch src global  1587
full batch dst global  60
full batch train ------ loss 0.0005703275674022734

full batch src global  1608
full batch dst global  60
full batch train ------ loss 0.0006028445204719901

full batch src global  1594
full batch dst global  60
full batch train ------ loss 0.0007234293152578175

full batch src global  1604
full batch dst global  60
full batch train ------ loss 0.0005153518868610263

full batch src global  1597
full batch dst global  60
full batch train ------ loss 0.0005724513903260231

full batch src global  1604
full batch dst global  60
full batch train ------ loss 0.0005211589741520584

full batch src global  1610
full batch dst global  60
full batch train ------ loss 0.0007528894348070025

full batch src global  1587
full batch dst global  60
full batch train ------ loss 0.000619300757534802

full batch src global  1606
full batch dst global  60
full batch train ------ loss 0.0007371624815277755

full batch src global  1592
full batch dst global  60
full batch train ------ loss 0.00045020089601166546

full batch src global  1586
full batch dst global  60
full batch train ------ loss 0.0006418395205400884

full batch src global  1585
full batch dst global  60
full batch train ------ loss 0.00033363644615747035

full batch src global  1619
full batch dst global  60
full batch train ------ loss 0.0008089097100310028

full batch src global  1604
full batch dst global  60
full batch train ------ loss 0.0007869768305681646

full batch src global  1595
full batch dst global  60
full batch train ------ loss 0.0004987817374058068

full batch src global  1596
full batch dst global  60
full batch train ------ loss 0.0004832038830500096

full batch src global  1589
full batch dst global  60
full batch train ------ loss 0.00044378128950484097

full batch src global  1583
full batch dst global  60
full batch train ------ loss 0.00034638604847714305

full batch src global  1595
full batch dst global  60
full batch train ------ loss 0.0005212673568166792

full batch src global  1582
full batch dst global  60
full batch train ------ loss 0.00038854937884025276

full batch src global  1595
full batch dst global  60
full batch train ------ loss 0.0004774718836415559

full batch src global  1564
full batch dst global  60
full batch train ------ loss 0.0005222273175604641

full batch src global  1579
full batch dst global  60
full batch train ------ loss 0.00026343698846176267

full batch src global  1608
full batch dst global  60
full batch train ------ loss 0.00046903392649255693

full batch src global  1605
full batch dst global  60
full batch train ------ loss 0.0005034146597608924

full batch src global  1596
full batch dst global  60
full batch train ------ loss 0.00034540952765382826

full batch src global  1594
full batch dst global  60
full batch train ------ loss 0.0002558694395702332

full batch src global  1578
full batch dst global  60
full batch train ------ loss 0.0004590646713040769

full batch src global  1606
full batch dst global  60
full batch train ------ loss 0.0003853036614600569

full batch src global  1574
full batch dst global  60
full batch train ------ loss 0.0005671560647897422

full batch src global  1584
full batch dst global  60
full batch train ------ loss 0.00041051700827665627

full batch src global  1598
full batch dst global  60
full batch train ------ loss 0.0007154268096201122

full batch src global  1607
full batch dst global  60
full batch train ------ loss 0.0003637897898443043

full batch src global  1586
full batch dst global  60
full batch train ------ loss 0.00047966238344088197

full batch src global  1586
full batch dst global  60
full batch train ------ loss 0.000407465297030285

full batch src global  1597
full batch dst global  60
full batch train ------ loss 0.00035395598388276994

full batch src global  1604
full batch dst global  60
full batch train ------ loss 0.0003994501894339919

full batch src global  1576
full batch dst global  60
full batch train ------ loss 0.0005218199221417308

full batch src global  1590
full batch dst global  60
full batch train ------ loss 0.00021526026830542833

full batch src global  1593
full batch dst global  60
full batch train ------ loss 0.00040264675044454634

full batch src global  1577
full batch dst global  60
full batch train ------ loss 0.0003905041376128793

full batch src global  1591
full batch dst global  60
full batch train ------ loss 0.00045389580191113055

full batch src global  1597
full batch dst global  60
full batch train ------ loss 0.00034468749072402716

full batch src global  1598
full batch dst global  60
full batch train ------ loss 0.0003587952523957938

full batch src global  1586
full batch dst global  60
full batch train ------ loss 0.0003204045060556382

full batch src global  1584
full batch dst global  60
full batch train ------ loss 0.0003152801073156297

full batch src global  1590
full batch dst global  60
full batch train ------ loss 0.0006000691209919751

full batch src global  1597
full batch dst global  60
full batch train ------ loss 0.0004513909516390413

full batch src global  1609
full batch dst global  60
full batch train ------ loss 0.0005524139269255102

full batch src global  1584
full batch dst global  60
full batch train ------ loss 0.0006997208693064749

full batch src global  1565
full batch dst global  60
full batch train ------ loss 0.000469252176117152

full batch src global  1586
full batch dst global  60
full batch train ------ loss 0.0002644854539539665

full batch src global  1597
full batch dst global  60
full batch train ------ loss 0.0002697268791962415

full batch src global  1599
full batch dst global  60
full batch train ------ loss 0.00039761888911016285

full batch src global  1594
full batch dst global  60
full batch train ------ loss 0.00033161562168970704

full batch src global  1621
full batch dst global  60
full batch train ------ loss 0.0002370282163610682

full batch src global  1588
full batch dst global  60
full batch train ------ loss 0.0002630195231176913

full batch src global  1601
full batch dst global  60
full batch train ------ loss 0.00022789060312788934

full batch src global  1590
full batch dst global  60
full batch train ------ loss 0.0002337222103960812

full batch src global  1601
full batch dst global  60
full batch train ------ loss 0.0004958295030519366

full batch src global  1591
full batch dst global  60
full batch train ------ loss 0.00017848056450020522

full batch src global  1588
full batch dst global  60
full batch train ------ loss 0.00024622888304293156

full batch src global  1578
full batch dst global  60
full batch train ------ loss 0.00032515922794118524

full batch src global  1602
full batch dst global  60
full batch train ------ loss 0.00036962373997084796

full batch src global  1613
full batch dst global  60
full batch train ------ loss 0.0002836634812410921

full batch src global  1590
full batch dst global  60
full batch train ------ loss 0.00020877161296084523

full batch src global  1606
full batch dst global  60
full batch train ------ loss 0.0004250599886290729

full batch src global  1579
full batch dst global  60
full batch train ------ loss 0.0006987476954236627

full batch src global  1592
full batch dst global  60
full batch train ------ loss 0.0003271425957791507

full batch src global  1588
full batch dst global  60
full batch train ------ loss 0.00043601737706921995

full batch src global  1577
full batch dst global  60
full batch train ------ loss 0.00034173138556070626

full batch src global  1577
full batch dst global  60
full batch train ------ loss 0.0002578853745944798

full batch src global  1596
full batch dst global  60
full batch train ------ loss 0.0004127468855585903

full batch src global  1600
full batch dst global  60
full batch train ------ loss 0.00028269263566471636

full batch src global  1613
full batch dst global  60
full batch train ------ loss 0.00032430473947897553

full batch src global  1595
full batch dst global  60
full batch train ------ loss 0.00041222674190066755

full batch src global  1597
full batch dst global  60
full batch train ------ loss 0.00018760483362711966

full batch src global  1579
full batch dst global  60
full batch train ------ loss 0.00025106396060436964

full batch src global  1579
full batch dst global  60
full batch train ------ loss 0.00014529198233503848

full batch src global  1587
full batch dst global  60
full batch train ------ loss 0.0002772962034214288

full batch src global  1581
full batch dst global  60
full batch train ------ loss 0.0002478218812029809

full batch src global  1598
full batch dst global  60
full batch train ------ loss 0.0002954048977699131

full batch src global  1593
full batch dst global  60
full batch train ------ loss 0.0003120452456641942

full batch src global  1604
full batch dst global  60
full batch train ------ loss 0.00016712026263121516

full batch src global  1595
full batch dst global  60
full batch train ------ loss 0.0004062627849634737

full batch src global  1599
full batch dst global  60
full batch train ------ loss 0.0002113859518431127

full batch src global  1601
full batch dst global  60
full batch train ------ loss 0.0001929048157762736

full batch src global  1596
full batch dst global  60
full batch train ------ loss 0.0001838239695644006

full batch src global  1595
full batch dst global  60
full batch train ------ loss 0.00018451512733008713

full batch src global  1601
full batch dst global  60
full batch train ------ loss 0.00021875112724956125

full batch src global  1585
full batch dst global  60
full batch train ------ loss 0.0008064669091254473

full batch src global  1598
full batch dst global  60
full batch train ------ loss 0.00025441416073590517

full batch src global  1600
full batch dst global  60
full batch train ------ loss 0.00027751020388677716

full batch src global  1579
full batch dst global  60
full batch train ------ loss 0.00027248807600699365

full batch src global  1597
full batch dst global  60
full batch train ------ loss 0.00021214406297076494

full batch src global  1612
full batch dst global  60
full batch train ------ loss 0.00019153095490764827

full batch src global  1596
full batch dst global  60
full batch train ------ loss 0.00023487958242185414

full batch src global  1609
full batch dst global  60
full batch train ------ loss 0.00020427178242243826

full batch src global  1581
full batch dst global  60
full batch train ------ loss 0.000258068524999544

full batch src global  1600
full batch dst global  60
full batch train ------ loss 0.00032561513944528997

full batch src global  1593
full batch dst global  60
full batch train ------ loss 0.00019242514099460095

full batch src global  1577
full batch dst global  60
full batch train ------ loss 0.0001819154858822003

full batch src global  1587
full batch dst global  60
full batch train ------ loss 0.00019857917504850775

full batch src global  1578
full batch dst global  60
full batch train ------ loss 0.00013074130401946604

full batch src global  1572
full batch dst global  60
full batch train ------ loss 0.00026747086667455733

full batch src global  1567
full batch dst global  60
full batch train ------ loss 0.00014511612243950367

full batch src global  1581
full batch dst global  60
full batch train ------ loss 0.0002343579544685781

full batch src global  1593
full batch dst global  60
full batch train ------ loss 0.00023409271670971066

full batch src global  1601
full batch dst global  60
full batch train ------ loss 0.0001661913120187819

full batch src global  1582
full batch dst global  60
full batch train ------ loss 0.00013399469025898725

full batch src global  1595
full batch dst global  60
full batch train ------ loss 0.000147111204569228

full batch src global  1560
full batch dst global  60
full batch train ------ loss 0.00017411990847904235

full batch src global  1585
full batch dst global  60
full batch train ------ loss 0.00020496579236350954

full batch src global  1572
full batch dst global  60
full batch train ------ loss 0.000150323859998025

full batch src global  1607
full batch dst global  60
full batch train ------ loss 0.00025104175438173115

full batch src global  1593
full batch dst global  60
full batch train ------ loss 0.00037266919389367104

full batch src global  1587
full batch dst global  60
full batch train ------ loss 0.00024464173475280404

full batch src global  1568
full batch dst global  60
full batch train ------ loss 0.00019661242549773306

full batch src global  1614
full batch dst global  60
full batch train ------ loss 0.00017733866116032004

full batch src global  1605
full batch dst global  60
full batch train ------ loss 0.0001473866868764162

full batch src global  1593
full batch dst global  60
full batch train ------ loss 0.00015556214202661067

full batch src global  1603
full batch dst global  60
full batch train ------ loss 0.00015053036622703075

full batch src global  1605
full batch dst global  60
full batch train ------ loss 0.00022487439855467528

full batch src global  1613
full batch dst global  60
full batch train ------ loss 0.00023905010311864316

full batch src global  1572
full batch dst global  60
full batch train ------ loss 0.00023224804317578673

full batch src global  1584
full batch dst global  60
full batch train ------ loss 0.00015605700900778174

end to end time  0.09952545166015625
Total (block generation + training)time/epoch 0.09952545166015625
pure train time per /epoch  []
pure train time average  nan
input num list  []
