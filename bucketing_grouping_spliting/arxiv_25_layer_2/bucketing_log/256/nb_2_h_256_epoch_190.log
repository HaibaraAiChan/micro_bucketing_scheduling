main start at this time 1691117996.8526456
-----------------------------------------before load data 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

----------------------------------------start of run function 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0009732246398925781
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014512062072753906
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5543606281280518
len local_batched_seeds_list  2
partition total batch output list spend :  0.6407897472381592
self.buckets_partition() spend  sec:  0.568906307220459
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.06036972999572754

in edges time spent  0.15885686874389648
local to global src and eids time spent  0.2744884490966797
time gen tails  0.05174565315246582
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.10385417938232422

in edges time spent  0.40256738662719727
local to global src and eids time spent  0.5760502815246582
time gen tails  0.08118557929992676
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.529296875 GB
    Memory Allocated: 0.08729362487792969  GigaBytes
Max Memory Allocated: 0.08729362487792969  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 15.095703125 GB
    Memory Allocated: 12.835214138031006  GigaBytes
Max Memory Allocated: 13.296953678131104  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 15.095703125 GB
    Memory Allocated: 12.843029499053955  GigaBytes
Max Memory Allocated: 13.296953678131104  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 15.857421875 GB
    Memory Allocated: 0.10744524002075195  GigaBytes
Max Memory Allocated: 13.296953678131104  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 18.49609375 GB
    Memory Allocated: 12.043825149536133  GigaBytes
Max Memory Allocated: 13.296953678131104  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 18.49609375 GB
    Memory Allocated: 12.049562931060791  GigaBytes
Max Memory Allocated: 13.296953678131104  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 19.171875 GB
    Memory Allocated: 0.12422370910644531  GigaBytes
Max Memory Allocated: 13.296953678131104  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.8353219032287598
pure train time :  0.9373157024383545
train time :  1.6280033588409424
end to end time :  5.243255138397217
connection check time:  1.9504764080047607
block generation time  1.0019636154174805
Run 00 | Epoch 00000 | Loss 3.8353 | Test 0.0431
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004711151123046875
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014827966690063477
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5586888790130615
len local_batched_seeds_list  2
partition total batch output list spend :  0.6452994346618652
self.buckets_partition() spend  sec:  0.5735561847686768
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05312204360961914

in edges time spent  0.15582990646362305
local to global src and eids time spent  0.2717282772064209
time gen tails  0.05370688438415527
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09323573112487793

in edges time spent  0.4129185676574707
local to global src and eids time spent  0.5783548355102539
time gen tails  0.08327674865722656
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.77734375 GB
    Memory Allocated: 0.11103200912475586  GigaBytes
Max Memory Allocated: 13.296953678131104  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.77734375 GB
    Memory Allocated: 12.873152256011963  GigaBytes
Max Memory Allocated: 13.339655876159668  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.77734375 GB
    Memory Allocated: 12.871847152709961  GigaBytes
Max Memory Allocated: 13.339655876159668  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.77734375 GB
    Memory Allocated: 0.1132512092590332  GigaBytes
Max Memory Allocated: 13.339655876159668  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 12.001291275024414  GigaBytes
Max Memory Allocated: 13.339655876159668  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 12.007225513458252  GigaBytes
Max Memory Allocated: 13.339655876159668  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 0.1244969367980957  GigaBytes
Max Memory Allocated: 13.339655876159668  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.576540470123291
pure train time :  0.4364163875579834
train time :  0.6111078262329102
end to end time :  4.254804611206055
connection check time:  1.9437496662139893
block generation time  1.0314977169036865
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004699230194091797
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014614343643188477
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.513361930847168
len local_batched_seeds_list  2
partition total batch output list spend :  0.5998473167419434
self.buckets_partition() spend  sec:  0.5280108451843262
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05372500419616699

in edges time spent  0.1583099365234375
local to global src and eids time spent  0.2722434997558594
time gen tails  0.05376482009887695
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.10031008720397949

in edges time spent  0.370833158493042
local to global src and eids time spent  0.5598165988922119
time gen tails  0.08240628242492676
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 0.11066150665283203  GigaBytes
Max Memory Allocated: 13.339655876159668  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 12.877851486206055  GigaBytes
Max Memory Allocated: 13.344621658325195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 12.876373291015625  GigaBytes
Max Memory Allocated: 13.344621658325195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 0.11208057403564453  GigaBytes
Max Memory Allocated: 13.344621658325195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 12.048143863677979  GigaBytes
Max Memory Allocated: 13.344621658325195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 12.053881645202637  GigaBytes
Max Memory Allocated: 13.344621658325195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 0.1230921745300293  GigaBytes
Max Memory Allocated: 13.344621658325195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.365786075592041
pure train time :  0.43570375442504883
train time :  0.5934779644012451
end to end time :  4.086489677429199
connection check time:  1.8895573616027832
block generation time  0.9857072830200195
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004658699035644531
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014177560806274414
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.515470027923584
len local_batched_seeds_list  2
partition total batch output list spend :  0.6022322177886963
self.buckets_partition() spend  sec:  0.5296859741210938
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05405068397521973

in edges time spent  0.15677809715270996
local to global src and eids time spent  0.2700209617614746
time gen tails  0.052881479263305664
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09638762474060059

in edges time spent  0.3703775405883789
local to global src and eids time spent  0.5627655982971191
time gen tails  0.08224368095397949
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 0.11053037643432617  GigaBytes
Max Memory Allocated: 13.344621658325195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 12.870700359344482  GigaBytes
Max Memory Allocated: 13.344621658325195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 12.869604587554932  GigaBytes
Max Memory Allocated: 13.344621658325195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 0.11269187927246094  GigaBytes
Max Memory Allocated: 13.344621658325195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 12.04412317276001  GigaBytes
Max Memory Allocated: 13.344621658325195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 12.049860954284668  GigaBytes
Max Memory Allocated: 13.344621658325195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 0.12363767623901367  GigaBytes
Max Memory Allocated: 13.344621658325195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.2180991172790527
pure train time :  0.4412200450897217
train time :  0.5995547771453857
end to end time :  4.077130556106567
connection check time:  1.8830554485321045
block generation time  0.9767296314239502
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004687309265136719
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01407766342163086
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4107706546783447
len local_batched_seeds_list  2
partition total batch output list spend :  0.4976511001586914
self.buckets_partition() spend  sec:  0.42496323585510254
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05426454544067383

in edges time spent  0.1567554473876953
local to global src and eids time spent  0.2720918655395508
time gen tails  0.053861141204833984
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0969841480255127

in edges time spent  0.3765859603881836
local to global src and eids time spent  0.5785946846008301
time gen tails  0.08187532424926758
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 0.11040544509887695  GigaBytes
Max Memory Allocated: 13.344621658325195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 12.87832260131836  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 12.87712287902832  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 0.11255931854248047  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 12.041742324829102  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 12.04767656326294  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 0.12357091903686523  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.171693801879883
pure train time :  0.42919111251831055
train time :  0.5863306522369385
end to end time :  3.9918389320373535
connection check time:  1.9091670513153076
block generation time  0.9820184707641602
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0005016326904296875
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014307737350463867
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4855527877807617
len local_batched_seeds_list  2
partition total batch output list spend :  0.572037935256958
self.buckets_partition() spend  sec:  0.4998917579650879
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.053696632385253906

in edges time spent  0.15514516830444336
local to global src and eids time spent  0.2677617073059082
time gen tails  0.05312156677246094
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0908961296081543

in edges time spent  0.3723611831665039
local to global src and eids time spent  0.5583274364471436
time gen tails  0.08230328559875488
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 0.11145734786987305  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 12.867652416229248  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 12.866392612457275  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 0.11199283599853516  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 12.031390190124512  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 12.03732442855835  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 19.783203125 GB
    Memory Allocated: 0.12375974655151367  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.1217188835144043
pure train time :  0.4404599666595459
train time :  0.6002435684204102
end to end time :  4.0377068519592285
connection check time:  1.86983060836792
block generation time  0.9795322418212891
Run 00 | Epoch 00005 | Loss 3.1217 | Test 0.2334
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004947185516357422
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014629125595092773
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5332577228546143
len local_batched_seeds_list  2
partition total batch output list spend :  0.6200017929077148
self.buckets_partition() spend  sec:  0.5479249954223633
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05356121063232422

in edges time spent  0.16055536270141602
local to global src and eids time spent  0.2739522457122803
time gen tails  0.05375051498413086
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09940361976623535

in edges time spent  0.39440083503723145
local to global src and eids time spent  0.5757930278778076
time gen tails  0.0831298828125
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 0.1110835075378418  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.864743709564209  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.86288833618164  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 0.1130518913269043  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.028894901275635  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.034632682800293  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 0.12415313720703125  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.055438995361328
pure train time :  0.4369010925292969
train time :  0.6050441265106201
end to end time :  4.1978232860565186
connection check time:  1.9374802112579346
block generation time  1.0163049697875977
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004553794860839844
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014377593994140625
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.49875593185424805
len local_batched_seeds_list  2
partition total batch output list spend :  0.5862715244293213
self.buckets_partition() spend  sec:  0.5131690502166748
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05389761924743652

in edges time spent  0.1581895351409912
local to global src and eids time spent  0.2725973129272461
time gen tails  0.05388283729553223
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09209895133972168

in edges time spent  0.38205838203430176
local to global src and eids time spent  0.5713248252868652
time gen tails  0.08368825912475586
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 0.11173629760742188  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.872557163238525  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.87083387374878  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 0.11265182495117188  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.049520492553711  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.05525827407837  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 0.12389802932739258  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 3.0042266845703125
pure train time :  0.4342215061187744
train time :  0.5931954383850098
end to end time :  4.108985662460327
connection check time:  1.9115104675292969
block generation time  1.0019545555114746
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004131793975830078
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014155149459838867
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5025944709777832
len local_batched_seeds_list  2
partition total batch output list spend :  0.5894324779510498
self.buckets_partition() spend  sec:  0.5167949199676514
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05407905578613281

in edges time spent  0.15674686431884766
local to global src and eids time spent  0.2739369869232178
time gen tails  0.05358433723449707
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0885934829711914

in edges time spent  0.37500762939453125
local to global src and eids time spent  0.5689804553985596
time gen tails  0.08359861373901367
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 0.11069631576538086  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.871510982513428  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.870020389556885  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 0.11199808120727539  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.034597396850586  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.040335178375244  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 0.12324333190917969  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.959336280822754
pure train time :  0.4364759922027588
train time :  0.595186710357666
end to end time :  4.1023149490356445
connection check time:  1.8974127769470215
block generation time  1.0043957233428955
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004894733428955078
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015915870666503906
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5165479183197021
len local_batched_seeds_list  2
partition total batch output list spend :  0.6049368381500244
self.buckets_partition() spend  sec:  0.5325710773468018
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05440711975097656

in edges time spent  0.16034817695617676
local to global src and eids time spent  0.2717020511627197
time gen tails  0.0539546012878418
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09195709228515625

in edges time spent  0.378246545791626
local to global src and eids time spent  0.5766212940216064
time gen tails  0.08614206314086914
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 0.11034965515136719  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.874707221984863  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.873539924621582  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 0.11317110061645508  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.03540563583374  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.041143417358398  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 0.1241464614868164  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.911900758743286
pure train time :  0.4342992305755615
train time :  0.6037094593048096
end to end time :  4.1544084548950195
connection check time:  1.9222660064697266
block generation time  1.0058867931365967
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004715919494628906
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014263629913330078
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5052368640899658
len local_batched_seeds_list  2
partition total batch output list spend :  0.5917725563049316
self.buckets_partition() spend  sec:  0.5195326805114746
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05378317832946777

in edges time spent  0.15771055221557617
local to global src and eids time spent  0.2730424404144287
time gen tails  0.05458879470825195
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09812235832214355

in edges time spent  0.3740835189819336
local to global src and eids time spent  0.5677974224090576
time gen tails  0.08353447914123535
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 0.11087179183959961  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.873257160186768  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.871572494506836  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 0.1128997802734375  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.048340797424316  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 12.054078578948975  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 20.392578125 GB
    Memory Allocated: 0.12391042709350586  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.866450071334839
pure train time :  0.446483850479126
train time :  0.6204042434692383
end to end time :  4.130720853805542
connection check time:  1.9071533679962158
block generation time  0.9900617599487305
Run 00 | Epoch 00010 | Loss 2.8665 | Test 0.2739
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0005893707275390625
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015338659286499023
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5586831569671631
len local_batched_seeds_list  2
partition total batch output list spend :  0.6459696292877197
self.buckets_partition() spend  sec:  0.5740647315979004
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05437612533569336

in edges time spent  0.1615285873413086
local to global src and eids time spent  0.2711489200592041
time gen tails  0.05353426933288574
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08612918853759766

in edges time spent  0.39453721046447754
local to global src and eids time spent  0.5671944618225098
time gen tails  0.0823514461517334
res  length 2
block collection to dataloader spend  1.1682510375976562e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11147928237915039  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.87436294555664  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.873117446899414  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11243581771850586  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.000667095184326  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.006404876708984  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12357044219970703  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.813866138458252
pure train time :  0.43598151206970215
train time :  0.605950117111206
end to end time :  4.171520471572876
connection check time:  1.906534194946289
block generation time  0.9935970306396484
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004684925079345703
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01482534408569336
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5204918384552002
len local_batched_seeds_list  2
partition total batch output list spend :  0.6071305274963379
self.buckets_partition() spend  sec:  0.5353507995605469
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05334877967834473

in edges time spent  0.15795397758483887
local to global src and eids time spent  0.270397424697876
time gen tails  0.05330920219421387
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09066033363342285

in edges time spent  0.37575626373291016
local to global src and eids time spent  0.5633957386016846
time gen tails  0.08218693733215332
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11061954498291016  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.836342334747314  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.83492374420166  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11243247985839844  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.043667316436768  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.049405097961426  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12348604202270508  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.7587950229644775
pure train time :  0.43492746353149414
train time :  0.5935518741607666
end to end time :  4.084681987762451
connection check time:  1.883739948272705
block generation time  0.9841930866241455
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004131793975830078
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014630794525146484
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5107951164245605
len local_batched_seeds_list  2
partition total batch output list spend :  0.5971691608428955
self.buckets_partition() spend  sec:  0.5254645347595215
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.053488969802856445

in edges time spent  0.1539607048034668
local to global src and eids time spent  0.26207637786865234
time gen tails  0.0518949031829834
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08867669105529785

in edges time spent  0.3681807518005371
local to global src and eids time spent  0.5566074848175049
time gen tails  0.0823063850402832
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11147212982177734  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.869791030883789  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.868496894836426  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11250495910644531  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.005393028259277  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.011130809783936  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12359189987182617  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.7018516063690186
pure train time :  0.4384584426879883
train time :  0.6065406799316406
end to end time :  4.021858215332031
connection check time:  1.849442720413208
block generation time  0.9539375305175781
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.000446319580078125
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01433873176574707
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4879176616668701
len local_batched_seeds_list  2
partition total batch output list spend :  0.5739998817443848
self.buckets_partition() spend  sec:  0.5023670196533203
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0559847354888916

in edges time spent  0.16289591789245605
local to global src and eids time spent  0.2785494327545166
time gen tails  0.0563051700592041
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09060239791870117

in edges time spent  0.3999183177947998
local to global src and eids time spent  0.5719485282897949
time gen tails  0.08604907989501953
res  length 2
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11152887344360352  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.869319915771484  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.86796522140503  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11233711242675781  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.043107032775879  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.048844814300537  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12384271621704102  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.653123617172241
pure train time :  0.43987369537353516
train time :  0.6152167320251465
end to end time :  4.140426874160767
connection check time:  1.9464466571807861
block generation time  0.9877481460571289
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0005412101745605469
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014794111251831055
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.38674211502075195
len local_batched_seeds_list  2
partition total batch output list spend :  0.4720163345336914
self.buckets_partition() spend  sec:  0.40157341957092285
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0618281364440918

in edges time spent  0.1578686237335205
local to global src and eids time spent  0.2647073268890381
time gen tails  0.05232691764831543
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09897923469543457

in edges time spent  0.3734922409057617
local to global src and eids time spent  0.5564277172088623
time gen tails  0.08303093910217285
res  length 2
block collection to dataloader spend  6.4373016357421875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11078596115112305  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.869791507720947  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.868198871612549  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11304569244384766  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.013118743896484  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.018856525421143  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12401819229125977  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.603689670562744
pure train time :  0.423492431640625
train time :  0.5851175785064697
end to end time :  3.742082357406616
connection check time:  1.8651807308197021
block generation time  0.8051087856292725
Run 00 | Epoch 00015 | Loss 2.6037 | Test 0.2995
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.000507354736328125
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015291213989257812
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.23110365867614746
len local_batched_seeds_list  2
partition total batch output list spend :  0.2702751159667969
self.buckets_partition() spend  sec:  0.24642348289489746
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0339813232421875

in edges time spent  0.0838327407836914
local to global src and eids time spent  0.11175036430358887
time gen tails  0.03198361396789551
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0564570426940918

in edges time spent  0.19039511680603027
local to global src and eids time spent  0.23342633247375488
time gen tails  0.04839897155761719
res  length 2
block collection to dataloader spend  6.4373016357421875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11187601089477539  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.873698234558105  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.87208890914917  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11240243911743164  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.035154342651367  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.040892124176025  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12342643737792969  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.5479276180267334
pure train time :  0.43236517906188965
train time :  0.5932018756866455
end to end time :  2.483206272125244
connection check time:  0.8987751007080078
block generation time  0.7077639102935791
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004658699035644531
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014298439025878906
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.3835182189941406
len local_batched_seeds_list  2
partition total batch output list spend :  0.46871495246887207
self.buckets_partition() spend  sec:  0.39785170555114746
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05357670783996582

in edges time spent  0.1520092487335205
local to global src and eids time spent  0.2592000961303711
time gen tails  0.05198168754577637
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0844886302947998

in edges time spent  0.36404895782470703
local to global src and eids time spent  0.5374181270599365
time gen tails  0.0803384780883789
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11089611053466797  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.832715034484863  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.831454753875732  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11313390731811523  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.046050548553467  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.051788330078125  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12417840957641602  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.4930572509765625
pure train time :  0.4383053779602051
train time :  0.6026840209960938
end to end time :  3.864588737487793
connection check time:  1.8157167434692383
block generation time  0.9616334438323975
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004360675811767578
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01364588737487793
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.48107028007507324
len local_batched_seeds_list  2
partition total batch output list spend :  0.566408634185791
self.buckets_partition() spend  sec:  0.4947514533996582
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05377340316772461

in edges time spent  0.15690016746520996
local to global src and eids time spent  0.26938366889953613
time gen tails  0.05307269096374512
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0912165641784668

in edges time spent  0.36875057220458984
local to global src and eids time spent  0.5572049617767334
time gen tails  0.08234858512878418
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11034774780273438  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.873573780059814  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.872446060180664  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11266422271728516  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.04565143585205  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.051389217376709  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12388849258422852  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.4457015991210938
pure train time :  0.43100738525390625
train time :  0.5913736820220947
end to end time :  4.024293661117554
connection check time:  1.8750712871551514
block generation time  0.9753541946411133
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00046133995056152344
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01412343978881836
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4883232116699219
len local_batched_seeds_list  2
partition total batch output list spend :  0.5742607116699219
self.buckets_partition() spend  sec:  0.5025601387023926
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05423569679260254

in edges time spent  0.1568775177001953
local to global src and eids time spent  0.26905107498168945
time gen tails  0.053217411041259766
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09445381164550781

in edges time spent  0.37331366539001465
local to global src and eids time spent  0.5620632171630859
time gen tails  0.08306574821472168
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11061906814575195  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.87038278579712  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.869203567504883  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11272096633911133  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.031535625457764  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.037273406982422  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.1237936019897461  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.409451723098755
pure train time :  0.4402134418487549
train time :  0.605553150177002
end to end time :  4.064401865005493
connection check time:  1.8911397457122803
block generation time  0.9790077209472656
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0005307197570800781
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.02272939682006836
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5047125816345215
len local_batched_seeds_list  2
partition total batch output list spend :  0.5997281074523926
self.buckets_partition() spend  sec:  0.5274734497070312
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.053765296936035156

in edges time spent  0.1639423370361328
local to global src and eids time spent  0.27187037467956543
time gen tails  0.053505659103393555
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09682774543762207

in edges time spent  0.4003269672393799
local to global src and eids time spent  0.5783288478851318
time gen tails  0.08356499671936035
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.1104440689086914  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.868887901306152  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.867653846740723  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11255407333374023  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.032242774963379  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.037980556488037  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12363433837890625  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.3669466972351074
pure train time :  0.4338340759277344
train time :  0.6046807765960693
end to end time :  4.147862911224365
connection check time:  1.9447073936462402
block generation time  0.9838626384735107
Run 00 | Epoch 00020 | Loss 2.3669 | Test 0.4597
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00042724609375
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014180660247802734
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5389418601989746
len local_batched_seeds_list  2
partition total batch output list spend :  0.624802827835083
self.buckets_partition() spend  sec:  0.5531585216522217
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05360293388366699

in edges time spent  0.1582050323486328
local to global src and eids time spent  0.2180624008178711
time gen tails  0.03953266143798828
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08531427383422852

in edges time spent  0.38506531715393066
local to global src and eids time spent  0.5697240829467773
time gen tails  0.08372902870178223
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11105060577392578  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.871798515319824  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.87055492401123  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.1136775016784668  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.006539344787598  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.012473583221436  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.1247396469116211  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.331059455871582
pure train time :  0.43392229080200195
train time :  0.5940098762512207
end to end time :  4.050379514694214
connection check time:  1.8349030017852783
block generation time  0.9794456958770752
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00043845176696777344
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014264345169067383
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.49550771713256836
len local_batched_seeds_list  2
partition total batch output list spend :  0.5812981128692627
self.buckets_partition() spend  sec:  0.5098047256469727
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05403852462768555

in edges time spent  0.1561880111694336
local to global src and eids time spent  0.2620372772216797
time gen tails  0.052262306213378906
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08895015716552734

in edges time spent  0.3834037780761719
local to global src and eids time spent  0.5634164810180664
time gen tails  0.08165764808654785
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11115217208862305  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.873049259185791  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.87109088897705  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11317205429077148  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.001434803009033  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.007369041442871  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.1245870590209961  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.290559768676758
pure train time :  0.4381732940673828
train time :  0.6020543575286865
end to end time :  4.047597885131836
connection check time:  1.880307674407959
block generation time  0.9692459106445312
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00047135353088378906
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01415109634399414
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5081827640533447
len local_batched_seeds_list  2
partition total batch output list spend :  0.5943312644958496
self.buckets_partition() spend  sec:  0.522371768951416
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.053583621978759766

in edges time spent  0.15604090690612793
local to global src and eids time spent  0.2621011734008789
time gen tails  0.05260610580444336
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0856013298034668

in edges time spent  0.3811655044555664
local to global src and eids time spent  0.5545158386230469
time gen tails  0.08078193664550781
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.1115264892578125  GigaBytes
Max Memory Allocated: 13.345080375671387  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.878799438476562  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.876469135284424  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11251020431518555  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 11.996920108795166  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.002657890319824  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12397575378417969  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.2576658725738525
pure train time :  0.4355337619781494
train time :  0.5995118618011475
end to end time :  4.0189478397369385
connection check time:  1.8584909439086914
block generation time  0.9472341537475586
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00046324729919433594
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01569056510925293
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4980027675628662
len local_batched_seeds_list  2
partition total batch output list spend :  0.5847444534301758
self.buckets_partition() spend  sec:  0.5138087272644043
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05289769172668457

in edges time spent  0.16000866889953613
local to global src and eids time spent  0.2691786289215088
time gen tails  0.05245637893676758
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09473967552185059

in edges time spent  0.39879679679870605
local to global src and eids time spent  0.5674951076507568
time gen tails  0.08251714706420898
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11144399642944336  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.862999439239502  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.861260414123535  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11345481872558594  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.044404029846191  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.05014181137085  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12456655502319336  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.2143659591674805
pure train time :  0.43029260635375977
train time :  0.600902795791626
end to end time :  4.1003618240356445
connection check time:  1.9159579277038574
block generation time  0.9780902862548828
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00043582916259765625
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.02187347412109375
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.47995829582214355
len local_batched_seeds_list  2
partition total batch output list spend :  0.5325205326080322
self.buckets_partition() spend  sec:  0.5018651485443115
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04273271560668945

in edges time spent  0.14872097969055176
local to global src and eids time spent  0.2665274143218994
time gen tails  0.05214738845825195
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09343194961547852

in edges time spent  0.37889790534973145
local to global src and eids time spent  0.5586247444152832
time gen tails  0.0798799991607666
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11112785339355469  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.87519359588623  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.873839378356934  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.1129302978515625  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.005881786346436  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.011619567871094  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12417459487915039  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.176328182220459
pure train time :  0.43430638313293457
train time :  0.5978999137878418
end to end time :  3.969940185546875
connection check time:  1.849844217300415
block generation time  0.9714186191558838
Run 00 | Epoch 00025 | Loss 2.1763 | Test 0.4628
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0003902912139892578
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013139009475708008
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.25462770462036133
len local_batched_seeds_list  2
partition total batch output list spend :  0.29172611236572266
self.buckets_partition() spend  sec:  0.26779723167419434
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.03499960899353027

in edges time spent  0.08124470710754395
local to global src and eids time spent  0.11177849769592285
time gen tails  0.03222537040710449
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0637819766998291

in edges time spent  0.3788154125213623
local to global src and eids time spent  0.55025315284729
time gen tails  0.08069062232971191
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11078071594238281  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.87275218963623  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.871413707733154  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11243247985839844  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.043657779693604  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.049395561218262  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12346410751342773  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.139796257019043
pure train time :  0.43373632431030273
train time :  0.5983843803405762
end to end time :  3.328068494796753
connection check time:  1.524526596069336
block generation time  0.8998827934265137
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.000438690185546875
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.016980409622192383
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.47849225997924805
len local_batched_seeds_list  2
partition total batch output list spend :  0.5257878303527832
self.buckets_partition() spend  sec:  0.49550509452819824
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04266619682312012

in edges time spent  0.14980196952819824
local to global src and eids time spent  0.26870226860046387
time gen tails  0.0534360408782959
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08638238906860352

in edges time spent  0.38106584548950195
local to global src and eids time spent  0.5615930557250977
time gen tails  0.08223509788513184
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11074590682983398  GigaBytes
Max Memory Allocated: 13.345406532287598  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.880389213562012  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.879111289978027  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.1122736930847168  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.008055686950684  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.013793468475342  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12334823608398438  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.096005439758301
pure train time :  0.43839263916015625
train time :  0.6011340618133545
end to end time :  3.990321397781372
connection check time:  1.8642969131469727
block generation time  0.981987476348877
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004353523254394531
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015303850173950195
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.38970017433166504
len local_batched_seeds_list  2
partition total batch output list spend :  0.4361598491668701
self.buckets_partition() spend  sec:  0.4050440788269043
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04304981231689453

in edges time spent  0.14927148818969727
local to global src and eids time spent  0.2674238681793213
time gen tails  0.05313277244567871
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08604836463928223

in edges time spent  0.3761301040649414
local to global src and eids time spent  0.564295768737793
time gen tails  0.08173918724060059
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.1105046272277832  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.844183921813965  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.842843532562256  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11252355575561523  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.049971103668213  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.055708885192871  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.1237325668334961  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.0574896335601807
pure train time :  0.4380686283111572
train time :  0.602327823638916
end to end time :  3.893277406692505
connection check time:  1.859349250793457
block generation time  0.9757671356201172
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004715919494628906
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014048576354980469
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4958629608154297
len local_batched_seeds_list  2
partition total batch output list spend :  0.582064151763916
self.buckets_partition() spend  sec:  0.5100252628326416
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05396556854248047

in edges time spent  0.1553056240081787
local to global src and eids time spent  0.26757049560546875
time gen tails  0.05313992500305176
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09148287773132324

in edges time spent  0.37694263458251953
local to global src and eids time spent  0.5619921684265137
time gen tails  0.08185696601867676
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11083173751831055  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.872608184814453  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.87117052078247  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11266803741455078  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.03549575805664  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.041233539581299  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12363672256469727  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 2.0214669704437256
pure train time :  0.4269835948944092
train time :  0.5862338542938232
end to end time :  4.0419762134552
connection check time:  1.8822684288024902
block generation time  0.9716992378234863
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004553794860839844
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014073848724365234
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4962043762207031
len local_batched_seeds_list  2
partition total batch output list spend :  0.5821523666381836
self.buckets_partition() spend  sec:  0.5103194713592529
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05441641807556152

in edges time spent  0.1551964282989502
local to global src and eids time spent  0.26663661003112793
time gen tails  0.05317187309265137
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09102272987365723

in edges time spent  0.3755338191986084
local to global src and eids time spent  0.565711259841919
time gen tails  0.08556985855102539
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11040306091308594  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.870599746704102  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.869380950927734  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11239004135131836  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.006147861480713  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.011885643005371  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12432384490966797  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.991490125656128
pure train time :  0.4366927146911621
train time :  0.5999302864074707
end to end time :  4.073171854019165
connection check time:  1.891937255859375
block generation time  0.9786860942840576
Run 00 | Epoch 00030 | Loss 1.9915 | Test 0.4545
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004677772521972656
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014120817184448242
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5512237548828125
len local_batched_seeds_list  2
partition total batch output list spend :  0.6379475593566895
self.buckets_partition() spend  sec:  0.565382719039917
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05351614952087402

in edges time spent  0.16171622276306152
local to global src and eids time spent  0.27201151847839355
time gen tails  0.05258655548095703
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08890056610107422

in edges time spent  0.39560770988464355
local to global src and eids time spent  0.5469114780426025
time gen tails  0.0811007022857666
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11142921447753906  GigaBytes
Max Memory Allocated: 13.34745454788208  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.881929874420166  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.88007402420044  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11256122589111328  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.01787519454956  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.023612976074219  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12374353408813477  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.950847864151001
pure train time :  0.43580079078674316
train time :  0.6042332649230957
end to end time :  4.1061742305755615
connection check time:  1.8817293643951416
block generation time  0.9625494480133057
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00044846534729003906
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014168500900268555
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.49960756301879883
len local_batched_seeds_list  2
partition total batch output list spend :  0.5857388973236084
self.buckets_partition() spend  sec:  0.5138089656829834
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05253481864929199

in edges time spent  0.15113544464111328
local to global src and eids time spent  0.26196908950805664
time gen tails  0.05250191688537598
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08801579475402832

in edges time spent  0.3698432445526123
local to global src and eids time spent  0.5483081340789795
time gen tails  0.08048248291015625
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11089611053466797  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.880423069000244  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.87898063659668  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11237192153930664  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.005104064941406  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.011038303375244  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12353515625  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.9256863594055176
pure train time :  0.42649006843566895
train time :  0.5870316028594971
end to end time :  3.9689793586730957
connection check time:  1.8337056636810303
block generation time  0.9444715976715088
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004253387451171875
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014364957809448242
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5054187774658203
len local_batched_seeds_list  2
partition total batch output list spend :  0.5914638042449951
self.buckets_partition() spend  sec:  0.5198192596435547
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.053992271423339844

in edges time spent  0.1551225185394287
local to global src and eids time spent  0.2637150287628174
time gen tails  0.05202531814575195
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08823132514953613

in edges time spent  0.375410795211792
local to global src and eids time spent  0.5410699844360352
time gen tails  0.08012151718139648
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11060953140258789  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.871811866760254  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.87037706375122  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11336040496826172  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.050261497497559  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.055999279022217  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12439870834350586  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.8919514417648315
pure train time :  0.438995361328125
train time :  0.6031451225280762
end to end time :  3.9909937381744385
connection check time:  1.8383615016937256
block generation time  0.9415028095245361
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004391670227050781
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014519214630126953
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.50803542137146
len local_batched_seeds_list  2
partition total batch output list spend :  0.5942769050598145
self.buckets_partition() spend  sec:  0.5226671695709229
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.052672624588012695

in edges time spent  0.1498734951019287
local to global src and eids time spent  0.2647864818572998
time gen tails  0.05339670181274414
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0879509449005127

in edges time spent  0.3762693405151367
local to global src and eids time spent  0.5508630275726318
time gen tails  0.08008074760437012
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11135435104370117  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.874354362487793  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.872435569763184  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11332845687866211  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.034624576568604  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.040362358093262  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12427711486816406  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.8547120094299316
pure train time :  0.43501949310302734
train time :  0.5943465232849121
end to end time :  3.991546154022217
connection check time:  1.8476626873016357
block generation time  0.9410285949707031
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004589557647705078
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014541149139404297
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5113060474395752
len local_batched_seeds_list  2
partition total batch output list spend :  0.5981976985931396
self.buckets_partition() spend  sec:  0.5258824825286865
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05267024040222168

in edges time spent  0.15111970901489258
local to global src and eids time spent  0.2603154182434082
time gen tails  0.05245685577392578
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09579658508300781

in edges time spent  0.3710465431213379
local to global src and eids time spent  0.5351073741912842
time gen tails  0.08088397979736328
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11155843734741211  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.8729829788208  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.871156215667725  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11337089538574219  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.04477071762085  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.050508499145508  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12449884414672852  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.834351897239685
pure train time :  0.4292004108428955
train time :  0.5928158760070801
end to end time :  3.991584300994873
connection check time:  1.8276207447052002
block generation time  0.9557688236236572
Run 00 | Epoch 00035 | Loss 1.8344 | Test 0.4902
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004467964172363281
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014745712280273438
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5523881912231445
len local_batched_seeds_list  2
partition total batch output list spend :  0.6383304595947266
self.buckets_partition() spend  sec:  0.5671725273132324
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0539090633392334

in edges time spent  0.1647796630859375
local to global src and eids time spent  0.26708340644836426
time gen tails  0.05217313766479492
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0857384204864502

in edges time spent  0.3937802314758301
local to global src and eids time spent  0.5602321624755859
time gen tails  0.08057522773742676
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11098241806030273  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.874699115753174  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.873482704162598  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11306524276733398  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.004321575164795  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.010059356689453  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12408256530761719  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.800771713256836
pure train time :  0.4303121566772461
train time :  0.6034595966339111
end to end time :  4.110104560852051
connection check time:  1.8896758556365967
block generation time  0.9606237411499023
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00045561790466308594
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014096498489379883
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5032553672790527
len local_batched_seeds_list  2
partition total batch output list spend :  0.5898303985595703
self.buckets_partition() spend  sec:  0.5173854827880859
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0530242919921875

in edges time spent  0.1558208465576172
local to global src and eids time spent  0.26525115966796875
time gen tails  0.052039384841918945
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08580565452575684

in edges time spent  0.364516019821167
local to global src and eids time spent  0.5349161624908447
time gen tails  0.08014702796936035
res  length 2
block collection to dataloader spend  9.775161743164062e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11058187484741211  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.871317386627197  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.870202541351318  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11302900314331055  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.044955253601074  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.050889492034912  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12401485443115234  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.7742213010787964
pure train time :  0.43883371353149414
train time :  0.6026749610900879
end to end time :  3.9755308628082275
connection check time:  1.8212807178497314
block generation time  0.9435327053070068
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004305839538574219
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014119148254394531
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5019104480743408
len local_batched_seeds_list  2
partition total batch output list spend :  0.5877118110656738
self.buckets_partition() spend  sec:  0.5160701274871826
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05340313911437988

in edges time spent  0.15126848220825195
local to global src and eids time spent  0.2583198547363281
time gen tails  0.052082061767578125
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08813714981079102

in edges time spent  0.3785262107849121
local to global src and eids time spent  0.5503849983215332
time gen tails  0.08036279678344727
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11062002182006836  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.874420642852783  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.873194694519043  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.1128387451171875  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.047416687011719  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.053350925445557  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12386178970336914  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.7517077922821045
pure train time :  0.4350442886352539
train time :  0.5936908721923828
end to end time :  3.9859516620635986
connection check time:  1.8426151275634766
block generation time  0.945624828338623
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004565715789794922
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014203548431396484
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4149012565612793
len local_batched_seeds_list  2
partition total batch output list spend :  0.5015590190887451
self.buckets_partition() spend  sec:  0.4292278289794922
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.053272247314453125

in edges time spent  0.15145325660705566
local to global src and eids time spent  0.25978994369506836
time gen tails  0.052219390869140625
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08814096450805664

in edges time spent  0.37341809272766113
local to global src and eids time spent  0.5474319458007812
time gen tails  0.07993125915527344
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11133050918579102  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.874234676361084  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.872327327728271  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11307573318481445  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.044950485229492  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.05068826675415  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12420940399169922  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.7282541990280151
pure train time :  0.4375627040863037
train time :  0.5976018905639648
end to end time :  3.894231081008911
connection check time:  1.8349151611328125
block generation time  0.942183256149292
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00045871734619140625
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013550043106079102
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4645113945007324
len local_batched_seeds_list  2
partition total batch output list spend :  0.5481753349304199
self.buckets_partition() spend  sec:  0.47809290885925293
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05263066291809082

in edges time spent  0.1508173942565918
local to global src and eids time spent  0.25958728790283203
time gen tails  0.05218791961669922
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09509086608886719

in edges time spent  0.3732144832611084
local to global src and eids time spent  0.554710865020752
time gen tails  0.08049488067626953
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11146688461303711  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.87276315689087  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.870735168457031  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11285638809204102  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.043434143066406  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.049368381500244  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12392425537109375  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.703871488571167
pure train time :  0.4353947639465332
train time :  0.5922598838806152
end to end time :  3.9472458362579346
connection check time:  1.8479526042938232
block generation time  0.9420149326324463
Run 00 | Epoch 00040 | Loss 1.7039 | Test 0.5140
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004241466522216797
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014331817626953125
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4888138771057129
len local_batched_seeds_list  2
partition total batch output list spend :  0.5748980045318604
self.buckets_partition() spend  sec:  0.5031797885894775
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0545353889465332

in edges time spent  0.16229677200317383
local to global src and eids time spent  0.27328062057495117
time gen tails  0.05354714393615723
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09537148475646973

in edges time spent  0.3868978023529053
local to global src and eids time spent  0.5648574829101562
time gen tails  0.08235883712768555
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11072587966918945  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.872968196868896  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.871636390686035  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11281919479370117  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.03499460220337  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.040732383728027  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.1238393783569336  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.6804465055465698
pure train time :  0.4353058338165283
train time :  0.6124167442321777
end to end time :  4.105967998504639
connection check time:  1.912442684173584
block generation time  0.9851095676422119
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004267692565917969
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014025449752807617
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5018627643585205
len local_batched_seeds_list  2
partition total batch output list spend :  0.5881142616271973
self.buckets_partition() spend  sec:  0.5159211158752441
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.054824113845825195

in edges time spent  0.15497255325317383
local to global src and eids time spent  0.2615647315979004
time gen tails  0.0520939826965332
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08844971656799316

in edges time spent  0.37895965576171875
local to global src and eids time spent  0.5559930801391602
time gen tails  0.08048534393310547
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11065912246704102  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.878162384033203  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.876902103424072  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11254692077636719  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.041261672973633  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.04719591140747  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12363386154174805  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.6578081846237183
pure train time :  0.436509370803833
train time :  0.5938637256622314
end to end time :  4.001353979110718
connection check time:  1.8555092811584473
block generation time  0.944523811340332
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004343986511230469
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013965368270874023
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.46905970573425293
len local_batched_seeds_list  2
partition total batch output list spend :  0.5537765026092529
self.buckets_partition() spend  sec:  0.48305797576904297
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05364394187927246

in edges time spent  0.15484976768493652
local to global src and eids time spent  0.26767945289611816
time gen tails  0.05330610275268555
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08794498443603516

in edges time spent  0.376384973526001
local to global src and eids time spent  0.5532550811767578
time gen tails  0.07995843887329102
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.1105337142944336  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.8748779296875  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.87353229522705  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11257219314575195  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.043962478637695  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.049700260162354  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.1241464614868164  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.6338179111480713
pure train time :  0.4309697151184082
train time :  0.5880570411682129
end to end time :  3.9680349826812744
connection check time:  1.8585174083709717
block generation time  0.9491181373596191
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004334449768066406
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013840913772583008
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.47310733795166016
len local_batched_seeds_list  2
partition total batch output list spend :  0.5566074848175049
self.buckets_partition() spend  sec:  0.4870588779449463
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05232429504394531

in edges time spent  0.15168285369873047
local to global src and eids time spent  0.2601325511932373
time gen tails  0.05207467079162598
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08863282203674316

in edges time spent  0.3779747486114502
local to global src and eids time spent  0.5553402900695801
time gen tails  0.0805349349975586
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11121606826782227  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.845415592193604  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.843595504760742  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11248302459716797  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.034486293792725  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.040224075317383  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12354516983032227  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.6173925399780273
pure train time :  0.4273221492767334
train time :  0.5863914489746094
end to end time :  3.948903799057007
connection check time:  1.846350908279419
block generation time  0.9416236877441406
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00048613548278808594
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.019076108932495117
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4996623992919922
len local_batched_seeds_list  2
partition total batch output list spend :  0.5896918773651123
self.buckets_partition() spend  sec:  0.5187718868255615
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05332231521606445

in edges time spent  0.15144801139831543
local to global src and eids time spent  0.2621285915374756
time gen tails  0.05237722396850586
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08671784400939941

in edges time spent  0.37593913078308105
local to global src and eids time spent  0.5405189990997314
time gen tails  0.08007049560546875
res  length 2
block collection to dataloader spend  1.3828277587890625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11051082611083984  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.871542930603027  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.870238304138184  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11226606369018555  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.015447616577148  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.021185398101807  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.1234893798828125  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.6001497507095337
pure train time :  0.43912720680236816
train time :  0.6035363674163818
end to end time :  3.9887681007385254
connection check time:  1.830617904663086
block generation time  0.9455914497375488
Run 00 | Epoch 00045 | Loss 1.6001 | Test 0.5214
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00042510032653808594
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014437198638916016
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5137009620666504
len local_batched_seeds_list  2
partition total batch output list spend :  0.5996742248535156
self.buckets_partition() spend  sec:  0.5281736850738525
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05349564552307129

in edges time spent  0.16598939895629883
local to global src and eids time spent  0.2747986316680908
time gen tails  0.05318784713745117
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09130620956420898

in edges time spent  0.39058446884155273
local to global src and eids time spent  0.5938410758972168
time gen tails  0.08228158950805664
res  length 2
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11066865921020508  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.873587608337402  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.87244176864624  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.1129302978515625  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.034332275390625  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.040070056915283  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12404680252075195  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.5865615606307983
pure train time :  0.44075703620910645
train time :  0.6113805770874023
end to end time :  4.1596174240112305
connection check time:  1.9517664909362793
block generation time  0.9810492992401123
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004417896270751953
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014367341995239258
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5134367942810059
len local_batched_seeds_list  2
partition total batch output list spend :  0.5999295711517334
self.buckets_partition() spend  sec:  0.5278387069702148
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05468106269836426

in edges time spent  0.1581439971923828
local to global src and eids time spent  0.2707021236419678
time gen tails  0.053138017654418945
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09138607978820801

in edges time spent  0.38710904121398926
local to global src and eids time spent  0.5748991966247559
time gen tails  0.08233094215393066
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11051321029663086  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.835543632507324  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.834194660186768  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11276674270629883  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.048469066619873  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.054206848144531  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12372493743896484  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.564974308013916
pure train time :  0.4402034282684326
train time :  0.6007568836212158
end to end time :  4.111331462860107
connection check time:  1.9113693237304688
block generation time  0.9824368953704834
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004944801330566406
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014209508895874023
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5411384105682373
len local_batched_seeds_list  2
partition total batch output list spend :  0.627204179763794
self.buckets_partition() spend  sec:  0.555391788482666
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0536954402923584

in edges time spent  0.15521574020385742
local to global src and eids time spent  0.26726722717285156
time gen tails  0.05324745178222656
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09000515937805176

in edges time spent  0.37502193450927734
local to global src and eids time spent  0.5659091472625732
time gen tails  0.08252358436584473
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11020565032958984  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.87041711807251  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.86939001083374  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11268281936645508  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.030791759490967  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.036529541015625  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12392807006835938  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.5456669330596924
pure train time :  0.4384012222290039
train time :  0.5989761352539062
end to end time :  4.102806329727173
connection check time:  1.8813166618347168
block generation time  0.9802412986755371
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004603862762451172
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014264583587646484
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5143113136291504
len local_batched_seeds_list  2
partition total batch output list spend :  0.6006512641906738
self.buckets_partition() spend  sec:  0.5286853313446045
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05355572700500488

in edges time spent  0.15528655052185059
local to global src and eids time spent  0.26777100563049316
time gen tails  0.05345654487609863
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09252333641052246

in edges time spent  0.3762378692626953
local to global src and eids time spent  0.5625863075256348
time gen tails  0.08195614814758301
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11110305786132812  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.875002384185791  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.87367296218872  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11319494247436523  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.045726299285889  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.051464080810547  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.12418174743652344  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.5335195064544678
pure train time :  0.43866634368896484
train time :  0.6038234233856201
end to end time :  4.091650009155273
connection check time:  1.8815979957580566
block generation time  0.9896271228790283
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00046825408935546875
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015666961669921875
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.3901028633117676
len local_batched_seeds_list  2
partition total batch output list spend :  0.4368433952331543
self.buckets_partition() spend  sec:  0.4058043956756592
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04330277442932129

in edges time spent  0.14884495735168457
local to global src and eids time spent  0.26715898513793945
time gen tails  0.05329179763793945
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09372973442077637

in edges time spent  0.3703000545501709
local to global src and eids time spent  0.5625619888305664
time gen tails  0.08215832710266113
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11042308807373047  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.871161460876465  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.8699951171875  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.11275196075439453  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.016458511352539  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 12.022196292877197  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.0078125 GB
    Memory Allocated: 0.1235957145690918  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.516054630279541
pure train time :  0.4406001567840576
train time :  0.6082355976104736
end to end time :  3.8973376750946045
connection check time:  1.8561882972717285
block generation time  0.9771146774291992
Run 00 | Epoch 00050 | Loss 1.5161 | Test 0.5493
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00043201446533203125
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015556812286376953
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.40947604179382324
len local_batched_seeds_list  2
partition total batch output list spend :  0.4970364570617676
self.buckets_partition() spend  sec:  0.425067663192749
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05457496643066406

in edges time spent  0.1593916416168213
local to global src and eids time spent  0.27403736114501953
time gen tails  0.05391979217529297
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08971929550170898

in edges time spent  0.3750910758972168
local to global src and eids time spent  0.5614056587219238
time gen tails  0.08202934265136719
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.1105794906616211  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.872484683990479  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.871159076690674  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.1130223274230957  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.047069549560547  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.052807331085205  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.1239614486694336  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.503830909729004
pure train time :  0.42919445037841797
train time :  0.5872035026550293
end to end time :  3.968126058578491
connection check time:  1.8887414932250977
block generation time  0.9802799224853516
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004603862762451172
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013859748840332031
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4798407554626465
len local_batched_seeds_list  2
partition total batch output list spend :  0.5656239986419678
self.buckets_partition() spend  sec:  0.49373292922973633
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.053907155990600586

in edges time spent  0.15564417839050293
local to global src and eids time spent  0.27321600914001465
time gen tails  0.05582761764526367
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08612680435180664

in edges time spent  0.38597774505615234
local to global src and eids time spent  0.5599038600921631
time gen tails  0.08272838592529297
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11093282699584961  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.871772766113281  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.870262622833252  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11244678497314453  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.046854019165039  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.052591800689697  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12342405319213867  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.489872694015503
pure train time :  0.4366331100463867
train time :  0.5958786010742188
end to end time :  4.048273086547852
connection check time:  1.891596794128418
block generation time  0.9778392314910889
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00047087669372558594
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01392674446105957
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.49769091606140137
len local_batched_seeds_list  2
partition total batch output list spend :  0.5835978984832764
self.buckets_partition() spend  sec:  0.5116548538208008
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05423426628112793

in edges time spent  0.15953302383422852
local to global src and eids time spent  0.2700197696685791
time gen tails  0.053322792053222656
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09190940856933594

in edges time spent  0.3922593593597412
local to global src and eids time spent  0.5652492046356201
time gen tails  0.08239173889160156
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.1103978157043457  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.874567031860352  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.873351573944092  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11252164840698242  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.045068740844727  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.051002979278564  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12354278564453125  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4738585948944092
pure train time :  0.4395608901977539
train time :  0.6025490760803223
end to end time :  4.084474802017212
connection check time:  1.907522201538086
block generation time  0.9752275943756104
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004649162292480469
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01538848876953125
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5032603740692139
len local_batched_seeds_list  2
partition total batch output list spend :  0.5906596183776855
self.buckets_partition() spend  sec:  0.5187642574310303
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05376863479614258

in edges time spent  0.15558171272277832
local to global src and eids time spent  0.2651076316833496
time gen tails  0.05201077461242676
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0932321548461914

in edges time spent  0.3570699691772461
local to global src and eids time spent  0.5376226902008057
time gen tails  0.08814358711242676
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.1105351448059082  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.873966217041016  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.872693061828613  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11229133605957031  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.041096687316895  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.047030925750732  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.1237187385559082  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4588282108306885
pure train time :  0.4343140125274658
train time :  0.5898733139038086
end to end time :  3.971672534942627
connection check time:  1.8295800685882568
block generation time  0.9417190551757812
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004825592041015625
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014173507690429688
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4724884033203125
len local_batched_seeds_list  2
partition total batch output list spend :  0.5572810173034668
self.buckets_partition() spend  sec:  0.4866933822631836
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05331015586853027

in edges time spent  0.15120911598205566
local to global src and eids time spent  0.2579667568206787
time gen tails  0.05225539207458496
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09378314018249512

in edges time spent  0.3728165626525879
local to global src and eids time spent  0.5507502555847168
time gen tails  0.08091545104980469
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11089563369750977  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.875004291534424  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.87365436553955  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11284780502319336  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 11.999669551849365  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.005407333374023  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12395000457763672  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.453210473060608
pure train time :  0.43646836280822754
train time :  0.6128270626068115
end to end time :  3.9981942176818848
connection check time:  1.8437941074371338
block generation time  0.965895414352417
Run 00 | Epoch 00055 | Loss 1.4532 | Test 0.5815
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0005042552947998047
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013854265213012695
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5037341117858887
len local_batched_seeds_list  2
partition total batch output list spend :  0.5882320404052734
self.buckets_partition() spend  sec:  0.5176236629486084
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05361199378967285

in edges time spent  0.15172266960144043
local to global src and eids time spent  0.26212573051452637
time gen tails  0.05243182182312012
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08872556686401367

in edges time spent  0.3793060779571533
local to global src and eids time spent  0.563723087310791
time gen tails  0.08244752883911133
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11057662963867188  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.872172832489014  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.870792865753174  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11226367950439453  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.042716979980469  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.048651218414307  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12323236465454102  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4376440048217773
pure train time :  0.43640995025634766
train time :  0.6011748313903809
end to end time :  4.053150177001953
connection check time:  1.8691582679748535
block generation time  0.9772400856018066
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004699230194091797
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01412200927734375
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.49392175674438477
len local_batched_seeds_list  2
partition total batch output list spend :  0.5798699855804443
self.buckets_partition() spend  sec:  0.508075475692749
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05371356010437012

in edges time spent  0.15557193756103516
local to global src and eids time spent  0.26514768600463867
time gen tails  0.05237412452697754
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08849334716796875

in edges time spent  0.374530553817749
local to global src and eids time spent  0.5497643947601318
time gen tails  0.0804445743560791
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.1102590560913086  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.877301692962646  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.876242637634277  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11319637298583984  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.005954265594482  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.01169204711914  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12435197830200195  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4282433986663818
pure train time :  0.43758678436279297
train time :  0.5953576564788818
end to end time :  3.982456684112549
connection check time:  1.847607135772705
block generation time  0.9433286190032959
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00047135353088378906
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014023065567016602
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5129821300506592
len local_batched_seeds_list  2
partition total batch output list spend :  0.5993714332580566
self.buckets_partition() spend  sec:  0.5270450115203857
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05450916290283203

in edges time spent  0.15523672103881836
local to global src and eids time spent  0.26779770851135254
time gen tails  0.05316281318664551
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0912008285522461

in edges time spent  0.3795907497406006
local to global src and eids time spent  0.5493819713592529
time gen tails  0.08030962944030762
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.1121969223022461  GigaBytes
Max Memory Allocated: 13.348543643951416  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.882655620574951  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.880727291107178  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11269760131835938  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.004589557647705  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.010327339172363  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12403154373168945  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.4143354892730713
pure train time :  0.43111586570739746
train time :  0.5920207500457764
end to end time :  4.028313398361206
connection check time:  1.8630294799804688
block generation time  0.9578182697296143
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004897117614746094
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014248371124267578
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5136144161224365
len local_batched_seeds_list  2
partition total batch output list spend :  0.5999963283538818
self.buckets_partition() spend  sec:  0.5279731750488281
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.052703857421875

in edges time spent  0.15145349502563477
local to global src and eids time spent  0.2587149143218994
time gen tails  0.05202174186706543
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08811712265014648

in edges time spent  0.3756752014160156
local to global src and eids time spent  0.5540807247161865
time gen tails  0.08252906799316406
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11063671112060547  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.838449478149414  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.83716344833374  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11299514770507812  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.049209594726562  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.05494737625122  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12383222579956055  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.409787893295288
pure train time :  0.4368133544921875
train time :  0.5950379371643066
end to end time :  4.02589225769043
connection check time:  1.8500690460205078
block generation time  0.9675817489624023
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00043487548828125
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014693021774291992
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5154116153717041
len local_batched_seeds_list  2
partition total batch output list spend :  0.6025612354278564
self.buckets_partition() spend  sec:  0.530137300491333
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0538485050201416

in edges time spent  0.1517167091369629
local to global src and eids time spent  0.25901031494140625
time gen tails  0.05233597755432129
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09088277816772461

in edges time spent  0.37981581687927246
local to global src and eids time spent  0.5516848564147949
time gen tails  0.07983636856079102
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11145305633544922  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.87192440032959  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.870484352111816  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11293506622314453  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.005188941955566  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.010926723480225  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12428998947143555  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3978586196899414
pure train time :  0.42768096923828125
train time :  0.5850813388824463
end to end time :  3.9936060905456543
connection check time:  1.847322940826416
block generation time  0.9448714256286621
Run 00 | Epoch 00060 | Loss 1.3979 | Test 0.5991
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0006206035614013672
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01390385627746582
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5288028717041016
len local_batched_seeds_list  2
partition total batch output list spend :  0.6149539947509766
self.buckets_partition() spend  sec:  0.5427422523498535
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.054502010345458984

in edges time spent  0.1602647304534912
local to global src and eids time spent  0.2694206237792969
time gen tails  0.05297398567199707
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08693313598632812

in edges time spent  0.37357449531555176
local to global src and eids time spent  0.513951301574707
time gen tails  0.059710025787353516
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11083650588989258  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.87194538116455  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.87033462524414  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11236333847045898  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.044744491577148  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.050482273101807  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.1235809326171875  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3880302906036377
pure train time :  0.43944764137268066
train time :  0.599137544631958
end to end time :  4.009324312210083
connection check time:  1.8078384399414062
block generation time  0.9692423343658447
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00046443939208984375
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015389442443847656
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.3901336193084717
len local_batched_seeds_list  2
partition total batch output list spend :  0.4370734691619873
self.buckets_partition() spend  sec:  0.40555548667907715
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04366636276245117

in edges time spent  0.14464950561523438
local to global src and eids time spent  0.2670934200286865
time gen tails  0.053334951400756836
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08643150329589844

in edges time spent  0.3841545581817627
local to global src and eids time spent  0.5617461204528809
time gen tails  0.08250308036804199
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11032915115356445  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.870397567749023  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.869258403778076  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11287879943847656  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.035033702850342  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.040771484375  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12375164031982422  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3766334056854248
pure train time :  0.43975830078125
train time :  0.6009187698364258
end to end time :  3.8898892402648926
connection check time:  1.8586881160736084
block generation time  0.9772124290466309
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004277229309082031
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014055967330932617
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4964590072631836
len local_batched_seeds_list  2
partition total batch output list spend :  0.5828647613525391
self.buckets_partition() spend  sec:  0.5105540752410889
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05454826354980469

in edges time spent  0.15460777282714844
local to global src and eids time spent  0.2676982879638672
time gen tails  0.05332231521606445
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09227824211120605

in edges time spent  0.3861863613128662
local to global src and eids time spent  0.5628588199615479
time gen tails  0.08524417877197266
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11130857467651367  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.872256755828857  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.870831489562988  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11327838897705078  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.028920650482178  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.034658432006836  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12419414520263672  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3697459697723389
pure train time :  0.4390227794647217
train time :  0.6076903343200684
end to end time :  4.087966203689575
connection check time:  1.8995742797851562
block generation time  0.9802305698394775
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00044536590576171875
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014101505279541016
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5018332004547119
len local_batched_seeds_list  2
partition total batch output list spend :  0.5881178379058838
self.buckets_partition() spend  sec:  0.5160455703735352
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05343747138977051

in edges time spent  0.15780019760131836
local to global src and eids time spent  0.26769208908081055
time gen tails  0.05339193344116211
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08664798736572266

in edges time spent  0.3896341323852539
local to global src and eids time spent  0.5729429721832275
time gen tails  0.08242321014404297
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11056375503540039  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.87118148803711  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.870011806488037  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11273050308227539  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.044189929962158  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.049927711486816  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12377643585205078  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3607110977172852
pure train time :  0.4408588409423828
train time :  0.6063361167907715
end to end time :  4.089571952819824
connection check time:  1.901304006576538
block generation time  0.9766645431518555
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004382133483886719
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014078855514526367
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4928581714630127
len local_batched_seeds_list  2
partition total batch output list spend :  0.5784111022949219
self.buckets_partition() spend  sec:  0.506969690322876
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05335879325866699

in edges time spent  0.1546032428741455
local to global src and eids time spent  0.2672605514526367
time gen tails  0.05347132682800293
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09112668037414551

in edges time spent  0.3718092441558838
local to global src and eids time spent  0.5557460784912109
time gen tails  0.08283853530883789
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11074018478393555  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.87645959854126  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.87516164779663  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11356353759765625  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.051843166351318  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.057580947875977  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.1236882209777832  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.353516936302185
pure train time :  0.4322049617767334
train time :  0.5933873653411865
end to end time :  4.0327653884887695
connection check time:  1.8683576583862305
block generation time  0.9748990535736084
Run 00 | Epoch 00065 | Loss 1.3535 | Test 0.6008
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00046825408935546875
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014003276824951172
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5264420509338379
len local_batched_seeds_list  2
partition total batch output list spend :  0.6118338108062744
self.buckets_partition() spend  sec:  0.5404813289642334
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0548858642578125

in edges time spent  0.15616345405578613
local to global src and eids time spent  0.27073240280151367
time gen tails  0.053812265396118164
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09147095680236816

in edges time spent  0.37496447563171387
local to global src and eids time spent  0.5607552528381348
time gen tails  0.0823965072631836
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11017513275146484  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.871588706970215  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.87056016921997  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11247825622558594  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.043424606323242  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.0491623878479  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12349271774291992  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3432707786560059
pure train time :  0.4383361339569092
train time :  0.6107561588287354
end to end time :  4.103602170944214
connection check time:  1.882080316543579
block generation time  0.9842088222503662
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00041031837463378906
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013882160186767578
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5065402984619141
len local_batched_seeds_list  2
partition total batch output list spend :  0.592557430267334
self.buckets_partition() spend  sec:  0.5204558372497559
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05397319793701172

in edges time spent  0.15417051315307617
local to global src and eids time spent  0.26725316047668457
time gen tails  0.05340409278869629
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08876252174377441

in edges time spent  0.3740248680114746
local to global src and eids time spent  0.5612339973449707
time gen tails  0.08199071884155273
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11084318161010742  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.86733102798462  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.86623239517212  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11380577087402344  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.032417297363281  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.03835153579712  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12484121322631836  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3345763683319092
pure train time :  0.42934274673461914
train time :  0.586672306060791
end to end time :  4.03961443901062
connection check time:  1.8723359107971191
block generation time  0.9698519706726074
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00042819976806640625
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014075994491577148
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5112969875335693
len local_batched_seeds_list  2
partition total batch output list spend :  0.5982558727264404
self.buckets_partition() spend  sec:  0.5254123210906982
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.053800344467163086

in edges time spent  0.15540027618408203
local to global src and eids time spent  0.2687036991119385
time gen tails  0.053316354751586914
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0926809310913086

in edges time spent  0.37590909004211426
local to global src and eids time spent  0.5632452964782715
time gen tails  0.08223891258239746
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.1111297607421875  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.876943111419678  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.875007629394531  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11224699020385742  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.013228416442871  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.019162654876709  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12339115142822266  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3254756927490234
pure train time :  0.436312198638916
train time :  0.594595193862915
end to end time :  4.06809663772583
connection check time:  1.8828134536743164
block generation time  0.9767541885375977
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004477500915527344
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01427149772644043
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5102214813232422
len local_batched_seeds_list  2
partition total batch output list spend :  0.5966522693634033
self.buckets_partition() spend  sec:  0.5246071815490723
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05429816246032715

in edges time spent  0.1547701358795166
local to global src and eids time spent  0.2689223289489746
time gen tails  0.05352640151977539
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08597278594970703

in edges time spent  0.37950634956359863
local to global src and eids time spent  0.5578963756561279
time gen tails  0.08196711540222168
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11041784286499023  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.874826431274414  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.873587131500244  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11269474029541016  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.04292106628418  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.048658847808838  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12425565719604492  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3242077827453613
pure train time :  0.438617467880249
train time :  0.6016337871551514
end to end time :  4.063822984695435
connection check time:  1.8740060329437256
block generation time  0.9771037101745605
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004630088806152344
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014301538467407227
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5039165019989014
len local_batched_seeds_list  2
partition total batch output list spend :  0.5900933742523193
self.buckets_partition() spend  sec:  0.5182504653930664
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05352282524108887

in edges time spent  0.1549515724182129
local to global src and eids time spent  0.26758360862731934
time gen tails  0.053226470947265625
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09148406982421875

in edges time spent  0.3765523433685303
local to global src and eids time spent  0.5623042583465576
time gen tails  0.08235049247741699
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.1119389533996582  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.871602058410645  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.869956016540527  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11442375183105469  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.04652214050293  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.052259922027588  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12617254257202148  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3100852966308594
pure train time :  0.42767786979675293
train time :  0.5845520496368408
end to end time :  4.043707609176636
connection check time:  1.879223346710205
block generation time  0.9755010604858398
Run 00 | Epoch 00070 | Loss 1.3101 | Test 0.6136
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004436969757080078
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01517796516418457
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5043966770172119
len local_batched_seeds_list  2
partition total batch output list spend :  0.5910100936889648
self.buckets_partition() spend  sec:  0.5196094512939453
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05457425117492676

in edges time spent  0.16435790061950684
local to global src and eids time spent  0.26807594299316406
time gen tails  0.05375051498413086
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09120464324951172

in edges time spent  0.41413235664367676
local to global src and eids time spent  0.5756139755249023
time gen tails  0.08267831802368164
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11180305480957031  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.870574951171875  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.86814022064209  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.1127004623413086  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.029439926147461  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.03517770767212  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12388086318969727  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.3037300109863281
pure train time :  0.43032288551330566
train time :  0.5889461040496826
end to end time :  4.119010925292969
connection check time:  1.9417378902435303
block generation time  0.9798867702484131
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.000457763671875
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014346599578857422
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5155491828918457
len local_batched_seeds_list  2
partition total batch output list spend :  0.6018280982971191
self.buckets_partition() spend  sec:  0.52992844581604
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05464768409729004

in edges time spent  0.15693306922912598
local to global src and eids time spent  0.26984596252441406
time gen tails  0.053237199783325195
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09141874313354492

in edges time spent  0.3791942596435547
local to global src and eids time spent  0.5604331493377686
time gen tails  0.08263826370239258
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11081695556640625  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.872030258178711  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.870607376098633  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.1134796142578125  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.0195894241333  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.025327205657959  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12423372268676758  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.296714425086975
pure train time :  0.43203186988830566
train time :  0.5874831676483154
end to end time :  4.071969032287598
connection check time:  1.8852341175079346
block generation time  0.9791252613067627
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00044417381286621094
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013829231262207031
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.38403797149658203
len local_batched_seeds_list  2
partition total batch output list spend :  0.46752333641052246
self.buckets_partition() spend  sec:  0.39791107177734375
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05259275436401367

in edges time spent  0.15418052673339844
local to global src and eids time spent  0.2594430446624756
time gen tails  0.05257558822631836
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08896279335021973

in edges time spent  0.3765733242034912
local to global src and eids time spent  0.5555019378662109
time gen tails  0.08066272735595703
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11107492446899414  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.868573665618896  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.86689567565918  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11250877380371094  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.016042709350586  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.021780490875244  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12367868423461914  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2925922870635986
pure train time :  0.43749260902404785
train time :  0.5954270362854004
end to end time :  3.88142466545105
connection check time:  1.8472235202789307
block generation time  0.9570248126983643
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00044846534729003906
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014398813247680664
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4840571880340576
len local_batched_seeds_list  2
partition total batch output list spend :  0.5700886249542236
self.buckets_partition() spend  sec:  0.4986119270324707
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.053804874420166016

in edges time spent  0.1531362533569336
local to global src and eids time spent  0.25932765007019043
time gen tails  0.05241107940673828
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08825206756591797

in edges time spent  0.37325549125671387
local to global src and eids time spent  0.5470459461212158
time gen tails  0.08052587509155273
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11025094985961914  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.873570919036865  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.872581005096436  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11243057250976562  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.013281345367432  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.01901912689209  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12337255477905273  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2916698455810547
pure train time :  0.4343574047088623
train time :  0.5899953842163086
end to end time :  3.949754238128662
connection check time:  1.8343236446380615
block generation time  0.9388258457183838
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004715919494628906
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014133214950561523
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.48763084411621094
len local_batched_seeds_list  2
partition total batch output list spend :  0.5732765197753906
self.buckets_partition() spend  sec:  0.5017955303192139
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.054615020751953125

in edges time spent  0.15028071403503418
local to global src and eids time spent  0.25994277000427246
time gen tails  0.052167415618896484
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09709453582763672

in edges time spent  0.3698081970214844
local to global src and eids time spent  0.5458908081054688
time gen tails  0.08092546463012695
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.1107931137084961  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.875975608825684  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.874937534332275  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11301326751708984  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.046159267425537  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.051897048950195  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12405920028686523  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.279841423034668
pure train time :  0.42666196823120117
train time :  0.592559814453125
end to end time :  3.9675159454345703
connection check time:  1.849501609802246
block generation time  0.9390289783477783
Run 00 | Epoch 00075 | Loss 1.2798 | Test 0.6162
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004608631134033203
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014005184173583984
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5244884490966797
len local_batched_seeds_list  2
partition total batch output list spend :  0.6101138591766357
self.buckets_partition() spend  sec:  0.5385308265686035
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0549311637878418

in edges time spent  0.15140819549560547
local to global src and eids time spent  0.263416051864624
time gen tails  0.05252361297607422
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08963823318481445

in edges time spent  0.3757805824279785
local to global src and eids time spent  0.5511808395385742
time gen tails  0.08070015907287598
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11038446426391602  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.871374607086182  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.870165824890137  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11269760131835938  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.040046215057373  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.045980453491211  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12407350540161133  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2756688594818115
pure train time :  0.4381837844848633
train time :  0.5978116989135742
end to end time :  4.025125980377197
connection check time:  1.8471293449401855
block generation time  0.9520237445831299
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004334449768066406
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014087915420532227
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4709439277648926
len local_batched_seeds_list  2
partition total batch output list spend :  0.5557701587677002
self.buckets_partition() spend  sec:  0.4850635528564453
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05285811424255371

in edges time spent  0.15142583847045898
local to global src and eids time spent  0.2624330520629883
time gen tails  0.052806854248046875
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08803892135620117

in edges time spent  0.3742072582244873
local to global src and eids time spent  0.54799485206604
time gen tails  0.08009815216064453
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.110992431640625  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.876528263092041  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.875006198883057  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11264991760253906  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 11.994571685791016  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.000505924224854  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.1241307258605957  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.269112229347229
pure train time :  0.4375779628753662
train time :  0.5927388668060303
end to end time :  3.946587085723877
connection check time:  1.8369569778442383
block generation time  0.9428203105926514
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004394054412841797
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014376163482666016
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5048291683197021
len local_batched_seeds_list  2
partition total batch output list spend :  0.5909695625305176
self.buckets_partition() spend  sec:  0.5192420482635498
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05400824546813965

in edges time spent  0.15501809120178223
local to global src and eids time spent  0.2674422264099121
time gen tails  0.053594350814819336
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08564376831054688

in edges time spent  0.374373197555542
local to global src and eids time spent  0.5520930290222168
time gen tails  0.08013725280761719
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11075067520141602  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.873914241790771  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.87247085571289  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11252307891845703  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.047557830810547  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.053295612335205  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12345075607299805  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2638132572174072
pure train time :  0.42914843559265137
train time :  0.5837771892547607
end to end time :  3.9933807849884033
connection check time:  1.851879596710205
block generation time  0.9528720378875732
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00044465065002441406
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014206409454345703
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4968702793121338
len local_batched_seeds_list  2
partition total batch output list spend :  0.58286452293396
self.buckets_partition() spend  sec:  0.5111870765686035
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.052937984466552734

in edges time spent  0.15193986892700195
local to global src and eids time spent  0.2595832347869873
time gen tails  0.05249905586242676
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08338451385498047

in edges time spent  0.3708832263946533
local to global src and eids time spent  0.5385739803314209
time gen tails  0.08021807670593262
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.1107931137084961  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.87952995300293  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.878526210784912  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11311006546020508  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.033788204193115  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.039525985717773  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.1240692138671875  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.257591962814331
pure train time :  0.42647624015808105
train time :  0.5849752426147461
end to end time :  3.93784236907959
connection check time:  1.8162422180175781
block generation time  0.9405577182769775
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00046539306640625
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014182090759277344
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4775736331939697
len local_batched_seeds_list  2
partition total batch output list spend :  0.5623345375061035
self.buckets_partition() spend  sec:  0.4917900562286377
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.053513526916503906

in edges time spent  0.1511540412902832
local to global src and eids time spent  0.2600884437561035
time gen tails  0.05258512496948242
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08293485641479492

in edges time spent  0.3751993179321289
local to global src and eids time spent  0.5451478958129883
time gen tails  0.08001017570495605
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11048316955566406  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.872689723968506  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.871400833129883  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.11291170120239258  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.042938232421875  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 21.625 GB
    Memory Allocated: 12.048872470855713  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 21.625 GB
    Memory Allocated: 0.12379741668701172  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2557775974273682
pure train time :  0.42717981338500977
train time :  0.5843546390533447
end to end time :  3.926565647125244
connection check time:  1.8264009952545166
block generation time  0.9397165775299072
Run 00 | Epoch 00080 | Loss 1.2558 | Test 0.6223
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00047087669372558594
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013816356658935547
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4988365173339844
len local_batched_seeds_list  2
partition total batch output list spend :  0.5845787525177002
self.buckets_partition() spend  sec:  0.5126855373382568
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0546414852142334

in edges time spent  0.15651392936706543
local to global src and eids time spent  0.2671830654144287
time gen tails  0.053444623947143555
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09192132949829102

in edges time spent  0.3781900405883789
local to global src and eids time spent  0.5641772747039795
time gen tails  0.08316922187805176
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11055994033813477  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.870400428771973  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.869027614593506  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.1125636100769043  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.047292232513428  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.053030014038086  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.12405872344970703  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.249354362487793
pure train time :  0.42657899856567383
train time :  0.5854623317718506
end to end time :  4.049123287200928
connection check time:  1.8860893249511719
block generation time  0.9760849475860596
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00048232078552246094
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014392852783203125
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.502016544342041
len local_batched_seeds_list  2
partition total batch output list spend :  0.5882744789123535
self.buckets_partition() spend  sec:  0.5164422988891602
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.053846120834350586

in edges time spent  0.15514540672302246
local to global src and eids time spent  0.2680013179779053
time gen tails  0.053258657455444336
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09108829498291016

in edges time spent  0.3817253112792969
local to global src and eids time spent  0.562105655670166
time gen tails  0.08231782913208008
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.1115121841430664  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.872936248779297  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.871201038360596  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11304283142089844  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.048846244812012  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.05458402633667  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.12394380569458008  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2395439147949219
pure train time :  0.43604063987731934
train time :  0.5932619571685791
end to end time :  4.057163953781128
connection check time:  1.884509563446045
block generation time  0.9774038791656494
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004646778106689453
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014255523681640625
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5147714614868164
len local_batched_seeds_list  2
partition total batch output list spend :  0.6008234024047852
self.buckets_partition() spend  sec:  0.5290675163269043
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05407977104187012

in edges time spent  0.1553187370300293
local to global src and eids time spent  0.26775074005126953
time gen tails  0.053319454193115234
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08645796775817871

in edges time spent  0.3835015296936035
local to global src and eids time spent  0.5621569156646729
time gen tails  0.08170533180236816
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11070060729980469  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.874447345733643  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.87346601486206  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11316251754760742  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.049567699432373  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.055305480957031  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.12426376342773438  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2354531288146973
pure train time :  0.4385874271392822
train time :  0.5983033180236816
end to end time :  4.071249008178711
connection check time:  1.8810224533081055
block generation time  0.9767868518829346
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004608631134033203
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014201641082763672
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.41443705558776855
len local_batched_seeds_list  2
partition total batch output list spend :  0.5006985664367676
self.buckets_partition() spend  sec:  0.4287536144256592
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.054416656494140625

in edges time spent  0.15564370155334473
local to global src and eids time spent  0.26712512969970703
time gen tails  0.05342245101928711
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09273409843444824

in edges time spent  0.38134050369262695
local to global src and eids time spent  0.5524477958679199
time gen tails  0.08022499084472656
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.1107797622680664  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.873920917510986  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.872579097747803  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11239147186279297  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 11.997269630432129  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.003007411956787  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.12396764755249023  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2309558391571045
pure train time :  0.4379305839538574
train time :  0.5935513973236084
end to end time :  3.9543957710266113
connection check time:  1.8683595657348633
block generation time  0.9752066135406494
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004363059997558594
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01429605484008789
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.49762415885925293
len local_batched_seeds_list  2
partition total batch output list spend :  0.5832507610321045
self.buckets_partition() spend  sec:  0.511953592300415
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05283021926879883

in edges time spent  0.1508467197418213
local to global src and eids time spent  0.25902748107910156
time gen tails  0.05254983901977539
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08784699440002441

in edges time spent  0.3731389045715332
local to global src and eids time spent  0.5500001907348633
time gen tails  0.08022713661193848
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11103200912475586  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.879164218902588  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.877314567565918  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11256170272827148  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.032034873962402  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.03777265548706  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.12391948699951172  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.22719407081604
pure train time :  0.4316730499267578
train time :  0.5886900424957275
end to end time :  3.9684181213378906
connection check time:  1.8362679481506348
block generation time  0.946073055267334
Run 00 | Epoch 00085 | Loss 1.2272 | Test 0.6193
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004754066467285156
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014343976974487305
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5003726482391357
len local_batched_seeds_list  2
partition total batch output list spend :  0.5862696170806885
self.buckets_partition() spend  sec:  0.51474928855896
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.054344892501831055

in edges time spent  0.16272759437561035
local to global src and eids time spent  0.27407336235046387
time gen tails  0.05380892753601074
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09052824974060059

in edges time spent  0.3816554546356201
local to global src and eids time spent  0.5651412010192871
time gen tails  0.08303523063659668
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11142444610595703  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.87828540802002  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.876683712005615  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11281013488769531  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.010227680206299  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.015965461730957  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.12380170822143555  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2230652570724487
pure train time :  0.43995237350463867
train time :  0.6008963584899902
end to end time :  4.086890697479248
connection check time:  1.901921272277832
block generation time  0.9807782173156738
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.000492095947265625
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01435995101928711
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4893176555633545
len local_batched_seeds_list  2
partition total batch output list spend :  0.5753417015075684
self.buckets_partition() spend  sec:  0.5037102699279785
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05383181571960449

in edges time spent  0.15444540977478027
local to global src and eids time spent  0.2669947147369385
time gen tails  0.05344724655151367
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09065413475036621

in edges time spent  0.37864255905151367
local to global src and eids time spent  0.5574259757995605
time gen tails  0.08250880241394043
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.1105351448059082  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.872403144836426  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.871314525604248  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.1125020980834961  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.033965110778809  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.039702892303467  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.12356138229370117  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.217942714691162
pure train time :  0.4385654926300049
train time :  0.6018810272216797
end to end time :  4.050572156906128
connection check time:  1.875009298324585
block generation time  0.9800863265991211
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004367828369140625
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014274358749389648
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.500777006149292
len local_batched_seeds_list  2
partition total batch output list spend :  0.5872616767883301
self.buckets_partition() spend  sec:  0.5150878429412842
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05384659767150879

in edges time spent  0.15482568740844727
local to global src and eids time spent  0.26691770553588867
time gen tails  0.0536646842956543
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08983516693115234

in edges time spent  0.37770962715148926
local to global src and eids time spent  0.5579712390899658
time gen tails  0.08268117904663086
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11052799224853516  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.87325143814087  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.871933937072754  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11257505416870117  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 11.999611854553223  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.00534963607788  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.12366294860839844  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2122724056243896
pure train time :  0.4301426410675049
train time :  0.5880179405212402
end to end time :  4.037625312805176
connection check time:  1.873514175415039
block generation time  0.9755263328552246
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004353523254394531
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015490055084228516
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.47838735580444336
len local_batched_seeds_list  2
partition total batch output list spend :  0.5236835479736328
self.buckets_partition() spend  sec:  0.49399614334106445
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04291248321533203

in edges time spent  0.14858078956604004
local to global src and eids time spent  0.2676730155944824
time gen tails  0.053514719009399414
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08737921714782715

in edges time spent  0.36690306663513184
local to global src and eids time spent  0.5560393333435059
time gen tails  0.0822138786315918
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11155462265014648  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.87171983718872  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.87035846710205  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11252546310424805  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.002772808074951  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.00851058959961  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.12355995178222656  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.2086468935012817
pure train time :  0.42871809005737305
train time :  0.5863494873046875
end to end time :  3.9397850036621094
connection check time:  1.8384792804718018
block generation time  0.9764306545257568
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0008039474487304688
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014049530029296875
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5068001747131348
len local_batched_seeds_list  2
partition total batch output list spend :  0.5975079536437988
self.buckets_partition() spend  sec:  0.5208818912506104
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.053702592849731445

in edges time spent  0.15479540824890137
local to global src and eids time spent  0.26744556427001953
time gen tails  0.05300712585449219
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08582854270935059

in edges time spent  0.36953258514404297
local to global src and eids time spent  0.5551002025604248
time gen tails  0.08255791664123535
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11047506332397461  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.863494873046875  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.862194538116455  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11218738555908203  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.045658111572266  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.051395893096924  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.12352991104125977  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.204097867012024
pure train time :  0.43752431869506836
train time :  0.5942010879516602
end to end time :  4.048497915267944
connection check time:  1.8592283725738525
block generation time  0.9797830581665039
Run 00 | Epoch 00090 | Loss 1.2041 | Test 0.6173
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004401206970214844
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013791084289550781
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5181193351745605
len local_batched_seeds_list  2
partition total batch output list spend :  0.6040685176849365
self.buckets_partition() spend  sec:  0.5319433212280273
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05418848991394043

in edges time spent  0.15630888938903809
local to global src and eids time spent  0.2681272029876709
time gen tails  0.05373811721801758
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09165048599243164

in edges time spent  0.3752574920654297
local to global src and eids time spent  0.5631861686706543
time gen tails  0.08222746849060059
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11061573028564453  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.871066570281982  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.869643211364746  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11295747756958008  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.016304969787598  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.022042751312256  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.1243429183959961  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.198336124420166
pure train time :  0.43671512603759766
train time :  0.603161096572876
end to end time :  4.088857412338257
connection check time:  1.8816628456115723
block generation time  0.9813816547393799
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00045752525329589844
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014154434204101562
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4975872039794922
len local_batched_seeds_list  2
partition total batch output list spend :  0.5836067199707031
self.buckets_partition() spend  sec:  0.5117762088775635
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05394887924194336

in edges time spent  0.15498924255371094
local to global src and eids time spent  0.2682032585144043
time gen tails  0.05362510681152344
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08790826797485352

in edges time spent  0.38124537467956543
local to global src and eids time spent  0.5586118698120117
time gen tails  0.08298611640930176
res  length 2
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11231565475463867  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.877665519714355  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.875650882720947  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11282634735107422  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.00465202331543  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.010389804840088  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.12371683120727539  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1985366344451904
pure train time :  0.44046640396118164
train time :  0.6028542518615723
end to end time :  4.058855295181274
connection check time:  1.8779652118682861
block generation time  0.9799070358276367
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.000431060791015625
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013962745666503906
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5021460056304932
len local_batched_seeds_list  2
partition total batch output list spend :  0.5875453948974609
self.buckets_partition() spend  sec:  0.5161478519439697
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.053733110427856445

in edges time spent  0.15444445610046387
local to global src and eids time spent  0.2674415111541748
time gen tails  0.053579092025756836
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08646869659423828

in edges time spent  0.3810696601867676
local to global src and eids time spent  0.5611116886138916
time gen tails  0.08220410346984863
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11062002182006836  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.871730327606201  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.870580196380615  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11273431777954102  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.029617309570312  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.03535509109497  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.1237630844116211  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.194150686264038
pure train time :  0.43456315994262695
train time :  0.5954577922821045
end to end time :  4.068693399429321
connection check time:  1.8765838146209717
block generation time  0.9854023456573486
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004298686981201172
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014260292053222656
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5174872875213623
len local_batched_seeds_list  2
partition total batch output list spend :  0.603776216506958
self.buckets_partition() spend  sec:  0.5318605899810791
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05413103103637695

in edges time spent  0.15765118598937988
local to global src and eids time spent  0.26746511459350586
time gen tails  0.05359840393066406
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08959412574768066

in edges time spent  0.38036561012268066
local to global src and eids time spent  0.5565550327301025
time gen tails  0.08227396011352539
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11067867279052734  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.869755268096924  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.868470668792725  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11224985122680664  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.036773681640625  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.042511463165283  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.12389469146728516  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1918859481811523
pure train time :  0.43544840812683105
train time :  0.5905075073242188
end to end time :  4.064488649368286
connection check time:  1.877645492553711
block generation time  0.9785828590393066
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004336833953857422
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013912677764892578
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4145021438598633
len local_batched_seeds_list  2
partition total batch output list spend :  0.5004820823669434
self.buckets_partition() spend  sec:  0.4284496307373047
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.055295467376708984

in edges time spent  0.15538763999938965
local to global src and eids time spent  0.26937198638916016
time gen tails  0.054003000259399414
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08787012100219727

in edges time spent  0.3784959316253662
local to global src and eids time spent  0.5607750415802002
time gen tails  0.08240747451782227
res  length 2
block collection to dataloader spend  1.1444091796875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11127328872680664  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.872694969177246  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.870815753936768  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.11280679702758789  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.019090175628662  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 12.02482795715332  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.244140625 GB
    Memory Allocated: 0.1237945556640625  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1882460117340088
pure train time :  0.43817973136901855
train time :  0.6022887229919434
end to end time :  3.9903547763824463
connection check time:  1.8833999633789062
block generation time  0.9880542755126953
Run 00 | Epoch 00095 | Loss 1.1882 | Test 0.6130
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0005447864532470703
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014792680740356445
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5391302108764648
len local_batched_seeds_list  2
partition total batch output list spend :  0.6254432201385498
self.buckets_partition() spend  sec:  0.5539591312408447
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.053798675537109375

in edges time spent  0.1626296043395996
local to global src and eids time spent  0.2713956832885742
time gen tails  0.05407071113586426
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09530091285705566

in edges time spent  0.3824629783630371
local to global src and eids time spent  0.5599761009216309
time gen tails  0.08169913291931152
res  length 2
block collection to dataloader spend  1.0251998901367188e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11063575744628906  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.86740493774414  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.86616325378418  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11251544952392578  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.028877258300781  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.03461503982544  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12363767623901367  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1805684566497803
pure train time :  0.4405229091644287
train time :  0.6100156307220459
end to end time :  4.117339849472046
connection check time:  1.8916726112365723
block generation time  0.9703731536865234
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004436969757080078
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014341115951538086
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4037947654724121
len local_batched_seeds_list  2
partition total batch output list spend :  0.4896969795227051
self.buckets_partition() spend  sec:  0.418170690536499
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05400562286376953

in edges time spent  0.15581130981445312
local to global src and eids time spent  0.26709985733032227
time gen tails  0.053619384765625
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08974575996398926

in edges time spent  0.3736131191253662
local to global src and eids time spent  0.5383336544036865
time gen tails  0.08153009414672852
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11057901382446289  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.86982250213623  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.868438243865967  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11220979690551758  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.01407766342163  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.019815444946289  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12313270568847656  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1761928796768188
pure train time :  0.43575239181518555
train time :  0.5946710109710693
end to end time :  3.91200852394104
connection check time:  1.8444950580596924
block generation time  0.9670488834381104
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00048542022705078125
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014037847518920898
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4989430904388428
len local_batched_seeds_list  2
partition total batch output list spend :  0.5845963954925537
self.buckets_partition() spend  sec:  0.5130186080932617
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05344343185424805

in edges time spent  0.155442476272583
local to global src and eids time spent  0.26732707023620605
time gen tails  0.05378317832946777
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09096813201904297

in edges time spent  0.3789815902709961
local to global src and eids time spent  0.5651121139526367
time gen tails  0.08310651779174805
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11020803451538086  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.87419080734253  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.873170852661133  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11209726333618164  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.014034271240234  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.019772052764893  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1230926513671875  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1744303703308105
pure train time :  0.4402177333831787
train time :  0.6024720668792725
end to end time :  4.067629337310791
connection check time:  1.8849737644195557
block generation time  0.9770684242248535
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0005278587341308594
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01421809196472168
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4893310070037842
len local_batched_seeds_list  2
partition total batch output list spend :  0.5754427909851074
self.buckets_partition() spend  sec:  0.5036602020263672
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05475974082946777

in edges time spent  0.1557624340057373
local to global src and eids time spent  0.2706642150878906
time gen tails  0.0542454719543457
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09228229522705078

in edges time spent  0.3798067569732666
local to global src and eids time spent  0.5660450458526611
time gen tails  0.08288311958312988
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11083078384399414  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.876519203186035  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.875430583953857  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11293411254882812  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.02811861038208  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.034052848815918  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12398290634155273  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1730506420135498
pure train time :  0.4270472526550293
train time :  0.5873174667358398
end to end time :  4.061921834945679
connection check time:  1.8952953815460205
block generation time  0.9866526126861572
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0005135536193847656
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014248132705688477
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.492215633392334
len local_batched_seeds_list  2
partition total batch output list spend :  0.5783042907714844
self.buckets_partition() spend  sec:  0.5064966678619385
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.053980112075805664

in edges time spent  0.15549707412719727
local to global src and eids time spent  0.26769495010375977
time gen tails  0.05371713638305664
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09094691276550293

in edges time spent  0.3795914649963379
local to global src and eids time spent  0.564765214920044
time gen tails  0.08302783966064453
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1104278564453125  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.8738431930542  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.872618675231934  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11254453659057617  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.04887580871582  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.054613590240479  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12362289428710938  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.169783592224121
pure train time :  0.43589305877685547
train time :  0.5940113067626953
end to end time :  4.052078008651733
connection check time:  1.8855066299438477
block generation time  0.9784533977508545
Run 00 | Epoch 00100 | Loss 1.1698 | Test 0.6245
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00048351287841796875
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014991283416748047
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5023486614227295
len local_batched_seeds_list  2
partition total batch output list spend :  0.5886015892028809
self.buckets_partition() spend  sec:  0.5173723697662354
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.054813385009765625

in edges time spent  0.16390109062194824
local to global src and eids time spent  0.2715470790863037
time gen tails  0.053960561752319336
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08840227127075195

in edges time spent  0.39027976989746094
local to global src and eids time spent  0.5686209201812744
time gen tails  0.08379888534545898
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11080265045166016  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.869685173034668  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.868596076965332  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11346769332885742  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.009087085723877  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.015021324157715  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12512588500976562  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1648448705673218
pure train time :  0.44034647941589355
train time :  0.5992131233215332
end to end time :  4.093942880630493
connection check time:  1.9116272926330566
block generation time  0.9792671203613281
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004265308380126953
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014518976211547852
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5083425045013428
len local_batched_seeds_list  2
partition total batch output list spend :  0.5951898097991943
self.buckets_partition() spend  sec:  0.5228927135467529
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05559253692626953

in edges time spent  0.15829181671142578
local to global src and eids time spent  0.2706422805786133
time gen tails  0.05408477783203125
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09103012084960938

in edges time spent  0.3795802593231201
local to global src and eids time spent  0.5617098808288574
time gen tails  0.08284759521484375
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11198091506958008  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.872834205627441  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.870270252227783  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11310768127441406  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.018024444580078  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.023762226104736  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12458944320678711  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1630699634552002
pure train time :  0.44020724296569824
train time :  0.6029891967773438
end to end time :  4.084472417831421
connection check time:  1.8904895782470703
block generation time  0.9789619445800781
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004220008850097656
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014144420623779297
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.49706459045410156
len local_batched_seeds_list  2
partition total batch output list spend :  0.5833208560943604
self.buckets_partition() spend  sec:  0.5112488269805908
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05532264709472656

in edges time spent  0.15582776069641113
local to global src and eids time spent  0.26913952827453613
time gen tails  0.05364871025085449
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09376239776611328

in edges time spent  0.38498544692993164
local to global src and eids time spent  0.5543074607849121
time gen tails  0.08232808113098145
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1116037368774414  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.880807399749756  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.878427982330322  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11246109008789062  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.005311012268066  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.011048793792725  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12373685836791992  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1627113819122314
pure train time :  0.4358246326446533
train time :  0.5987505912780762
end to end time :  4.065211296081543
connection check time:  1.885845422744751
block generation time  0.9780488014221191
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00044536590576171875
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014040946960449219
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.49601316452026367
len local_batched_seeds_list  2
partition total batch output list spend :  0.5816974639892578
self.buckets_partition() spend  sec:  0.5100882053375244
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05460047721862793

in edges time spent  0.15523028373718262
local to global src and eids time spent  0.26729798316955566
time gen tails  0.0534205436706543
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09119367599487305

in edges time spent  0.3702857494354248
local to global src and eids time spent  0.557302713394165
time gen tails  0.0827322006225586
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1117558479309082  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.869537353515625  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.867969989776611  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1126399040222168  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.042544841766357  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.048282623291016  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12408733367919922  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1597657203674316
pure train time :  0.43259358406066895
train time :  0.5982236862182617
end to end time :  4.049530506134033
connection check time:  1.8684678077697754
block generation time  0.9838404655456543
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00042057037353515625
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014200448989868164
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5030255317687988
len local_batched_seeds_list  2
partition total batch output list spend :  0.5888879299163818
self.buckets_partition() spend  sec:  0.5172626972198486
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05500054359436035

in edges time spent  0.15509510040283203
local to global src and eids time spent  0.2680051326751709
time gen tails  0.05352067947387695
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08633899688720703

in edges time spent  0.3788416385650635
local to global src and eids time spent  0.5601141452789307
time gen tails  0.0827779769897461
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1107492446899414  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.878235340118408  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.876898765563965  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11265754699707031  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.001956939697266  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.007891178131104  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12349128723144531  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1568019390106201
pure train time :  0.4383664131164551
train time :  0.5977139472961426
end to end time :  4.062695503234863
connection check time:  1.8758094310760498
block generation time  0.9803006649017334
Run 00 | Epoch 00105 | Loss 1.1568 | Test 0.6233
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00047278404235839844
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014872550964355469
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5660390853881836
len local_batched_seeds_list  2
partition total batch output list spend :  0.6533558368682861
self.buckets_partition() spend  sec:  0.5809478759765625
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05530261993408203

in edges time spent  0.16292524337768555
local to global src and eids time spent  0.2691161632537842
time gen tails  0.052895545959472656
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09488487243652344

in edges time spent  0.3835477828979492
local to global src and eids time spent  0.5525562763214111
time gen tails  0.0804452896118164
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11094951629638672  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.879580974578857  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.878652095794678  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11316061019897461  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.044570446014404  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.050308227539062  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1242666244506836  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1523611545562744
pure train time :  0.4268615245819092
train time :  0.5944898128509521
end to end time :  4.124744176864624
connection check time:  1.8782153129577637
block generation time  0.9721713066101074
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00047659873962402344
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014422893524169922
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5179543495178223
len local_batched_seeds_list  2
partition total batch output list spend :  0.6049776077270508
self.buckets_partition() spend  sec:  0.5324103832244873
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.054125308990478516

in edges time spent  0.1541740894317627
local to global src and eids time spent  0.268341064453125
time gen tails  0.0529937744140625
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09443545341491699

in edges time spent  0.37630796432495117
local to global src and eids time spent  0.5612695217132568
time gen tails  0.08260273933410645
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11056852340698242  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.871818542480469  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.870452404022217  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11264848709106445  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.047391414642334  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.053129196166992  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1236715316772461  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.153152346611023
pure train time :  0.43639421463012695
train time :  0.5949075222015381
end to end time :  4.05960488319397
connection check time:  1.8794910907745361
block generation time  0.9605646133422852
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004947185516357422
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014325380325317383
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4159538745880127
len local_batched_seeds_list  2
partition total batch output list spend :  0.5024020671844482
self.buckets_partition() spend  sec:  0.43031835556030273
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05414104461669922

in edges time spent  0.15163373947143555
local to global src and eids time spent  0.26076269149780273
time gen tails  0.052410125732421875
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08905696868896484

in edges time spent  0.3758199214935303
local to global src and eids time spent  0.5459444522857666
time gen tails  0.08011317253112793
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11048173904418945  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.872846126556396  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.871901035308838  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1131124496459961  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.04666805267334  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.052405834197998  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12431001663208008  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1510688066482544
pure train time :  0.4376683235168457
train time :  0.5932695865631104
end to end time :  3.8896267414093018
connection check time:  1.8365345001220703
block generation time  0.9432907104492188
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00048470497131347656
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01413416862487793
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5086007118225098
len local_batched_seeds_list  2
partition total batch output list spend :  0.594245195388794
self.buckets_partition() spend  sec:  0.5228886604309082
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05296921730041504

in edges time spent  0.1522994041442871
local to global src and eids time spent  0.2654237747192383
time gen tails  0.05262327194213867
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09304547309875488

in edges time spent  0.3694608211517334
local to global src and eids time spent  0.5403847694396973
time gen tails  0.08262038230895996
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11090278625488281  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.877795219421387  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.876365184783936  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11280441284179688  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.04770565032959  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.053443431854248  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12422323226928711  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1516366004943848
pure train time :  0.4282529354095459
train time :  0.5894567966461182
end to end time :  4.009655237197876
connection check time:  1.8417844772338867
block generation time  0.968339204788208
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00044536590576171875
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014170169830322266
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5056211948394775
len local_batched_seeds_list  2
partition total batch output list spend :  0.5929780006408691
self.buckets_partition() spend  sec:  0.519824743270874
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.055314064025878906

in edges time spent  0.15233922004699707
local to global src and eids time spent  0.2762439250946045
time gen tails  0.052794694900512695
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09380888938903809

in edges time spent  0.3828718662261963
local to global src and eids time spent  0.571514368057251
time gen tails  0.08221769332885742
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.111419677734375  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.873713493347168  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.872072219848633  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11317205429077148  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.049334526062012  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.05507230758667  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12400054931640625  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1461912393569946
pure train time :  0.43404722213745117
train time :  0.5919251441955566
end to end time :  4.069363832473755
connection check time:  1.9006125926971436
block generation time  0.9667689800262451
Run 00 | Epoch 00110 | Loss 1.1462 | Test 0.6225
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.000457763671875
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015472650527954102
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5041851997375488
len local_batched_seeds_list  2
partition total batch output list spend :  0.5918064117431641
self.buckets_partition() spend  sec:  0.5196912288665771
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05426478385925293

in edges time spent  0.16092801094055176
local to global src and eids time spent  0.26964426040649414
time gen tails  0.054091691970825195
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09252309799194336

in edges time spent  0.3936460018157959
local to global src and eids time spent  0.566331148147583
time gen tails  0.08237528800964355
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11043405532836914  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.871712684631348  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.870804786682129  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11258745193481445  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 11.992154121398926  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 11.997891902923584  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12370586395263672  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1467154026031494
pure train time :  0.4309275150299072
train time :  0.5996930599212646
end to end time :  4.1102399826049805
connection check time:  1.9101877212524414
block generation time  0.9893567562103271
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00044345855712890625
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014263629913330078
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.48835277557373047
len local_batched_seeds_list  2
partition total batch output list spend :  0.5742623805999756
self.buckets_partition() spend  sec:  0.5026504993438721
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.054543256759643555

in edges time spent  0.15706562995910645
local to global src and eids time spent  0.2643911838531494
time gen tails  0.05243802070617676
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08903789520263672

in edges time spent  0.37548184394836426
local to global src and eids time spent  0.5588326454162598
time gen tails  0.08309555053710938
res  length 2
block collection to dataloader spend  1.0728836059570312e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11060428619384766  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.873350620269775  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.871938705444336  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11326169967651367  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.04242992401123  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.048167705535889  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12440204620361328  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1453224420547485
pure train time :  0.4409339427947998
train time :  0.6028802394866943
end to end time :  4.032851219177246
connection check time:  1.868302583694458
block generation time  0.9731080532073975
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004436969757080078
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014276504516601562
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.517688512802124
len local_batched_seeds_list  2
partition total batch output list spend :  0.6036503314971924
self.buckets_partition() spend  sec:  0.5320055484771729
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05464458465576172

in edges time spent  0.1546182632446289
local to global src and eids time spent  0.26844263076782227
time gen tails  0.05353498458862305
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09145975112915039

in edges time spent  0.37508416175842285
local to global src and eids time spent  0.558286190032959
time gen tails  0.08286881446838379
res  length 2
block collection to dataloader spend  1.3828277587890625e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11087465286254883  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.871614456176758  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.870384693145752  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1132965087890625  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.046043395996094  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.051781177520752  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12410974502563477  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1434426307678223
pure train time :  0.43887925148010254
train time :  0.6045026779174805
end to end time :  4.074523448944092
connection check time:  1.875699758529663
block generation time  0.9774162769317627
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00048732757568359375
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01421976089477539
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5004873275756836
len local_batched_seeds_list  2
partition total batch output list spend :  0.5868065357208252
self.buckets_partition() spend  sec:  0.5148301124572754
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05418825149536133

in edges time spent  0.15557599067687988
local to global src and eids time spent  0.2680201530456543
time gen tails  0.05347299575805664
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09133267402648926

in edges time spent  0.3790595531463623
local to global src and eids time spent  0.5636489391326904
time gen tails  0.08295202255249023
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11078834533691406  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.872265815734863  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.87121057510376  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11322593688964844  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.03290319442749  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.038640975952148  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12468862533569336  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1413072347640991
pure train time :  0.42682480812072754
train time :  0.584479808807373
end to end time :  4.065611124038696
connection check time:  1.8866703510284424
block generation time  0.9904625415802002
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004432201385498047
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01426553726196289
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5090048313140869
len local_batched_seeds_list  2
partition total batch output list spend :  0.5950279235839844
self.buckets_partition() spend  sec:  0.5233056545257568
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.054860591888427734

in edges time spent  0.15518641471862793
local to global src and eids time spent  0.2667579650878906
time gen tails  0.05352616310119629
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0922091007232666

in edges time spent  0.3723258972167969
local to global src and eids time spent  0.5558013916015625
time gen tails  0.08283424377441406
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11139440536499023  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.875953674316406  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.874406814575195  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1130828857421875  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.032927513122559  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.038665294647217  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12458944320678711  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1412010192871094
pure train time :  0.43593406677246094
train time :  0.5940132141113281
end to end time :  4.0529046058654785
connection check time:  1.8705906867980957
block generation time  0.9792723655700684
Run 00 | Epoch 00115 | Loss 1.1412 | Test 0.6251
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004544258117675781
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014716863632202148
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5559074878692627
len local_batched_seeds_list  2
partition total batch output list spend :  0.6434948444366455
self.buckets_partition() spend  sec:  0.570662260055542
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05479693412780762

in edges time spent  0.16631364822387695
local to global src and eids time spent  0.225297212600708
time gen tails  0.041065216064453125
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09444117546081543

in edges time spent  0.3838639259338379
local to global src and eids time spent  0.5329313278198242
time gen tails  0.060297489166259766
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11103343963623047  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.869311809539795  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.867714881896973  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1129007339477539  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.032537460327148  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.038275241851807  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12447309494018555  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1405425071716309
pure train time :  0.4342684745788574
train time :  0.6015546321868896
end to end time :  4.090333938598633
connection check time:  1.803145170211792
block generation time  1.0224134922027588
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004634857177734375
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015669584274291992
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.49141979217529297
len local_batched_seeds_list  2
partition total batch output list spend :  0.5385308265686035
self.buckets_partition() spend  sec:  0.5071232318878174
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0443425178527832

in edges time spent  0.1372823715209961
local to global src and eids time spent  0.22804617881774902
time gen tails  0.04065227508544922
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09530019760131836

in edges time spent  0.3691411018371582
local to global src and eids time spent  0.5276401042938232
time gen tails  0.06052517890930176
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11099624633789062  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.87193250656128  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.87011194229126  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11265373229980469  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.051220893859863  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.056958675384521  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12358236312866211  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1349703073501587
pure train time :  0.4356100559234619
train time :  0.5933055877685547
end to end time :  3.8983609676361084
connection check time:  1.7446434497833252
block generation time  1.0073893070220947
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00045561790466308594
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015304803848266602
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4869396686553955
len local_batched_seeds_list  2
partition total batch output list spend :  0.5328466892242432
self.buckets_partition() spend  sec:  0.5022859573364258
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.044228553771972656

in edges time spent  0.1356651782989502
local to global src and eids time spent  0.22495341300964355
time gen tails  0.04090714454650879
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09490489959716797

in edges time spent  0.3629283905029297
local to global src and eids time spent  0.5293290615081787
time gen tails  0.06064105033874512
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1105642318725586  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.873283863067627  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.872126579284668  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11248302459716797  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.046099662780762  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.05183744430542  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12422418594360352  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1338320970535278
pure train time :  0.4363083839416504
train time :  0.5945415496826172
end to end time :  3.8979642391204834
connection check time:  1.7371814250946045
block generation time  1.0137104988098145
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004513263702392578
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015504837036132812
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.39138102531433105
len local_batched_seeds_list  2
partition total batch output list spend :  0.43805980682373047
self.buckets_partition() spend  sec:  0.40700268745422363
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043905019760131836

in edges time spent  0.13606762886047363
local to global src and eids time spent  0.22465276718139648
time gen tails  0.04107093811035156
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0963287353515625

in edges time spent  0.37097692489624023
local to global src and eids time spent  0.5254495143890381
time gen tails  0.060491085052490234
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11091947555541992  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.87849760055542  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.876834392547607  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11322259902954102  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.00928544998169  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.015023231506348  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12418937683105469  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1349828243255615
pure train time :  0.4443845748901367
train time :  0.6106221675872803
end to end time :  3.8096988201141357
connection check time:  1.7406489849090576
block generation time  1.0056769847869873
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00045800209045410156
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015195846557617188
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.47357821464538574
len local_batched_seeds_list  2
partition total batch output list spend :  0.5186262130737305
self.buckets_partition() spend  sec:  0.48880791664123535
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04315972328186035

in edges time spent  0.1360490322113037
local to global src and eids time spent  0.22469353675842285
time gen tails  0.04069972038269043
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09169983863830566

in edges time spent  0.3716292381286621
local to global src and eids time spent  0.5302519798278809
time gen tails  0.06079745292663574
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11089420318603516  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.877113342285156  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.875409603118896  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11256933212280273  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.04500675201416  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.050744533538818  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1236581802368164  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1313291788101196
pure train time :  0.42801332473754883
train time :  0.5863113403320312
end to end time :  3.8680925369262695
connection check time:  1.7409355640411377
block generation time  1.00775146484375
Run 00 | Epoch 00120 | Loss 1.1313 | Test 0.6285
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004398822784423828
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.016989707946777344
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.47768664360046387
len local_batched_seeds_list  2
partition total batch output list spend :  0.5252962112426758
self.buckets_partition() spend  sec:  0.49470949172973633
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04324054718017578

in edges time spent  0.14403939247131348
local to global src and eids time spent  0.22441387176513672
time gen tails  0.04084897041320801
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09185314178466797

in edges time spent  0.3738248348236084
local to global src and eids time spent  0.5314998626708984
time gen tails  0.06179356575012207
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11153554916381836  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.872844696044922  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.871513366699219  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1124734878540039  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.026961326599121  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.03269910812378  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12349653244018555  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1303155422210693
pure train time :  0.4320368766784668
train time :  0.5908606052398682
end to end time :  3.8874552249908447
connection check time:  1.7508180141448975
block generation time  1.0042777061462402
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00044727325439453125
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015455007553100586
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4755101203918457
len local_batched_seeds_list  2
partition total batch output list spend :  0.5214314460754395
self.buckets_partition() spend  sec:  0.490997314453125
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.043024539947509766

in edges time spent  0.13819241523742676
local to global src and eids time spent  0.22999310493469238
time gen tails  0.04083728790283203
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09253644943237305

in edges time spent  0.3703160285949707
local to global src and eids time spent  0.5334398746490479
time gen tails  0.061583757400512695
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11049032211303711  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.869184494018555  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.867901802062988  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1123957633972168  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.044949054718018  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.050686836242676  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1233358383178711  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1276808977127075
pure train time :  0.43310117721557617
train time :  0.5909018516540527
end to end time :  3.884730100631714
connection check time:  1.7527897357940674
block generation time  1.0041532516479492
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00043702125549316406
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015272140502929688
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.47820496559143066
len local_batched_seeds_list  2
partition total batch output list spend :  0.5240111351013184
self.buckets_partition() spend  sec:  0.4935142993927002
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04380607604980469

in edges time spent  0.13631439208984375
local to global src and eids time spent  0.22386693954467773
time gen tails  0.04070115089416504
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09440016746520996

in edges time spent  0.37128520011901855
local to global src and eids time spent  0.5265343189239502
time gen tails  0.06034207344055176
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11073637008666992  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.873309135437012  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.872288227081299  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11336183547973633  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.032211780548096  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.037949562072754  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12435340881347656  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.129573941230774
pure train time :  0.4380190372467041
train time :  0.5958600044250488
end to end time :  3.875391960144043
connection check time:  1.7382268905639648
block generation time  1.002572774887085
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00045800209045410156
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015402078628540039
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.47786593437194824
len local_batched_seeds_list  2
partition total batch output list spend :  0.5241496562957764
self.buckets_partition() spend  sec:  0.4932985305786133
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04342222213745117

in edges time spent  0.1371924877166748
local to global src and eids time spent  0.226853609085083
time gen tails  0.04079008102416992
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09368896484375

in edges time spent  0.3699204921722412
local to global src and eids time spent  0.5224745273590088
time gen tails  0.060865163803100586
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1104273796081543  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.870842456817627  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.86959457397461  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11342477798461914  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.030870914459229  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.036805152893066  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.124359130859375  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.126402735710144
pure train time :  0.43907880783081055
train time :  0.5995686054229736
end to end time :  3.9023449420928955
connection check time:  1.7383012771606445
block generation time  1.0202817916870117
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00043082237243652344
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01556539535522461
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4952116012573242
len local_batched_seeds_list  2
partition total batch output list spend :  0.5410706996917725
self.buckets_partition() spend  sec:  0.5108096599578857
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04480147361755371

in edges time spent  0.13758039474487305
local to global src and eids time spent  0.2270066738128662
time gen tails  0.04165220260620117
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09598064422607422

in edges time spent  0.3688981533050537
local to global src and eids time spent  0.5229227542877197
time gen tails  0.060811758041381836
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11122846603393555  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.867679119110107  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.8658447265625  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11335992813110352  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.036715507507324  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.042649745941162  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12437820434570312  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1234264373779297
pure train time :  0.4389824867248535
train time :  0.6005125045776367
end to end time :  3.9095258712768555
connection check time:  1.7434349060058594
block generation time  1.0058612823486328
Run 00 | Epoch 00125 | Loss 1.1234 | Test 0.6300
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004363059997558594
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.016343355178833008
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5230040550231934
len local_batched_seeds_list  2
partition total batch output list spend :  0.5695428848266602
self.buckets_partition() spend  sec:  0.5393826961517334
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04347109794616699

in edges time spent  0.1452651023864746
local to global src and eids time spent  0.22763538360595703
time gen tails  0.04116010665893555
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09264516830444336

in edges time spent  0.38452577590942383
local to global src and eids time spent  0.534799337387085
time gen tails  0.06071925163269043
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11108207702636719  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.8771653175354  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.875257015228271  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11291027069091797  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.045133590698242  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.0508713722229  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12399148941040039  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1247050762176514
pure train time :  0.43488264083862305
train time :  0.6011714935302734
end to end time :  3.970822811126709
connection check time:  1.7715482711791992
block generation time  1.0133051872253418
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00041961669921875
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015146970748901367
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4878275394439697
len local_batched_seeds_list  2
partition total batch output list spend :  0.5338640213012695
self.buckets_partition() spend  sec:  0.5030081272125244
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04390072822570801

in edges time spent  0.13805508613586426
local to global src and eids time spent  0.22333288192749023
time gen tails  0.04062175750732422
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0957484245300293

in edges time spent  0.3621249198913574
local to global src and eids time spent  0.5246925354003906
time gen tails  0.06099557876586914
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11057090759277344  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.87210988998413  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.870776176452637  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11251401901245117  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.043901443481445  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.049835681915283  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12370777130126953  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.121095061302185
pure train time :  0.43238258361816406
train time :  0.5903308391571045
end to end time :  3.9103150367736816
connection check time:  1.7315659523010254
block generation time  1.0066652297973633
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004343986511230469
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01565837860107422
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.501507043838501
len local_batched_seeds_list  2
partition total batch output list spend :  0.5476200580596924
self.buckets_partition() spend  sec:  0.5172045230865479
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.04523324966430664

in edges time spent  0.08226585388183594
local to global src and eids time spent  0.11297059059143066
time gen tails  0.032761335372924805
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.06478071212768555

in edges time spent  0.19391345977783203
local to global src and eids time spent  0.4616577625274658
time gen tails  0.06100130081176758
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11049985885620117  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.872007846832275  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.870726585388184  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11239337921142578  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.013710498809814  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.019448280334473  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12335920333862305  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1202080249786377
pure train time :  0.4313521385192871
train time :  0.5938806533813477
end to end time :  3.3187644481658936
connection check time:  1.2480638027191162
block generation time  0.9141745567321777
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00044226646423339844
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014347553253173828
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5211100578308105
len local_batched_seeds_list  2
partition total batch output list spend :  0.6079540252685547
self.buckets_partition() spend  sec:  0.5354914665222168
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05569720268249512

in edges time spent  0.15915203094482422
local to global src and eids time spent  0.27264833450317383
time gen tails  0.05535387992858887
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09882187843322754

in edges time spent  0.40701818466186523
local to global src and eids time spent  0.5871977806091309
time gen tails  0.08389544486999512
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11076545715332031  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.876311779022217  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.875257015228271  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11297178268432617  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.037271976470947  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.043009757995605  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12391090393066406  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.119210124015808
pure train time :  0.442734956741333
train time :  0.614044189453125
end to end time :  4.211671590805054
connection check time:  1.9657182693481445
block generation time  1.0047194957733154
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0005049705505371094
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014394998550415039
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.41452717781066895
len local_batched_seeds_list  2
partition total batch output list spend :  0.5013015270233154
self.buckets_partition() spend  sec:  0.4289588928222656
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0554962158203125

in edges time spent  0.15825438499450684
local to global src and eids time spent  0.2741048336029053
time gen tails  0.05441403388977051
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09496450424194336

in edges time spent  0.37592625617980957
local to global src and eids time spent  0.5799930095672607
time gen tails  0.0852055549621582
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11088705062866211  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.872118473052979  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.87094497680664  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11276960372924805  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.048803806304932  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.05454158782959  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12359857559204102  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1176389455795288
pure train time :  0.4353630542755127
train time :  0.5977597236633301
end to end time :  4.060439586639404
connection check time:  1.9245967864990234
block generation time  1.016310453414917
Run 00 | Epoch 00130 | Loss 1.1176 | Test 0.6308
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0005359649658203125
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.017853736877441406
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4223935604095459
len local_batched_seeds_list  2
partition total batch output list spend :  0.5131325721740723
self.buckets_partition() spend  sec:  0.44028639793395996
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.044113874435424805

in edges time spent  0.15980195999145508
local to global src and eids time spent  0.27378082275390625
time gen tails  0.05465817451477051
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09516096115112305

in edges time spent  0.39159727096557617
local to global src and eids time spent  0.5731453895568848
time gen tails  0.08560705184936523
res  length 2
block collection to dataloader spend  1.430511474609375e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11032342910766602  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.868677139282227  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.867591857910156  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11233329772949219  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.04498815536499  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.050725936889648  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1232304573059082  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1176888942718506
pure train time :  0.4327833652496338
train time :  0.600238561630249
end to end time :  4.081684827804565
connection check time:  1.9234354496002197
block generation time  1.018752098083496
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004394054412841797
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014444828033447266
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5187084674835205
len local_batched_seeds_list  2
partition total batch output list spend :  0.6054966449737549
self.buckets_partition() spend  sec:  0.5331869125366211
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05576682090759277

in edges time spent  0.16065716743469238
local to global src and eids time spent  0.27193522453308105
time gen tails  0.05463576316833496
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09769725799560547

in edges time spent  0.3937685489654541
local to global src and eids time spent  0.5809841156005859
time gen tails  0.08416199684143066
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1103978157043457  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.877357482910156  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.876380443572998  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11268901824951172  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.018211364746094  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.023949146270752  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1245121955871582  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.115429401397705
pure train time :  0.4430885314941406
train time :  0.6082983016967773
end to end time :  4.179593086242676
connection check time:  1.9442005157470703
block generation time  1.0063886642456055
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00043964385986328125
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013991355895996094
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5067660808563232
len local_batched_seeds_list  2
partition total batch output list spend :  0.5934789180755615
self.buckets_partition() spend  sec:  0.5207972526550293
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05532503128051758

in edges time spent  0.15662145614624023
local to global src and eids time spent  0.27290964126586914
time gen tails  0.05464363098144531
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09352278709411621

in edges time spent  0.3839728832244873
local to global src and eids time spent  0.5752556324005127
time gen tails  0.0842139720916748
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11190366744995117  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.879202842712402  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.877286434173584  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11330699920654297  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.042945384979248  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.048683166503906  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1248021125793457  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1085789203643799
pure train time :  0.44585227966308594
train time :  0.6072964668273926
end to end time :  4.156936883926392
connection check time:  1.9195671081542969
block generation time  1.0160057544708252
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004749298095703125
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014162778854370117
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5133507251739502
len local_batched_seeds_list  2
partition total batch output list spend :  0.600043535232544
self.buckets_partition() spend  sec:  0.5276274681091309
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0561830997467041

in edges time spent  0.1589827537536621
local to global src and eids time spent  0.2754955291748047
time gen tails  0.05466747283935547
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09767293930053711

in edges time spent  0.38348960876464844
local to global src and eids time spent  0.5929665565490723
time gen tails  0.08420419692993164
res  length 2
block collection to dataloader spend  8.821487426757812e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1109619140625  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.871296405792236  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.869551181793213  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11206912994384766  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.047418117523193  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.053155899047852  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1233210563659668  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1124485731124878
pure train time :  0.43894052505493164
train time :  0.5983619689941406
end to end time :  4.189640998840332
connection check time:  1.9480650424957275
block generation time  1.0236191749572754
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00042748451232910156
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014063596725463867
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5050351619720459
len local_batched_seeds_list  2
partition total batch output list spend :  0.5912368297576904
self.buckets_partition() spend  sec:  0.5191316604614258
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0554044246673584

in edges time spent  0.1591968536376953
local to global src and eids time spent  0.27446794509887695
time gen tails  0.05498695373535156
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09818410873413086

in edges time spent  0.3807649612426758
local to global src and eids time spent  0.5250918865203857
time gen tails  0.08188986778259277
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11097574234008789  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.875554084777832  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.874380588531494  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11298179626464844  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.048025608062744  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.053763389587402  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12409162521362305  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1122103929519653
pure train time :  0.44100022315979004
train time :  0.598599910736084
end to end time :  4.08061408996582
connection check time:  1.8533122539520264
block generation time  1.0161688327789307
Run 00 | Epoch 00135 | Loss 1.1122 | Test 0.6289
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.010074615478515625
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015712976455688477
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5221035480499268
len local_batched_seeds_list  2
partition total batch output list spend :  0.6105623245239258
self.buckets_partition() spend  sec:  0.5378491878509521
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0557096004486084

in edges time spent  0.16558218002319336
local to global src and eids time spent  0.2862272262573242
time gen tails  0.054291486740112305
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09937191009521484

in edges time spent  0.39649391174316406
local to global src and eids time spent  0.5789191722869873
time gen tails  0.08426094055175781
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1103663444519043  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.871775150299072  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.870781898498535  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11296987533569336  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.048699378967285  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.054437160491943  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12395668029785156  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1079347133636475
pure train time :  0.44467735290527344
train time :  0.6040751934051514
end to end time :  4.200779914855957
connection check time:  1.9650371074676514
block generation time  1.0065534114837646
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004885196685791016
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014118194580078125
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5090899467468262
len local_batched_seeds_list  2
partition total batch output list spend :  0.5959374904632568
self.buckets_partition() spend  sec:  0.523240327835083
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05604887008666992

in edges time spent  0.16196298599243164
local to global src and eids time spent  0.2731914520263672
time gen tails  0.05440688133239746
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09670543670654297

in edges time spent  0.3839709758758545
local to global src and eids time spent  0.5794131755828857
time gen tails  0.08419346809387207
res  length 2
block collection to dataloader spend  9.298324584960938e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11152362823486328  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.872037887573242  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.870588302612305  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11340951919555664  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.042694091796875  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.048628330230713  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1245260238647461  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1057591438293457
pure train time :  0.44095563888549805
train time :  0.5989348888397217
end to end time :  4.152062177658081
connection check time:  1.9337234497070312
block generation time  1.0095105171203613
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0005013942718505859
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014303922653198242
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5069525241851807
len local_batched_seeds_list  2
partition total batch output list spend :  0.5935671329498291
self.buckets_partition() spend  sec:  0.5212969779968262
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.054970502853393555

in edges time spent  0.1590104103088379
local to global src and eids time spent  0.2725398540496826
time gen tails  0.05439019203186035
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09879899024963379

in edges time spent  0.38200831413269043
local to global src and eids time spent  0.5695669651031494
time gen tails  0.08416438102722168
res  length 2
block collection to dataloader spend  9.5367431640625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11077260971069336  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.870479106903076  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.869100570678711  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11269330978393555  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.046792984008789  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.052727222442627  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12372589111328125  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1053296327590942
pure train time :  0.43759989738464355
train time :  0.5956540107727051
end to end time :  4.122076749801636
connection check time:  1.9185152053833008
block generation time  1.0011076927185059
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00048422813415527344
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014147281646728516
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5104155540466309
len local_batched_seeds_list  2
partition total batch output list spend :  0.5972082614898682
self.buckets_partition() spend  sec:  0.5246694087982178
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.054967403411865234

in edges time spent  0.15656566619873047
local to global src and eids time spent  0.27311205863952637
time gen tails  0.05986475944519043
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09367895126342773

in edges time spent  0.39406466484069824
local to global src and eids time spent  0.5739133358001709
time gen tails  0.08428478240966797
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.110443115234375  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.872505187988281  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.871235847473145  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11268997192382812  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.048746585845947  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.054484367370605  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12375497817993164  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1037888526916504
pure train time :  0.4351961612701416
train time :  0.5927879810333252
end to end time :  4.154784202575684
connection check time:  1.9410481452941895
block generation time  1.0099196434020996
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004913806915283203
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014438867568969727
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5162889957427979
len local_batched_seeds_list  2
partition total batch output list spend :  0.6031911373138428
self.buckets_partition() spend  sec:  0.5307626724243164
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05451393127441406

in edges time spent  0.15734481811523438
local to global src and eids time spent  0.2647533416748047
time gen tails  0.054567813873291016
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09856843948364258

in edges time spent  0.3792252540588379
local to global src and eids time spent  0.5717513561248779
time gen tails  0.08397507667541504
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11101675033569336  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.870828628540039  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.869533061981201  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1127328872680664  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.049505233764648  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.055243015289307  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12377595901489258  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.103293538093567
pure train time :  0.4353961944580078
train time :  0.5935258865356445
end to end time :  4.1479103565216064
connection check time:  1.9109115600585938
block generation time  1.0262632369995117
Run 00 | Epoch 00140 | Loss 1.1033 | Test 0.6280
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004475116729736328
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014865875244140625
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5217394828796387
len local_batched_seeds_list  2
partition total batch output list spend :  0.607337474822998
self.buckets_partition() spend  sec:  0.5366439819335938
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05479717254638672

in edges time spent  0.1592874526977539
local to global src and eids time spent  0.2711164951324463
time gen tails  0.05279040336608887
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09368562698364258

in edges time spent  0.39104580879211426
local to global src and eids time spent  0.5761172771453857
time gen tails  0.08089971542358398
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11046218872070312  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.87057638168335  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.869287014007568  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11295032501220703  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.043385982513428  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.049123764038086  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12467336654663086  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1021912097930908
pure train time :  0.4396243095397949
train time :  0.6110274791717529
end to end time :  4.109825372695923
connection check time:  1.9161479473114014
block generation time  0.9561975002288818
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004374980926513672
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014704704284667969
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5184135437011719
len local_batched_seeds_list  2
partition total batch output list spend :  0.6048648357391357
self.buckets_partition() spend  sec:  0.5331525802612305
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05464887619018555

in edges time spent  0.15436983108520508
local to global src and eids time spent  0.259540319442749
time gen tails  0.052548885345458984
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0847632884979248

in edges time spent  0.3853898048400879
local to global src and eids time spent  0.560006856918335
time gen tails  0.08542776107788086
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11174583435058594  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.875749111175537  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.873766422271729  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11311626434326172  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.010859489440918  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.016597270965576  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12419652938842773  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.1029528379440308
pure train time :  0.4383842945098877
train time :  0.6046178340911865
end to end time :  4.065901517868042
connection check time:  1.87337327003479
block generation time  0.9673888683319092
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004563331604003906
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014413833618164062
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.38546276092529297
len local_batched_seeds_list  2
partition total batch output list spend :  0.4708724021911621
self.buckets_partition() spend  sec:  0.3999204635620117
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05449223518371582

in edges time spent  0.15118169784545898
local to global src and eids time spent  0.25951123237609863
time gen tails  0.052698373794555664
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0870661735534668

in edges time spent  0.36205077171325684
local to global src and eids time spent  0.5447273254394531
time gen tails  0.08049702644348145
res  length 2
block collection to dataloader spend  1.1682510375976562e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11056756973266602  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.873790740966797  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.872438430786133  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11239051818847656  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.031511306762695  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.037445545196533  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12363290786743164  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.097571611404419
pure train time :  0.43235278129577637
train time :  0.5875043869018555
end to end time :  3.8435630798339844
connection check time:  1.8180723190307617
block generation time  0.9535183906555176
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004401206970214844
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014039278030395508
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5180447101593018
len local_batched_seeds_list  2
partition total batch output list spend :  0.6025776863098145
self.buckets_partition() spend  sec:  0.5321178436279297
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05316758155822754

in edges time spent  0.15059447288513184
local to global src and eids time spent  0.25969982147216797
time gen tails  0.05244040489196777
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08509039878845215

in edges time spent  0.38104248046875
local to global src and eids time spent  0.5427489280700684
time gen tails  0.08037686347961426
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11035394668579102  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.875135898590088  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.873970985412598  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11337566375732422  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.0474534034729  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.053191184997559  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12450361251831055  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.097530484199524
pure train time :  0.4383809566497803
train time :  0.6043434143066406
end to end time :  3.9969124794006348
connection check time:  1.8307878971099854
block generation time  0.9420218467712402
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0005285739898681641
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014198541641235352
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4896681308746338
len local_batched_seeds_list  2
partition total batch output list spend :  0.5753352642059326
self.buckets_partition() spend  sec:  0.503899097442627
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.053049325942993164

in edges time spent  0.15095210075378418
local to global src and eids time spent  0.26047563552856445
time gen tails  0.052401065826416016
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09076714515686035

in edges time spent  0.3766477108001709
local to global src and eids time spent  0.5422041416168213
time gen tails  0.08060622215270996
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11118412017822266  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.842543125152588  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.84052324295044  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11347293853759766  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.046357154846191  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.05209493637085  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12442445755004883  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.095749020576477
pure train time :  0.4384753704071045
train time :  0.5959875583648682
end to end time :  3.963085412979126
connection check time:  1.8327324390411377
block generation time  0.9420344829559326
Run 00 | Epoch 00145 | Loss 1.0957 | Test 0.6274
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004401206970214844
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014831304550170898
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5511016845703125
len local_batched_seeds_list  2
partition total batch output list spend :  0.6380031108856201
self.buckets_partition() spend  sec:  0.5659694671630859
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05414628982543945

in edges time spent  0.16225481033325195
local to global src and eids time spent  0.2721824645996094
time gen tails  0.05384945869445801
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.094482421875

in edges time spent  0.3831353187561035
local to global src and eids time spent  0.5647740364074707
time gen tails  0.08318829536437988
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11127424240112305  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.871042728424072  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.869201183319092  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11259794235229492  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.034955501556396  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.040693283081055  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12404727935791016  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0939016342163086
pure train time :  0.44156479835510254
train time :  0.6090013980865479
end to end time :  4.165723562240601
connection check time:  1.9051849842071533
block generation time  0.9901442527770996
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004355907440185547
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014640092849731445
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.49126100540161133
len local_batched_seeds_list  2
partition total batch output list spend :  0.5774567127227783
self.buckets_partition() spend  sec:  0.5059340000152588
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.054219961166381836

in edges time spent  0.16016650199890137
local to global src and eids time spent  0.27016639709472656
time gen tails  0.05375313758850098
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08919835090637207

in edges time spent  0.37903857231140137
local to global src and eids time spent  0.5577335357666016
time gen tails  0.08287358283996582
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11092948913574219  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.874809265136719  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.873109817504883  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11234521865844727  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.047480583190918  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.053218364715576  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1237039566040039  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0941556692123413
pure train time :  0.4398164749145508
train time :  0.6034402847290039
end to end time :  4.057014226913452
connection check time:  1.884615182876587
block generation time  0.9779555797576904
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004546642303466797
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014172792434692383
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4941740036010742
len local_batched_seeds_list  2
partition total batch output list spend :  0.5802257061004639
self.buckets_partition() spend  sec:  0.5083842277526855
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05495762825012207

in edges time spent  0.15497660636901855
local to global src and eids time spent  0.2665579319000244
time gen tails  0.05377459526062012
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09186315536499023

in edges time spent  0.3811647891998291
local to global src and eids time spent  0.5625953674316406
time gen tails  0.08231401443481445
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11104202270507812  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.876668930053711  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.875388622283936  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11307144165039062  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.031356811523438  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.037094593048096  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12412691116333008  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0935869216918945
pure train time :  0.4293978214263916
train time :  0.5852310657501221
end to end time :  4.042683362960815
connection check time:  1.8844199180603027
block generation time  0.9778196811676025
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004363059997558594
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014144659042358398
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.49694108963012695
len local_batched_seeds_list  2
partition total batch output list spend :  0.583162784576416
self.buckets_partition() spend  sec:  0.5112001895904541
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05500960350036621

in edges time spent  0.1551978588104248
local to global src and eids time spent  0.2673051357269287
time gen tails  0.05362510681152344
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09161758422851562

in edges time spent  0.37321925163269043
local to global src and eids time spent  0.5625424385070801
time gen tails  0.0828249454498291
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11033153533935547  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.868908882141113  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.867756843566895  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11298084259033203  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.048693180084229  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.054430961608887  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.12398290634155273  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0888867378234863
pure train time :  0.4376811981201172
train time :  0.5951249599456787
end to end time :  4.053143739700317
connection check time:  1.8781402111053467
block generation time  0.9785490036010742
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004520416259765625
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014405012130737305
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.49613285064697266
len local_batched_seeds_list  2
partition total batch output list spend :  0.5825903415679932
self.buckets_partition() spend  sec:  0.5105743408203125
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05479764938354492

in edges time spent  0.155914306640625
local to global src and eids time spent  0.26694583892822266
time gen tails  0.05360817909240723
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0917961597442627

in edges time spent  0.3789644241333008
local to global src and eids time spent  0.5660440921783447
time gen tails  0.08275008201599121
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11080503463745117  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.866764068603516  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.865128993988037  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.11343765258789062  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.045578002929688  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 12.051512241363525  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 22.865234375 GB
    Memory Allocated: 0.1246190071105957  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0919588804244995
pure train time :  0.4381248950958252
train time :  0.6023657321929932
end to end time :  4.065875291824341
connection check time:  1.8876426219940186
block generation time  0.9794559478759766
Run 00 | Epoch 00150 | Loss 1.0920 | Test 0.6299
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00046324729919433594
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014991521835327148
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5401694774627686
len local_batched_seeds_list  2
partition total batch output list spend :  0.6268999576568604
self.buckets_partition() spend  sec:  0.5551986694335938
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05457115173339844

in edges time spent  0.1665029525756836
local to global src and eids time spent  0.26976609230041504
time gen tails  0.05472278594970703
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09251284599304199

in edges time spent  0.38306236267089844
local to global src and eids time spent  0.562161922454834
time gen tails  0.08289623260498047
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11126518249511719  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.879765510559082  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.877692222595215  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11256742477416992  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.03227424621582  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.038012027740479  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12343311309814453  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.089622139930725
pure train time :  0.4400806427001953
train time :  0.61409592628479
end to end time :  4.157641410827637
connection check time:  1.9043519496917725
block generation time  0.9919228553771973
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0005247592926025391
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014211654663085938
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5097908973693848
len local_batched_seeds_list  2
partition total batch output list spend :  0.5959305763244629
self.buckets_partition() spend  sec:  0.5240414142608643
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.055450439453125

in edges time spent  0.15691781044006348
local to global src and eids time spent  0.26761317253112793
time gen tails  0.05378413200378418
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09189677238464355

in edges time spent  0.3911280632019043
local to global src and eids time spent  0.5622162818908691
time gen tails  0.08560442924499512
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11086368560791016  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.873297691345215  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.872185707092285  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11311054229736328  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.007084846496582  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.01282262802124  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12432193756103516  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0870741605758667
pure train time :  0.4407651424407959
train time :  0.6097517013549805
end to end time :  4.109416484832764
connection check time:  1.9028925895690918
block generation time  0.983339786529541
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0013892650604248047
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014737844467163086
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5082259178161621
len local_batched_seeds_list  2
partition total batch output list spend :  0.5947299003601074
self.buckets_partition() spend  sec:  0.523003339767456
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.054773807525634766

in edges time spent  0.16014623641967773
local to global src and eids time spent  0.26875734329223633
time gen tails  0.05236530303955078
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09272599220275879

in edges time spent  0.38015031814575195
local to global src and eids time spent  0.5705239772796631
time gen tails  0.0828866958618164
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11074066162109375  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.873755931854248  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.87226915359497  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11215877532958984  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 11.993832111358643  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 11.99976634979248  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12291574478149414  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0842410326004028
pure train time :  0.43976640701293945
train time :  0.6053130626678467
end to end time :  4.098202705383301
connection check time:  1.896031141281128
block generation time  0.9812562465667725
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00046133995056152344
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01376032829284668
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.38928675651550293
len local_batched_seeds_list  2
partition total batch output list spend :  0.47432470321655273
self.buckets_partition() spend  sec:  0.40316343307495117
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.052819013595581055

in edges time spent  0.1601264476776123
local to global src and eids time spent  0.26726651191711426
time gen tails  0.05259370803833008
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09180402755737305

in edges time spent  0.37672948837280273
local to global src and eids time spent  0.5737113952636719
time gen tails  0.08393573760986328
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.10985374450683594  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.871534824371338  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.87085485458374  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.1130218505859375  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.026009559631348  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.031747341156006  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12400674819946289  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0857765674591064
pure train time :  0.4383656978607178
train time :  0.6037533283233643
end to end time :  3.9742283821105957
connection check time:  1.9007680416107178
block generation time  0.9763610363006592
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004935264587402344
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014055967330932617
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5140018463134766
len local_batched_seeds_list  2
partition total batch output list spend :  0.5996203422546387
self.buckets_partition() spend  sec:  0.5280911922454834
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.054328203201293945

in edges time spent  0.15487217903137207
local to global src and eids time spent  0.26721620559692383
time gen tails  0.053467512130737305
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09705042839050293

in edges time spent  0.37420225143432617
local to global src and eids time spent  0.5627002716064453
time gen tails  0.0821983814239502
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11062860488891602  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.867632865905762  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.866398334503174  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11343765258789062  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.033737659454346  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.039475440979004  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.1250443458557129  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0836734771728516
pure train time :  0.43793249130249023
train time :  0.5999660491943359
end to end time :  4.0760581493377686
connection check time:  1.882103443145752
block generation time  0.9767115116119385
Run 00 | Epoch 00155 | Loss 1.0837 | Test 0.6254
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004496574401855469
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015128374099731445
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5254981517791748
len local_batched_seeds_list  2
partition total batch output list spend :  0.61244797706604
self.buckets_partition() spend  sec:  0.5406639575958252
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05463600158691406

in edges time spent  0.16398024559020996
local to global src and eids time spent  0.2696835994720459
time gen tails  0.0538330078125
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08915472030639648

in edges time spent  0.385190486907959
local to global src and eids time spent  0.5671594142913818
time gen tails  0.08381319046020508
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.1118927001953125  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.871830463409424  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.86933183670044  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11298322677612305  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.049686431884766  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.055424213409424  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12383365631103516  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0830252170562744
pure train time :  0.4291222095489502
train time :  0.5985965728759766
end to end time :  4.141565561294556
connection check time:  1.9048349857330322
block generation time  1.001906156539917
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0005195140838623047
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01429128646850586
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5104422569274902
len local_batched_seeds_list  2
partition total batch output list spend :  0.5968883037567139
self.buckets_partition() spend  sec:  0.5247664451599121
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0546269416809082

in edges time spent  0.15761947631835938
local to global src and eids time spent  0.2620890140533447
time gen tails  0.05309438705444336
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08554792404174805

in edges time spent  0.3793361186981201
local to global src and eids time spent  0.5515706539154053
time gen tails  0.08068180084228516
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11080503463745117  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.868022918701172  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.866955280303955  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11269855499267578  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.02049207687378  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.026229858398438  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12361955642700195  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0812668800354004
pure train time :  0.43836498260498047
train time :  0.599034309387207
end to end time :  4.007501602172852
connection check time:  1.850637674331665
block generation time  0.9475548267364502
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004723072052001953
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014089822769165039
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.46588611602783203
len local_batched_seeds_list  2
partition total batch output list spend :  0.5506317615509033
self.buckets_partition() spend  sec:  0.4800131320953369
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0533754825592041

in edges time spent  0.15088844299316406
local to global src and eids time spent  0.25954604148864746
time gen tails  0.052324533462524414
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08881592750549316

in edges time spent  0.3766341209411621
local to global src and eids time spent  0.5486054420471191
time gen tails  0.08081889152526855
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11040496826171875  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.868981838226318  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.867970943450928  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11308574676513672  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.014888286590576  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.020626068115234  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12400054931640625  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0750460624694824
pure train time :  0.4362037181854248
train time :  0.5945234298706055
end to end time :  3.946810722351074
connection check time:  1.8370585441589355
block generation time  0.9448857307434082
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004189014434814453
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014169454574584961
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5050098896026611
len local_batched_seeds_list  2
partition total batch output list spend :  0.5904898643493652
self.buckets_partition() spend  sec:  0.5192925930023193
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.054345130920410156

in edges time spent  0.15100431442260742
local to global src and eids time spent  0.26038622856140137
time gen tails  0.05283951759338379
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08591580390930176

in edges time spent  0.36701154708862305
local to global src and eids time spent  0.547382116317749
time gen tails  0.08044934272766113
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11076068878173828  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.869429111480713  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.867859840393066  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11254358291625977  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.031753540039062  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.03749132156372  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12425708770751953  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0764915943145752
pure train time :  0.4304947853088379
train time :  0.5892152786254883
end to end time :  3.965975761413574
connection check time:  1.825284481048584
block generation time  0.9443318843841553
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00048613548278808594
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014194488525390625
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.49190521240234375
len local_batched_seeds_list  2
partition total batch output list spend :  0.57674241065979
self.buckets_partition() spend  sec:  0.5061323642730713
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.052964210510253906

in edges time spent  0.15254664421081543
local to global src and eids time spent  0.2634248733520508
time gen tails  0.05364108085632324
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09168839454650879

in edges time spent  0.37534260749816895
local to global src and eids time spent  0.5578629970550537
time gen tails  0.08241724967956543
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11113643646240234  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.83818006515503  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.83621072769165  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11270809173583984  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.045340538024902  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.05107831954956  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12366914749145508  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0759845972061157
pure train time :  0.43819499015808105
train time :  0.5975935459136963
end to end time :  4.034746408462524
connection check time:  1.8668630123138428
block generation time  0.9801418781280518
Run 00 | Epoch 00160 | Loss 1.0760 | Test 0.6266
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0005116462707519531
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014278888702392578
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.537085771560669
len local_batched_seeds_list  2
partition total batch output list spend :  0.6230204105377197
self.buckets_partition() spend  sec:  0.5514023303985596
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05453991889953613

in edges time spent  0.16384243965148926
local to global src and eids time spent  0.27423596382141113
time gen tails  0.05402827262878418
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09221005439758301

in edges time spent  0.38756656646728516
local to global src and eids time spent  0.5560626983642578
time gen tails  0.08272624015808105
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11094474792480469  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.870399951934814  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.86919641494751  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11281156539916992  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.0433030128479  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.049040794372559  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12412548065185547  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0755382776260376
pure train time :  0.4410064220428467
train time :  0.6101016998291016
end to end time :  4.152925252914429
connection check time:  1.9022753238677979
block generation time  0.9938709735870361
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004563331604003906
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014072179794311523
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5002143383026123
len local_batched_seeds_list  2
partition total batch output list spend :  0.5861685276031494
self.buckets_partition() spend  sec:  0.5143206119537354
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.054018259048461914

in edges time spent  0.15679144859313965
local to global src and eids time spent  0.27132177352905273
time gen tails  0.05351614952087402
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09051966667175293

in edges time spent  0.37624430656433105
local to global src and eids time spent  0.5544734001159668
time gen tails  0.08286738395690918
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11111974716186523  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.869978427886963  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.868573188781738  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11335515975952148  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.035131931304932  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.04086971282959  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12455558776855469  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0754902362823486
pure train time :  0.43804502487182617
train time :  0.6032657623291016
end to end time :  4.0660483837127686
connection check time:  1.8786578178405762
block generation time  0.980837345123291
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004546642303466797
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014195680618286133
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5009236335754395
len local_batched_seeds_list  2
partition total batch output list spend :  0.5869836807250977
self.buckets_partition() spend  sec:  0.5151636600494385
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05507302284240723

in edges time spent  0.15680980682373047
local to global src and eids time spent  0.26526355743408203
time gen tails  0.052942514419555664
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0893857479095459

in edges time spent  0.37552857398986816
local to global src and eids time spent  0.5531277656555176
time gen tails  0.08134841918945312
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11063432693481445  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.878332614898682  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.877098083496094  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11242341995239258  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 11.995594024658203  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.001331806182861  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12306976318359375  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.073155403137207
pure train time :  0.43602776527404785
train time :  0.5947003364562988
end to end time :  3.9948787689208984
connection check time:  1.8559112548828125
block generation time  0.9441065788269043
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00046634674072265625
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014041900634765625
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4853067398071289
len local_batched_seeds_list  2
partition total batch output list spend :  0.5709476470947266
self.buckets_partition() spend  sec:  0.49938344955444336
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05442953109741211

in edges time spent  0.1566755771636963
local to global src and eids time spent  0.26749444007873535
time gen tails  0.05344080924987793
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08984971046447754

in edges time spent  0.37302589416503906
local to global src and eids time spent  0.5550951957702637
time gen tails  0.08285355567932129
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11066484451293945  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.870370864868164  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.869425296783447  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11384820938110352  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.050168514251709  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.055906295776367  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12525463104248047  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.072018027305603
pure train time :  0.43799638748168945
train time :  0.6000850200653076
end to end time :  4.040765047073364
connection check time:  1.8701531887054443
block generation time  0.9807021617889404
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004420280456542969
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013875246047973633
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.40510082244873047
len local_batched_seeds_list  2
partition total batch output list spend :  0.49108290672302246
self.buckets_partition() spend  sec:  0.4190104007720947
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05525660514831543

in edges time spent  0.15682697296142578
local to global src and eids time spent  0.2674438953399658
time gen tails  0.05377507209777832
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09707236289978027

in edges time spent  0.3697237968444824
local to global src and eids time spent  0.554495096206665
time gen tails  0.08272194862365723
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.1115260124206543  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.876316547393799  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.874022006988525  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11266660690307617  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.048449039459229  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.054186820983887  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12369823455810547  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0675972700119019
pure train time :  0.4383852481842041
train time :  0.5950407981872559
end to end time :  3.9615182876586914
connection check time:  1.8750152587890625
block generation time  0.9828052520751953
Run 00 | Epoch 00165 | Loss 1.0676 | Test 0.6247
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00045609474182128906
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01525425910949707
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4148061275482178
len local_batched_seeds_list  2
partition total batch output list spend :  0.5019392967224121
self.buckets_partition() spend  sec:  0.43010759353637695
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05441164970397949

in edges time spent  0.1656951904296875
local to global src and eids time spent  0.2707850933074951
time gen tails  0.05450630187988281
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09876513481140137

in edges time spent  0.39214301109313965
local to global src and eids time spent  0.5615522861480713
time gen tails  0.08158087730407715
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11106300354003906  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.880701065063477  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.879423141479492  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.1127786636352539  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.002553462982178  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.008291244506836  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12385034561157227  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0691906213760376
pure train time :  0.43996238708496094
train time :  0.6119420528411865
end to end time :  4.004191875457764
connection check time:  1.9108994007110596
block generation time  0.9597630500793457
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00047588348388671875
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01393270492553711
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.506272554397583
len local_batched_seeds_list  2
partition total batch output list spend :  0.5921719074249268
self.buckets_partition() spend  sec:  0.5202372074127197
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05499267578125

in edges time spent  0.15924072265625
local to global src and eids time spent  0.2705192565917969
time gen tails  0.05374264717102051
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08933138847351074

in edges time spent  0.3739778995513916
local to global src and eids time spent  0.5537877082824707
time gen tails  0.08261394500732422
res  length 2
block collection to dataloader spend  1.049041748046875e-05
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11034440994262695  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.871109962463379  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.869944095611572  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11291265487670898  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.004284858703613  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.010022640228271  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12387275695800781  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0666210651397705
pure train time :  0.43938326835632324
train time :  0.6045010089874268
end to end time :  4.070364713668823
connection check time:  1.8756415843963623
block generation time  0.9821443557739258
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004286766052246094
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014090776443481445
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4870295524597168
len local_batched_seeds_list  2
partition total batch output list spend :  0.5727975368499756
self.buckets_partition() spend  sec:  0.5011589527130127
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05453824996948242

in edges time spent  0.15543341636657715
local to global src and eids time spent  0.2678546905517578
time gen tails  0.053551435470581055
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09184956550598145

in edges time spent  0.36039257049560547
local to global src and eids time spent  0.5358009338378906
time gen tails  0.08018684387207031
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11079883575439453  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.869996070861816  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.868380546569824  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11253976821899414  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.043740272521973  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.04947805404663  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12354755401611328  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0679185390472412
pure train time :  0.4385867118835449
train time :  0.5986263751983643
end to end time :  3.9687979221343994
connection check time:  1.8286149501800537
block generation time  0.9520370960235596
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0005023479461669922
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01436161994934082
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.46812009811401367
len local_batched_seeds_list  2
partition total batch output list spend :  0.5532100200653076
self.buckets_partition() spend  sec:  0.48259830474853516
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.053983211517333984

in edges time spent  0.15136981010437012
local to global src and eids time spent  0.2591097354888916
time gen tails  0.053006649017333984
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08948636054992676

in edges time spent  0.369931697845459
local to global src and eids time spent  0.5402572154998779
time gen tails  0.08020424842834473
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11066246032714844  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.874972820281982  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.873716831207275  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11221742630004883  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.00532054901123  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.011058330535889  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12344837188720703  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0657224655151367
pure train time :  0.43848299980163574
train time :  0.5971028804779053
end to end time :  3.945880651473999
connection check time:  1.8266723155975342
block generation time  0.9557256698608398
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004780292510986328
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014133214950561523
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.482990026473999
len local_batched_seeds_list  2
partition total batch output list spend :  0.5680627822875977
self.buckets_partition() spend  sec:  0.49715566635131836
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05541634559631348

in edges time spent  0.15056061744689941
local to global src and eids time spent  0.2594339847564697
time gen tails  0.05271029472351074
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08477926254272461

in edges time spent  0.3671455383300781
local to global src and eids time spent  0.5391185283660889
time gen tails  0.08076643943786621
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11033773422241211  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.875802516937256  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.874649047851562  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11258363723754883  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.015281677246094  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.021019458770752  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12366485595703125  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0624747276306152
pure train time :  0.4359283447265625
train time :  0.5923972129821777
end to end time :  3.93705415725708
connection check time:  1.8171732425689697
block generation time  0.944385290145874
Run 00 | Epoch 00170 | Loss 1.0625 | Test 0.6230
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004374980926513672
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014378070831298828
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4939877986907959
len local_batched_seeds_list  2
partition total batch output list spend :  0.5796599388122559
self.buckets_partition() spend  sec:  0.5083999633789062
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.054273128509521484

in edges time spent  0.16225743293762207
local to global src and eids time spent  0.27495265007019043
time gen tails  0.05631089210510254
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09068799018859863

in edges time spent  0.3879837989807129
local to global src and eids time spent  0.5666549205780029
time gen tails  0.08159923553466797
res  length 2
block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.1107330322265625  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.8712158203125  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.869876861572266  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11249637603759766  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.045480728149414  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.051218509674072  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12372350692749023  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.062461495399475
pure train time :  0.42705273628234863
train time :  0.5847842693328857
end to end time :  4.047828674316406
connection check time:  1.9073412418365479
block generation time  0.9610714912414551
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004451274871826172
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014596223831176758
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.49234700202941895
len local_batched_seeds_list  2
partition total batch output list spend :  0.5788142681121826
self.buckets_partition() spend  sec:  0.5069770812988281
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0553591251373291

in edges time spent  0.15861916542053223
local to global src and eids time spent  0.2676811218261719
time gen tails  0.053972721099853516
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09433913230895996

in edges time spent  0.3885776996612549
local to global src and eids time spent  0.5684688091278076
time gen tails  0.08291792869567871
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.1106405258178711  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.878514289855957  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.877050399780273  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11259794235229492  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.02849006652832  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.034227848052979  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12375640869140625  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0632314682006836
pure train time :  0.43436193466186523
train time :  0.5941312313079834
end to end time :  4.084184885025024
connection check time:  1.9084601402282715
block generation time  0.9888801574707031
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00048470497131347656
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01425623893737793
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4982435703277588
len local_batched_seeds_list  2
partition total batch output list spend :  0.5841207504272461
self.buckets_partition() spend  sec:  0.5125422477722168
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.054764509201049805

in edges time spent  0.15639543533325195
local to global src and eids time spent  0.26749730110168457
time gen tails  0.0537877082824707
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09638547897338867

in edges time spent  0.37566184997558594
local to global src and eids time spent  0.5416393280029297
time gen tails  0.08031463623046875
res  length 2
block collection to dataloader spend  8.344650268554688e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11119890213012695  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.874014377593994  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.87260389328003  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11303567886352539  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.031862258911133  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.037600040435791  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12406253814697266  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0617300271987915
pure train time :  0.43891263008117676
train time :  0.6023097038269043
end to end time :  4.018385887145996
connection check time:  1.857346534729004
block generation time  0.957944393157959
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004703998565673828
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013729095458984375
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.48091650009155273
len local_batched_seeds_list  2
partition total batch output list spend :  0.5656194686889648
self.buckets_partition() spend  sec:  0.49476099014282227
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.053803443908691406

in edges time spent  0.15197157859802246
local to global src and eids time spent  0.2654585838317871
time gen tails  0.05368995666503906
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09137487411499023

in edges time spent  0.3722047805786133
local to global src and eids time spent  0.5550730228424072
time gen tails  0.0857694149017334
res  length 2
block collection to dataloader spend  7.3909759521484375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11052513122558594  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.874878406524658  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.873595714569092  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.1123661994934082  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.014348030090332  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.02008581161499  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12365245819091797  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0596331357955933
pure train time :  0.43138647079467773
train time :  0.5887088775634766
end to end time :  4.0147013664245605
connection check time:  1.8667125701904297
block generation time  0.9808533191680908
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00041794776916503906
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014159440994262695
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.503018856048584
len local_batched_seeds_list  2
partition total batch output list spend :  0.5887277126312256
self.buckets_partition() spend  sec:  0.5172109603881836
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0558011531829834

in edges time spent  0.15584921836853027
local to global src and eids time spent  0.2687056064605713
time gen tails  0.05381917953491211
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08703827857971191

in edges time spent  0.37413835525512695
local to global src and eids time spent  0.5579228401184082
time gen tails  0.08235621452331543
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11040353775024414  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.875409603118896  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.874200820922852  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.1130976676940918  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.047935009002686  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.053672790527344  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12398195266723633  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0587403774261475
pure train time :  0.43791866302490234
train time :  0.5952541828155518
end to end time :  4.061444997787476
connection check time:  1.8734748363494873
block generation time  0.9865262508392334
Run 00 | Epoch 00175 | Loss 1.0587 | Test 0.6271
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004832744598388672
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013905048370361328
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5412917137145996
len local_batched_seeds_list  2
partition total batch output list spend :  0.6266827583312988
self.buckets_partition() spend  sec:  0.5552361011505127
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05573558807373047

in edges time spent  0.1557331085205078
local to global src and eids time spent  0.26772308349609375
time gen tails  0.05396008491516113
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08979916572570801

in edges time spent  0.37111711502075195
local to global src and eids time spent  0.5587294101715088
time gen tails  0.0825803279876709
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11078548431396484  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.87152910232544  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.869951725006104  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11238336563110352  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.031937599182129  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.037675380706787  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12340259552001953  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0596634149551392
pure train time :  0.43735313415527344
train time :  0.6116995811462402
end to end time :  4.126683235168457
connection check time:  1.87241530418396
block generation time  0.9936034679412842
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00045871734619140625
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014086723327636719
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4049677848815918
len local_batched_seeds_list  2
partition total batch output list spend :  0.49103546142578125
self.buckets_partition() spend  sec:  0.41908955574035645
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.0542759895324707

in edges time spent  0.15465855598449707
local to global src and eids time spent  0.267195463180542
time gen tails  0.0539393424987793
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0937504768371582

in edges time spent  0.3757967948913574
local to global src and eids time spent  0.5631053447723389
time gen tails  0.08276867866516113
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11142921447753906  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.87328815460205  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.872013092041016  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11235570907592773  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.01118278503418  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.017117023468018  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12374114990234375  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.054936170578003
pure train time :  0.438518762588501
train time :  0.5992617607116699
end to end time :  3.97328519821167
connection check time:  1.8831119537353516
block generation time  0.9828095436096191
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004749298095703125
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014141321182250977
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4853692054748535
len local_batched_seeds_list  2
partition total batch output list spend :  0.5710787773132324
self.buckets_partition() spend  sec:  0.49954652786254883
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.055197954177856445

in edges time spent  0.15468525886535645
local to global src and eids time spent  0.267042875289917
time gen tails  0.05393576622009277
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09225726127624512

in edges time spent  0.3743472099304199
local to global src and eids time spent  0.5549430847167969
time gen tails  0.08234739303588867
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11104917526245117  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.864065170288086  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.862410068511963  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11239099502563477  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.030488967895508  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.036226749420166  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12367534637451172  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0565060377120972
pure train time :  0.42656946182250977
train time :  0.5837979316711426
end to end time :  4.0201544761657715
connection check time:  1.871964454650879
block generation time  0.9791867733001709
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004725456237792969
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014239788055419922
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.48744654655456543
len local_batched_seeds_list  2
partition total batch output list spend :  0.5734841823577881
self.buckets_partition() spend  sec:  0.5018010139465332
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05441164970397949

in edges time spent  0.15574264526367188
local to global src and eids time spent  0.2644805908203125
time gen tails  0.05295920372009277
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09160208702087402

in edges time spent  0.36676931381225586
local to global src and eids time spent  0.5453050136566162
time gen tails  0.08050370216369629
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11054468154907227  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.867665767669678  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.86629581451416  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11247014999389648  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.044923305511475  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.050661087036133  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.1238107681274414  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0568737983703613
pure train time :  0.4382448196411133
train time :  0.6019127368927002
end to end time :  3.9844698905944824
connection check time:  1.8393363952636719
block generation time  0.9522027969360352
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004858970642089844
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014206409454345703
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4814784526824951
len local_batched_seeds_list  2
partition total batch output list spend :  0.5665252208709717
self.buckets_partition() spend  sec:  0.49572300910949707
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05328202247619629

in edges time spent  0.16165924072265625
local to global src and eids time spent  0.26820826530456543
time gen tails  0.05254244804382324
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08893036842346191

in edges time spent  0.35982418060302734
local to global src and eids time spent  0.5361402034759521
time gen tails  0.08399271965026855
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11114120483398438  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.874703884124756  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.873285293579102  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11292409896850586  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.004807472229004  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.010545253753662  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.1244039535522461  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0513739585876465
pure train time :  0.438779354095459
train time :  0.6016192436218262
end to end time :  3.960808515548706
connection check time:  1.8314952850341797
block generation time  0.947955846786499
Run 00 | Epoch 00180 | Loss 1.0514 | Test 0.6239
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00047898292541503906
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014645099639892578
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5063459873199463
len local_batched_seeds_list  2
partition total batch output list spend :  0.5915100574493408
self.buckets_partition() spend  sec:  0.5210278034210205
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05409669876098633

in edges time spent  0.1601104736328125
local to global src and eids time spent  0.27136826515197754
time gen tails  0.05324578285217285
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08907341957092285

in edges time spent  0.38401126861572266
local to global src and eids time spent  0.5530135631561279
time gen tails  0.0806281566619873
res  length 2
block collection to dataloader spend  7.152557373046875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11089849472045898  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.874143600463867  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.872462749481201  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11266469955444336  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.045475006103516  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.051212787628174  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12429428100585938  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0516854524612427
pure train time :  0.4397881031036377
train time :  0.6067330837249756
end to end time :  4.051588535308838
connection check time:  1.8729212284088135
block generation time  0.9665045738220215
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004627704620361328
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013982057571411133
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.47496700286865234
len local_batched_seeds_list  2
partition total batch output list spend :  0.5599772930145264
self.buckets_partition() spend  sec:  0.48899340629577637
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05381155014038086

in edges time spent  0.1540372371673584
local to global src and eids time spent  0.26935577392578125
time gen tails  0.05283498764038086
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08927774429321289

in edges time spent  0.3800685405731201
local to global src and eids time spent  0.5518331527709961
time gen tails  0.08104133605957031
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11130475997924805  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.864766120910645  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.86265516281128  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.1130976676940918  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.047658920288086  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.053396701812744  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.1249380111694336  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0498732328414917
pure train time :  0.43088507652282715
train time :  0.588737964630127
end to end time :  3.969282865524292
connection check time:  1.8591630458831787
block generation time  0.9469654560089111
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.00046634674072265625
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014219284057617188
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4750790596008301
len local_batched_seeds_list  2
partition total batch output list spend :  0.5609567165374756
self.buckets_partition() spend  sec:  0.48934030532836914
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.053843021392822266

in edges time spent  0.15132880210876465
local to global src and eids time spent  0.2592489719390869
time gen tails  0.05288386344909668
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09245872497558594

in edges time spent  0.3750433921813965
local to global src and eids time spent  0.5484094619750977
time gen tails  0.08106708526611328
res  length 2
block collection to dataloader spend  7.62939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11179494857788086  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.87427282333374  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.871871948242188  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.1128544807434082  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.035638809204102  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.04137659072876  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12359857559204102  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0507303476333618
pure train time :  0.4275825023651123
train time :  0.5850396156311035
end to end time :  3.946323871612549
connection check time:  1.841874599456787
block generation time  0.9458291530609131
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004553794860839844
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013738870620727539
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4999570846557617
len local_batched_seeds_list  2
partition total batch output list spend :  0.5847954750061035
self.buckets_partition() spend  sec:  0.5138125419616699
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.055701494216918945

in edges time spent  0.15435504913330078
local to global src and eids time spent  0.26461172103881836
time gen tails  0.05326652526855469
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08885788917541504

in edges time spent  0.3810141086578369
local to global src and eids time spent  0.5508971214294434
time gen tails  0.08073115348815918
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11014413833618164  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.867098331451416  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.866135597229004  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11329460144042969  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.051330089569092  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.05706787109375  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12464761734008789  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0513343811035156
pure train time :  0.438706636428833
train time :  0.59975266456604
end to end time :  4.006501913070679
connection check time:  1.8578815460205078
block generation time  0.9472358226776123
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004892349243164062
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013834238052368164
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.4817821979522705
len local_batched_seeds_list  2
partition total batch output list spend :  0.5661678314208984
self.buckets_partition() spend  sec:  0.495650053024292
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05315661430358887

in edges time spent  0.15033769607543945
local to global src and eids time spent  0.2603490352630615
time gen tails  0.05296921730041504
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0891575813293457

in edges time spent  0.3759932518005371
local to global src and eids time spent  0.545851469039917
time gen tails  0.08065676689147949
res  length 2
block collection to dataloader spend  7.867813110351562e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11164236068725586  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.873781204223633  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.871557712554932  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11260986328125  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.013165950775146  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.019100189208984  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12376832962036133  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0473904609680176
pure train time :  0.43773674964904785
train time :  0.5934023857116699
end to end time :  3.9577372074127197
connection check time:  1.834974765777588
block generation time  0.9462404251098633
Run 00 | Epoch 00185 | Loss 1.0474 | Test 0.6279
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004451274871826172
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.015484333038330078
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5302951335906982
len local_batched_seeds_list  2
partition total batch output list spend :  0.6173427104949951
self.buckets_partition() spend  sec:  0.5458171367645264
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05453991889953613

in edges time spent  0.1639399528503418
local to global src and eids time spent  0.2745802402496338
time gen tails  0.05460309982299805
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09188985824584961

in edges time spent  0.38451576232910156
local to global src and eids time spent  0.5641250610351562
time gen tails  0.0835268497467041
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11059904098510742  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.875364780426025  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.873944282531738  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11256933212280273  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.028329849243164  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.034067630767822  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12378215789794922  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.046749234199524
pure train time :  0.4414939880371094
train time :  0.6150650978088379
end to end time :  4.148611068725586
connection check time:  1.9106552600860596
block generation time  0.9837472438812256
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004737377166748047
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014115095138549805
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.5056817531585693
len local_batched_seeds_list  2
partition total batch output list spend :  0.5918757915496826
self.buckets_partition() spend  sec:  0.5198321342468262
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05374288558959961

in edges time spent  0.1597456932067871
local to global src and eids time spent  0.27051854133605957
time gen tails  0.05366086959838867
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.08619236946105957

in edges time spent  0.38771891593933105
local to global src and eids time spent  0.5638041496276855
time gen tails  0.08301234245300293
res  length 2
block collection to dataloader spend  8.106231689453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11118555068969727  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.86851978302002  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.867054462432861  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11398839950561523  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.045857906341553  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.051595687866211  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12504863739013672  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.046105146408081
pure train time :  0.4401252269744873
train time :  0.6032605171203613
end to end time :  4.101216077804565
connection check time:  1.8977875709533691
block generation time  0.9861102104187012
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004703998565673828
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013806343078613281
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.40436601638793945
len local_batched_seeds_list  2
partition total batch output list spend :  0.48905110359191895
self.buckets_partition() spend  sec:  0.4182119369506836
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.054175376892089844

in edges time spent  0.1548442840576172
local to global src and eids time spent  0.26665687561035156
time gen tails  0.05387282371520996
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.09200382232666016

in edges time spent  0.3762631416320801
local to global src and eids time spent  0.5556409358978271
time gen tails  0.0827324390411377
res  length 2
block collection to dataloader spend  8.58306884765625e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11134481430053711  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.87023401260376  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.86828327178955  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11241531372070312  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.012100219726562  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.01783800125122  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12345457077026367  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0427289009094238
pure train time :  0.4388697147369385
train time :  0.5983436107635498
end to end time :  3.955328941345215
connection check time:  1.8735668659210205
block generation time  0.9803860187530518
generate_dataloader_bucket_block=======
len(bkt)  13428
len(bkt)  11706
len(bkt)  9277
len(bkt)  7320
len(bkt)  6222
len(bkt)  4868
len(bkt)  4045
len(bkt)  3472
len(bkt)  2976
len(bkt)  2599
len(bkt)  2203
len(bkt)  1937
len(bkt)  1656
len(bkt)  1434
len(bkt)  1289
len(bkt)  1111
len(bkt)  1030
len(bkt)  948
len(bkt)  836
len(bkt)  807
len(bkt)  717
len(bkt)  556
len(bkt)  519
len(bkt)  525
len(bkt)  9460
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
type of fanout_dst_nids  <class 'torch.Tensor'>
self.K  2
the grouping_fanout_arxiv called successfully
capacity  6240
 
sorted_dict  {5: 618, 4: 617, 6: 609, 7: 605, 3: 602, 8: 591, 9: 587, 2: 586, 11: 560, 10: 557, 1: 545, 12: 530, 13: 518, 14: 507, 0: 480, 16: 480, 15: 476, 17: 464, 18: 457, 19: 449, 20: 434, 22: 400, 23: 396, 21: 394}

weights after sort [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
res_tmp  [609 605 602 591 587 586 560 545 530 518 507]

remove bucket_id:  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13]
original bucket_id :,  [6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14]
remove weights:  [609 605 602 591 587 586 560 545 530 518 507], 		------------sum 6240

before remove weights,  [618, 617, 609, 605, 602, 591, 587, 586, 560, 557, 545, 530, 518, 507, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
after remove pre pack weights,  [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]
G_BUCKET_ID_list [[6, 7, 3, 8, 9, 2, 11, 1, 12, 13, 14], [5, 4, 10, 0, 16, 15, 17, 18, 19, 20, 22, 23, 21]]
Groups_mem_list  [[609, 605, 602, 591, 587, 586, 560, 545, 530, 518, 507], [618, 617, 557, 480, 480, 476, 464, 457, 449, 434, 400, 396, 394]]
G_BUCKET_ID_list length 2
len(g_bucket_nids_list)  2
len(local_split_batches_nid_list)  2
current group_mem  6.24538265003302
current group_mem  6.226616458349287
batches output list generation spend  0.0004439353942871094
self.weights_list  [0.5766485963426837, 0.42335140365731627]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014168262481689453
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.48319530487060547
len local_batched_seeds_list  2
partition total batch output list spend :  0.5688173770904541
self.buckets_partition() spend  sec:  0.49747276306152344
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  0.05474734306335449

in edges time spent  0.15505480766296387
local to global src and eids time spent  0.21746277809143066
time gen tails  0.04031181335449219
res  length 2
layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  0.0903785228729248

in edges time spent  0.3713796138763428
local to global src and eids time spent  0.5555498600006104
time gen tails  0.08283805847167969
res  length 2
block collection to dataloader spend  9.059906005859375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11052846908569336  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.864723205566406  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.863416194915771  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.11259222030639648  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.0483078956604  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 12.054045677185059  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 23.490234375 GB
    Memory Allocated: 0.12382221221923828  GigaBytes
Max Memory Allocated: 13.349260330200195  GigaBytes

----------------------------------------------------------pseudo_mini_loss sum 1.0445556640625
pure train time :  0.43448710441589355
train time :  0.5903794765472412
end to end time :  3.963587999343872
connection check time:  1.8045315742492676
block generation time  0.9809048175811768
end to end time  4.068965196609497
Total (block generation + training)time/epoch 4.068965196609497
pure train time per /epoch  [0.9373157024383545, 0.4364163875579834, 0.43570375442504883, 0.4412200450897217, 0.42919111251831055, 0.4404599666595459, 0.4369010925292969, 0.4342215061187744, 0.4364759922027588, 0.4342992305755615, 0.446483850479126, 0.43598151206970215, 0.43492746353149414, 0.4384584426879883, 0.43987369537353516, 0.423492431640625, 0.43236517906188965, 0.4383053779602051, 0.43100738525390625, 0.4402134418487549, 0.4338340759277344, 0.43392229080200195, 0.4381732940673828, 0.4355337619781494, 0.43029260635375977, 0.43430638313293457, 0.43373632431030273, 0.43839263916015625, 0.4380686283111572, 0.4269835948944092, 0.4366927146911621, 0.43580079078674316, 0.42649006843566895, 0.438995361328125, 0.43501949310302734, 0.4292004108428955, 0.4303121566772461, 0.43883371353149414, 0.4350442886352539, 0.4375627040863037, 0.4353947639465332, 0.4353058338165283, 0.436509370803833, 0.4309697151184082, 0.4273221492767334, 0.43912720680236816, 0.44075703620910645, 0.4402034282684326, 0.4384012222290039, 0.43866634368896484, 0.4406001567840576, 0.42919445037841797, 0.4366331100463867, 0.4395608901977539, 0.4343140125274658, 0.43646836280822754, 0.43640995025634766, 0.43758678436279297, 0.43111586570739746, 0.4368133544921875, 0.42768096923828125, 0.43944764137268066, 0.43975830078125, 0.4390227794647217, 0.4408588409423828, 0.4322049617767334, 0.4383361339569092, 0.42934274673461914, 0.436312198638916, 0.438617467880249, 0.42767786979675293, 0.43032288551330566, 0.43203186988830566, 0.43749260902404785, 0.4343574047088623, 0.42666196823120117, 0.4381837844848633, 0.4375779628753662, 0.42914843559265137, 0.42647624015808105, 0.42717981338500977, 0.42657899856567383, 0.43604063987731934, 0.4385874271392822, 0.4379305839538574, 0.4316730499267578, 0.43995237350463867, 0.4385654926300049, 0.4301426410675049, 0.42871809005737305, 0.43752431869506836, 0.43671512603759766, 0.44046640396118164, 0.43456315994262695, 0.43544840812683105, 0.43817973136901855, 0.4405229091644287, 0.43575239181518555, 0.4402177333831787, 0.4270472526550293, 0.43589305877685547, 0.44034647941589355, 0.44020724296569824, 0.4358246326446533, 0.43259358406066895, 0.4383664131164551, 0.4268615245819092, 0.43639421463012695, 0.4376683235168457, 0.4282529354095459, 0.43404722213745117, 0.4309275150299072, 0.4409339427947998, 0.43887925148010254, 0.42682480812072754, 0.43593406677246094, 0.4342684745788574, 0.4356100559234619, 0.4363083839416504, 0.4443845748901367, 0.42801332473754883, 0.4320368766784668, 0.43310117721557617, 0.4380190372467041, 0.43907880783081055, 0.4389824867248535, 0.43488264083862305, 0.43238258361816406, 0.4313521385192871, 0.442734956741333, 0.4353630542755127, 0.4327833652496338, 0.4430885314941406, 0.44585227966308594, 0.43894052505493164, 0.44100022315979004, 0.44467735290527344, 0.44095563888549805, 0.43759989738464355, 0.4351961612701416, 0.4353961944580078, 0.4396243095397949, 0.4383842945098877, 0.43235278129577637, 0.4383809566497803, 0.4384753704071045, 0.44156479835510254, 0.4398164749145508, 0.4293978214263916, 0.4376811981201172, 0.4381248950958252, 0.4400806427001953, 0.4407651424407959, 0.43976640701293945, 0.4383656978607178, 0.43793249130249023, 0.4291222095489502, 0.43836498260498047, 0.4362037181854248, 0.4304947853088379, 0.43819499015808105, 0.4410064220428467, 0.43804502487182617, 0.43602776527404785, 0.43799638748168945, 0.4383852481842041, 0.43996238708496094, 0.43938326835632324, 0.4385867118835449, 0.43848299980163574, 0.4359283447265625, 0.42705273628234863, 0.43436193466186523, 0.43891263008117676, 0.43138647079467773, 0.43791866302490234, 0.43735313415527344, 0.438518762588501, 0.42656946182250977, 0.4382448196411133, 0.438779354095459, 0.4397881031036377, 0.43088507652282715, 0.4275825023651123, 0.438706636428833, 0.43773674964904785, 0.4414939880371094, 0.4401252269744873, 0.4388697147369385, 0.43448710441589355]
pure train time average  0.435818076133728
input num  average  312681.3
