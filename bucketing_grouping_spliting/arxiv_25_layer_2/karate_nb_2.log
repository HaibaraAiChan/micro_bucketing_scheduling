main start at this time 1698364571.0466747
-----------------------------------------before load data 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

karate data
{}
{}
Graph(num_nodes=7, num_edges=14,
      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'feat': Scheme(shape=(4,), dtype=torch.float32)}
      edata_schemes={})
#nodes: 7
#edges: 14
#classes: 2
success----------------------------------------
4
2
1
# Nodes: 7
# Edges: 14
# Train: 4
# Val: 2
# Test: 1
# Classes: 2

----------------------------------------start of run function 
 Nvidia-smi: 0.166015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

main fucntion generate_dataloader_bucket_block=======
get_in_degree_bucketing src global nid  tensor([2, 0, 1, 3, 5, 4])
get_in_degree_bucketing dst global nid  tensor([2, 0, 1, 3])
get_in_degree_bucketing corresponding in degs tensor([2, 1, 3, 3])
len(bkt)  1
local bkt nids  tensor([1])
len(bkt)  1
local bkt nids  tensor([0])
len(bkt)  2
local bkt nids  tensor([2, 3])
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
partitioner **** batches_nid_list  [tensor([2]), tensor([3])]
 the number of batches:  2
the ratio of the output nids to be processed:  0.5
K_Hop_neighbor: weights list of these split output nids:  [0.25, 0.25]
generate K hop neighbors layer id (from bottom to top)),  0
gen K hop neighbors check_connections_block*********************************
len of local_batched_nodes_list  2

step  0
len(mini_batch_src_global)  3
len(r_)  3
remove values openmp spend  1.8596649169921875e-05
one layer mini_batch_src_local collection stoped 
generate_one_hop_neighbors global srcnid  tensor([1, 0, 2, 5])
generate_one_hop_neighbors global dstnid  tensor([1])
the bottom layer global src list  [tensor([1, 0, 2, 5])]
the bottom layer global dst list  [tensor([1])]
generate K hop neighbors layer id (from bottom to top)),  1
layer  1
gen k hop neighbor num of batch  1
gen K hop neighbors check_connections_block*********************************
len of local_batched_nodes_list  1

step  0
len(mini_batch_src_global)  4
len(r_)  2
remove values openmp spend  5.4836273193359375e-06
one layer mini_batch_src_local collection stoped 
generate_one_hop_neighbors global srcnid  tensor([0, 2, 1, 4, 3, 5])
generate_one_hop_neighbors global dstnid  tensor([0, 2, 1, 4])
 the layer 1 global src list [tensor([0, 2, 1, 4, 3, 5])]
 the layer 1 global dst list [tensor([0, 2, 1, 4])]
generate k hop neighbors  [tensor([0, 2, 1, 4, 3, 5])]
generate_K_hop_neighbors time  0.0015072822570800781
src_list  [tensor([0, 2, 1, 4, 3, 5])]
self.weights_list  [0.5, 0.5]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0016312599182128906
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.002162933349609375
len local_batched_seeds_list  2
partition total batch output list spend :  0.004302024841308594
self.buckets_partition() spend  sec:  0.003808736801147461
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  2.2649765014648438e-05

in edges time spent  0.002853870391845703
local to global src and eids time spent  8.7738037109375e-05
time gen tails  4.172325134277344e-05
res  length 2

block_gen_time in "generate_blocks_for_one_layer_block"  0.00916290283203125

layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  1.2636184692382812e-05

in edges time spent  0.004206657409667969
local to global src and eids time spent  8.821487426757812e-05
time gen tails  1.0013580322265625e-05
res  length 2

block_gen_time in "generate_blocks_for_one_layer_block"  0.003156900405883789

block collection to dataloader spend  6.9141387939453125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.462890625 GB
    Memory Allocated: 0.03133106231689453  GigaBytes
Max Memory Allocated: 0.03133106231689453  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.552734375 GB
    Memory Allocated: 0.031641483306884766  GigaBytes
Max Memory Allocated: 0.03167533874511719  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 1.552734375 GB
    Memory Allocated: 0.031642913818359375  GigaBytes
Max Memory Allocated: 0.03167533874511719  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.623046875 GB
    Memory Allocated: 0.06266450881958008  GigaBytes
Max Memory Allocated: 0.09408807754516602  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.623046875 GB
    Memory Allocated: 0.06302785873413086  GigaBytes
Max Memory Allocated: 0.09408807754516602  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 1.623046875 GB
    Memory Allocated: 0.06302881240844727  GigaBytes
Max Memory Allocated: 0.09408807754516602  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 1.701171875 GB
    Memory Allocated: 0.12532520294189453  GigaBytes
Max Memory Allocated: 0.17220020294189453  GigaBytes

epoch  0
----------------------------------------------------------pseudo_mini_loss sum 0.7422652840614319
pure train time :  0.45386743545532227
train time :  0.9913070201873779
end to end time :  1.0161397457122803
connection check time:  0.007523298263549805
block generation time  0.012319803237915039
main fucntion generate_dataloader_bucket_block=======
get_in_degree_bucketing src global nid  tensor([1, 3, 2, 0, 5, 4])
get_in_degree_bucketing dst global nid  tensor([1, 3, 2, 0])
get_in_degree_bucketing corresponding in degs tensor([3, 3, 2, 1])
len(bkt)  1
local bkt nids  tensor([3])
len(bkt)  1
local bkt nids  tensor([2])
len(bkt)  2
local bkt nids  tensor([0, 1])
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
partitioner **** batches_nid_list  [tensor([0]), tensor([1])]
 the number of batches:  2
the ratio of the output nids to be processed:  0.5
K_Hop_neighbor: weights list of these split output nids:  [0.25, 0.25]
generate K hop neighbors layer id (from bottom to top)),  0
gen K hop neighbors check_connections_block*********************************
len of local_batched_nodes_list  2

step  0
len(mini_batch_src_global)  3
len(r_)  3
remove values openmp spend  9.059906005859375e-06
one layer mini_batch_src_local collection stoped 
generate_one_hop_neighbors global srcnid  tensor([1, 0, 2, 5])
generate_one_hop_neighbors global dstnid  tensor([1])
the bottom layer global src list  [tensor([1, 0, 2, 5])]
the bottom layer global dst list  [tensor([1])]
generate K hop neighbors layer id (from bottom to top)),  1
layer  1
gen k hop neighbor num of batch  1
gen K hop neighbors check_connections_block*********************************
len of local_batched_nodes_list  1

step  0
len(mini_batch_src_global)  6
len(r_)  2
remove values openmp spend  7.867813110351562e-06
one layer mini_batch_src_local collection stoped 
generate_one_hop_neighbors global srcnid  tensor([3, 1, 2, 4, 0, 5])
generate_one_hop_neighbors global dstnid  tensor([3, 1, 2, 4])
 the layer 1 global src list [tensor([3, 1, 2, 4, 0, 5])]
 the layer 1 global dst list [tensor([3, 1, 2, 4])]
generate k hop neighbors  [tensor([3, 1, 2, 4, 0, 5])]
generate_K_hop_neighbors time  0.001828908920288086
src_list  [tensor([3, 1, 2, 4, 0, 5])]
self.weights_list  [0.5, 0.5]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0010371208190917969
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.0022373199462890625
len local_batched_seeds_list  2
partition total batch output list spend :  0.0035657882690429688
self.buckets_partition() spend  sec:  0.0032842159271240234
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  1.621246337890625e-05

in edges time spent  0.0029168128967285156
local to global src and eids time spent  0.00011014938354492188
time gen tails  1.430511474609375e-05
res  length 2

block_gen_time in "generate_blocks_for_one_layer_block"  0.0038862228393554688

layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  1.2874603271484375e-05

in edges time spent  0.003431081771850586
local to global src and eids time spent  9.250640869140625e-05
time gen tails  1.3113021850585938e-05
res  length 2

block_gen_time in "generate_blocks_for_one_layer_block"  0.0033833980560302734

block collection to dataloader spend  4.291534423828125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.701171875 GB
    Memory Allocated: 0.1253204345703125  GigaBytes
Max Memory Allocated: 0.17220020294189453  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.701171875 GB
    Memory Allocated: 0.12563037872314453  GigaBytes
Max Memory Allocated: 0.17220020294189453  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 1.701171875 GB
    Memory Allocated: 0.1256275177001953  GigaBytes
Max Memory Allocated: 0.17220020294189453  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.1253209114074707  GigaBytes
Max Memory Allocated: 0.18805742263793945  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.12568426132202148  GigaBytes
Max Memory Allocated: 0.18805742263793945  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.1256852149963379  GigaBytes
Max Memory Allocated: 0.18805742263793945  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.12532520294189453  GigaBytes
Max Memory Allocated: 0.18811511993408203  GigaBytes

epoch  1
----------------------------------------------------------pseudo_mini_loss sum 0.6633391380310059
pure train time :  0.04081439971923828
train time :  0.042249441146850586
end to end time :  0.06218838691711426
connection check time:  0.006882190704345703
block generation time  0.007269620895385742
main fucntion generate_dataloader_bucket_block=======
get_in_degree_bucketing src global nid  tensor([1, 2, 3, 0, 5, 4])
get_in_degree_bucketing dst global nid  tensor([1, 2, 3, 0])
get_in_degree_bucketing corresponding in degs tensor([3, 2, 3, 1])
len(bkt)  1
local bkt nids  tensor([3])
len(bkt)  1
local bkt nids  tensor([1])
len(bkt)  2
local bkt nids  tensor([0, 2])
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
partitioner **** batches_nid_list  [tensor([0]), tensor([2])]
 the number of batches:  2
the ratio of the output nids to be processed:  0.5
K_Hop_neighbor: weights list of these split output nids:  [0.25, 0.25]
generate K hop neighbors layer id (from bottom to top)),  0
gen K hop neighbors check_connections_block*********************************
len of local_batched_nodes_list  2

step  0
len(mini_batch_src_global)  3
len(r_)  3
remove values openmp spend  1.0013580322265625e-05
one layer mini_batch_src_local collection stoped 
generate_one_hop_neighbors global srcnid  tensor([1, 0, 2, 5])
generate_one_hop_neighbors global dstnid  tensor([1])
the bottom layer global src list  [tensor([1, 0, 2, 5])]
the bottom layer global dst list  [tensor([1])]
generate K hop neighbors layer id (from bottom to top)),  1
layer  1
gen k hop neighbor num of batch  1
gen K hop neighbors check_connections_block*********************************
len of local_batched_nodes_list  1

step  0
len(mini_batch_src_global)  5
len(r_)  2
remove values openmp spend  1.0251998901367188e-05
one layer mini_batch_src_local collection stoped 
generate_one_hop_neighbors global srcnid  tensor([2, 1, 3, 4, 5, 0])
generate_one_hop_neighbors global dstnid  tensor([2, 1, 3, 4])
 the layer 1 global src list [tensor([2, 1, 3, 4, 5, 0])]
 the layer 1 global dst list [tensor([2, 1, 3, 4])]
generate k hop neighbors  [tensor([2, 1, 3, 4, 5, 0])]
generate_K_hop_neighbors time  0.002622842788696289
src_list  [tensor([2, 1, 3, 4, 5, 0])]
self.weights_list  [0.5, 0.5]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.001230478286743164
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.0031676292419433594
len local_batched_seeds_list  2
partition total batch output list spend :  0.004868745803833008
self.buckets_partition() spend  sec:  0.00441431999206543
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  2.4080276489257812e-05

in edges time spent  0.0035750865936279297
local to global src and eids time spent  0.0001819133758544922
time gen tails  2.1219253540039062e-05
res  length 2

block_gen_time in "generate_blocks_for_one_layer_block"  0.004331111907958984

layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  1.6450881958007812e-05

in edges time spent  0.003201007843017578
local to global src and eids time spent  0.00011849403381347656
time gen tails  1.52587890625e-05
res  length 2

block_gen_time in "generate_blocks_for_one_layer_block"  0.0038290023803710938

block collection to dataloader spend  4.291534423828125e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.1253204345703125  GigaBytes
Max Memory Allocated: 0.18811511993408203  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.12563037872314453  GigaBytes
Max Memory Allocated: 0.18811511993408203  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.1256275177001953  GigaBytes
Max Memory Allocated: 0.18811511993408203  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.1253209114074707  GigaBytes
Max Memory Allocated: 0.18811511993408203  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.12568426132202148  GigaBytes
Max Memory Allocated: 0.18811511993408203  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.1256852149963379  GigaBytes
Max Memory Allocated: 0.18811511993408203  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.12532520294189453  GigaBytes
Max Memory Allocated: 0.18811511993408203  GigaBytes

epoch  2
----------------------------------------------------------pseudo_mini_loss sum 0.6576522588729858
pure train time :  0.041082143783569336
train time :  0.042568206787109375
end to end time :  0.06587004661560059
connection check time:  0.0074310302734375
block generation time  0.008160114288330078
main fucntion generate_dataloader_bucket_block=======
get_in_degree_bucketing src global nid  tensor([0, 3, 2, 1, 4, 5])
get_in_degree_bucketing dst global nid  tensor([0, 3, 2, 1])
get_in_degree_bucketing corresponding in degs tensor([1, 3, 2, 3])
len(bkt)  1
local bkt nids  tensor([0])
len(bkt)  1
local bkt nids  tensor([2])
len(bkt)  2
local bkt nids  tensor([1, 3])
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
partitioner **** batches_nid_list  [tensor([1]), tensor([3])]
 the number of batches:  2
the ratio of the output nids to be processed:  0.5
K_Hop_neighbor: weights list of these split output nids:  [0.25, 0.25]
generate K hop neighbors layer id (from bottom to top)),  0
gen K hop neighbors check_connections_block*********************************
len of local_batched_nodes_list  2

step  0
len(mini_batch_src_global)  3
len(r_)  3
remove values openmp spend  9.059906005859375e-06
one layer mini_batch_src_local collection stoped 
generate_one_hop_neighbors global srcnid  tensor([3, 1, 2, 4])
generate_one_hop_neighbors global dstnid  tensor([3])
the bottom layer global src list  [tensor([3, 1, 2, 4])]
the bottom layer global dst list  [tensor([3])]
generate K hop neighbors layer id (from bottom to top)),  1
layer  1
gen k hop neighbor num of batch  1
gen K hop neighbors check_connections_block*********************************
len of local_batched_nodes_list  1

step  0
len(mini_batch_src_global)  4
len(r_)  1
remove values openmp spend  1.1682510375976562e-05
one layer mini_batch_src_local collection stoped 
generate_one_hop_neighbors global srcnid  tensor([1, 3, 2, 4, 0])
generate_one_hop_neighbors global dstnid  tensor([1, 3, 2, 4])
 the layer 1 global src list [tensor([1, 3, 2, 4, 0])]
 the layer 1 global dst list [tensor([1, 3, 2, 4])]
generate k hop neighbors  [tensor([1, 3, 2, 4, 0])]
generate_K_hop_neighbors time  0.0031015872955322266
src_list  [tensor([1, 3, 2, 4, 0])]
self.weights_list  [0.5, 0.5]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0017066001892089844
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.003742694854736328
len local_batched_seeds_list  2
partition total batch output list spend :  0.0057697296142578125
self.buckets_partition() spend  sec:  0.005460500717163086
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  1.621246337890625e-05

in edges time spent  0.003023862838745117
local to global src and eids time spent  0.00013065338134765625
time gen tails  1.1920928955078125e-05
res  length 2

block_gen_time in "generate_blocks_for_one_layer_block"  0.004232168197631836

layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  1.6927719116210938e-05

in edges time spent  0.0034813880920410156
local to global src and eids time spent  0.00011301040649414062
time gen tails  8.821487426757812e-06
res  length 2

block_gen_time in "generate_blocks_for_one_layer_block"  0.0032444000244140625

block collection to dataloader spend  4.5299530029296875e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.1253204345703125  GigaBytes
Max Memory Allocated: 0.18811511993408203  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.1256389617919922  GigaBytes
Max Memory Allocated: 0.18811511993408203  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.12563610076904297  GigaBytes
Max Memory Allocated: 0.18811511993408203  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.1253209114074707  GigaBytes
Max Memory Allocated: 0.18811511993408203  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.12569665908813477  GigaBytes
Max Memory Allocated: 0.18811511993408203  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.12569761276245117  GigaBytes
Max Memory Allocated: 0.18811511993408203  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.12532520294189453  GigaBytes
Max Memory Allocated: 0.1881237030029297  GigaBytes

epoch  3
----------------------------------------------------------pseudo_mini_loss sum 0.5355501174926758
pure train time :  0.0415339469909668
train time :  0.0429685115814209
end to end time :  0.06566214561462402
connection check time:  0.007025003433227539
block generation time  0.0074765682220458984
main fucntion generate_dataloader_bucket_block=======
get_in_degree_bucketing src global nid  tensor([3, 0, 2, 1, 4, 5])
get_in_degree_bucketing dst global nid  tensor([3, 0, 2, 1])
get_in_degree_bucketing corresponding in degs tensor([3, 1, 2, 3])
len(bkt)  1
local bkt nids  tensor([1])
len(bkt)  1
local bkt nids  tensor([2])
len(bkt)  2
local bkt nids  tensor([0, 3])
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
partitioner **** batches_nid_list  [tensor([0]), tensor([3])]
 the number of batches:  2
the ratio of the output nids to be processed:  0.5
K_Hop_neighbor: weights list of these split output nids:  [0.25, 0.25]
generate K hop neighbors layer id (from bottom to top)),  0
gen K hop neighbors check_connections_block*********************************
len of local_batched_nodes_list  2

step  0
len(mini_batch_src_global)  3
len(r_)  3
remove values openmp spend  9.059906005859375e-06
one layer mini_batch_src_local collection stoped 
generate_one_hop_neighbors global srcnid  tensor([3, 1, 2, 4])
generate_one_hop_neighbors global dstnid  tensor([3])
the bottom layer global src list  [tensor([3, 1, 2, 4])]
the bottom layer global dst list  [tensor([3])]
generate K hop neighbors layer id (from bottom to top)),  1
layer  1
gen k hop neighbor num of batch  1
gen K hop neighbors check_connections_block*********************************
len of local_batched_nodes_list  1

step  0
len(mini_batch_src_global)  4
len(r_)  1
remove values openmp spend  9.059906005859375e-06
one layer mini_batch_src_local collection stoped 
generate_one_hop_neighbors global srcnid  tensor([1, 0, 2, 4, 3])
generate_one_hop_neighbors global dstnid  tensor([1, 0, 2, 4])
 the layer 1 global src list [tensor([1, 0, 2, 4, 3])]
 the layer 1 global dst list [tensor([1, 0, 2, 4])]
generate k hop neighbors  [tensor([1, 0, 2, 4, 3])]
generate_K_hop_neighbors time  0.002772808074951172
src_list  [tensor([1, 0, 2, 4, 3])]
self.weights_list  [0.5, 0.5]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.002385854721069336
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.0035400390625
len local_batched_seeds_list  2
partition total batch output list spend :  0.006368398666381836
self.buckets_partition() spend  sec:  0.005940437316894531
layer  0
 the number of batches:  2
check_connections_block*********************************

the find indices time spent  2.288818359375e-05

in edges time spent  0.0035233497619628906
local to global src and eids time spent  0.00016570091247558594
time gen tails  1.621246337890625e-05
res  length 2

block_gen_time in "generate_blocks_for_one_layer_block"  0.005548715591430664

layer  1
num of batch  2
check_connections_block*********************************

the find indices time spent  1.621246337890625e-05

in edges time spent  0.0033097267150878906
local to global src and eids time spent  0.00012087821960449219
time gen tails  1.2159347534179688e-05
res  length 2

block_gen_time in "generate_blocks_for_one_layer_block"  0.0039730072021484375

block collection to dataloader spend  5.4836273193359375e-06
step  0
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.1253204345703125  GigaBytes
Max Memory Allocated: 0.1881237030029297  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.1256389617919922  GigaBytes
Max Memory Allocated: 0.1881237030029297  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.12563610076904297  GigaBytes
Max Memory Allocated: 0.1881237030029297  GigaBytes

step  1
----------------------------------------before batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.1253209114074707  GigaBytes
Max Memory Allocated: 0.1881237030029297  GigaBytes

----------------------------------------after batch_pred = model(blocks, batch_inputs)
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.12569665908813477  GigaBytes
Max Memory Allocated: 0.1881237030029297  GigaBytes

----------------------------------------after loss function
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.12569761276245117  GigaBytes
Max Memory Allocated: 0.1881237030029297  GigaBytes

----------------------------------------after optimizer
 Nvidia-smi: 1.716796875 GB
    Memory Allocated: 0.12532520294189453  GigaBytes
Max Memory Allocated: 0.1881237030029297  GigaBytes

epoch  4
----------------------------------------------------------pseudo_mini_loss sum 0.6078296899795532
pure train time :  0.043079376220703125
train time :  0.044385433197021484
end to end time :  0.07035374641418457
connection check time:  0.007452964782714844
block generation time  0.009521722793579102
end to end time  0.0779571533203125
